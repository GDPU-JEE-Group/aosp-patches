From c9b0a2b487332f5862d7cbcdfc993f7eaf424ce7 Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Wed, 4 Sep 2024 11:15:48 +0800
Subject: [PATCH] =?UTF-8?q?=E7=A9=BA=E6=8C=87=E9=92=88=E5=80=92=E6=98=AF?=
 =?UTF-8?q?=E7=9B=B8=E6=9C=BA=E5=B4=A9=E6=BA=83=E7=9A=84BUG?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 hardware/ntimespace/camera/v4l2_wrapper.cpp | 10 ++++++++++
 1 file changed, 10 insertions(+)

diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
index 4ef9235031..c11f8205d0 100644
--- a/hardware/ntimespace/camera/v4l2_wrapper.cpp
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -981,6 +981,16 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
         buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
       }
       last_dq_index = buffer.index;
+      if (!request_context){
+        HAL_LOGE("DequeueRequest failed, request_context is null");
+        ret = -EAGAIN;
+        goto Exit;
+      }
+      if (!request_context->request){
+        HAL_LOGE("DequeueRequest failed, request_context->request is null");
+        ret = -EAGAIN;
+        goto Exit;
+      }
       dump_data_index = request_context->request->frame_number;
       HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
         (uint32_t)request_context->request->output_buffers.size());
-- 
2.25.1

From 62e5148d1d3e83606b1c7f52d46ed1922775eef0 Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Tue, 3 Sep 2024 19:36:32 +0800
Subject: [PATCH] =?UTF-8?q?4=E7=A7=92=E6=89=93=E5=8D=B0=E4=B8=80=E6=AC=A1?=
 =?UTF-8?q?=E7=A9=BA=E6=95=B0=E6=8D=AE?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 hardware/ntimespace/camera/v4l2_wrapper.cpp | 11 ++---------
 1 file changed, 2 insertions(+), 9 deletions(-)

diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
index 4839edd423..4ef9235031 100644
--- a/hardware/ntimespace/camera/v4l2_wrapper.cpp
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -896,7 +896,6 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
 
   int ret = 0;
   int res = 0;
-
   if (!format_) {
     HAL_LOGV(
         "Format not set, so stream can't be on, "
@@ -904,14 +903,12 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
     ret = -EAGAIN;
     goto Exit;
   }
-
   if (!request)
   {
     HAL_LOGE("DequeueRequest failed, request is null");
     ret = -EAGAIN;
     goto Exit;
   }
-
   {
     v4l2_buffer buffer;
     memset(&buffer, 0, sizeof(buffer));
@@ -935,7 +932,7 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
                 else
                 {
                     frame_count++;
-                    if (5000 <= toMilliSeconds(timeNanos() - printfTimeNs)){
+                    if (4000 <= toMilliSeconds(timeNanos() - printfTimeNs)){//不能为5秒，因为上面usleep(5*1000);
                       HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d \n", strerror(errno), frame_count);
                       printfTimeNs = timeNanos();
                     }
@@ -964,7 +961,6 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
         goto Exit;
     }
     HAL_LOGD("VIDIOC_DQBUF got buffer index %d", buffer.index);
-
     {
       RequestContext* request_context = &buffers_[buffer.index];
 
@@ -984,7 +980,6 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
       {
         buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
       }
-
       last_dq_index = buffer.index;
       dump_data_index = request_context->request->frame_number;
       HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
@@ -992,7 +987,7 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
 
       // Perform the format conversion.
       arc::CachedFrame cached_frame;
-      uint32_t output_buffer_size = request_context->request->output_buffers.size();      
+      uint32_t output_buffer_size = request_context->request->output_buffers.size();     
       for(uint32_t i = 0; i < output_buffer_size; i++) {
           HAL_LOGV("-----------------------------------------------------------");
           HAL_LOGD("Process buffer[%d]", i);
@@ -1038,7 +1033,6 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
             ret = -EINVAL;
             goto Exit;
           }
-
           uint64_t time = timeNanos();
           if (request_context->camera_buffer->GetFourcc() == fourcc &&
             request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
@@ -1087,7 +1081,6 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
           }  
  
       }
-
       //EAGAIN we will not QBUF
       if (ret == -EAGAIN) {
         ret = 0;
-- 
2.25.1

From 42b32d4b191d06f4b0610a9c93bda69ad9a1f3ee Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Tue, 3 Sep 2024 19:25:39 +0800
Subject: [PATCH] =?UTF-8?q?5=E7=A7=92=E6=89=93=E5=8D=B0=E4=B8=80=E6=AC=A1?=
 =?UTF-8?q?=E7=A9=BA=E6=95=B0=E6=8D=AE?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 hardware/ntimespace/camera/v4l2_wrapper.cpp | 9 ++++++++-
 1 file changed, 8 insertions(+), 1 deletion(-)

diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
index 90709f5ebd..4839edd423 100644
--- a/hardware/ntimespace/camera/v4l2_wrapper.cpp
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -29,6 +29,8 @@
 #include "android-base/properties.h"
 #include "debug.h"
 
+
+
 namespace v4l2_camera_hal {
 
 using arc::V4L2FrameBuffer;
@@ -890,6 +892,8 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
   uint64_t convertTimeNs = 0;
   uint64_t memcpyTimeNs = 0;
 
+  static uint64_t printfTimeNs = timeNanos();
+
   int ret = 0;
   int res = 0;
 
@@ -931,7 +935,10 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
                 else
                 {
                     frame_count++;
-                    if (frame_count%100 == 0)HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    if (5000 <= toMilliSeconds(timeNanos() - printfTimeNs)){
+                      HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d \n", strerror(errno), frame_count);
+                      printfTimeNs = timeNanos();
+                    }
                     ret = -EAGAIN;
                     goto Exit;
                 }
-- 
2.25.1

From 1c822ced73620e7577675e3813f1d7d0e181217e Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Tue, 3 Sep 2024 14:09:53 +0800
Subject: [PATCH] =?UTF-8?q?=E5=A6=82=E6=9E=9C=E6=98=AF=E6=91=84=E5=83=8F?=
 =?UTF-8?q?=E5=A4=B4=E6=8E=A8=E9=80=81=E7=A9=BA=E6=95=B0=E6=8D=AE=E6=97=B6?=
 =?UTF-8?q?=E5=80=99=EF=BC=8CCPU=E8=BE=BE=E5=88=B040%=E5=B7=A6=E5=8F=B3?=
 =?UTF-8?q?=E7=9A=84BUG?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 hardware/ntimespace/camera/v4l2_wrapper.cpp | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
index f794a6b708..90709f5ebd 100644
--- a/hardware/ntimespace/camera/v4l2_wrapper.cpp
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -931,9 +931,9 @@ int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
                 else
                 {
                     frame_count++;
-                    HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    if (frame_count%100 == 0)HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
                     ret = -EAGAIN;
-                    //goto Exit;
+                    goto Exit;
                 }
             } else {
                 // Unexpected failure.
-- 
2.25.1

From 67405259d89896b93e224bad52a754812c7b9a7b Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Mon, 2 Sep 2024 18:14:07 +0800
Subject: [PATCH] =?UTF-8?q?=E7=9B=B8=E6=9C=BA=E5=90=8E=E5=8E=BB=E6=91=84?=
 =?UTF-8?q?=E5=83=8F=E5=A4=B4=E7=89=88=E6=9C=AC=E6=97=B6=E5=80=99=E7=94=A8?=
 =?UTF-8?q?=E8=B6=85=E6=97=B610=E7=A7=92=E6=9B=BF=E6=8D=A2=E6=AD=BB?=
 =?UTF-8?q?=E5=BE=AA=E7=8E=AF?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../camera/libcameraservice/CameraService.cpp      | 14 +++++++-------
 1 file changed, 7 insertions(+), 7 deletions(-)

diff --git a/frameworks/av/services/camera/libcameraservice/CameraService.cpp b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
index 6116c61936..0828db999a 100755
--- a/frameworks/av/services/camera/libcameraservice/CameraService.cpp
+++ b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
@@ -1432,13 +1432,11 @@ Status CameraService::connectHelper(const sp<CALLBACK>& cameraCb, const String8&
                     "Cannot open camera %s for \"%s\" (PID %d): Too many other clients connecting",
                     cameraId.string(), clientName8.string(), clientPid);
         }
-
         // Enforce client permissions and do basic sanity checks
         if(!(ret = validateConnectLocked(cameraId, clientName8,
                 /*inout*/clientUid, /*inout*/clientPid, /*out*/originalClientPid)).isOk()) {
             return ret;
         }
-
         // Check the shim parameters after acquiring lock, if they have already been updated and
         // we were doing a shim update, return immediately
         if (shimUpdateOnly) {
@@ -1447,7 +1445,6 @@ Status CameraService::connectHelper(const sp<CALLBACK>& cameraCb, const String8&
                 if (!cameraState->getShimParams().isEmpty()) return ret;
             }
         }
-
         status_t err;
 
         sp<BasicClient> clientTmp = nullptr;
@@ -1470,7 +1467,6 @@ Status CameraService::connectHelper(const sp<CALLBACK>& cameraCb, const String8&
                             strerror(-err), err, cameraId.string());
             }
         }
-
         if (clientTmp.get() != nullptr) {
             // Handle special case for API1 MediaRecorder where the existing client is returned
             device = static_cast<CLIENT*>(clientTmp.get());
@@ -1479,7 +1475,7 @@ Status CameraService::connectHelper(const sp<CALLBACK>& cameraCb, const String8&
 
         // give flashlight a chance to close devices if necessary.
         mFlashlight->prepareDeviceOpen(cameraId);
-
+        
         int facing = -1;
         int deviceVersion = getDeviceVersion(cameraId, /*out*/&facing);
         if (facing == -1) {
@@ -1943,9 +1939,13 @@ Status CameraService::supportsCameraApi(const String16& cameraId, int apiVersion
     }
 
     int deviceVersion = getDeviceVersion(id);
-    while(deviceVersion == -1){
+    int totalNum = 100;
+    //设置超时10秒，获取相机的版本，相机获取到版本才不会崩溃，所以这里是等待驱动启动后，才能获取版本
+    while(0 < totalNum && deviceVersion == -1){
         usleep(100000);
-        deviceVersion = getDeviceVersion(id);
+        deviceVersion = getDeviceVersion(id); 
+        ALOGV("%s: Camera id %s getDeviceVersion: totalNum: %d",__FUNCTION__, id.string(), totalNum);
+        --totalNum;
     }
     switch (deviceVersion) {
         case CAMERA_DEVICE_API_VERSION_1_0:
-- 
2.25.1

From 657d2adf59bda02e0b4b676c1b33a13eb170ca2d Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Fri, 23 Aug 2024 17:51:30 +0800
Subject: [PATCH] =?UTF-8?q?=E9=95=9C=E5=83=8F=E6=8F=90=E4=BA=A4=E6=91=84?=
 =?UTF-8?q?=E5=83=8F=E5=A4=B4=E4=BB=A3=E7=A0=81?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../rk3588/rk3588_docker/manifest.xml         |   10 +
 .../rk3588/rk3588_docker/rk3588_docker.mk     |    7 +
 .../rk3588/rk3588_docker_guozhen/manifest.xml |    9 +
 .../rk3588_docker_guozhen.mk                  |    7 +
 .../rk3588/rk3588_docker_inland/manifest.xml  |    9 +
 .../rk3588_docker_inland.mk                   |    7 +
 .../rk3588_docker_overseas/manifest.xml       |    9 +
 .../rk3588_docker_overseas.mk                 |    7 +
 device/rockchip/space-common/device_common.mk |    6 +
 .../camera/libcameraservice/CameraService.cpp |    4 +
 hardware/ntimespace/camera/Android.mk         |  178 +++
 hardware/ntimespace/camera/Android.mk-1       |  227 ++++
 hardware/ntimespace/camera/README.md          |  156 +++
 .../ntimespace/camera/arc/cached_frame.cpp    |  424 ++++++
 hardware/ntimespace/camera/arc/cached_frame.h |   97 ++
 hardware/ntimespace/camera/arc/common.h       |   37 +
 hardware/ntimespace/camera/arc/common_types.h |   55 +
 hardware/ntimespace/camera/arc/exif_utils.cpp |  512 ++++++++
 hardware/ntimespace/camera/arc/exif_utils.h   |  178 +++
 .../camera/arc/format_convert_test.cpp        |  248 ++++
 .../camera/arc/format_convert_test.h          |   23 +
 .../ntimespace/camera/arc/frame_buffer.cpp    |  379 ++++++
 hardware/ntimespace/camera/arc/frame_buffer.h |  268 ++++
 .../ntimespace/camera/arc/image_processor.cpp |  663 ++++++++++
 .../ntimespace/camera/arc/image_processor.h   |   47 +
 .../ntimespace/camera/arc/jpeg_compressor.cpp |  188 +++
 .../ntimespace/camera/arc/jpeg_compressor.h   |   73 ++
 hardware/ntimespace/camera/camera.cpp         |  643 ++++++++++
 hardware/ntimespace/camera/camera.h           |  151 +++
 hardware/ntimespace/camera/camera_init.rc     |    5 +
 hardware/ntimespace/camera/camera_init.sh     |   13 +
 .../ntimespace/camera/capture_request.cpp     |   54 +
 hardware/ntimespace/camera/capture_request.h  |   44 +
 hardware/ntimespace/camera/common.h           |   65 +
 hardware/ntimespace/camera/debug.cpp          |  316 +++++
 hardware/ntimespace/camera/debug.h            |   58 +
 hardware/ntimespace/camera/flash.cpp          |  340 +++++
 hardware/ntimespace/camera/flash.h            |   70 +
 .../camera/format_metadata_factory.cpp        |  271 ++++
 .../camera/format_metadata_factory.h          |   36 +
 .../camera/format_metadata_factory_test.cpp   |  198 +++
 hardware/ntimespace/camera/function_thread.h  |   41 +
 .../camera/gralloc/gralloc3_impl.cpp          |  317 +++++
 .../ntimespace/camera/gralloc/gralloc3_impl.h |   84 ++
 .../ntimespace/camera/gralloc/hal_public.h    |  215 ++++
 .../ntimespace/camera/gralloc/img_gralloc.h   |  107 ++
 .../ntimespace/camera/gralloc/img_gralloc1.h  |  305 +++++
 .../gralloc/img_gralloc_common_public.h       |  370 ++++++
 .../ntimespace/camera/gralloc/psb_gralloc.cpp |  242 ++++
 .../ntimespace/camera/gralloc/psb_gralloc.h   |   60 +
 .../camera/gralloc/psb_gralloc3.cpp           |  151 +++
 .../ntimespace/camera/gralloc/psb_gralloc3.h  |   55 +
 .../ntimespace/camera/hardware/hw_converter.h |   94 ++
 .../camera/hardware/qc_hw_converter.cpp       |  252 ++++
 .../camera/hardware/rk_hw_converter.cpp       |  159 +++
 .../ntimespace/camera/metadata/array_vector.h |   52 +
 .../metadata/boottime_state_delegate.cpp      |   47 +
 .../camera/metadata/boottime_state_delegate.h |   38 +
 .../camera/metadata/camera_metadata.cpp       |  565 ++++++++
 .../camera/metadata/camera_metadata.h         |  234 ++++
 hardware/ntimespace/camera/metadata/control.h |  221 ++++
 .../metadata/control_delegate_interface.h     |   41 +
 .../control_delegate_interface_mock.h         |   38 +
 .../metadata/control_options_interface.h      |   44 +
 .../metadata/control_options_interface_mock.h |   39 +
 .../camera/metadata/control_test.cpp          |  458 +++++++
 .../camera/metadata/converter_interface.h     |   35 +
 .../metadata/converter_interface_mock.h       |   38 +
 .../camera/metadata/default_option_delegate.h |   60 +
 .../metadata/default_option_delegate_mock.h   |   37 +
 .../metadata/default_option_delegate_test.cpp |   62 +
 .../camera/metadata/enum_converter.cpp        |   81 ++
 .../camera/metadata/enum_converter.h          |   43 +
 .../camera/metadata/enum_converter_test.cpp   |   99 ++
 .../metadata/ignored_control_delegate.h       |   43 +
 .../ignored_control_delegate_test.cpp         |   44 +
 .../camera/metadata/map_converter.h           |  139 ++
 .../camera/metadata/map_converter_test.cpp    |  110 ++
 .../camera/metadata/menu_control_options.h    |   77 ++
 .../metadata/menu_control_options_test.cpp    |  108 ++
 .../ntimespace/camera/metadata/metadata.cpp   |  232 ++++
 .../ntimespace/camera/metadata/metadata.h     |   50 +
 .../camera/metadata/metadata_common.h         |  323 +++++
 .../camera/metadata/metadata_reader.cpp       |  297 +++++
 .../camera/metadata/metadata_reader.h         |   76 ++
 .../camera/metadata/metadata_reader_mock.h    |   46 +
 .../camera/metadata/metadata_reader_test.cpp  |  368 ++++++
 .../camera/metadata/metadata_test.cpp         |  322 +++++
 .../metadata/no_effect_control_delegate.h     |   46 +
 .../no_effect_control_delegate_test.cpp       |   43 +
 .../metadata/partial_metadata_factory.h       |  335 +++++
 .../partial_metadata_factory_test.cpp         |  456 +++++++
 .../metadata/partial_metadata_interface.h     |   64 +
 .../partial_metadata_interface_mock.h         |   45 +
 .../ntimespace/camera/metadata/property.h     |   69 +
 .../camera/metadata/property_test.cpp         |  156 +++
 .../camera/metadata/ranged_converter.h        |  103 ++
 .../camera/metadata/ranged_converter_test.cpp |   86 ++
 .../camera/metadata/scaling_converter.h       |   75 ++
 .../camera/metadata/slider_control_options.h  |   80 ++
 .../metadata/slider_control_options_test.cpp  |  128 ++
 hardware/ntimespace/camera/metadata/state.h   |   96 ++
 .../metadata/state_delegate_interface.h       |   34 +
 .../metadata/state_delegate_interface_mock.h  |   37 +
 .../ntimespace/camera/metadata/state_test.cpp |  117 ++
 .../camera/metadata/tagged_control_delegate.h |   50 +
 .../metadata/tagged_control_delegate_test.cpp |   90 ++
 .../camera/metadata/tagged_control_options.h  |   61 +
 .../metadata/tagged_control_options_test.cpp  |  102 ++
 .../ntimespace/camera/metadata/test_common.h  |   96 ++
 hardware/ntimespace/camera/metadata/types.h   |   82 ++
 .../camera/metadata/v4l2_control_delegate.h   |   66 +
 .../metadata/v4l2_control_delegate_test.cpp   |  109 ++
 .../ntimespace/camera/request_tracker.cpp     |  159 +++
 hardware/ntimespace/camera/request_tracker.h  |   80 ++
 .../camera/request_tracker_test.cpp           |  259 ++++
 .../ntimespace/camera/static_properties.cpp   |  503 ++++++++
 .../ntimespace/camera/static_properties.h     |  120 ++
 .../camera/static_properties_test.cpp         |  674 ++++++++++
 hardware/ntimespace/camera/stream_format.cpp  |  242 ++++
 hardware/ntimespace/camera/stream_format.h    |   83 ++
 hardware/ntimespace/camera/v4l2_camera.cpp    |  912 +++++++++++++
 hardware/ntimespace/camera/v4l2_camera.h      |  120 ++
 .../ntimespace/camera/v4l2_camera_hal.cpp     |  345 +++++
 hardware/ntimespace/camera/v4l2_camera_hal.h  |   74 ++
 .../camera/v4l2_metadata_factory.cpp          |  601 +++++++++
 .../ntimespace/camera/v4l2_metadata_factory.h |   34 +
 hardware/ntimespace/camera/v4l2_wrapper.cpp   | 1136 +++++++++++++++++
 .../ntimespace/camera/v4l2_wrapper.cpp_10     | 1089 ++++++++++++++++
 hardware/ntimespace/camera/v4l2_wrapper.h     |  187 +++
 .../ntimespace/camera/v4l2_wrapper_mock.h     |   56 +
 .../camera/{Android.mk => Android.mk.1}       |    0
 132 files changed, 22311 insertions(+)
 create mode 100644 hardware/ntimespace/camera/Android.mk
 create mode 100644 hardware/ntimespace/camera/Android.mk-1
 create mode 100644 hardware/ntimespace/camera/README.md
 create mode 100644 hardware/ntimespace/camera/arc/cached_frame.cpp
 create mode 100644 hardware/ntimespace/camera/arc/cached_frame.h
 create mode 100644 hardware/ntimespace/camera/arc/common.h
 create mode 100644 hardware/ntimespace/camera/arc/common_types.h
 create mode 100644 hardware/ntimespace/camera/arc/exif_utils.cpp
 create mode 100644 hardware/ntimespace/camera/arc/exif_utils.h
 create mode 100644 hardware/ntimespace/camera/arc/format_convert_test.cpp
 create mode 100644 hardware/ntimespace/camera/arc/format_convert_test.h
 create mode 100644 hardware/ntimespace/camera/arc/frame_buffer.cpp
 create mode 100644 hardware/ntimespace/camera/arc/frame_buffer.h
 create mode 100644 hardware/ntimespace/camera/arc/image_processor.cpp
 create mode 100644 hardware/ntimespace/camera/arc/image_processor.h
 create mode 100644 hardware/ntimespace/camera/arc/jpeg_compressor.cpp
 create mode 100644 hardware/ntimespace/camera/arc/jpeg_compressor.h
 create mode 100644 hardware/ntimespace/camera/camera.cpp
 create mode 100644 hardware/ntimespace/camera/camera.h
 create mode 100644 hardware/ntimespace/camera/camera_init.rc
 create mode 100644 hardware/ntimespace/camera/camera_init.sh
 create mode 100644 hardware/ntimespace/camera/capture_request.cpp
 create mode 100644 hardware/ntimespace/camera/capture_request.h
 create mode 100644 hardware/ntimespace/camera/common.h
 create mode 100644 hardware/ntimespace/camera/debug.cpp
 create mode 100644 hardware/ntimespace/camera/debug.h
 create mode 100644 hardware/ntimespace/camera/flash.cpp
 create mode 100644 hardware/ntimespace/camera/flash.h
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory.cpp
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory_test.cpp
 create mode 100644 hardware/ntimespace/camera/function_thread.h
 create mode 100644 hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/gralloc3_impl.h
 create mode 100644 hardware/ntimespace/camera/gralloc/hal_public.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc1.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc.h
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc3.h
 create mode 100644 hardware/ntimespace/camera/hardware/hw_converter.h
 create mode 100644 hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
 create mode 100644 hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/array_vector.h
 create mode 100644 hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/boottime_state_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/camera_metadata.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/camera_metadata.h
 create mode 100644 hardware/ntimespace/camera/metadata/control.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_delegate_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_options_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_options_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/converter_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/converter_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/ignored_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/map_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/map_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/menu_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_common.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/property.h
 create mode 100644 hardware/ntimespace/camera/metadata/property_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/ranged_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/scaling_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/slider_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/state.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_delegate_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/test_common.h
 create mode 100644 hardware/ntimespace/camera/metadata/types.h
 create mode 100644 hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/request_tracker.cpp
 create mode 100644 hardware/ntimespace/camera/request_tracker.h
 create mode 100644 hardware/ntimespace/camera/request_tracker_test.cpp
 create mode 100644 hardware/ntimespace/camera/static_properties.cpp
 create mode 100644 hardware/ntimespace/camera/static_properties.h
 create mode 100644 hardware/ntimespace/camera/static_properties_test.cpp
 create mode 100644 hardware/ntimespace/camera/stream_format.cpp
 create mode 100644 hardware/ntimespace/camera/stream_format.h
 create mode 100644 hardware/ntimespace/camera/v4l2_camera.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_camera.h
 create mode 100644 hardware/ntimespace/camera/v4l2_camera_hal.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_camera_hal.h
 create mode 100644 hardware/ntimespace/camera/v4l2_metadata_factory.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.cpp_10
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.h
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper_mock.h
 rename hardware/rockchip/camera/{Android.mk => Android.mk.1} (100%)

diff --git a/device/rockchip/rk3588/rk3588_docker/manifest.xml b/device/rockchip/rk3588/rk3588_docker/manifest.xml
index c540005b47..68277ef61e 100644
--- a/device/rockchip/rk3588/rk3588_docker/manifest.xml
+++ b/device/rockchip/rk3588/rk3588_docker/manifest.xml
@@ -164,6 +164,16 @@
             <instance>default</instance>
         </interface>
     </hal>
+    <hal format="hidl">
+        <name>android.hardware.camera.provider</name>
+        <transport>hwbinder</transport>
+        <version>2.4</version>
+        <interface>
+            <name>ICameraProvider</name>
+            <instance>legacy/0</instance>
+        </interface>
+    </hal>
+
     <hal format="hidl">
         <name>android.hardware.radio</name>
         <transport>hwbinder</transport>
diff --git a/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk b/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
index d5ecafe845..b98580ce11 100755
--- a/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
+++ b/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
@@ -57,6 +57,13 @@ PRODUCT_PACKAGES += \
 	binder_alloc \
 	ipconfigstore \
 
+PRODUCT_PACKAGES += \
+	camera.$(TARGET_BOARD_HARDWARE) \
+	camera.device@1.0-impl \
+	camera.device@3.2-impl \
+	android.hardware.camera.provider@2.4-impl \
+	android.hardware.camera.provider@2.4-service
+
 PRODUCT_COPY_FILES += \
 	$(LOCAL_PATH)/init.redroid.rc:$(TARGET_COPY_OUT_VENDOR)/etc/init/init.redroid.rc \
 	$(LOCAL_PATH)/chmod.sh:$(TARGET_COPY_OUT_VENDOR)/bin/chmod.sh \
diff --git a/device/rockchip/rk3588/rk3588_docker_guozhen/manifest.xml b/device/rockchip/rk3588/rk3588_docker_guozhen/manifest.xml
index c540005b47..4d36816ea2 100644
--- a/device/rockchip/rk3588/rk3588_docker_guozhen/manifest.xml
+++ b/device/rockchip/rk3588/rk3588_docker_guozhen/manifest.xml
@@ -164,6 +164,15 @@
             <instance>default</instance>
         </interface>
     </hal>
+    <hal format="hidl">
+        <name>android.hardware.camera.provider</name>
+        <transport>hwbinder</transport>
+        <version>2.4</version>
+        <interface>
+            <name>ICameraProvider</name>
+            <instance>legacy/0</instance>
+        </interface>
+    </hal>
     <hal format="hidl">
         <name>android.hardware.radio</name>
         <transport>hwbinder</transport>
diff --git a/device/rockchip/rk3588/rk3588_docker_guozhen/rk3588_docker_guozhen.mk b/device/rockchip/rk3588/rk3588_docker_guozhen/rk3588_docker_guozhen.mk
index a09a20dcaa..2e7f975dc1 100755
--- a/device/rockchip/rk3588/rk3588_docker_guozhen/rk3588_docker_guozhen.mk
+++ b/device/rockchip/rk3588/rk3588_docker_guozhen/rk3588_docker_guozhen.mk
@@ -59,6 +59,13 @@ PRODUCT_PACKAGES += \
 	binder_alloc \
 	ipconfigstore \
 
+PRODUCT_PACKAGES += \
+	camera.$(TARGET_BOARD_HARDWARE) \
+	camera.device@1.0-impl \
+	camera.device@3.2-impl \
+	android.hardware.camera.provider@2.4-impl \
+	android.hardware.camera.provider@2.4-service
+
 PRODUCT_COPY_FILES += \
 	$(LOCAL_PATH)/init.redroid.rc:$(TARGET_COPY_OUT_VENDOR)/etc/init/init.redroid.rc \
 	$(LOCAL_PATH)/chmod.sh:$(TARGET_COPY_OUT_VENDOR)/bin/chmod.sh \
diff --git a/device/rockchip/rk3588/rk3588_docker_inland/manifest.xml b/device/rockchip/rk3588/rk3588_docker_inland/manifest.xml
index c540005b47..4d36816ea2 100644
--- a/device/rockchip/rk3588/rk3588_docker_inland/manifest.xml
+++ b/device/rockchip/rk3588/rk3588_docker_inland/manifest.xml
@@ -164,6 +164,15 @@
             <instance>default</instance>
         </interface>
     </hal>
+    <hal format="hidl">
+        <name>android.hardware.camera.provider</name>
+        <transport>hwbinder</transport>
+        <version>2.4</version>
+        <interface>
+            <name>ICameraProvider</name>
+            <instance>legacy/0</instance>
+        </interface>
+    </hal>
     <hal format="hidl">
         <name>android.hardware.radio</name>
         <transport>hwbinder</transport>
diff --git a/device/rockchip/rk3588/rk3588_docker_inland/rk3588_docker_inland.mk b/device/rockchip/rk3588/rk3588_docker_inland/rk3588_docker_inland.mk
index 5052a5a6c5..9fb6c47b7b 100755
--- a/device/rockchip/rk3588/rk3588_docker_inland/rk3588_docker_inland.mk
+++ b/device/rockchip/rk3588/rk3588_docker_inland/rk3588_docker_inland.mk
@@ -58,6 +58,13 @@ PRODUCT_PACKAGES += \
 	binder_alloc \
 	ipconfigstore \
 
+PRODUCT_PACKAGES += \
+	camera.$(TARGET_BOARD_HARDWARE) \
+	camera.device@1.0-impl \
+	camera.device@3.2-impl \
+	android.hardware.camera.provider@2.4-impl \
+	android.hardware.camera.provider@2.4-service
+
 PRODUCT_COPY_FILES += \
 	$(LOCAL_PATH)/init.redroid.rc:$(TARGET_COPY_OUT_VENDOR)/etc/init/init.redroid.rc \
 	$(LOCAL_PATH)/chmod.sh:$(TARGET_COPY_OUT_VENDOR)/bin/chmod.sh \
diff --git a/device/rockchip/rk3588/rk3588_docker_overseas/manifest.xml b/device/rockchip/rk3588/rk3588_docker_overseas/manifest.xml
index c540005b47..4d36816ea2 100644
--- a/device/rockchip/rk3588/rk3588_docker_overseas/manifest.xml
+++ b/device/rockchip/rk3588/rk3588_docker_overseas/manifest.xml
@@ -164,6 +164,15 @@
             <instance>default</instance>
         </interface>
     </hal>
+    <hal format="hidl">
+        <name>android.hardware.camera.provider</name>
+        <transport>hwbinder</transport>
+        <version>2.4</version>
+        <interface>
+            <name>ICameraProvider</name>
+            <instance>legacy/0</instance>
+        </interface>
+    </hal>
     <hal format="hidl">
         <name>android.hardware.radio</name>
         <transport>hwbinder</transport>
diff --git a/device/rockchip/rk3588/rk3588_docker_overseas/rk3588_docker_overseas.mk b/device/rockchip/rk3588/rk3588_docker_overseas/rk3588_docker_overseas.mk
index 93df0442bf..8f2f363349 100755
--- a/device/rockchip/rk3588/rk3588_docker_overseas/rk3588_docker_overseas.mk
+++ b/device/rockchip/rk3588/rk3588_docker_overseas/rk3588_docker_overseas.mk
@@ -59,6 +59,13 @@ PRODUCT_PACKAGES += \
 	binder_alloc \
 	ipconfigstore \
 
+PRODUCT_PACKAGES += \
+	camera.$(TARGET_BOARD_HARDWARE) \
+	camera.device@1.0-impl \
+	camera.device@3.2-impl \
+	android.hardware.camera.provider@2.4-impl \
+	android.hardware.camera.provider@2.4-service
+
 PRODUCT_COPY_FILES += \
 	$(LOCAL_PATH)/init.redroid.rc:$(TARGET_COPY_OUT_VENDOR)/etc/init/init.redroid.rc \
 	$(LOCAL_PATH)/chmod.sh:$(TARGET_COPY_OUT_VENDOR)/bin/chmod.sh \
diff --git a/device/rockchip/space-common/device_common.mk b/device/rockchip/space-common/device_common.mk
index 6ec5c81062..3212ab06e3 100644
--- a/device/rockchip/space-common/device_common.mk
+++ b/device/rockchip/space-common/device_common.mk
@@ -74,6 +74,12 @@ PRODUCT_COPY_FILES += \
         vendor/ntimespace/scripts/s9.boot.rc:system/etc/init/s9.boot.rc \
         vendor/ntimespace/scripts/script.sh:system/bin/script.sh
 
+# camera
+PRODUCT_COPY_FILES += \
+        hardware/ntimespace/camera/camera_init.sh:system/bin/camera_init.sh \
+        hardware/ntimespace/camera/camera_init.rc:system/etc/init/camera_init.rc 
+
+
 # logcatd
 PRODUCT_PACKAGES += logcatd logpersist.start
 PRODUCT_PROPERTY_OVERRIDES += logd.logpersistd=logcatd 
diff --git a/frameworks/av/services/camera/libcameraservice/CameraService.cpp b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
index ccc4caf5aa..6116c61936 100755
--- a/frameworks/av/services/camera/libcameraservice/CameraService.cpp
+++ b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
@@ -1943,6 +1943,10 @@ Status CameraService::supportsCameraApi(const String16& cameraId, int apiVersion
     }
 
     int deviceVersion = getDeviceVersion(id);
+    while(deviceVersion == -1){
+        usleep(100000);
+        deviceVersion = getDeviceVersion(id);
+    }
     switch (deviceVersion) {
         case CAMERA_DEVICE_API_VERSION_1_0:
         case CAMERA_DEVICE_API_VERSION_3_0:
diff --git a/hardware/ntimespace/camera/Android.mk b/hardware/ntimespace/camera/Android.mk
new file mode 100644
index 0000000000..c7b383dad8
--- /dev/null
+++ b/hardware/ntimespace/camera/Android.mk
@@ -0,0 +1,178 @@
+#
+# Copyright 2016 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+LOCAL_PATH:= $(call my-dir)
+include $(CLEAR_VARS)
+
+TARGET_HAS_RGA := true
+
+# Prevent the HAL from building on devices not specifically
+# requesting to use it.
+v4l2_shared_libs := \
+  libbase \
+  libchrome \
+  libcamera_metadata \
+  libcutils \
+  libexif \
+  libhardware \
+  liblog \
+  libsync \
+  libutils \
+  libion \
+  libhidlbase \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0 \
+  android.hardware.graphics.allocator@2.0	
+
+  #libgralloctypes \
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  librga 
+endif
+
+v4l2_static_libs := \
+  libyuv \
+  libjpeg 
+
+v4l2_cflags := -fno-short-enums -Wall -Wextra -Werror -fvisibility=hidden -DHAVE_JPEG -Wno-date-time -g
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_cflags += -DHAS_RGA
+endif
+
+v4l2_c_includes := $(call include-path-for, camera) \
+    external/libyuv/files/include \
+    frameworks/native/libs/ui/include \
+    hardware/libhardware/include/ \
+    system/core/libcutils/include \
+    hardware/libhardware/modules/gralloc \
+    system/core/libsystem/include \
+    system/memory/libion/original-kernel-headers \
+    system/core/liblog/include \
+    frameworks/native/include \
+    system/core/libsync \
+    system/core/libsync/include\
+    external/libdrm/include/drm \
+    system/libhidl/base/include \
+    system/libfmq/base \
+    hardware/rockchip/libgralloc \
+    frameworks/native/libs/gralloc/types/include \
+    frameworks/native/libs/nativewindow/include \
+    frameworks/native/libs/nativebase/include \
+    frameworks/native/libs/arect/include    
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/rockchip/librga/include/
+endif
+
+  
+v4l2_src_files := \
+  arc/cached_frame.cpp \
+  arc/exif_utils.cpp \
+  arc/frame_buffer.cpp \
+  arc/image_processor.cpp \
+  arc/jpeg_compressor.cpp \
+  arc/format_convert_test.cpp \
+  camera.cpp \
+  capture_request.cpp \
+  format_metadata_factory.cpp \
+  metadata/boottime_state_delegate.cpp \
+  metadata/enum_converter.cpp \
+  metadata/metadata.cpp \
+  metadata/metadata_reader.cpp \
+  metadata/camera_metadata.cpp \
+  request_tracker.cpp \
+  static_properties.cpp \
+  stream_format.cpp \
+  v4l2_camera.cpp \
+  v4l2_camera_hal.cpp \
+  v4l2_metadata_factory.cpp \
+  v4l2_wrapper.cpp \
+  gralloc/psb_gralloc3.cpp \
+  gralloc/gralloc3_impl.cpp \
+  debug.cpp \
+  flash.cpp
+
+
+ifeq ($(TARGET_HAS_RGA),true)
+  v4l2_src_files += hardware/rk_hw_converter.cpp
+endif
+
+
+#v4l2_test_files := \
+#  format_metadata_factory_test.cpp \
+#  metadata/control_test.cpp \
+#  metadata/default_option_delegate_test.cpp \
+#  metadata/enum_converter_test.cpp \
+#  metadata/ignored_control_delegate_test.cpp \
+#  metadata/map_converter_test.cpp \
+#  metadata/menu_control_options_test.cpp \
+#  metadata/metadata_reader_test.cpp \
+#  metadata/metadata_test.cpp \
+#  metadata/no_effect_control_delegate_test.cpp \
+#  metadata/partial_metadata_factory_test.cpp \
+#  metadata/property_test.cpp \
+#  metadata/ranged_converter_test.cpp \
+#  metadata/slider_control_options_test.cpp \
+#  metadata/state_test.cpp \
+#  metadata/tagged_control_delegate_test.cpp \
+#  metadata/tagged_control_options_test.cpp \
+#  metadata/v4l2_control_delegate_test.cpp \
+#  request_tracker_test.cpp \
+#  static_properties_test.cpp 
+
+# V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.rk3588luckion
+LOCAL_MODULE := camera.$(TARGET_BOARD_HARDWARE)
+LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+LOCAL_MODULE_RELATIVE_PATH := hw
+LOCAL_CFLAGS += $(v4l2_cflags) -DLOG_NDEBUG=0
+LOCAL_SHARED_LIBRARIES += $(v4l2_shared_libs)
+#LOCAL_HEADER_LIBRARIES := libgtest_prod_headers
+LOCAL_STATIC_LIBRARIES := $(v4l2_static_libs)
+
+LOCAL_VENDOR_MODULE := true
+
+LOCAL_C_INCLUDES += $(v4l2_c_includes)
+LOCAL_SRC_FILES := $(v4l2_src_files)
+
+include $(BUILD_SHARED_LIBRARY)
+
+# Unit tests for V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.v4l2_test
+#LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+#LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+
+#LOCAL_CFLAGS += $(v4l2_cflags)
+#LOCAL_SHARED_LIBRARIES := $(v4l2_shared_libs)
+#LOCAL_STATIC_LIBRARIES := \
+#  libgmock \
+#  $(v4l2_static_libs) \
+
+#LOCAL_C_INCLUDES += $(v4l2_c_includes)
+#LOCAL_SRC_FILES := \
+#  $(v4l2_src_files) \
+#  $(v4l2_test_files) \
+
+#include $(BUILD_NATIVE_TEST)
diff --git a/hardware/ntimespace/camera/Android.mk-1 b/hardware/ntimespace/camera/Android.mk-1
new file mode 100644
index 0000000000..8912d4b8a1
--- /dev/null
+++ b/hardware/ntimespace/camera/Android.mk-1
@@ -0,0 +1,227 @@
+#
+# Copyright 2016 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+LOCAL_PATH:= $(call my-dir)
+include $(CLEAR_VARS)
+
+ifeq ($(PRODUCT_HARDWARE),rk30board)
+TARGET_HAS_C2D2 := false
+TARGET_HAS_RGA := true
+else
+TARGET_HAS_C2D2 := true
+TARGET_HAS_RGA := false
+endif
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+$(warning "TARGET_BOARD_PLATFORM [$(TARGET_BOARD_PLATFORM)]")
+$(warning "just be careful!the camera hal may be need develop for this device...")
+TARGET_HAS_C2D2 := false
+TARGET_HAS_RGA := false
+endif
+
+# Prevent the HAL from building on devices not specifically
+# requesting to use it.
+v4l2_shared_libs := \
+  libbase \
+  libchrome \
+  libcamera_metadata \
+  libcutils \
+  libexif \
+  libhardware \
+  liblog \
+  libsync \
+  libutils \
+  libion \
+  libhidlbase 
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0
+endif 
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+v4l2_shared_libs += \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0
+endif
+
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_shared_libs += \
+  libc2dcolorconvert 
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  librga 
+endif
+
+v4l2_static_libs := \
+  libyuv \
+  libjpeg
+
+v4l2_cflags := -fno-short-enums  -Wextra -Wmacro-redefined -fvisibility=hidden -DHAVE_JPEG -Wno-date-time -g
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_cflags += -DHAS_C2D2
+endif
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_cflags += -DHAS_RGA
+endif
+
+v4l2_c_includes := $(call include-path-for, camera) \
+    external/libyuv/files/include \
+    frameworks/native/libs/ui/include \
+    hardware/libhardware/modules/gralloc
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += \
+    hardware/libhardware/include/ \
+    system/core/libcutils/include \
+    system/core/libsystem/include \
+    system/memory/libion/original-kernel-headers \
+    system/core/liblog/include \
+    frameworks/native/include \
+    system/core/libsync \
+    system/core/libsync/include\
+    external/libdrm/include/drm \
+    system/libhidl/base/include \
+    system/libfmq/base \
+    hardware/rockchip/libgralloc \
+    frameworks/native/libs/gralloc/types/include \
+    frameworks/native/libs/nativewindow/include \
+    frameworks/native/libs/nativebase/include \
+    frameworks/native/libs/arect/include  
+endif
+
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/mci/qcom-media/$(TARGET_BOARD_PLATFORM)/libc2dcolorconvert \
+    $(TARGET_OUT_HEADERS)/adreno \
+    $(MCI_KERNEL_PREFIX)/usr/include \
+    $(TOP)/vendor/mci/qcom-opensource/display/gralloc
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/rockchip/librga/include
+endif
+
+  
+v4l2_src_files := \
+  arc/cached_frame.cpp \
+  arc/exif_utils.cpp \
+  arc/frame_buffer.cpp \
+  arc/image_processor.cpp \
+  arc/jpeg_compressor.cpp \
+  arc/format_convert_test.cpp \
+  camera.cpp \
+  capture_request.cpp \
+  format_metadata_factory.cpp \
+  metadata/boottime_state_delegate.cpp \
+  metadata/enum_converter.cpp \
+  metadata/metadata.cpp \
+  metadata/metadata_reader.cpp \
+  metadata/camera_metadata.cpp \
+  request_tracker.cpp \
+  static_properties.cpp \
+  stream_format.cpp \
+  v4l2_camera.cpp \
+  v4l2_camera_hal.cpp \
+  v4l2_metadata_factory.cpp \
+  v4l2_wrapper.cpp \
+  debug.cpp \
+  flash.cpp 
+
+ifeq ($(TARGET_HAS_C2D2),true)
+  v4l2_src_files += hardware/qc_hw_converter.cpp \
+    gralloc/psb_gralloc.cpp
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+  v4l2_src_files += hardware/rk_hw_converter.cpp \
+    gralloc/psb_gralloc3.cpp \
+    gralloc/gralloc3_impl.cpp
+endif
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+    v4l2_src_files += gralloc/psb_gralloc3.cpp \
+        gralloc/gralloc3_impl.cpp
+endif
+
+
+#v4l2_test_files := \
+#  format_metadata_factory_test.cpp \
+#  metadata/control_test.cpp \
+#  metadata/default_option_delegate_test.cpp \
+#  metadata/enum_converter_test.cpp \
+#  metadata/ignored_control_delegate_test.cpp \
+#  metadata/map_converter_test.cpp \
+#  metadata/menu_control_options_test.cpp \
+#  metadata/metadata_reader_test.cpp \
+#  metadata/metadata_test.cpp \
+#  metadata/no_effect_control_delegate_test.cpp \
+#  metadata/partial_metadata_factory_test.cpp \
+#  metadata/property_test.cpp \
+#  metadata/ranged_converter_test.cpp \
+#  metadata/slider_control_options_test.cpp \
+#  metadata/state_test.cpp \
+#  metadata/tagged_control_delegate_test.cpp \
+#  metadata/tagged_control_options_test.cpp \
+#  metadata/v4l2_control_delegate_test.cpp \
+#  request_tracker_test.cpp \
+#  static_properties_test.cpp 
+
+# V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+LOCAL_MODULE := camera.$(PRODUCT_HARDWARE)
+LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+LOCAL_MODULE_RELATIVE_PATH := hw
+LOCAL_CFLAGS += $(v4l2_cflags) 
+#-DLOG_NDEBUG=0
+LOCAL_SHARED_LIBRARIES += $(v4l2_shared_libs)
+#LOCAL_HEADER_LIBRARIES := libgtest_prod_headers
+LOCAL_STATIC_LIBRARIES := $(v4l2_static_libs)
+
+LOCAL_VENDOR_MODULE := true
+
+LOCAL_C_INCLUDES += $(v4l2_c_includes)
+LOCAL_SRC_FILES := $(v4l2_src_files)
+
+include $(BUILD_SHARED_LIBRARY)
+
+# Unit tests for V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.v4l2_test
+#LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+#LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+
+#LOCAL_CFLAGS += $(v4l2_cflags)
+#LOCAL_SHARED_LIBRARIES := $(v4l2_shared_libs)
+#LOCAL_STATIC_LIBRARIES := \
+#  libgmock \
+#  $(v4l2_static_libs) \
+
+#LOCAL_C_INCLUDES += $(v4l2_c_includes)
+#LOCAL_SRC_FILES := \
+#  $(v4l2_src_files) \
+#  $(v4l2_test_files) \
+
+#include $(BUILD_NATIVE_TEST)
diff --git a/hardware/ntimespace/camera/README.md b/hardware/ntimespace/camera/README.md
new file mode 100644
index 0000000000..8c682e9968
--- /dev/null
+++ b/hardware/ntimespace/camera/README.md
@@ -0,0 +1,156 @@
+# V4L2 Camera HALv3
+
+The camera.v4l2 library implements a Camera HALv3 using the
+Video For Linux 2 (V4L2) interface. This allows it to theoretically
+work with a wide variety of devices, though the limitations of V4L2
+introduce some [caveats](#V4L2-Deficiencies), causing this HAL to
+not be fully spec-compliant.
+
+## Current status
+
+People are free to use that library if that works for their purpose,
+but it's not maintained by Android Camera team. There is another V4L2
+camera HAL implementation which is maintained by Android Camera team
+starting in Android P. See more information
+[here](https://source.android.com/devices/camera/external-usb-cameras).
+
+## Building a Device with the HAL
+
+To ensure the HAL is built for a device, include the following in your
+`<device>.mk`:
+
+```
+USE_CAMERA_V4L2_HAL := true
+PRODUCT_PACKAGES += camera.v4l2
+PRODUCT_PROPERTY_OVERRIDES += ro.hardware.camera=v4l2
+```
+
+The first line ensures the V4L2 HAL module is visible to the build system.
+This prevents checkbuilds on devices that don't have the necessary support
+from failing. The product packages tells the build system to include the V4L2
+HALv3 library in the system image. The final line tells the hardware manager
+to load the V4L2 HAL instead of a default Camera HAL.
+
+## Requirements for Using the HAL
+
+Devices and cameras wishing to use this HAL must meet
+the following requirements:
+
+* The camera must support BGR32, YUV420, and JPEG formats.
+* The gralloc and other graphics modules used by the device must use
+`HAL_PIXEL_FORMAT_RGBA_8888` as the `HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED`
+
+## Understanding the HAL Code
+
+There are three large pieces to the V4L2 Camera HAL: the general HALv3
+Camera & HAL code, the specific implementation using V4L2,
+and the Metadata system.
+
+For context, you may also wish to read some of the documentation in
+libhardware/include/camera3.h about how the framework interacts with the HAL.
+
+### Camera & HAL Interface
+
+The camera and HAL interfaces are implemented by the Camera and
+V4L2CameraHAL classes.
+
+The V4L2CameraHAL class deals primarily with initialization of the system.
+On creation, it searches /dev/video* nodes for ones with the necessary
+capabilities. These are then all presented to the framework as available
+for use. Further operations are passed to the individual Cameras as appropriate.
+
+The Camera class implements the general logic for handling the camera -
+opening and closing, configuring streams, preparing and tracking requests, etc.
+While it handles the logistics surrounding the camera, actual image
+capture and settings logic are implemented by calling down into the
+[V4L2 Camera](#V4L2-Camera). The Camera (using helper classes) enforces
+restrictions given in the [Metadata](#Metadata) initialized by the V4L2Camera,
+such as limits on the number of in-flight requests per stream.
+Notably, this means you should be able to replace the V4L2 implementation
+with something else, and as long as you fill in the metadata correctly the
+Camera class should "just work".
+
+### V4L2 Specific Implementation
+
+The V4L2Camera class is the implementation of all the capture functionality.
+It includes some methods for the Camera class to verify the setup, but the
+bulk of the class is the request queue. The Camera class submits CaptureRequests
+as they come in and are verified. The V4L2Camera runs these through a three
+stage asynchronous pipeline:
+
+* Acceptance: the V4L2Camera accepts the request, and puts it into waiting to be
+picked up by the enqueuer.
+* Enqueuing: the V4L2Camera reads the request settings, applies them to the
+device, takes a snapshot of the settings, and hands the buffer over to the
+V4L2 driver.
+* Dequeueing: A completed frame is reclaimed from the driver, and sent
+back to the Camera class for final processing (validation, filling in the
+result object, and sending the data back to the framework).
+
+Much of this work is aided by the V4L2Wrapper helper class,
+which provides simpler inputs and outputs around the V4L2 ioctls
+based on their known use by the HAL; filling in common values automatically
+and extracting the information useful to the HAL from the results.
+This wrapper is also used to expose V4L2 controls to their corresponding
+Metadata components.
+
+### Metadata
+
+The Metadata subsystem attempts to organize and simplify handling of
+camera metadata (system/media/camera/docs/docs.html). At the top level
+is the Metadata class and the PartialMetadataInterface. The Metadata
+class provides high level interaction with the individual components -
+filling the static metadata, validating, getting, and setting settings,
+etc. The Metadata class passes all of these things on to the component
+PartialMetadataInterfaces, each of which filter for their specific
+metadata components and perform the requested task.
+
+Some generalized metadata classes are provided to simplify common logic
+for this filtering and application. At a high level, there are three
+types:
+
+* Properties: a static value.
+* Controls: dynamically adjustable values, and optionally an
+associated static property indicating what allowable values are.
+* States: a dynamic read-only value.
+
+The Metadata system uses further interfaces and subclasses to distinguish
+the variety of different functionalities necessary for different metadata
+tags.
+
+#### Metadata Factory
+
+This V4L2 Camera HAL implementation utilizes a metadata factory method.
+This method initializes all the 100+ required metadata components for
+basic HAL spec compliance. Most do nothing/report fixed values,
+but a few are hooked up to the V4L2 driver.
+
+This HAL was initially designed for use with the Raspberry Pi camera module
+v2.1, so the fixed defaults are usually assigned based on that camera.
+
+## V4L2 Deficiencies
+
+* One stream at a time is supported. Notably, this means you must re-configure
+the stream between preview and capture if they're not the same format.
+This makes this HAL not backwards compatible with the Android Camera (v1) API
+as many of its methods attempt to do just that; Camera2 must be used instead.
+* A variety of metadata properties can't be filled in from V4L2,
+such as physical properties of the camera. Thus this HAL will never be capable
+of providing perfectly accurate information for all cameras it can theoretically
+support.
+* Android requires HALs support YUV420, JPEG, and a format of the graphics
+stack's choice ("implementation defined"). Very few cameras actually support
+all of these formats (so far the Raspberry Pi cameras are the only known ones),
+so some form of format conversion built in to the HAL would be a useful feature
+to expand the reach/usefulness of this HAL.
+* V4L2 doesn't make promises about how fast settings will apply, and there's no
+good way to determine what settings were in effect for a given frame. Thus,
+the settings passed into requests and out with results are applied/read as
+a best effort and may be incorrect.
+* Many features V4L2 is capable of are not hooked up to the HAL, so the HAL
+is underfeatured compared to the ideal/what is possible.
+
+## Other Known Issues
+
+* A variety of features are unimplemented: High speed capture,
+flash torch mode, hotplugging/unplugging.
diff --git a/hardware/ntimespace/camera/arc/cached_frame.cpp b/hardware/ntimespace/camera/arc/cached_frame.cpp
new file mode 100644
index 0000000000..a4f7377950
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/cached_frame.cpp
@@ -0,0 +1,424 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+#include "v4l2_camera_hal.h"
+#include "arc/cached_frame.h"
+#include <cerrno>
+#include <libyuv.h>
+#include "arc/common.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+
+
+namespace arc {
+
+using android::CameraMetadata;
+
+CachedFrame::CachedFrame()
+    : source_frame_(nullptr),
+      cropped_buffer_capacity_(0),
+      yu12_frame_(new IonFrameBuffer()),
+      scaled_frame_(new IonFrameBuffer()),
+      cropped_frame_(new IonFrameBuffer()){
+  already_cached = false;
+}
+
+CachedFrame::~CachedFrame() { UnsetSource(); }
+
+int CachedFrame::SetSource(const CameraMetadata& metadata, const FrameBuffer* frame, int rotate_degree) {
+  VLOGF_ENTER();
+
+  (void)rotate_degree;
+
+  source_frame_ = frame;
+  int res = ConvertToYU12(metadata);
+  if (res != 0) {
+    LOGF(ERROR) << "ConvertToYU12() fail: " << res;    
+    return res;
+  }
+
+  return res;
+}
+
+void CachedFrame::UnsetSource() { 
+  source_frame_ = nullptr; 
+}
+
+uint8_t* CachedFrame::GetSourceBuffer() const {
+  return source_frame_->GetData();
+}
+
+size_t CachedFrame::GetSourceDataSize() const {
+  return source_frame_->GetDataSize();
+}
+
+uint32_t CachedFrame::GetSourceFourCC() const {
+  return source_frame_->GetFourcc();
+}
+
+uint8_t* CachedFrame::GetCachedBuffer() const { 
+  return yu12_frame_->GetData(); 
+}
+
+uint32_t CachedFrame::GetCachedFourCC() const {
+  return yu12_frame_->GetFourcc();
+}
+
+uint32_t CachedFrame::GetWidth() const { 
+  return yu12_frame_->GetWidth(); 
+}
+
+uint32_t CachedFrame::GetHeight() const { 
+  return yu12_frame_->GetHeight(); 
+}
+
+size_t CachedFrame::GetConvertedSize(int fourcc) const {
+  return ImageProcessor::GetConvertedSize(fourcc, yu12_frame_->GetWidth(), yu12_frame_->GetHeight());
+}
+
+int CachedFrame::DoConvert(const CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  int ret = -1;
+#if defined(HAS_C2D2) || defined(HAS_RGA)
+  if (v4l2_camera_hal::using_hw) {
+    ret = hw_conv::convert_format(metadata, in_frame, out_frame);
+  }
+#endif
+
+  if (ret < 0) {
+    ret = ImageProcessor::ConvertFormat(metadata, in_frame, out_frame);    
+  }
+
+  return 0;
+}
+
+int CachedFrame::Convert(const CameraMetadata& metadata, FrameBuffer* out_frame, int buf_id) {
+  VLOGF_ENTER();
+
+  FrameBuffer* source_frame = yu12_frame_.get();
+  if (GetWidth() != out_frame->GetWidth() ||
+    GetHeight() != out_frame->GetHeight()) {
+    LOGF(INFO) << "In/Out mis-match. Need to do scale"; 
+
+    size_t cache_size = ImageProcessor::GetConvertedSize(
+        yu12_frame_->GetFourcc(), out_frame->GetWidth(),
+        out_frame->GetHeight());
+    if (cache_size == 0) {
+      LOGF(ERROR) << "cache_size error";
+      return -EINVAL;
+    } 
+
+    scaled_frame_->SetFourcc(V4L2_PIX_FMT_YUV420);
+    scaled_frame_->SetWidth(out_frame->GetWidth());
+    scaled_frame_->SetHeight(out_frame->GetHeight());
+    scaled_frame_->SetDataSize(cache_size);
+
+    if (cache_size > scaled_frame_->GetBufferSize()) {
+      LOGF(ERROR) << "cache_size > buffer_size, overflow error";
+      //scaled_frame_.reset(new IonFrameBuffer(cache_size));
+      return -EINVAL;
+    }
+
+    #if 0
+      ImageProcessor::Scale(*yu12_frame_.get(), scaled_frame_.get(), buf_id);
+    #else
+      float target_aspect = static_cast<float>(out_frame->GetWidth()) / static_cast<float>(out_frame->GetHeight());
+      int res = CropRotateScaleEx(*source_frame, scaled_frame_.get(), 0, target_aspect, buf_id);
+      if (res < 0)
+        return res;
+    #endif
+
+    source_frame = scaled_frame_.get();
+  }
+
+  return DoConvert(metadata, *source_frame, out_frame);
+}
+
+int CachedFrame::ConvertDirectly(const android::CameraMetadata& metadata, 
+                                 FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  VLOGF_ENTER();
+
+  if (in_frame.GetWidth() != out_frame->GetWidth() || in_frame.GetHeight() != out_frame->GetHeight()) {
+        LOGF(INFO) << "Wrong path. Size mis-match. Need to do scale";
+        return -EINVAL;
+  }
+
+  return DoConvert(metadata, in_frame, out_frame);
+}
+
+int CachedFrame::ConvertToYU12(const CameraMetadata& metadata) {
+  VLOGF_ENTER();
+  size_t cache_size = ImageProcessor::GetConvertedSize(
+      V4L2_PIX_FMT_YUV420, source_frame_->GetWidth(),
+      source_frame_->GetHeight());
+  if (cache_size == 0) {
+    LOGF(ERROR) << "cache_size error";
+    return -EINVAL;
+  }
+
+  yu12_frame_->SetFourcc(V4L2_PIX_FMT_YUV420);
+  yu12_frame_->SetWidth(source_frame_->GetWidth());
+  yu12_frame_->SetHeight(source_frame_->GetHeight());
+  yu12_frame_->SetDataSize(cache_size);  
+
+  int res = DoConvert(metadata, *source_frame_, yu12_frame_.get());
+  if (res) {
+    LOGF(ERROR) << "Convert from " << FormatToString(source_frame_->GetFourcc())
+                << " to YU12 fails.";
+    return res;
+  }
+  return 0;
+}
+
+int CachedFrame::CropRotateScale(int rotate_degree) {
+  // TODO(henryhsu): Move libyuv part to ImageProcessor.
+  if (yu12_frame_->GetHeight() % 2 != 0 || yu12_frame_->GetWidth() % 2 != 0) {
+    LOGF(ERROR) << "yu12_frame_ has odd dimension: " << yu12_frame_->GetWidth()
+                << "x" << yu12_frame_->GetHeight();
+    return -EINVAL;
+  }
+
+  if (yu12_frame_->GetHeight() > yu12_frame_->GetWidth()) {
+    LOGF(ERROR) << "yu12_frame_ is tall frame already: "
+                << yu12_frame_->GetWidth() << "x" << yu12_frame_->GetHeight();
+    return -EINVAL;
+  }
+
+  // Step 1: Crop and rotate
+  //
+  //   Original frame                  Cropped frame              Rotated frame
+  // --------------------               --------
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |                 |             |
+  // |     |      |     |   =======>>   |      |     =======>>   |             |
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |
+  // --------------------               --------
+  //
+  int cropped_width = yu12_frame_->GetHeight() * yu12_frame_->GetHeight() /
+                      yu12_frame_->GetWidth();
+  if (cropped_width % 2 == 1) {
+    // Make cropped_width to the closest even number.
+    cropped_width++;
+  }
+  int cropped_height = yu12_frame_->GetHeight();
+  int margin = (yu12_frame_->GetWidth() - cropped_width) / 2;
+
+  int rotated_height = cropped_width;
+  int rotated_width = cropped_height;
+
+  int rotated_y_stride = rotated_width;
+  int rotated_uv_stride = rotated_width / 2;
+  size_t rotated_size =
+      rotated_y_stride * rotated_height + rotated_uv_stride * rotated_height;
+  if (rotated_size > cropped_buffer_capacity_) {
+    cropped_buffer_.reset(new uint8_t[rotated_size]);
+    cropped_buffer_capacity_ = rotated_size;
+  }
+  uint8_t* rotated_y_plane = cropped_buffer_.get();
+  uint8_t* rotated_u_plane =
+      rotated_y_plane + rotated_y_stride * rotated_height;
+  uint8_t* rotated_v_plane =
+      rotated_u_plane + rotated_uv_stride * rotated_height / 2;
+  libyuv::RotationMode rotation_mode = libyuv::RotationMode::kRotate90;
+  switch (rotate_degree) {
+    case 90:
+      rotation_mode = libyuv::RotationMode::kRotate90;
+      break;
+    case 270:
+      rotation_mode = libyuv::RotationMode::kRotate270;
+      break;
+    default:
+      LOGF(ERROR) << "Invalid rotation degree: " << rotate_degree;
+      return -EINVAL;
+  }
+  // This libyuv method first crops the frame and then rotates it 90 degrees
+  // clockwise.
+  int res = libyuv::ConvertToI420(
+      yu12_frame_->GetData(), yu12_frame_->GetDataSize(), rotated_y_plane,
+      rotated_y_stride, rotated_u_plane, rotated_uv_stride, rotated_v_plane,
+      rotated_uv_stride, margin, 0, yu12_frame_->GetWidth(),
+      yu12_frame_->GetHeight(), cropped_width, cropped_height, rotation_mode,
+      libyuv::FourCC::FOURCC_I420);
+
+  if (res) {
+    LOGF(ERROR) << "ConvertToI420 failed: " << res;
+    return res;
+  }
+
+  // Step 2: Scale
+  //
+  //                               Final frame
+  //  Rotated frame            ---------------------
+  // --------------            |                   |
+  // |            |  =====>>   |                   |
+  // |            |            |                   |
+  // --------------            |                   |
+  //                           |                   |
+  //                           ---------------------
+  //
+  //
+  res = libyuv::I420Scale(
+      rotated_y_plane, rotated_y_stride, rotated_u_plane, rotated_uv_stride,
+      rotated_v_plane, rotated_uv_stride, rotated_width, rotated_height,
+      yu12_frame_->GetData(), yu12_frame_->GetWidth(),
+      yu12_frame_->GetData() +
+          yu12_frame_->GetWidth() * yu12_frame_->GetHeight(),
+      yu12_frame_->GetWidth() / 2,
+      yu12_frame_->GetData() +
+          yu12_frame_->GetWidth() * yu12_frame_->GetHeight() * 5 / 4,
+      yu12_frame_->GetWidth() / 2, yu12_frame_->GetWidth(),
+      yu12_frame_->GetHeight(), libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, res) << "I420Scale failed: " << res;
+  return res;
+}
+
+int CachedFrame::CropRotateScaleEx(FrameBuffer& in_frame, FrameBuffer* out_frame, int rotate_degree, float target_aspect, int buf_id) {
+  (void)rotate_degree;
+
+  dump_data(dump_data_index, (unsigned char *)in_frame.GetData(), 
+                          in_frame.GetWidth(), 
+                          in_frame.GetHeight(), 
+                          in_frame.GetFourcc(),
+                          buf_id, "crs_pre");
+
+  if (in_frame.GetHeight() % 2 != 0 || in_frame.GetWidth() % 2 != 0) {
+    LOGF(ERROR) << "in_frame has odd dimension: " << in_frame.GetWidth()
+                << "x" << in_frame.GetHeight();
+    return -EINVAL;
+  }
+
+  if (in_frame.GetHeight() > in_frame.GetWidth()) {
+    LOGF(ERROR) << "in_frame is tall frame already: "
+                << in_frame.GetWidth() << "x" << in_frame.GetHeight();
+    return -EINVAL;
+  }
+
+  int scale_in_width = 0;
+  int scale_in_height = 0;
+  int scale_in_y_stride = 0;
+  int scale_in_uv_stride = 0;
+  uint8_t* scale_in_y_plane = nullptr;
+  uint8_t* scale_in_u_plane = nullptr;
+  uint8_t* scale_in_v_plane = nullptr;
+
+  int cropped_width = 0;
+  int cropped_height = 0;
+  int cropped_y_stride = 0;
+  int cropped_uv_stride = 0;
+  uint8_t* cropped_y_plane = nullptr;
+  uint8_t* cropped_u_plane = nullptr;
+  uint8_t* cropped_v_plane = nullptr;
+
+  float in_aspect = static_cast<float>(in_frame.GetWidth()) / static_cast<float>(in_frame.GetHeight());
+  LOGF(ERROR) << "in_aspect: " << in_aspect << " target_aspect: " << target_aspect;
+
+  if (in_aspect != target_aspect) {
+  // Step 1: Crop and rotate
+  //
+  //   Original frame                  Cropped frame              Rotated frame
+  // --------------------               --------
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |                 |             |
+  // |     |      |     |   =======>>   |      |     =======>>   |             |
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |
+  // --------------------               --------
+  //
+  cropped_width = target_aspect * in_frame.GetHeight();
+  if (cropped_width % 2 == 1) {
+    // Make cropped_width to the closest even number.
+    cropped_width++;
+  }
+  cropped_height = in_frame.GetHeight();
+  int margin = (in_frame.GetWidth() - cropped_width) / 2;
+
+  LOGF(ERROR) << "cropped size: " << cropped_width << " x " << cropped_height;
+
+  size_t cache_size = ImageProcessor::GetConvertedSize(
+      in_frame.GetFourcc(), cropped_width, cropped_height);
+  if (cache_size == 0) {
+    LOGF(ERROR) << "cache_size error";
+    return -EINVAL;
+  } 
+
+  cropped_frame_->SetWidth(cropped_width);
+  cropped_frame_->SetHeight(cropped_height);
+  cropped_frame_->SetDataSize(cache_size);
+
+  if (cache_size > cropped_frame_->GetBufferSize()) {
+    LOGF(ERROR) << "cache_size > buffer_size, overflow error";
+    return -EINVAL;
+  }
+
+  cropped_y_stride = cropped_width;
+  cropped_uv_stride = cropped_width / 2;
+  cropped_y_plane = cropped_frame_->GetData();
+  cropped_u_plane = cropped_y_plane + cropped_y_stride * cropped_height;
+  cropped_v_plane = cropped_u_plane + cropped_uv_stride * cropped_height / 2;
+
+  // This libyuv method first crops the frame and then rotates it clockwise.
+  int res = libyuv::ConvertToI420(
+      in_frame.GetData(), in_frame.GetDataSize(), cropped_y_plane,
+      cropped_y_stride, cropped_u_plane, cropped_uv_stride, cropped_v_plane,
+      cropped_uv_stride, margin, 0, in_frame.GetWidth(),
+      in_frame.GetHeight(), cropped_width, cropped_height, libyuv::RotationMode::kRotate0,
+      libyuv::FourCC::FOURCC_I420);
+
+  if (res) {
+    LOGF(ERROR) << "ConvertToI420 failed: " << res;
+    return res;
+  } 
+  }
+
+  // Step 2: Scale
+  //
+  //                               Final frame
+  //  Rotated frame            ---------------------
+  // --------------            |                   |
+  // |            |  =====>>   |                   |
+  // |            |            |                   |
+  // --------------            |                   |
+  //                           |                   |
+  //                           ---------------------
+  //
+  //
+  if (in_aspect != target_aspect) {
+    scale_in_width = cropped_width;
+    scale_in_height = cropped_height;
+    scale_in_y_stride = cropped_y_stride;
+    scale_in_uv_stride = cropped_uv_stride;
+    scale_in_y_plane = cropped_y_plane;
+    scale_in_u_plane = cropped_u_plane;
+    scale_in_v_plane = cropped_v_plane;     
+  } else {
+    scale_in_width = in_frame.GetWidth();
+    scale_in_height = in_frame.GetHeight();
+    scale_in_y_stride = in_frame.GetWidth();
+    scale_in_uv_stride = in_frame.GetWidth() / 2;
+    scale_in_y_plane = in_frame.GetData();
+    scale_in_u_plane = scale_in_y_plane + in_frame.GetWidth() * in_frame.GetHeight();
+    scale_in_v_plane = scale_in_u_plane + scale_in_uv_stride * in_frame.GetHeight() / 2;    
+  }
+
+  int res = libyuv::I420Scale(
+      scale_in_y_plane, scale_in_y_stride, scale_in_u_plane, scale_in_uv_stride,
+      scale_in_v_plane, scale_in_uv_stride, scale_in_width, scale_in_height,
+      out_frame->GetData(), out_frame->GetWidth(),
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+      out_frame->GetWidth() / 2,
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+      out_frame->GetWidth() / 2, out_frame->GetWidth(),
+      out_frame->GetHeight(), libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, res) << "I420Scale failed: " << res;
+  
+  dump_data(dump_data_index, (unsigned char *)out_frame->GetData(), 
+                        out_frame->GetWidth(), 
+                        out_frame->GetHeight(), 
+                        out_frame->GetFourcc(),
+                        buf_id, "scale_post");
+
+  return res;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/cached_frame.h b/hardware/ntimespace/camera/arc/cached_frame.h
new file mode 100644
index 0000000000..75c330e98c
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/cached_frame.h
@@ -0,0 +1,97 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_CACHED_FRAME_H_
+#define HAL_USB_CACHED_FRAME_H_
+
+#include <memory>
+#include "metadata/camera_metadata.h"
+#include "arc/image_processor.h"
+#include "hardware/hw_converter.h"
+
+namespace arc {
+
+using android::CameraMetadata;
+
+
+// CachedFrame contains a source FrameBuffer and a cached, converted
+// FrameBuffer. The incoming frames would be converted to YU12, the default
+// format of libyuv, to allow convenient processing.
+class CachedFrame {
+ public:
+  CachedFrame();
+  ~CachedFrame();
+
+  // SetSource() doesn't take ownership of |frame|. The caller can only release
+  // |frame| after calling UnsetSource(). SetSource() immediately converts
+  // incoming frame into YU12. Return non-zero values if it encounters errors.
+  // If |rotate_degree| is 90 or 270, |frame| will be cropped, rotated by the
+  // specified amount and scaled.
+  // If |rotate_degree| is -1, |frame| will not be cropped, rotated, and scaled.
+  // This function will return an error if |rotate_degree| is not -1, 90, or
+  // 270.
+  int SetSource(const CameraMetadata& metadata, const FrameBuffer* frame, int rotate_degree);
+  void UnsetSource();
+
+  uint8_t* GetSourceBuffer() const;
+  size_t GetSourceDataSize() const;
+  uint32_t GetSourceFourCC() const;
+  uint8_t* GetCachedBuffer() const;
+  uint32_t GetCachedFourCC() const;
+
+  uint32_t GetWidth() const;
+  uint32_t GetHeight() const;
+
+  // Calculate the output buffer size when converting to the specified pixel
+  // format. |fourcc| is defined as V4L2_PIX_FMT_* in linux/videodev2.h. Return
+  // 0 on error.
+  size_t GetConvertedSize(int fourcc) const;
+
+  // Caller should fill everything except |data_size| and |fd| of |out_frame|.
+  // The function will do format conversion and scale to fit |out_frame|
+  // requirement.
+  // If |video_hack| is true, it outputs YU12 when |hal_pixel_format| is YV12
+  // (swapping U/V planes). Caller should fill |fourcc|, |data|, and
+  // Return non-zero error code on failure; return 0 on success.
+  int Convert(const android::CameraMetadata& metadata, FrameBuffer* out_frame,
+              int buf_id);
+  int ConvertDirectly(const android::CameraMetadata& metadata, FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+  int DoConvert(const android::CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+ private:
+  int ConvertToYU12(const CameraMetadata& metadata);
+  // When we have a landscape mounted camera and the current camera activity is
+  // portrait, the frames shown in the activity would be stretched. Therefore,
+  // we want to simulate a native portrait camera. That's why we want to crop,
+  // rotate |rotate_degree| clockwise and scale the frame. HAL would not change
+  // CameraInfo.orientation. Instead, framework would fake the
+  // CameraInfo.orientation. Framework would then tell HAL how much the frame
+  // needs to rotate clockwise by |rotate_degree|.
+  int CropRotateScale(int rotate_degree);
+  int CropRotateScaleEx(FrameBuffer& in_frame, FrameBuffer* out_frame, int rotate_degree, float target_aspect, int buf_id);
+
+  const FrameBuffer* source_frame_;
+
+  // Temporary buffer for cropped and rotated results.
+  std::unique_ptr<uint8_t[]> cropped_buffer_;
+  size_t cropped_buffer_capacity_;
+
+
+public:
+  // Cache YU12 decoded results.
+  //std::unique_ptr<AllocatedFrameBuffer> yu12_frame_;
+  std::unique_ptr<IonFrameBuffer> yu12_frame_;
+
+  // Temporary buffer for scaled results.
+  //std::unique_ptr<AllocatedFrameBuffer> scaled_frame_;
+  std::unique_ptr<IonFrameBuffer> scaled_frame_;
+  std::unique_ptr<IonFrameBuffer> cropped_frame_;
+  bool already_cached;  
+};
+
+}  // namespace arc
+
+#endif  // HAL_USB_CACHED_FRAME_H_
diff --git a/hardware/ntimespace/camera/arc/common.h b/hardware/ntimespace/camera/arc/common.h
new file mode 100644
index 0000000000..0ad5ad4579
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/common.h
@@ -0,0 +1,37 @@
+/* Copyright 2016 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_COMMON_H_
+#define INCLUDE_ARC_COMMON_H_
+
+#include <string>
+
+#include <base/logging.h>
+
+#define MSG_TAG "[v4l2_camera]"
+
+#define LOGF(level) LOG(level)
+#define LOGFID(level, id) LOG(level) << MSG_TAG << __FUNCTION__ << "(): id: " << id << ": "
+#define LOGF_IF(level, res) LOG_IF(level, res) << MSG_TAG << __FUNCTION__ << "(): "
+
+#define VLOGF(level) VLOG(level) << MSG_TAG << __FUNCTION__ << "(): "
+#define VLOGFID(level, id) \
+  VLOG(level) << MSG_TAG << __FUNCTION__ << "(): id: " << id << ": "
+
+#if 1
+#define VLOGF_ENTER() VLOGF(1) << "enter"
+#define VLOGF_EXIT() VLOGF(1) << "exit"
+#else
+#define VLOGF_ENTER()  LOGF(INFO) << MSG_TAG << __FUNCTION__ << " enter"
+#define VLOGF_EXIT()  LOGF(INFO) << MSG_TAG << __FUNCTION__ << " exit"
+#endif
+
+
+
+inline std::string FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+#endif  // INCLUDE_ARC_COMMON_H_
diff --git a/hardware/ntimespace/camera/arc/common_types.h b/hardware/ntimespace/camera/arc/common_types.h
new file mode 100644
index 0000000000..8f62ad6e0d
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/common_types.h
@@ -0,0 +1,55 @@
+/*
+ * Copyright 2016 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_COMMON_TYPES_H_
+#define HAL_USB_COMMON_TYPES_H_
+
+#include <string>
+#include <vector>
+
+namespace arc {
+
+struct DeviceInfo {
+  // ex: /dev/video0
+  std::string device_path;
+  // USB vender id
+  std::string usb_vid;
+  // USB product id
+  std::string usb_pid;
+  // Some cameras need to wait several frames to output correct images.
+  uint32_t frames_to_skip_after_streamon;
+
+  // Member definitions can be found in https://developer.android.com/
+  // reference/android/hardware/camera2/CameraCharacteristics.html
+  uint32_t lens_facing;
+  int32_t sensor_orientation;
+  float horizontal_view_angle_16_9;
+  float horizontal_view_angle_4_3;
+  std::vector<float> lens_info_available_focal_lengths;
+  float lens_info_minimum_focus_distance;
+  float lens_info_optimal_focus_distance;
+  float vertical_view_angle_16_9;
+  float vertical_view_angle_4_3;
+};
+
+typedef std::vector<DeviceInfo> DeviceInfos;
+
+struct SupportedFormat {
+  uint32_t width;
+  uint32_t height;
+  uint32_t fourcc;
+  // All the supported frame rates in fps with given width, height, and
+  // pixelformat. This is not sorted. For example, suppose width, height, and
+  // fourcc are 640x480 YUYV. If frameRates are 15.0 and 30.0, the camera
+  // supports outputting 640X480 YUYV in 15fps or 30fps.
+  std::vector<float> frameRates;
+};
+
+typedef std::vector<SupportedFormat> SupportedFormats;
+
+}  // namespace arc
+
+#endif  // HAL_USB_COMMON_TYPES_H_
diff --git a/hardware/ntimespace/camera/arc/exif_utils.cpp b/hardware/ntimespace/camera/arc/exif_utils.cpp
new file mode 100644
index 0000000000..512fdb9eae
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/exif_utils.cpp
@@ -0,0 +1,512 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/exif_utils.h"
+
+#include <cstdlib>
+#include <ctime>
+
+#include <libyuv.h>
+#include "arc/common.h"
+
+namespace std {
+
+template <>
+struct default_delete<ExifEntry> {
+  inline void operator()(ExifEntry* entry) const { exif_entry_unref(entry); }
+};
+
+}  // namespace std
+
+namespace arc {
+
+// This comes from the Exif Version 2.3 standard table 9.
+const uint8_t gExifAsciiPrefix[] = {0x41, 0x53, 0x43, 0x49,
+                                    0x49, 0x0,  0x0,  0x0};
+
+static void SetLatitudeOrLongitudeData(unsigned char* data, double num) {
+  // Take the integer part of |num|.
+  ExifLong degrees = static_cast<ExifLong>(num);
+  ExifLong minutes = static_cast<ExifLong>(60 * (num - degrees));
+  ExifLong microseconds =
+      static_cast<ExifLong>(3600000000u * (num - degrees - minutes / 60.0));
+  exif_set_rational(data, EXIF_BYTE_ORDER_INTEL, {degrees, 1});
+  exif_set_rational(data + sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {minutes, 1});
+  exif_set_rational(data + 2 * sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {microseconds, 1000000});
+}
+
+ExifUtils::ExifUtils()
+    : yu12_buffer_(nullptr),
+      yu12_width_(0),
+      yu12_height_(0),
+      thumbnail_width_(0),
+      thumbnail_height_(0),
+      exif_data_(nullptr),
+      app1_buffer_(nullptr),
+      app1_length_(0) {}
+
+ExifUtils::~ExifUtils() { Reset(); }
+
+bool ExifUtils::Initialize(const uint8_t* buffer, uint16_t width,
+                           uint16_t height, int quality) {
+  Reset();
+
+  if (width % 2 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "invalid image size " << width << "x" << height;
+    return false;
+  }
+  if (quality < 1 || quality > 100) {
+    LOGF(ERROR) << "invalid jpeg quality " << quality;
+    return false;
+  }
+  thumbnail_jpeg_quality_ = quality;
+  yu12_buffer_ = buffer;
+  yu12_width_ = width;
+  yu12_height_ = height;
+
+  exif_data_ = exif_data_new();
+  if (exif_data_ == nullptr) {
+    LOGF(ERROR) << "allocate memory for exif_data_ failed";
+    return false;
+  }
+  // Set the image options.
+  exif_data_set_option(exif_data_, EXIF_DATA_OPTION_FOLLOW_SPECIFICATION);
+  exif_data_set_data_type(exif_data_, EXIF_DATA_TYPE_COMPRESSED);
+  exif_data_set_byte_order(exif_data_, EXIF_BYTE_ORDER_INTEL);
+
+  // Set image width and length.
+  SetImageWidth(width);
+  SetImageLength(height);
+
+  return true;
+}
+
+bool ExifUtils::SetMaker(const std::string& maker) {
+  size_t entrySize = maker.length() + 1;
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_0, EXIF_TAG_MAKE, EXIF_FORMAT_ASCII, entrySize, entrySize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Make exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, maker.c_str(), entrySize);
+  return true;
+}
+
+bool ExifUtils::SetModel(const std::string& model) {
+  size_t entrySize = model.length() + 1;
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_0, EXIF_TAG_MODEL, EXIF_FORMAT_ASCII, entrySize, entrySize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Model exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, model.c_str(), entrySize);
+  return true;
+}
+
+bool ExifUtils::SetDateTime(const struct tm& t) {
+  // The length is 20 bytes including NULL for termination in Exif standard.
+  char str[20];
+  int result = snprintf(str, sizeof(str), "%04i:%02i:%02i %02i:%02i:%02i",
+                        t.tm_year + 1900, t.tm_mon + 1, t.tm_mday, t.tm_hour,
+                        t.tm_min, t.tm_sec);
+  if (result != sizeof(str) - 1) {
+    LOGF(WARNING) << "Input time is invalid";
+    return false;
+  }
+  std::unique_ptr<ExifEntry> entry =
+      AddVariableLengthEntry(EXIF_IFD_0, EXIF_TAG_DATE_TIME, EXIF_FORMAT_ASCII,
+                             sizeof(str), sizeof(str));
+  if (!entry) {
+    LOGF(ERROR) << "Adding DateTime exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, str, sizeof(str));
+  return true;
+}
+
+bool ExifUtils::SetFocalLength(uint32_t numerator, uint32_t denominator) {
+  std::unique_ptr<ExifEntry> entry =
+      AddEntry(EXIF_IFD_EXIF, EXIF_TAG_FOCAL_LENGTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding FocalLength exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {numerator, denominator});
+  return true;
+}
+
+bool ExifUtils::SetGpsLatitude(double latitude) {
+  const ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_LATITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_ASCII, 2, 2);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSLatitudeRef exif entry failed";
+    return false;
+  }
+  if (latitude >= 0) {
+    memcpy(refEntry->data, "N", sizeof("N"));
+  } else {
+    memcpy(refEntry->data, "S", sizeof("S"));
+    latitude *= -1;
+  }
+
+  const ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_LATITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 3, 3 * sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSLatitude exif entry failed";
+    return false;
+  }
+  SetLatitudeOrLongitudeData(entry->data, latitude);
+
+  return true;
+}
+
+bool ExifUtils::SetGpsLongitude(double longitude) {
+  ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_LONGITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_ASCII, 2, 2);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSLongitudeRef exif entry failed";
+    return false;
+  }
+  if (longitude >= 0) {
+    memcpy(refEntry->data, "E", sizeof("E"));
+  } else {
+    memcpy(refEntry->data, "W", sizeof("W"));
+    longitude *= -1;
+  }
+
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_LONGITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 3, 3 * sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSLongitude exif entry failed";
+    return false;
+  }
+  SetLatitudeOrLongitudeData(entry->data, longitude);
+
+  return true;
+}
+
+bool ExifUtils::SetGpsAltitude(double altitude) {
+  ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_ALTITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_BYTE, 1, 1);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSAltitudeRef exif entry failed";
+    return false;
+  }
+  if (altitude >= 0) {
+    *refEntry->data = 0;
+  } else {
+    *refEntry->data = 1;
+    altitude *= -1;
+  }
+
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_ALTITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 1, sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSAltitude exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(altitude * 1000), 1000});
+
+  return true;
+}
+
+bool ExifUtils::SetGpsTimestamp(const struct tm& t) {
+  const ExifTag dateTag = static_cast<ExifTag>(EXIF_TAG_GPS_DATE_STAMP);
+  const size_t kGpsDateStampSize = 11;
+  std::unique_ptr<ExifEntry> entry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, dateTag, EXIF_FORMAT_ASCII,
+                             kGpsDateStampSize, kGpsDateStampSize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSDateStamp exif entry failed";
+    return false;
+  }
+  int result =
+      snprintf(reinterpret_cast<char*>(entry->data), kGpsDateStampSize,
+               "%04i:%02i:%02i", t.tm_year + 1900, t.tm_mon + 1, t.tm_mday);
+  if (result != kGpsDateStampSize - 1) {
+    LOGF(WARNING) << "Input time is invalid";
+    return false;
+  }
+
+  const ExifTag timeTag = static_cast<ExifTag>(EXIF_TAG_GPS_TIME_STAMP);
+  entry = AddVariableLengthEntry(EXIF_IFD_GPS, timeTag, EXIF_FORMAT_RATIONAL, 3,
+                                 3 * sizeof(ExifRational));
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSTimeStamp exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_hour), 1});
+  exif_set_rational(entry->data + sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_min), 1});
+  exif_set_rational(entry->data + 2 * sizeof(ExifRational),
+                    EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_sec), 1});
+
+  return true;
+}
+
+bool ExifUtils::SetGpsProcessingMethod(const std::string& method) {
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_PROCESSING_METHOD);
+  size_t size = sizeof(gExifAsciiPrefix) + method.length();
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_UNDEFINED, size, size);
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSProcessingMethod exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, gExifAsciiPrefix, sizeof(gExifAsciiPrefix));
+  // Since the exif format is undefined, NULL termination is not necessary.
+  memcpy(entry->data + sizeof(gExifAsciiPrefix), method.c_str(),
+         method.length());
+
+  return true;
+}
+
+bool ExifUtils::SetThumbnailSize(uint16_t width, uint16_t height) {
+  if (width % 2 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "Invalid thumbnail size " << width << "x" << height;
+    return false;
+  }
+  thumbnail_width_ = width;
+  thumbnail_height_ = height;
+  return true;
+}
+
+bool ExifUtils::SetOrientation(uint16_t orientation) {
+  std::unique_ptr<ExifEntry> entry = AddEntry(EXIF_IFD_0, EXIF_TAG_ORIENTATION);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Orientation exif entry failed";
+    return false;
+  }
+  /*
+   * Orientation value:
+   *  1      2      3      4      5          6          7          8
+   *
+   *  888888 888888     88 88     8888888888 88                 88 8888888888
+   *  88         88     88 88     88  88     88  88         88  88     88  88
+   *  8888     8888   8888 8888   88         8888888888 8888888888         88
+   *  88         88     88 88
+   *  88         88 888888 888888
+   */
+  int value = 1;
+  switch (orientation) {
+    case 90:
+      value = 6;
+      break;
+    case 180:
+      value = 3;
+      break;
+    case 270:
+      value = 8;
+      break;
+    default:
+      break;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, value);
+  return true;
+}
+
+bool ExifUtils::GenerateApp1() {
+  DestroyApp1();
+  if (thumbnail_width_ > 0 && thumbnail_height_ > 0) {
+    if (!GenerateThumbnail()) {
+      LOGF(ERROR) << "Generate thumbnail image failed";
+      return false;
+    }
+    exif_data_->data = const_cast<uint8_t*>(
+        static_cast<const uint8_t*>(compressor_.GetCompressedImagePtr()));
+    exif_data_->size = compressor_.GetCompressedImageSize();
+  }
+  // Save the result into |app1_buffer_|.
+  exif_data_save_data(exif_data_, &app1_buffer_, &app1_length_);
+  if (!app1_length_) {
+    LOGF(ERROR) << "Allocate memory for app1_buffer_ failed";
+    return false;
+  }
+  /*
+   * The JPEG segment size is 16 bits in spec. The size of APP1 segment should
+   * be smaller than 65533 because there are two bytes for segment size field.
+   */
+  if (app1_length_ > 65533) {
+    DestroyApp1();
+    LOGF(ERROR) << "The size of APP1 segment is too large";
+    return false;
+  }
+  return true;
+}
+
+const uint8_t* ExifUtils::GetApp1Buffer() { return app1_buffer_; }
+
+unsigned int ExifUtils::GetApp1Length() { return app1_length_; }
+
+void ExifUtils::Reset() {
+  yu12_buffer_ = nullptr;
+  yu12_width_ = 0;
+  yu12_height_ = 0;
+  thumbnail_width_ = 0;
+  thumbnail_height_ = 0;
+  DestroyApp1();
+  if (exif_data_) {
+    /*
+     * Since we decided to ignore the original APP1, we are sure that there is
+     * no thumbnail allocated by libexif. |exif_data_->data| is actually
+     * allocated by JpegCompressor. Sets |exif_data_->data| to nullptr to
+     * prevent exif_data_unref() destroy it incorrectly.
+     */
+    exif_data_->data = nullptr;
+    exif_data_->size = 0;
+    exif_data_unref(exif_data_);
+    exif_data_ = nullptr;
+  }
+}
+
+std::unique_ptr<ExifEntry> ExifUtils::AddVariableLengthEntry(
+    ExifIfd ifd, ExifTag tag, ExifFormat format, uint64_t components,
+    unsigned int size) {
+  // Remove old entry if exists.
+  exif_content_remove_entry(exif_data_->ifd[ifd],
+                            exif_content_get_entry(exif_data_->ifd[ifd], tag));
+  ExifMem* mem = exif_mem_new_default();
+  if (!mem) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    return nullptr;
+  }
+  std::unique_ptr<ExifEntry> entry(exif_entry_new_mem(mem));
+  if (!entry) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    exif_mem_unref(mem);
+    return nullptr;
+  }
+  void* tmpBuffer = exif_mem_alloc(mem, size);
+  if (!tmpBuffer) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    exif_mem_unref(mem);
+    return nullptr;
+  }
+
+  entry->data = static_cast<unsigned char*>(tmpBuffer);
+  entry->tag = tag;
+  entry->format = format;
+  entry->components = components;
+  entry->size = size;
+
+  exif_content_add_entry(exif_data_->ifd[ifd], entry.get());
+  exif_mem_unref(mem);
+
+  return entry;
+}
+
+std::unique_ptr<ExifEntry> ExifUtils::AddEntry(ExifIfd ifd, ExifTag tag) {
+  std::unique_ptr<ExifEntry> entry(
+      exif_content_get_entry(exif_data_->ifd[ifd], tag));
+  if (entry) {
+    // exif_content_get_entry() won't ref the entry, so we ref here.
+    exif_entry_ref(entry.get());
+    return entry;
+  }
+  entry.reset(exif_entry_new());
+  if (!entry) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    return nullptr;
+  }
+  entry->tag = tag;
+  exif_content_add_entry(exif_data_->ifd[ifd], entry.get());
+  exif_entry_initialize(entry.get(), tag);
+  return entry;
+}
+
+bool ExifUtils::SetImageWidth(uint16_t width) {
+  std::unique_ptr<ExifEntry> entry = AddEntry(EXIF_IFD_0, EXIF_TAG_IMAGE_WIDTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding ImageWidth exif entry failed";
+    return false;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, width);
+  return true;
+}
+
+bool ExifUtils::SetImageLength(uint16_t length) {
+  std::unique_ptr<ExifEntry> entry =
+      AddEntry(EXIF_IFD_0, EXIF_TAG_IMAGE_LENGTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding ImageLength exif entry failed";
+    return false;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, length);
+  return true;
+}
+
+bool ExifUtils::GenerateThumbnail() {
+  // Resize yuv image to |thumbnail_width_| x |thumbnail_height_|.
+  std::vector<uint8_t> scaled_buffer;
+  if (!GenerateYuvThumbnail(&scaled_buffer)) {
+    LOGF(ERROR) << "Generate YUV thumbnail failed";
+    return false;
+  }
+
+  // Compress thumbnail to JPEG.
+  if (!compressor_.CompressImage(scaled_buffer.data(), thumbnail_width_,
+                                 thumbnail_height_, thumbnail_jpeg_quality_,
+                                 NULL, 0)) {
+    LOGF(ERROR) << "Compress thumbnail failed";
+    return false;
+  }
+  return true;
+}
+
+bool ExifUtils::GenerateYuvThumbnail(std::vector<uint8_t>* scaled_buffer) {
+  size_t y_plane_size = yu12_width_ * yu12_height_;
+  const uint8_t* y_plane = yu12_buffer_;
+  const uint8_t* u_plane = y_plane + y_plane_size;
+  const uint8_t* v_plane = u_plane + y_plane_size / 4;
+
+  size_t scaled_y_plane_size = thumbnail_width_ * thumbnail_height_;
+  scaled_buffer->resize(scaled_y_plane_size * 3 / 2);
+  uint8_t* scaled_y_plane = scaled_buffer->data();
+  uint8_t* scaled_u_plane = scaled_y_plane + scaled_y_plane_size;
+  uint8_t* scaled_v_plane = scaled_u_plane + scaled_y_plane_size / 4;
+
+  int result = libyuv::I420Scale(
+      y_plane, yu12_width_, u_plane, yu12_width_ / 2, v_plane, yu12_width_ / 2,
+      yu12_width_, yu12_height_, scaled_y_plane, thumbnail_width_,
+      scaled_u_plane, thumbnail_width_ / 2, scaled_v_plane,
+      thumbnail_width_ / 2, thumbnail_width_, thumbnail_height_,
+      libyuv::kFilterNone);
+  if (result != 0) {
+    LOGF(ERROR) << "Scale I420 image failed";
+    return false;
+  }
+  return true;
+}
+
+void ExifUtils::DestroyApp1() {
+  /*
+   * Since there is no API to access ExifMem in ExifData->priv, we use free
+   * here, which is the default free function in libexif. See
+   * exif_data_dump_data() for detail.
+   */
+  free(app1_buffer_);
+  app1_buffer_ = nullptr;
+  app1_length_ = 0;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/exif_utils.h b/hardware/ntimespace/camera/arc/exif_utils.h
new file mode 100644
index 0000000000..956ee1d2a0
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/exif_utils.h
@@ -0,0 +1,178 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_EXIF_UTILS_H_
+#define INCLUDE_ARC_EXIF_UTILS_H_
+
+#include <cstddef>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+extern "C" {
+#include <libexif/exif-data.h>
+}
+
+#include "arc/jpeg_compressor.h"
+
+namespace arc {
+
+// ExifUtils can generate APP1 segment with tags which caller set. ExifUtils can
+// also add a thumbnail in the APP1 segment if thumbnail size is specified.
+// ExifUtils can be reused with different images by calling initialize().
+//
+// Example of using this class :
+//  ExifUtils utils;
+//  utils.initialize(inputYU12Buffer, inputWidth, inputHeight,
+//                   outputJpegQuality);
+//  ...
+//  // Call ExifUtils functions to set Exif tags.
+//  ...
+//  utils.generateApp1();
+//  unsigned int app1Length = utils.getApp1Length();
+//  uint8_t* app1Buffer = new uint8_t[app1Length];
+//  memcpy(app1Buffer, utils.getApp1Buffer(), app1Length);
+class ExifUtils {
+ public:
+  ExifUtils();
+  ~ExifUtils();
+
+  // Sets input YU12 image |buffer| with |width| x |height|. |quality| is the
+  // compressed JPEG image quality. The caller should not release |buffer| until
+  // generateApp1() or the destructor is called. initialize() can be called
+  // multiple times. The setting of Exif tags will be cleared.
+  bool Initialize(const uint8_t* buffer, uint16_t width, uint16_t height,
+                  int quality);
+
+  // Sets the manufacturer of camera.
+  // Returns false if memory allocation fails.
+  bool SetMaker(const std::string& maker);
+
+  // Sets the model number of camera.
+  // Returns false if memory allocation fails.
+  bool SetModel(const std::string& model);
+
+  // Sets the date and time of image last modified. It takes local time. The
+  // name of the tag is DateTime in IFD0.
+  // Returns false if memory allocation fails.
+  bool SetDateTime(const struct tm& t);
+
+  // Sets the focal length of lens used to take the image in millimeters.
+  // Returns false if memory allocation fails.
+  bool SetFocalLength(uint32_t numerator, uint32_t denominator);
+
+  // Sets the latitude with degrees minutes seconds format.
+  // Returns false if memory allocation fails.
+  bool SetGpsLatitude(double latitude);
+
+  // Sets the longitude with degrees minutes seconds format.
+  // Returns false if memory allocation fails.
+  bool SetGpsLongitude(double longitude);
+
+  // Sets the altitude in meters.
+  // Returns false if memory allocation fails.
+  bool SetGpsAltitude(double altitude);
+
+  // Sets GPS date stamp and time stamp (atomic clock). It takes UTC time.
+  // Returns false if memory allocation fails.
+  bool SetGpsTimestamp(const struct tm& t);
+
+  // Sets GPS processing method.
+  // Returns false if memory allocation fails.
+  bool SetGpsProcessingMethod(const std::string& method);
+
+  // Since the size of APP1 segment is limited, it is recommended the
+  // resolution of thumbnail is equal to or smaller than 640x480. If the
+  // thumbnail is too big, generateApp1() will return false.
+  // Returns false if |width| or |height| is not even.
+  bool SetThumbnailSize(uint16_t width, uint16_t height);
+
+  // Sets image orientation.
+  // Returns false if memory allocation fails.
+  bool SetOrientation(uint16_t orientation);
+
+  // Generates APP1 segment.
+  // Returns false if generating APP1 segment fails.
+  bool GenerateApp1();
+
+  // Gets buffer of APP1 segment. This method must be called only after calling
+  // generateAPP1().
+  const uint8_t* GetApp1Buffer();
+
+  // Gets length of APP1 segment. This method must be called only after calling
+  // generateAPP1().
+  unsigned int GetApp1Length();
+
+ private:
+  // Resets the pointers and memories.
+  void Reset();
+
+  // Adds a variable length tag to |exif_data_|. It will remove the original one
+  // if the tag exists.
+  // Returns the entry of the tag. The reference count of returned ExifEntry is
+  // two.
+  std::unique_ptr<ExifEntry> AddVariableLengthEntry(ExifIfd ifd, ExifTag tag,
+                                                    ExifFormat format,
+                                                    uint64_t components,
+                                                    unsigned int size);
+
+  // Adds a entry of |tag| in |exif_data_|. It won't remove the original one if
+  // the tag exists.
+  // Returns the entry of the tag. It adds one reference count to returned
+  // ExifEntry.
+  std::unique_ptr<ExifEntry> AddEntry(ExifIfd ifd, ExifTag tag);
+
+  // Sets the width (number of columes) of main image.
+  // Returns false if memory allocation fails.
+  bool SetImageWidth(uint16_t width);
+
+  // Sets the length (number of rows) of main image.
+  // Returns false if memory allocation fails.
+  bool SetImageLength(uint16_t length);
+
+  // Generates a thumbnail. Calls compressor_.getCompressedImagePtr() to get the
+  // result image.
+  // Returns false if failed.
+  bool GenerateThumbnail();
+
+  // Resizes the thumbnail yuv image to |thumbnail_width_| x |thumbnail_height_|
+  // and stores in |scaled_buffer|.
+  // Returns false if scale image failed.
+  bool GenerateYuvThumbnail(std::vector<uint8_t>* scaled_buffer);
+
+  // Destroys the buffer of APP1 segment if exists.
+  void DestroyApp1();
+
+  // The buffer pointer of yuv image (YU12). Not owned by this class.
+  const uint8_t* yu12_buffer_;
+  // The size of yuv image.
+  uint16_t yu12_width_;
+  uint16_t yu12_height_;
+
+  // The size of thumbnail.
+  uint16_t thumbnail_width_;
+  uint16_t thumbnail_height_;
+
+  // The Exif data (APP1). Owned by this class.
+  ExifData* exif_data_;
+  // The raw data of APP1 segment. It's allocated by ExifMem in |exif_data_| but
+  // owned by this class.
+  uint8_t* app1_buffer_;
+  // The length of |app1_buffer_|.
+  unsigned int app1_length_;
+  // The quality of compressed thumbnail image. The size of EXIF thumbnail has
+  // to be smaller than 64KB. If quality is 100, the size may be bigger than
+  // 64KB.
+  int thumbnail_jpeg_quality_;
+
+  // The YU12 to Jpeg compressor.
+  JpegCompressor compressor_;
+};
+
+}  // namespace arc
+
+#endif  // INCLUDE_ARC_EXIF_UTILS_H_
diff --git a/hardware/ntimespace/camera/arc/format_convert_test.cpp b/hardware/ntimespace/camera/arc/format_convert_test.cpp
new file mode 100644
index 0000000000..f4a8b2ee8f
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/format_convert_test.cpp
@@ -0,0 +1,248 @@
+#include "arc/image_processor.h"
+#include <cerrno>
+#include <ctime>
+#include <string>
+#include <libyuv.h>
+#include "arc/common.h"
+#include "arc/exif_utils.h"
+#include "arc/jpeg_compressor.h"
+#include "debug.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+#include "hardware/hw_converter.h"
+#include "frame_buffer.h"
+#include "arc/format_convert_test.h"
+
+
+using android::CameraMetadata;
+
+namespace arc {
+
+void fill_data(unsigned char * rgbdata, int w, int sr, int sc, int er, int ec, unsigned char color_r, 
+               unsigned char color_g, unsigned char color_b, unsigned char color_a)
+{
+  int rr, cc;
+
+  for (rr = sr; rr < er; rr++)
+  {
+    for (cc = sc; cc < ec; cc++)
+    {
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc)) = color_r; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 1) = color_g; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 2) = color_b; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 3) = color_a; 
+    }
+  }
+}
+
+void fill_rgb_matrix(unsigned char * rgbdata, int camera_width, int camera_height)
+{
+  int dw = camera_width/3;
+  int dh = camera_height/3;
+  unsigned char color[][4] = { //r/g/b/r
+    {0xFF, 0, 0, 0}, 
+    {0, 0xFF, 0xFF, 0}, //cygon
+    {0xFF, 0xFF, 0xFF, 0xFF}, //white
+    {0, 0xFF, 0xFF, 0},
+    {0, 0xFF, 0, 0}, //green
+    {0, 0xFF, 0xFF, 0},
+    {0, 0, 0, 0}, //black
+    {0, 0xFF, 0xFF, 0},
+    {0, 0, 0xFF, 0}, //blue
+  };
+
+  int idx = 0;
+  for (int r = 0; r < 3; r++)
+  {
+    for (int c = 0; c < 3; c++) 
+    {
+      fill_data(rgbdata, camera_width, /*camera_height,*/ r * dh, c * dw, (r + 1)* dh, (c + 1) * dw, 
+                color[idx][0], color[idx][1], color[idx][2], color[idx][3]);
+      idx++;
+    }					
+  }
+}
+
+void ConvertFormat(const FrameBuffer& in_frame, FrameBuffer* out_frame) 
+{
+  ImageProcessor::ConvertFormat(CameraMetadata(), in_frame, out_frame);
+}
+
+void ConvertFormat_HW(const FrameBuffer& in_frame, FrameBuffer* out_frame) 
+{
+  (void)in_frame;
+  (void)out_frame;
+  hw_conv::convert_format(CameraMetadata(), in_frame, out_frame);
+}
+
+void SW_Convert(int in_formatcc, int out_formatcc, int width, int height)
+{
+  dump_data_index++;
+
+  UnitTestFrameBuffer rgb_frame(V4L2_PIX_FMT_RGB32, width, height);
+  UnitTestFrameBuffer yu12_frame(V4L2_PIX_FMT_YUV420, width, height);
+  UnitTestFrameBuffer out_frame(out_formatcc, width, height);
+  
+  arc::fill_rgb_matrix(rgb_frame.GetData(), width, height);
+
+  {
+    UnitTestFrameBuffer in_frame(in_formatcc, width, height);
+
+    ConvertFormat(rgb_frame, &in_frame);
+    dump_data(dump_data_index, in_frame.GetData(), in_frame.GetWidth(), in_frame.GetHeight(), 
+              in_frame.GetFourcc(), 0, "in");
+
+    ConvertFormat(in_frame, &yu12_frame);
+    dump_data(dump_data_index, yu12_frame.GetData(), yu12_frame.GetWidth(), yu12_frame.GetHeight(), 
+              yu12_frame.GetFourcc(), 0, "yu12");
+
+    ConvertFormat(yu12_frame, &out_frame);
+    dump_data(dump_data_index, out_frame.GetData(), out_frame.GetWidth(), out_frame.GetHeight(), 
+              out_frame.GetFourcc(), 0, "post"); 
+  }
+}
+
+void FormatConvert_UnitTest_SW()
+{
+  bool unit_test = android::base::GetBoolProperty("camera.debug.unit_test", true);
+  if (!unit_test)
+    return;
+
+  android::base::SetProperty("camera.debug.dump", "true");
+
+  LOGF(INFO) << "FormatConvertUnitTest start.";
+  dump_data_init();
+
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_RGB32, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_YUV420, 640, 480); 
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_NV12, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_NV21, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_YVU420, 640, 480);
+
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_NV12,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_NV21,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_RGB32,  640, 480);  
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_YUV420,  640, 480);  
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_YVU420,  640, 480);    
+
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_NV12,  640, 480); 
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_RGB32,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_NV21,  640, 480); 
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_YUV420,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_YVU420,  640, 480);
+
+  unit_test = false;
+  android::base::SetProperty("camera.debug.unit_test", "false");
+  android::base::SetProperty("camera.debug.dump", "false");
+
+  LOGF(INFO) << "FormatConvertUnitTest end.";	
+}
+
+void HW_Convert(int in_formatcc, int out_formatcc, int in_width, int in_height, int out_width, int out_height)
+{
+  dump_data_index++;
+
+  IonFrameBuffer rgb_frame(V4L2_PIX_FMT_RGB32, in_width, in_height);
+  IonFrameBuffer out_frame(out_formatcc, out_width, out_height);
+  IonFrameBuffer in_frame(in_formatcc, in_width, in_height);
+
+  arc::fill_rgb_matrix(rgb_frame.GetData(), in_width, in_height);
+
+  ConvertFormat(rgb_frame, &in_frame);
+  dump_data(dump_data_index, in_frame.GetData(), in_frame.GetWidth(), in_frame.GetHeight(), 
+            in_frame.GetFourcc(), 0, "in");
+
+  ConvertFormat_HW(in_frame, &out_frame);
+  dump_data(dump_data_index, out_frame.GetData(), out_frame.GetWidth(), out_frame.GetHeight(), 
+            out_frame.GetFourcc(), 0, "post"); 
+}
+
+void Test_Template(int in_fortmat) 
+{
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_NV12,  640, 480, 320, 240);
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_RGB32,  640, 480, 320, 240);  
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_YUV420,  640, 480, 320, 240);  
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_YVU420,  640, 480, 320, 240);    
+}
+
+void FormatConvert_UnitTest_HW()
+{
+  bool unit_test = android::base::GetBoolProperty("camera.debug.unit_test", false);
+  if (!unit_test)
+    return;
+
+  android::base::SetProperty("camera.debug.dump", "true");
+
+  LOGF(INFO) << __FUNCTION__ << " start";
+  dump_data_init();
+
+  Test_Template(V4L2_PIX_FMT_RGB32);
+  Test_Template(V4L2_PIX_FMT_YUV420);
+  Test_Template(V4L2_PIX_FMT_NV12);
+  Test_Template(V4L2_PIX_FMT_YVU420);
+
+  android::base::SetProperty("camera.debug.unit_test", "false");
+  android::base::SetProperty("camera.debug.dump", "false");
+  LOGF(INFO) << __FUNCTION__ << " end";	
+}
+
+void FormatConvert_PerfTest(){
+  int in_width = 720;
+  int in_height = 1080;
+  int in_formatcc = V4L2_PIX_FMT_RGB32;
+  int out_formatcc = V4L2_PIX_FMT_YUV420;
+  int loop = 1000;
+
+  IonFrameBuffer out_frame(out_formatcc, in_width, in_height);
+  IonFrameBuffer in_frame(in_formatcc, in_width, in_height);
+
+  arc::fill_rgb_matrix(in_frame.GetData(), in_width, in_height);
+
+  uint64_t perf_time_start;
+  uint64_t perf_time_end;
+  uint64_t testDurationNs;
+  CPU_OCCUPY cpu_stat_start;
+  CPU_OCCUPY cpu_stat_end;  
+  int usage = 0;  
+
+  perf_time_start = timeNanos();
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start); 
+  for (int i = 0; i < loop; i++)
+    ConvertFormat(in_frame, &out_frame);
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_end);
+  perf_time_end = timeNanos();
+  testDurationNs = perf_time_end - perf_time_start;
+  usage = cal_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start,(CPU_OCCUPY *)&cpu_stat_end);
+  HAL_LOGD("SW convert perf - time: %d  cpu: %d%%", toMilliSeconds(testDurationNs), usage);     
+
+  sleep(3);
+
+  perf_time_start = timeNanos();
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start);   
+  for (int i = 0; i < loop; i++)
+    ConvertFormat_HW(in_frame, &out_frame);
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_end);    
+  perf_time_end = timeNanos();
+  testDurationNs = perf_time_end - perf_time_start;
+  usage = cal_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start,(CPU_OCCUPY *)&cpu_stat_end);
+  HAL_LOGD("HW convert perf - time: %d  cpu: %d%%", toMilliSeconds(testDurationNs), usage);     
+}
+
+void FormatConvert_UnitTest(){
+  #if 0
+  if (android::base::GetBoolProperty("camera.debug.unit_test", false)) {
+    char value[PROPERTY_VALUE_MAX];
+    if (property_get("camera.debug.convert_mode", value, "hw")) {
+      if (!strcmp("hw", value)) {
+        FormatConvert_UnitTest_HW();
+      } else if (!strcmp("libyuv", value)) {
+      FormatConvert_UnitTest_SW();
+      } else if (!strcmp("perf", value)) {
+        FormatConvert_PerfTest();
+      }
+    }
+  }
+#endif
+}
+
+}
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/arc/format_convert_test.h b/hardware/ntimespace/camera/arc/format_convert_test.h
new file mode 100644
index 0000000000..52f0c78368
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/format_convert_test.h
@@ -0,0 +1,23 @@
+#ifndef __FORMAT_CONVERT_HEADER__
+#define __FORMAT_CONVERT_HEADER__
+
+#include "metadata/camera_metadata.h"
+// FourCC pixel formats (defined as V4L2_PIX_FMT_*).
+#include <linux/videodev2.h>
+// Declarations of HAL_PIXEL_FORMAT_XXX.
+#include <system/graphics.h>
+
+#include "frame_buffer.h"
+
+namespace arc {
+
+void fill_rgb_matrix(unsigned char * rgbdata, int camera_width, int camera_height);
+
+void FormatConvert_UnitTest_SW();
+void FormatConvert_UnitTest_HW();
+void FormatConvert_UnitTest();
+
+}  // namespace arc
+
+
+#endif
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/arc/frame_buffer.cpp b/hardware/ntimespace/camera/arc/frame_buffer.cpp
new file mode 100644
index 0000000000..86e1bc0ea0
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/frame_buffer.cpp
@@ -0,0 +1,379 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "v4l2_camera_hal.h"
+#include "arc/frame_buffer.h"
+#include <utility>
+#include <sys/mman.h>
+#include "arc/common.h"
+#include "arc/image_processor.h"
+#include "gralloc/psb_gralloc3.h"
+#include "stream_format.h"
+#include "debug.h"
+#include <sys/types.h>
+#include <linux/ion.h>
+//#include "linux/msm_ion.h"
+#include <ion/ion.h>
+#include <linux/dma-buf.h>
+
+
+namespace arc {
+
+FrameBuffer::FrameBuffer()
+    : data_(nullptr),
+      data_size_(0),
+      buffer_size_(0),
+      width_(0),
+      height_(0),
+      fourcc_(0),
+      fd_(-1) {
+}
+
+FrameBuffer::~FrameBuffer() {
+}
+
+int FrameBuffer::SetDataSize(size_t data_size) {
+  //LOGF(INFO) << "size "<< data_size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (data_size > buffer_size_) {
+    LOGF(ERROR) << "Buffer overflow: Buffer only has " << buffer_size_
+                << ", but data needs " << data_size;
+    return -EINVAL;
+  }
+  data_size_ = data_size;
+  return 0;
+}
+
+AllocatedFrameBuffer::AllocatedFrameBuffer(int buffer_size) {
+  buffer_.reset(new uint8_t[buffer_size]);
+  buffer_size_ = buffer_size;
+  data_ = buffer_.get();
+}
+
+AllocatedFrameBuffer::AllocatedFrameBuffer(uint8_t* buffer, int buffer_size) {
+  buffer_.reset(buffer);
+  buffer_size_ = buffer_size;
+  data_ = buffer_.get();
+}
+
+AllocatedFrameBuffer::~AllocatedFrameBuffer() {
+  fd_ = -1;
+}
+
+int AllocatedFrameBuffer::SetDataSize(size_t size) {
+  //LOGF(INFO) << "size "<< size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (size > buffer_size_) {
+    buffer_.reset(new uint8_t[size]);
+    buffer_size_ = size;
+    data_ = buffer_.get();
+  }
+  data_size_ = size;
+  return 0;
+}
+
+void AllocatedFrameBuffer::Reset() { memset(data_, 0, buffer_size_); }
+
+#define CAMERAMEMSIZE (1024*1024*24)
+V4L2FrameBuffer::V4L2FrameBuffer() {
+  fd_ = -1;
+  buffer_size_ = CAMERAMEMSIZE;
+  width_ = 0;
+  height_ = 0;
+  fourcc_ = 0;
+  data_ = nullptr;
+  offset_ = 0;
+}
+
+V4L2FrameBuffer::~V4L2FrameBuffer() {
+  if (Unmap()) {
+    LOGF(ERROR) << "Unmap failed";
+  }
+}
+
+void V4L2FrameBuffer::SetData(uint8_t* data) {
+  data_ = data;
+}
+
+int V4L2FrameBuffer::SetDataSize(size_t size) {
+  LOGF(INFO) << "size "<< size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (size > buffer_size_) {
+    LOGF(ERROR) << "SetDataSize failed";
+    return -EINVAL;
+  }
+
+  data_size_ = size;
+  return 0;
+}
+
+void V4L2FrameBuffer::Reset() { memset(data_, 0, data_size_);}
+
+bool V4L2FrameBuffer::is_mapped_ = false;
+uint8_t* V4L2FrameBuffer::map_start_ = nullptr;
+
+int V4L2FrameBuffer::Map() {
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    return 0;
+  }
+
+  void* addr = mmap(NULL, data_size_, PROT_READ, MAP_SHARED, fd_, offset_);
+  if (addr == MAP_FAILED) {
+    HAL_LOGE("mmap() size %zu map_start_ offset %d fd %d failed: %s", data_size_, offset_, fd_, strerror(errno));
+    return -EINVAL;
+  }
+
+  map_start_ = static_cast<uint8_t*>(addr);
+  is_mapped_ = true;
+  HAL_LOGV("%s: map_start_ %p data_size_ %zd  ", __func__, map_start_, data_size_);    
+  return 0;
+}
+
+int V4L2FrameBuffer::Unmap() {
+  base::AutoLock l(lock_);
+  HAL_LOGV("%s: map_start_ %p data_size_ %zd  ", __func__, map_start_, data_size_);    
+  if (is_mapped_ && munmap(static_cast<void*>(map_start_), data_size_)) {
+    LOGF(ERROR) << "mummap() map_start_ failed: " << strerror(errno);
+    return -EINVAL;
+  }
+  HAL_LOGV("V4L2FrameBuffer::Unmap: map_start_ Try to Unmap success2");  
+  is_mapped_ = false; 
+ 
+  return 0;
+}
+ 
+GrallocFrameBuffer::GrallocFrameBuffer(buffer_handle_t buffer, uint32_t width,
+                                       uint32_t height, uint32_t fourcc,
+                                       uint32_t device_buffer_length,
+                                       uint32_t stream_usage)
+    : buffer_(buffer),
+      is_mapped_(false),
+      device_buffer_length_(device_buffer_length),
+      stream_usage_(stream_usage) {
+  width_ = width;
+  height_ = height;
+  fourcc_ = fourcc;
+  buffer_size_ = device_buffer_length;
+
+  fd_ = v4l2_camera_hal::ion_fd;
+  //LOGF(ERROR) << __FUNCTION__ << " fd_: " << fd_; 
+  /*
+  LOGF(INFO) << "buffer: " << buffer << " fourcc: " << fourcc << " width: " << width << " height: " << height
+              << " device_buffer_length: " << device_buffer_length_
+              << " stream_usage: " << stream_usage;
+  */
+}
+
+GrallocFrameBuffer::~GrallocFrameBuffer() {
+  fd_ = -1;
+  if (Unmap()) {
+    LOGF(ERROR) << "Unmap failed";
+  }
+}
+
+int GrallocFrameBuffer::Map() {
+  //LOGF(ERROR) << "Map enter";
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    LOGF(ERROR) << "The buffer is already mapped";
+    return -EINVAL;
+  }
+
+  void* addr;
+  switch (fourcc_) {
+    case V4L2_PIX_FMT_YUV420:
+    case V4L2_PIX_FMT_YVU420:
+    case V4L2_PIX_FMT_YUYV:
+    case V4L2_PIX_FMT_NV21:
+    case V4L2_PIX_FMT_NV12:    
+      if (gralloc_register(buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+      } else {
+        android_ycbcr yuv_data;
+        int hal_format = v4l2_camera_hal::StreamFormat::V4L2ToHalPixelFormat(fourcc_);
+        if (hal_format < 0) {
+          LOGF(ERROR) << "map to hal pixel format failed";
+          return -EINVAL;
+        }
+        if(gralloc_lock_ycbcr(buffer_, stream_usage_, 0, 0, width_, height_, &yuv_data,
+                                  hal_format, width_, height_)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;                                  
+        }
+        addr = yuv_data.y;
+      }
+      break;
+    case V4L2_PIX_FMT_JPEG:
+      if (gralloc_register((buffer_handle_t &)buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+        } else {
+          if(gralloc_lock(buffer_, stream_usage_, 0, 0, device_buffer_length_, 1, &addr)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;
+          }
+        }
+      break;    
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      if (gralloc_register((buffer_handle_t &)buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+        } else {
+          if(gralloc_lock(buffer_, stream_usage_, 0, 0, width_, height_, &addr)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;
+          }
+        }
+      break;
+    default:
+      LOGF(ERROR) << "Unsupported fourcc";
+      return -EINVAL;
+  }
+
+  data_ = static_cast<uint8_t*>(addr);
+  if (fourcc_ == V4L2_PIX_FMT_YVU420 || fourcc_ == V4L2_PIX_FMT_YUV420 ||
+      fourcc_ == V4L2_PIX_FMT_NV21 || fourcc_ == V4L2_PIX_FMT_RGB32 ||
+      fourcc_ == V4L2_PIX_FMT_BGR32 || fourcc_ == V4L2_PIX_FMT_JPEG ||
+      fourcc_ == V4L2_PIX_FMT_NV12) {
+    buffer_size_ = ImageProcessor::GetConvertedSize(fourcc_, width_, height_);
+  }
+
+  is_mapped_ = true;
+  return 0;
+}
+
+int GrallocFrameBuffer::Unmap() {
+  //LOGF(ERROR) << "Unmap enter";
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    if (gralloc_unlock(buffer_)) {
+      LOGF(ERROR) << "Failed to unmap buffer";
+      return -EINVAL;
+    }
+
+    if (gralloc_unregister(buffer_)){
+      LOGF(ERROR) << "Failed to unmap buffer";
+      return -EINVAL;
+    }
+
+    is_mapped_ = false;
+  }
+
+  return 0;
+}
+
+int IonFrameBuffer:: CreateIONBuffer(int len)
+{
+  #define ALIGN(x, y) (((x) + ((y) - 1)) & (~((y) - 1)))
+  #define HEAP_MASK_FROM_TYPE(type) (1 << type)
+  #define ION_HEAP_TYPE_SYSTEM 0
+  #define ION_FLAG_CACHED 1
+  
+  int fd;
+  int rc = ion_alloc_fd(v4l2_camera_hal::ion_fd, ALIGN(len,4096), 0, HEAP_MASK_FROM_TYPE(ION_HEAP_TYPE_SYSTEM), 
+    ION_FLAG_CACHED, &fd);
+  if (rc || fd < 0) {
+    LOGF(ERROR) << "ION ALLOC memory failed " << len << " bytes with error " << rc;      
+    return -1;
+  }
+
+  //LOGF(INFO) << "ion_fd: " << v4l2_camera_hal::ion_fd << " alloc_data.fd: " << fd;
+  return fd;
+}  
+
+char * IonFrameBuffer::IonMap(int fd, int len)
+{
+  VLOGF_ENTER();
+  char *bufaddr = (char*)mmap(NULL, len, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+  if (bufaddr != MAP_FAILED)
+      cache_clean_invalidate(fd);
+  //LOGF(ERROR) << "mnmap " << " bufaddr: " << bufaddr << " len: " << len;
+  return bufaddr;
+}
+
+int IonFrameBuffer::IonUnmap(int fd, void *bufaddr, int len)
+{
+  VLOGF_ENTER();
+  cache_clean_invalidate(fd);
+  //LOGF(ERROR) << "munmap " << " bufaddr: " << bufaddr << " len: " << len;
+  if (-1 == munmap(bufaddr, len)) {
+      LOGF(ERROR) << "munmap failed " << strerror(errno) << " bufaddr: " << bufaddr << " len: " << len;
+      return -1;
+  }
+  return 0;
+}
+
+bool IonFrameBuffer:: AllocIonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height, size_t data_size){
+  width_ = width;
+  height_ = height;
+  fourcc_ = fourcc;
+  fd_ = CreateIONBuffer(data_size);
+  if (fd_ < 0) {
+    return false;
+  }
+  data_ = (unsigned char *)IonMap(fd_, data_size);
+  if (data_ == (unsigned char *)MAP_FAILED) {
+    LOGF(ERROR) << "IonMap() failed";
+    return false;
+  }
+
+  data_size_ = data_size;
+  buffer_size_ = data_size;  
+  return true; 
+}
+
+IonFrameBuffer::IonFrameBuffer(){
+    data_ = (unsigned char *)MAP_FAILED;
+    data_size_ = 0;
+    buffer_size_ = 0;  
+    fd_ = -1;   
+ }
+
+IonFrameBuffer:: IonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height){
+  size_t data_size = ImageProcessor::GetConvertedSize(fourcc, width, height);
+  AllocIonFrameBuffer(fourcc, width, height, data_size);
+}
+
+IonFrameBuffer:: ~IonFrameBuffer( ){
+  VLOGF_ENTER();
+  if (data_ != MAP_FAILED && data_size_ != 0) {
+    if (IonUnmap(fd_, data_, data_size_) == -1) {
+      LOGF(ERROR) << "mummap() failed: " << strerror(errno);
+    }
+    data_ = (unsigned char *)MAP_FAILED;
+    data_size_ = 0;
+    buffer_size_ = 0;  
+
+    close(fd_);
+    fd_ = -1;    
+  }
+}
+
+int IonFrameBuffer:: SetDataSize(size_t data_size)  {
+  VLOGF_ENTER();
+  //LOGF(INFO) << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (data_size_ < data_size) {
+    if (AllocIonFrameBuffer(fourcc_, width_, height_, data_size)){
+      VLOGF_EXIT();      
+      return 0;
+    } else {
+      VLOGF_EXIT();                 
+      return -1;
+    }
+  }
+
+  VLOGF_EXIT();
+  return 0;
+}
+
+void do_sync_ioctl(int fd, struct dma_buf_sync* sync) {
+    int rc = ioctl(fd, DMA_BUF_IOCTL_SYNC, sync);
+    if (rc < 0) {
+        LOGF(ERROR) << "Failed DMA_BUF_IOCTL_SYNC flags " << sync->flags << " rc " << rc;
+        return;
+    }
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/frame_buffer.h b/hardware/ntimespace/camera/arc/frame_buffer.h
new file mode 100644
index 0000000000..d2464ad719
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/frame_buffer.h
@@ -0,0 +1,268 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_FRAME_BUFFER_H_
+#define HAL_USB_FRAME_BUFFER_H_
+
+#include <cstdint>
+#include <memory>
+
+#include <base/files/scoped_file.h>
+#include <base/synchronization/lock.h>
+#include <hardware/gralloc.h>
+#include "common.h"
+#include <sys/mman.h>
+#include "linux/ion.h"
+#include <linux/dma-buf.h>
+
+namespace arc {
+
+class FrameBuffer {
+ public:
+  FrameBuffer();
+  virtual ~FrameBuffer();
+
+  // If mapped successfully, the address will be assigned to |data_| and return
+  // 0. Otherwise, returns -EINVAL.
+  virtual int Map() = 0;
+
+  // Unmaps the mapped address. Returns 0 for success.
+  virtual int Unmap() = 0;
+
+  uint8_t* GetData() const { return data_; }
+  size_t GetDataSize() const { return data_size_; }
+  size_t GetBufferSize() const { return buffer_size_; }
+  uint32_t GetWidth() const { return width_; }
+  uint32_t GetHeight() const { return height_; }
+  uint32_t GetFourcc() const { return fourcc_; }
+
+  void SetFourcc(uint32_t fourcc) { fourcc_ = fourcc; }
+  virtual int SetDataSize(size_t data_size);
+
+  int GetFd() const { return fd_; }
+  void SetFd(int fd) {fd_ = fd;}
+
+ protected:
+  uint8_t* data_;
+
+  // The number of bytes used in the buffer.
+  size_t data_size_;
+
+  // The number of bytes allocated in the buffer.
+  size_t buffer_size_;
+
+  // Frame resolution.
+  uint32_t width_;
+  uint32_t height_;
+
+  // This is V4L2_PIX_FMT_* in linux/videodev2.h.
+  uint32_t fourcc_;
+
+  //for v4l2 buffer, it's dma fd
+  //for gralloc buffer, it's ion fd
+  //for allocated buffer, it's backup fd for ion fd
+  int fd_;   
+};
+
+// AllocatedFrameBuffer is used for the buffer from hal malloc-ed. User should
+// be aware to manage the memory.
+class AllocatedFrameBuffer : public FrameBuffer {
+ public:
+  explicit AllocatedFrameBuffer(int buffer_size);
+  explicit AllocatedFrameBuffer(uint8_t* buffer, int buffer_size);
+  ~AllocatedFrameBuffer() override;
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+  int SetDataSize(size_t data_size) override;
+
+  void Reset();
+
+ private:
+  std::unique_ptr<uint8_t[]> buffer_;
+};
+
+
+// V4L2FrameBuffer is used for the buffer from V4L2CameraDevice. Maps the fd
+// in constructor. Unmaps and closes the fd in destructor.
+class V4L2FrameBuffer : public FrameBuffer {
+ public:
+  V4L2FrameBuffer();
+  // Unmaps |data_| and closes |fd_|.
+  ~V4L2FrameBuffer();
+
+  int Map() override;
+  int Unmap() override;
+
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+  int SetDataSize(size_t data_size);
+  void Reset();
+  void SetData(uint8_t* data);
+  uint8_t* GetMapStart() {return map_start_;}
+  void SetBufferSize(int buffer_size) { buffer_size_ = buffer_size;}
+  void SetOffset(int offset) { offset_ = offset;}
+
+ private:
+  static bool is_mapped_;
+  static uint8_t* map_start_;
+  int offset_;
+
+  // Lock to guard |is_mapped_|.
+  base::Lock lock_;
+};
+
+// GrallocFrameBuffer is used for the buffer from Android framework. Uses
+// CameraBufferMapper to lock and unlock the buffer.
+class GrallocFrameBuffer : public FrameBuffer {
+ public:
+  GrallocFrameBuffer(buffer_handle_t buffer, uint32_t width, uint32_t height,
+                     uint32_t fourcc, uint32_t device_buffer_length,
+                     uint32_t stream_usage);
+  ~GrallocFrameBuffer();
+
+  int Map() override;
+  int Unmap() override;
+
+  // The currently used buffer for |buffer_mapper_| operations.
+  buffer_handle_t buffer_;
+
+ private:
+  // Used to import gralloc buffer.
+  //const gralloc_module_t* gralloc_module_;
+
+  bool is_mapped_;
+
+  // Lock to guard |is_mapped_|.
+  base::Lock lock_;
+
+  // Camera stream and device buffer context.
+  uint32_t device_buffer_length_;
+  uint32_t stream_usage_;
+};
+
+class UnitTestFrameBuffer: public FrameBuffer {
+public:	
+	UnitTestFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height){
+		width_ = width;
+		height_ = height;
+		fourcc_ = fourcc;
+    data_size_ = 1280*1280*4;
+    data_ = new uint8_t[data_size_];
+	}
+  ~UnitTestFrameBuffer( ){
+    delete data_;
+	}
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size)  { data_size_ = data_size; return 0;}
+};
+
+class IonFrameBuffer: public FrameBuffer {
+public:	
+  IonFrameBuffer();
+  IonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height);
+  ~IonFrameBuffer( );
+
+  int CreateIONBuffer(int len);
+	bool AllocIonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height, size_t data_size);  
+ 
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size);
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+
+  char * IonMap(int fd, int len); 
+  int IonUnmap(int fd, void *bufaddr, int len);   
+};
+
+class SimpleFrameBuffer: public FrameBuffer {
+public:	
+	SimpleFrameBuffer(uint8_t* data, uint32_t fourcc, uint32_t width, uint32_t height, int fd, uint32_t data_size){
+		width_ = width;
+		height_ = height;
+		fourcc_ = fourcc;
+    data_size_ = data_size;
+    data_ = data;
+    fd_ = fd;
+	}
+  ~SimpleFrameBuffer( ){
+    data_ = nullptr;
+    data_size_ = 0;
+	}
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size)  { data_size_ = data_size; return 0;}
+};
+
+
+void do_sync_ioctl(int fd, struct dma_buf_sync* sync);
+
+static inline void sync_start_write(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_WRITE;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_write(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_WRITE;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_start_read(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_READ;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_read(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_READ;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_start_rw(int fd) {
+    VLOGF_ENTER();
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_RW;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_rw(int fd) {
+    VLOGF_ENTER();
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_RW;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void cache_clean(int fd) {
+    sync_start_write(fd);
+    sync_end_write(fd);
+}
+
+static inline void cache_invalidate(int fd) {
+    sync_start_write(fd);
+    sync_end_read(fd);
+}
+
+static inline void cache_clean_invalidate(int /*fd*/) {
+    //sync_start_rw(fd);
+    //sync_end_rw(fd);
+}
+
+}  // namespace arc
+
+#endif  // HAL_USB_FRAME_BUFFER_H_
diff --git a/hardware/ntimespace/camera/arc/image_processor.cpp b/hardware/ntimespace/camera/arc/image_processor.cpp
new file mode 100644
index 0000000000..99f6f726fc
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/image_processor.cpp
@@ -0,0 +1,663 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/image_processor.h"
+
+#include <cerrno>
+#include <ctime>
+#include <string>
+
+#include <libyuv.h>
+#include "arc/common.h"
+#include "arc/exif_utils.h"
+#include "arc/jpeg_compressor.h"
+#include "debug.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+//#include "hardware/hw_converter.h"
+
+
+namespace arc {
+
+using android::CameraMetadata;
+
+/*
+ * Formats have different names in different header files. Here is the mapping
+ * table:
+ *
+ * android_pixel_format_t          videodev2.h           FOURCC in libyuv
+ * -----------------------------------------------------------------------------
+ * HAL_PIXEL_FORMAT_YV12         = V4L2_PIX_FMT_YVU420 = FOURCC_YV12
+ * HAL_PIXEL_FORMAT_YCrCb_420_SP = V4L2_PIX_FMT_NV21   = FOURCC_NV21
+ * HAL_PIXEL_FORMAT_RGBA_8888    = V4L2_PIX_FMT_RGB32  = FOURCC_BGR4 //wrong, should be V4L2_PIX_FMT_BGR32
+ * HAL_PIXEL_FORMAT_YCbCr_422_I  = V4L2_PIX_FMT_YUYV   = FOURCC_YUYV
+ *                                                     = FOURCC_YUY2
+ *                                 V4L2_PIX_FMT_YUV420 = FOURCC_I420
+ *                                                     = FOURCC_YU12
+ *                                 V4L2_PIX_FMT_MJPEG  = FOURCC_MJPG
+ *
+ * Camera device generates FOURCC_YUYV and FOURCC_MJPG.
+ * Preview needs FOURCC_ARGB format.
+ * Software video encoder needs FOURCC_YU12.
+ * CTS requires FOURCC_YV12 and FOURCC_NV21 for applications.
+ *
+ * Android stride requirement:
+ * YV12 horizontal stride should be a multiple of 16 pixels. See
+ * android.graphics.ImageFormat.YV12.
+ * The stride of ARGB, YU12, and NV21 are always equal to the width.
+ *
+ * Conversion Path:
+ * MJPG/YUYV (from camera) -> YU12 -> ARGB (preview)
+ *                                 -> NV21 (apps)
+ *                                 -> YV12 (apps)
+ *                                 -> YU12 (video encoder)
+ */
+
+// YV12 horizontal stride should be a multiple of 16 pixels for each plane.
+// |dst_stride_uv| is the pixel stride of u or v plane.
+static int YU12ToYV12(const void* yv12, void* yu12, int width, int height,
+                      int dst_stride_y, int dst_stride_uv);
+static int YU12ToNV21(const void* yv12, void* nv21, int width, int height);
+static bool ConvertToJpeg(const CameraMetadata& metadata,
+                          const FrameBuffer& in_frame, FrameBuffer* out_frame);
+static bool SetExifTags(const CameraMetadata& metadata, ExifUtils* utils);
+
+// How precise the float-to-rational conversion for EXIF tags would be.
+static const int kRationalPrecision = 10000;
+
+// Default JPEG quality settings.
+static const int DEFAULT_JPEG_QUALITY = 80;
+
+inline static size_t Align16(size_t value) { return (value + 15) & ~15; }
+
+size_t ImageProcessor::GetConvertedSize(int fourcc, uint32_t width,
+                                        uint32_t height) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return 0;
+  }
+
+  switch (fourcc) {
+    case V4L2_PIX_FMT_YVU420:  // YV12
+      return Align16(width) * height + Align16(width / 2) * height;
+    case V4L2_PIX_FMT_YUV420:  // YU12
+    // Fall-through.
+    case V4L2_PIX_FMT_NV21:  // NV21
+    case V4L2_PIX_FMT_NV12:  // NV12
+      return (width) * height * 3 / 2;
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      return (width) * height * 4;
+    case V4L2_PIX_FMT_JPEG:
+      return (width) * height * 4; // For JPEG real size will be calculated after conversion.
+    default:
+      LOGF(ERROR) << "Pixel format " << FormatToString(fourcc)
+                  << " is unsupported.";
+      return 0;
+  }
+}
+
+bool ImageProcessor::SupportsConversion(uint32_t from_fourcc,
+                                        uint32_t to_fourcc) {
+  switch (from_fourcc) {
+    case V4L2_PIX_FMT_YUYV:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420);
+    case V4L2_PIX_FMT_YUV420:
+      return (
+          to_fourcc == V4L2_PIX_FMT_YUV420 ||
+          to_fourcc == V4L2_PIX_FMT_YVU420 || to_fourcc == V4L2_PIX_FMT_NV21 ||
+          to_fourcc == V4L2_PIX_FMT_RGB32 || to_fourcc == V4L2_PIX_FMT_BGR32 ||
+          to_fourcc == V4L2_PIX_FMT_JPEG  || to_fourcc == V4L2_PIX_FMT_NV12);
+    case V4L2_PIX_FMT_MJPEG:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420);
+    case V4L2_PIX_FMT_RGB32:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420 || to_fourcc == V4L2_PIX_FMT_NV12
+             || to_fourcc == V4L2_PIX_FMT_NV21);      
+    default:
+      return false;
+  }
+}
+
+int ImageProcessor::ConvertFormat(const CameraMetadata& metadata,
+                                  const FrameBuffer& in_frame,
+                                  FrameBuffer* out_frame) {
+/*  LOGF(INFO) << "[libYUV] in_frame: "
+              << FormatToString(in_frame.GetFourcc())
+              << " "
+              << in_frame.GetFourcc()
+              << " width "
+              << in_frame.GetWidth()
+              << " height "
+              << in_frame.GetHeight()
+              << " size "
+              << in_frame.GetDataSize();   
+
+  LOGF(INFO) << "[libYUV] out_frame: "
+              << FormatToString(out_frame->GetFourcc())
+              << " "
+              << out_frame->GetFourcc()
+              << " width "
+              << out_frame->GetWidth()
+              << " height "
+              << out_frame->GetHeight()
+              << " size "
+              << out_frame->GetDataSize();              
+*/
+  if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                << " x " << in_frame.GetHeight() << ")";
+    return -EINVAL;
+  }
+
+  if (in_frame.GetFourcc() == out_frame->GetFourcc() &&
+      in_frame.GetWidth() == out_frame->GetWidth() &&
+      in_frame.GetHeight() == out_frame->GetHeight())
+  {
+    memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+    return 0;        
+  }
+  size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+
+  if (out_frame->SetDataSize(data_size)) {
+    LOGF(ERROR) << "Set data size failed";
+    return -EINVAL;
+  }
+
+  if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUYV) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int res = libyuv::YUY2ToI420(
+            in_frame.GetData(),      /* src_yuy2 */
+            in_frame.GetWidth() * 2, /* src_stride_yuy2 */
+            out_frame->GetData(),    /* dst_y */
+            out_frame->GetWidth(),   /* dst_stride_y */
+            out_frame->GetData() +
+                out_frame->GetWidth() * out_frame->GetHeight(), /* dst_u */
+            out_frame->GetWidth() / 2, /* dst_stride_u */
+            out_frame->GetData() + out_frame->GetWidth() *
+                                       out_frame->GetHeight() * 5 /
+                                       4, /* dst_v */
+            out_frame->GetWidth() / 2,    /* dst_stride_v */
+            in_frame.GetWidth(), in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "YUY2ToI420() for YU12 returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for YUYV source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUV420) { //YU12
+    // V4L2_PIX_FMT_YVU420 is YV12. I420 is usually referred to YU12
+    // (V4L2_PIX_FMT_YUV420), and YV12 is similar to YU12 except that U/V
+    // planes are swapped.
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YVU420:  // YV12
+      {  
+        int ystride = Align16(in_frame.GetWidth());
+        int uvstride = Align16(in_frame.GetWidth() / 2);
+        int res = YU12ToYV12(in_frame.GetData(), out_frame->GetData(),
+                             in_frame.GetWidth(), in_frame.GetHeight(), ystride,
+                             uvstride);
+        LOGF_IF(ERROR, res) << "YU12ToYV12() returns " << res;
+        return res ? -EINVAL : 0;    
+      }
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        memcpy(out_frame->GetData(), in_frame.GetData(),
+               in_frame.GetDataSize());
+        return 0;
+      }
+      case V4L2_PIX_FMT_NV21:  // NV21
+      {
+        // TODO(henryhsu): Use libyuv::I420ToNV21.
+        int res = YU12ToNV21(in_frame.GetData(), out_frame->GetData(),
+                             in_frame.GetWidth(), in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "YU12ToNV21() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_NV12:  
+      {
+        int res = libyuv::I420ToNV12(
+          in_frame.GetData(),  /* src_y */
+          in_frame.GetWidth(), /* src_stride_y */
+          in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+          in_frame.GetWidth() / 2,                        /* src_stride_u */
+          in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+          in_frame.GetWidth() / 2,   /* src_stride_v */
+          out_frame->GetData(),  /*dst_y*/
+          out_frame->GetWidth(),  /*dst_stride_y*/
+          out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(), /*dst_uv*/
+          out_frame->GetWidth(), /*dst_stride_uv*/
+          in_frame.GetWidth(), 
+          in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "I420ToNV12() returns " << res;
+        return res ? -EINVAL : 0;
+      }   
+      case V4L2_PIX_FMT_BGR32: {
+        int res = libyuv::I420ToABGR(
+            in_frame.GetData(),  /* src_y */
+            in_frame.GetWidth(), /* src_stride_y */
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+            in_frame.GetWidth() / 2,                        /* src_stride_u */
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+            in_frame.GetWidth() / 2,   /* src_stride_v */
+            out_frame->GetData(),      /* dst_abgr */
+            out_frame->GetWidth() * 4, /* dst_stride_abgr */
+            in_frame.GetWidth(), 
+            in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "I420ToABGR() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_RGB32: {
+        LOG(INFO) << "libyuv::I420ToABGR";
+        int res = libyuv::I420ToABGR(
+            in_frame.GetData(),  /* src_y */
+            in_frame.GetWidth(), /* src_stride_y */
+            in_frame.GetData() +
+                in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+            in_frame.GetWidth() / 2,                        /* src_stride_u */
+            in_frame.GetData() +
+                in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+            in_frame.GetWidth() / 2,   /* src_stride_v */
+            out_frame->GetData(),      /* dst_argb */
+            out_frame->GetWidth() * 4, /* dst_stride_argb */
+            in_frame.GetWidth(), in_frame.GetHeight());                
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_JPEG: {
+        bool res = ConvertToJpeg(metadata, in_frame, out_frame);
+        LOGF_IF(ERROR, !res) << "ConvertToJpeg() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for YU12 source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_MJPEG) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int res = libyuv::MJPGToI420(
+            in_frame.GetData(),     /* sample */
+            in_frame.GetDataSize(), /* sample_size */
+            out_frame->GetData(),   /* dst_y */
+            out_frame->GetWidth(),  /* dst_stride_y */
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(), /* dst_u */
+            out_frame->GetWidth() / 2, /* dst_stride_u */
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4, /* dst_v */
+            out_frame->GetWidth() / 2,    /* dst_stride_v */
+            in_frame.GetWidth(), 
+            in_frame.GetHeight(), 
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "MJPEGToI420() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for MJPEG source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int dst_stride = (out_frame->GetWidth());
+        int res = libyuv::ABGRToI420(  //memory map r/g/b/a
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),     /*dest y*/  
+            dst_stride,    /*dst_stride_y*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),  /*dst_u*/
+            dst_stride / 2,  /*dst_stide_u*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,       /*dst_v*/
+            dst_stride / 2,       /*dst_stride*/
+            out_frame->GetWidth(),
+            out_frame->GetHeight());          
+        LOGF_IF(ERROR, res) << "ABGRToI420() returns " << res;
+        return res ? -EINVAL : 0;   
+      }
+      case V4L2_PIX_FMT_NV12:  
+      {
+        uint32_t dst_c_stride = out_frame->GetWidth();
+        int res = libyuv::ARGBToNV12(
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),   
+            dst_c_stride,
+            out_frame->GetData() + dst_c_stride * out_frame->GetHeight(), 
+            dst_c_stride,  
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "ABGRToNV12() returns " << res;
+        return res ? -EINVAL : 0;        
+      }
+      case V4L2_PIX_FMT_NV21:  
+      {
+        uint32_t dst_c_stride = out_frame->GetWidth();
+        int res = libyuv::ARGBToNV21(
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),   
+            dst_c_stride,
+            out_frame->GetData() + dst_c_stride * out_frame->GetHeight(), 
+            dst_c_stride,  
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "ARGBToI420() returns " << res;
+        return res ? -EINVAL : 0;        
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for RGB32 source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:   //yu12, I420
+      {
+        int res = libyuv::NV12ToI420(
+            in_frame.GetData(),      /*src_y*/
+            in_frame.GetWidth(),     /*src_y_stride*/
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(),  /* src_uv */
+            in_frame.GetWidth(),    /*src_uv_stride*/
+            out_frame->GetData(),    /*dst_y*/
+            out_frame->GetWidth(),    /*dst_w*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+            out_frame->GetWidth() / 2,
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+            out_frame->GetWidth() / 2,
+            out_frame->GetWidth(), 
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "YUY2ToI420() for YU12 returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_RGB32: 
+      {
+        int res = libyuv::NV12ToARGB(
+            in_frame.GetData(),  
+            in_frame.GetWidth(), 
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), 
+            in_frame.GetWidth(),
+            out_frame->GetData(),      
+            out_frame->GetWidth() * 4, 
+            out_frame->GetWidth(), 
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "NV12ToARGB() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for NV12 source format.";
+        return -EINVAL;
+    }
+  } else {
+    LOGF(ERROR) << "Convert format doesn't support source format "
+                << FormatToString(in_frame.GetFourcc())
+                << "   "
+                << in_frame.GetFourcc();
+    return -EINVAL;
+  }
+}
+
+int ImageProcessor::Scale(const FrameBuffer& in_frame, FrameBuffer* out_frame, int buf_id) {
+  dump_data(dump_data_index, (unsigned char *)in_frame.GetData(), 
+                          in_frame.GetWidth(), 
+                          in_frame.GetHeight(), 
+                          in_frame.GetFourcc(),
+                          buf_id, "scale_pre");
+  if (in_frame.GetFourcc() != V4L2_PIX_FMT_YUV420) {
+    LOGF(ERROR) << "Pixel format " << FormatToString(in_frame.GetFourcc())
+                << " is unsupported.";
+    return -EINVAL;
+  }
+
+  size_t data_size = GetConvertedSize(
+      in_frame.GetFourcc(), out_frame->GetWidth(), out_frame->GetHeight());
+
+  if (out_frame->SetDataSize(data_size)) {
+    LOGF(ERROR) << "Set data size failed";
+    return -EINVAL;
+  }
+  out_frame->SetFourcc(in_frame.GetFourcc());
+
+  VLOGF(1) << "Scale image from " << in_frame.GetWidth() << "x"
+           << in_frame.GetHeight() << " to " << out_frame->GetWidth() << "x"
+           << out_frame->GetHeight();
+
+  int ret = libyuv::I420Scale(
+      in_frame.GetData(), in_frame.GetWidth(),
+      in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(),
+      in_frame.GetWidth() / 2,
+      in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4,
+      in_frame.GetWidth() / 2, in_frame.GetWidth(), in_frame.GetHeight(),
+      out_frame->GetData(), out_frame->GetWidth(),
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+      out_frame->GetWidth() / 2,
+      out_frame->GetData() +
+          out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+      out_frame->GetWidth() / 2, out_frame->GetWidth(), out_frame->GetHeight(),
+      libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, ret) << "I420Scale failed: " << ret;
+
+  dump_data(dump_data_index, (unsigned char *)out_frame->GetData(), 
+                        out_frame->GetWidth(), 
+                        out_frame->GetHeight(), 
+                        out_frame->GetFourcc(),
+                        buf_id, "scale_post");
+  return ret;
+}
+
+static int YU12ToYV12(const void* yu12, void* yv12, int width, int height,
+                      int dst_stride_y, int dst_stride_uv) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return -EINVAL;
+  }
+  if (dst_stride_y < width || dst_stride_uv < width / 2) {
+    LOGF(ERROR) << "Y plane stride (" << dst_stride_y
+                << ") or U/V plane stride (" << dst_stride_uv
+                << ") is invalid for width " << width;
+    return -EINVAL;
+  }
+
+  const uint8_t* src = reinterpret_cast<const uint8_t*>(yu12);
+  uint8_t* dst = reinterpret_cast<uint8_t*>(yv12);
+  const uint8_t* u_src = src + width * height;
+  uint8_t* u_dst = dst + dst_stride_y * height + dst_stride_uv * height / 2;
+  const uint8_t* v_src = src + width * height * 5 / 4;
+  uint8_t* v_dst = dst + dst_stride_y * height;
+
+  return libyuv::I420Copy(src, width, u_src, width / 2, v_src, width / 2, dst,
+                          dst_stride_y, u_dst, dst_stride_uv, v_dst,
+                          dst_stride_uv, width, height);
+}
+
+static int YU12ToNV21(const void* yu12, void* nv21, int width, int height) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return -EINVAL;
+  }
+
+  const uint8_t* src = reinterpret_cast<const uint8_t*>(yu12);
+  uint8_t* dst = reinterpret_cast<uint8_t*>(nv21);
+  const uint8_t* u_src = src + width * height;
+  const uint8_t* v_src = src + width * height * 5 / 4;
+  uint8_t* vu_dst = dst + width * height;
+
+  memcpy(dst, src, width * height);
+
+  for (int i = 0; i < height / 2; i++) {
+    for (int j = 0; j < width / 2; j++) {
+      *vu_dst++ = *v_src++;
+      *vu_dst++ = *u_src++;
+    }
+  }
+  return 0;
+}
+
+static bool ConvertToJpeg(const CameraMetadata& metadata,
+                          const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  ExifUtils utils;
+  int jpeg_quality, thumbnail_jpeg_quality;
+#if 0  
+  camera_metadata_ro_entry entry;
+
+  if (metadata.exists(ANDROID_JPEG_QUALITY)) {
+    entry = metadata.find(ANDROID_JPEG_QUALITY);
+    jpeg_quality = entry.data.u8[0];
+  } else {
+    LOGF(ERROR) << "Could not find jpeg quality in metadata, defaulting to "
+                << DEFAULT_JPEG_QUALITY;
+    jpeg_quality = DEFAULT_JPEG_QUALITY;
+  }
+  if (metadata.exists(ANDROID_JPEG_THUMBNAIL_QUALITY)) {
+    entry = metadata.find(ANDROID_JPEG_THUMBNAIL_QUALITY);
+    thumbnail_jpeg_quality = entry.data.u8[0];
+  } else {
+    thumbnail_jpeg_quality = jpeg_quality;
+  }
+#else
+  jpeg_quality = DEFAULT_JPEG_QUALITY;
+  thumbnail_jpeg_quality = DEFAULT_JPEG_QUALITY;
+#endif
+
+  if (!utils.Initialize(in_frame.GetData(), in_frame.GetWidth(),
+                        in_frame.GetHeight(), thumbnail_jpeg_quality)) {
+    LOGF(ERROR) << "ExifUtils initialization failed.";
+    return false;
+  }
+  if (!SetExifTags(metadata, &utils)) {
+    LOGF(ERROR) << "Setting Exif tags failed.";
+    return false;
+  }
+  if (!utils.GenerateApp1()) {
+    LOGF(ERROR) << "Generating APP1 segment failed.";
+    return false;
+  }
+  JpegCompressor compressor;
+  if (!compressor.CompressImage(in_frame.GetData(), in_frame.GetWidth(),
+                                in_frame.GetHeight(), jpeg_quality,
+                                utils.GetApp1Buffer(), utils.GetApp1Length())) {
+    LOGF(ERROR) << "JPEG image compression failed";
+    return false;
+  }
+  size_t buffer_length = compressor.GetCompressedImageSize();
+  if (out_frame->SetDataSize(buffer_length)) {
+    return false;
+  }
+  memcpy(out_frame->GetData(), compressor.GetCompressedImagePtr(),
+         buffer_length);
+  return true;
+}
+
+static bool SetExifTags(const CameraMetadata& metadata, ExifUtils* utils) {
+  time_t raw_time = 0;
+  struct tm time_info;
+  bool time_available = time(&raw_time) != -1;
+  localtime_r(&raw_time, &time_info);
+  if (!utils->SetDateTime(time_info)) {
+    LOGF(ERROR) << "Setting data time failed.";
+    return false;
+  }
+
+  float focal_length;
+  camera_metadata_ro_entry entry = metadata.find(ANDROID_LENS_FOCAL_LENGTH);
+  if (entry.count) {
+    focal_length = entry.data.f[0];
+  } else {
+    LOGF(ERROR) << "Cannot find focal length in metadata.";
+    return false;
+  }
+  if (!utils->SetFocalLength(
+          static_cast<uint32_t>(focal_length * kRationalPrecision),
+          kRationalPrecision)) {
+    LOGF(ERROR) << "Setting focal length failed.";
+    return false;
+  }
+
+  if (metadata.exists(ANDROID_JPEG_GPS_COORDINATES)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_COORDINATES);
+    if (entry.count < 3) {
+      LOGF(ERROR) << "Gps coordinates in metadata is not complete.";
+      return false;
+    }
+    if (!utils->SetGpsLatitude(entry.data.d[0])) {
+      LOGF(ERROR) << "Setting gps latitude failed.";
+      return false;
+    }
+    if (!utils->SetGpsLongitude(entry.data.d[1])) {
+      LOGF(ERROR) << "Setting gps longitude failed.";
+      return false;
+    }
+    if (!utils->SetGpsAltitude(entry.data.d[2])) {
+      LOGF(ERROR) << "Setting gps altitude failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_GPS_PROCESSING_METHOD)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_PROCESSING_METHOD);
+    std::string method_str(reinterpret_cast<const char*>(entry.data.u8));
+    if (!utils->SetGpsProcessingMethod(method_str)) {
+      LOGF(ERROR) << "Setting gps processing method failed.";
+      return false;
+    }
+  }
+
+  if (time_available && metadata.exists(ANDROID_JPEG_GPS_TIMESTAMP)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_TIMESTAMP);
+    time_t timestamp = static_cast<time_t>(entry.data.i64[0]);
+    if (gmtime_r(&timestamp, &time_info)) {
+      if (!utils->SetGpsTimestamp(time_info)) {
+        LOGF(ERROR) << "Setting gps timestamp failed.";
+        return false;
+      }
+    } else {
+      LOGF(ERROR) << "Time tranformation failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_ORIENTATION)) {
+    entry = metadata.find(ANDROID_JPEG_ORIENTATION);
+    LOGF(ERROR) << "Hit ANDROID_JPEG_ORIENTATION: " << entry.data.i32[0];
+    if (!utils->SetOrientation(entry.data.i32[0])) {
+      LOGF(ERROR) << "Setting orientation failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_THUMBNAIL_SIZE)) {
+    entry = metadata.find(ANDROID_JPEG_THUMBNAIL_SIZE);
+    if (entry.count < 2) {
+      LOGF(ERROR) << "Thumbnail size in metadata is not complete.";
+      return false;
+    }
+    int thumbnail_width = entry.data.i32[0];
+    int thumbnail_height = entry.data.i32[1];
+    if (thumbnail_width > 0 && thumbnail_height > 0) {
+      if (!utils->SetThumbnailSize(static_cast<uint16_t>(thumbnail_width),
+                                   static_cast<uint16_t>(thumbnail_height))) {
+        LOGF(ERROR) << "Setting thumbnail size failed.";
+        return false;
+      }
+    }
+  }
+  return true;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/image_processor.h b/hardware/ntimespace/camera/arc/image_processor.h
new file mode 100644
index 0000000000..cc25eb1b84
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/image_processor.h
@@ -0,0 +1,47 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_IMAGE_PROCESSOR_H_
+#define HAL_USB_IMAGE_PROCESSOR_H_
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+// FourCC pixel formats (defined as V4L2_PIX_FMT_*).
+#include <linux/videodev2.h>
+// Declarations of HAL_PIXEL_FORMAT_XXX.
+#include <system/graphics.h>
+
+#include "frame_buffer.h"
+
+namespace arc {
+
+// V4L2_PIX_FMT_YVU420(YV12) in ImageProcessor has alignment requirement.
+// The stride of Y, U, and V planes should a multiple of 16 pixels.
+struct ImageProcessor {
+  // Calculate the output buffer size when converting to the specified pixel
+  // format. |fourcc| is defined as V4L2_PIX_FMT_* in linux/videodev2.h.
+  // Return 0 on error.
+  static size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height);
+
+  // Return whether this class supports the provided conversion.
+  static bool SupportsConversion(uint32_t from_fourcc, uint32_t to_fourcc);
+
+  // Convert format from |in_frame.fourcc| to |out_frame->fourcc|. Caller should
+  // fill |data|, |buffer_size|, |width|, and |height| of |out_frame|. The
+  // function will fill |out_frame->data_size|. Return non-zero error code on
+  // failure; return 0 on success.
+  static int ConvertFormat(const android::CameraMetadata& metadata,
+                           const FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+  // Scale image size according to |in_frame| and |out_frame|. Only support
+  // V4L2_PIX_FMT_YUV420 format. Caller should fill |data|, |width|, |height|,
+  // and |buffer_size| of |out_frame|. The function will fill |data_size| and
+  // |fourcc| of |out_frame|.
+  static int Scale(const FrameBuffer& in_frame, FrameBuffer* out_frame, int buf_id);
+};
+
+}  // namespace arc
+
+#endif  // HAL_USB_IMAGE_PROCESSOR_H_
diff --git a/hardware/ntimespace/camera/arc/jpeg_compressor.cpp b/hardware/ntimespace/camera/arc/jpeg_compressor.cpp
new file mode 100644
index 0000000000..0a7b20bd69
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/jpeg_compressor.cpp
@@ -0,0 +1,188 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/jpeg_compressor.h"
+
+#include <memory>
+
+#include "arc/common.h"
+
+namespace arc {
+
+// The destination manager that can access |result_buffer_| in JpegCompressor.
+struct destination_mgr {
+ public:
+  struct jpeg_destination_mgr mgr;
+  JpegCompressor* compressor;
+};
+
+JpegCompressor::JpegCompressor() {}
+
+JpegCompressor::~JpegCompressor() {}
+
+bool JpegCompressor::CompressImage(const void* image, int width, int height,
+                                   int quality, const void* app1Buffer,
+                                   unsigned int app1Size) {
+  if (width % 8 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "Image size can not be handled: " << width << "x" << height;
+    return false;
+  }
+
+  result_buffer_.clear();
+  if (!Encode(image, width, height, quality, app1Buffer, app1Size)) {
+    return false;
+  }
+  LOGF(INFO) << "Compressed JPEG: " << (width * height * 12) / 8 << "[" << width
+             << "x" << height << "] -> " << result_buffer_.size() << " bytes";
+  return true;
+}
+
+const void* JpegCompressor::GetCompressedImagePtr() {
+  return result_buffer_.data();
+}
+
+size_t JpegCompressor::GetCompressedImageSize() {
+  return result_buffer_.size();
+}
+
+void JpegCompressor::InitDestination(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  buffer.resize(kBlockSize);
+  dest->mgr.next_output_byte = &buffer[0];
+  dest->mgr.free_in_buffer = buffer.size();
+}
+
+boolean JpegCompressor::EmptyOutputBuffer(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  size_t oldsize = buffer.size();
+  buffer.resize(oldsize + kBlockSize);
+  dest->mgr.next_output_byte = &buffer[oldsize];
+  dest->mgr.free_in_buffer = kBlockSize;
+  return true;
+}
+
+void JpegCompressor::TerminateDestination(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  buffer.resize(buffer.size() - dest->mgr.free_in_buffer);
+}
+
+void JpegCompressor::OutputErrorMessage(j_common_ptr cinfo) {
+  char buffer[JMSG_LENGTH_MAX];
+
+  /* Create the message */
+  (*cinfo->err->format_message)(cinfo, buffer);
+  LOGF(ERROR) << buffer;
+}
+
+bool JpegCompressor::Encode(const void* inYuv, int width, int height,
+                            int jpegQuality, const void* app1Buffer,
+                            unsigned int app1Size) {
+  jpeg_compress_struct cinfo;
+  jpeg_error_mgr jerr;
+
+  cinfo.err = jpeg_std_error(&jerr);
+  // Override output_message() to print error log with ALOGE().
+  cinfo.err->output_message = &OutputErrorMessage;
+  jpeg_create_compress(&cinfo);
+  SetJpegDestination(&cinfo);
+
+  SetJpegCompressStruct(width, height, jpegQuality, &cinfo);
+  jpeg_start_compress(&cinfo, TRUE);
+
+  if (app1Buffer != nullptr && app1Size > 0) {
+    jpeg_write_marker(&cinfo, JPEG_APP0 + 1,
+                      static_cast<const JOCTET*>(app1Buffer), app1Size);
+  }
+
+  if (!Compress(&cinfo, static_cast<const uint8_t*>(inYuv))) {
+    return false;
+  }
+  jpeg_finish_compress(&cinfo);
+  return true;
+}
+
+void JpegCompressor::SetJpegDestination(jpeg_compress_struct* cinfo) {
+  destination_mgr* dest =
+      static_cast<struct destination_mgr*>((*cinfo->mem->alloc_small)(
+          (j_common_ptr)cinfo, JPOOL_PERMANENT, sizeof(destination_mgr)));
+  dest->compressor = this;
+  dest->mgr.init_destination = &InitDestination;
+  dest->mgr.empty_output_buffer = &EmptyOutputBuffer;
+  dest->mgr.term_destination = &TerminateDestination;
+  cinfo->dest = reinterpret_cast<struct jpeg_destination_mgr*>(dest);
+}
+
+void JpegCompressor::SetJpegCompressStruct(int width, int height, int quality,
+                                           jpeg_compress_struct* cinfo) {
+  cinfo->image_width = width;
+  cinfo->image_height = height;
+  cinfo->input_components = 3;
+  cinfo->in_color_space = JCS_YCbCr;
+  jpeg_set_defaults(cinfo);
+
+  jpeg_set_quality(cinfo, quality, TRUE);
+  jpeg_set_colorspace(cinfo, JCS_YCbCr);
+  cinfo->raw_data_in = TRUE;
+  cinfo->dct_method = JDCT_IFAST;
+
+  // Configure sampling factors. The sampling factor is JPEG subsampling 420
+  // because the source format is YUV420.
+  cinfo->comp_info[0].h_samp_factor = 2;
+  cinfo->comp_info[0].v_samp_factor = 2;
+  cinfo->comp_info[1].h_samp_factor = 1;
+  cinfo->comp_info[1].v_samp_factor = 1;
+  cinfo->comp_info[2].h_samp_factor = 1;
+  cinfo->comp_info[2].v_samp_factor = 1;
+}
+
+bool JpegCompressor::Compress(jpeg_compress_struct* cinfo, const uint8_t* yuv) {
+  JSAMPROW y[kCompressBatchSize];
+  JSAMPROW cb[kCompressBatchSize / 2];
+  JSAMPROW cr[kCompressBatchSize / 2];
+  JSAMPARRAY planes[3]{y, cb, cr};
+
+  size_t y_plane_size = cinfo->image_width * cinfo->image_height;
+  size_t uv_plane_size = y_plane_size / 4;
+  uint8_t* y_plane = const_cast<uint8_t*>(yuv);
+  uint8_t* u_plane = const_cast<uint8_t*>(yuv + y_plane_size);
+  uint8_t* v_plane = const_cast<uint8_t*>(yuv + y_plane_size + uv_plane_size);
+  std::unique_ptr<uint8_t[]> empty(new uint8_t[cinfo->image_width]);
+  memset(empty.get(), 0, cinfo->image_width);
+
+  while (cinfo->next_scanline < cinfo->image_height) {
+    for (int i = 0; i < kCompressBatchSize; ++i) {
+      size_t scanline = cinfo->next_scanline + i;
+      if (scanline < cinfo->image_height) {
+        y[i] = y_plane + scanline * cinfo->image_width;
+      } else {
+        y[i] = empty.get();
+      }
+    }
+    // cb, cr only have half scanlines
+    for (int i = 0; i < kCompressBatchSize / 2; ++i) {
+      size_t scanline = cinfo->next_scanline / 2 + i;
+      if (scanline < cinfo->image_height / 2) {
+        int offset = scanline * (cinfo->image_width / 2);
+        cb[i] = u_plane + offset;
+        cr[i] = v_plane + offset;
+      } else {
+        cb[i] = cr[i] = empty.get();
+      }
+    }
+
+    int processed = jpeg_write_raw_data(cinfo, planes, kCompressBatchSize);
+    if (processed != kCompressBatchSize) {
+      LOGF(ERROR) << "Number of processed lines does not equal input lines.";
+      return false;
+    }
+  }
+  return true;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/jpeg_compressor.h b/hardware/ntimespace/camera/arc/jpeg_compressor.h
new file mode 100644
index 0000000000..499b9aaffc
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/jpeg_compressor.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_JPEG_COMPRESSOR_H_
+#define INCLUDE_ARC_JPEG_COMPRESSOR_H_
+
+// We must include cstdio before jpeglib.h. It is a requirement of libjpeg.
+#include <cstdio>
+#include <vector>
+
+extern "C" {
+#include <jerror.h>
+#include <jpeglib.h>
+}
+
+namespace arc {
+
+// Encapsulates a converter from YU12 to JPEG format. This class is not
+// thread-safe.
+class JpegCompressor {
+ public:
+  JpegCompressor();
+  ~JpegCompressor();
+
+  // Compresses YU12 image to JPEG format. After calling this method, call
+  // GetCompressedImagePtr() to get the image. |quality| is the resulted jpeg
+  // image quality. It ranges from 1 (poorest quality) to 100 (highest quality).
+  // |app1Buffer| is the buffer of APP1 segment (exif) which will be added to
+  // the compressed image. Returns false if errors occur during compression.
+  bool CompressImage(const void* image, int width, int height, int quality,
+                     const void* app1Buffer, unsigned int app1Size);
+
+  // Returns the compressed JPEG buffer pointer. This method must be called only
+  // after calling CompressImage().
+  const void* GetCompressedImagePtr();
+
+  // Returns the compressed JPEG buffer size. This method must be called only
+  // after calling CompressImage().
+  size_t GetCompressedImageSize();
+
+ private:
+  // InitDestination(), EmptyOutputBuffer() and TerminateDestination() are
+  // callback functions to be passed into jpeg library.
+  static void InitDestination(j_compress_ptr cinfo);
+  static boolean EmptyOutputBuffer(j_compress_ptr cinfo);
+  static void TerminateDestination(j_compress_ptr cinfo);
+  static void OutputErrorMessage(j_common_ptr cinfo);
+
+  // Returns false if errors occur.
+  bool Encode(const void* inYuv, int width, int height, int jpegQuality,
+              const void* app1Buffer, unsigned int app1Size);
+  void SetJpegDestination(jpeg_compress_struct* cinfo);
+  void SetJpegCompressStruct(int width, int height, int quality,
+                             jpeg_compress_struct* cinfo);
+  // Returns false if errors occur.
+  bool Compress(jpeg_compress_struct* cinfo, const uint8_t* yuv);
+
+  // The block size for encoded jpeg image buffer.
+  static const int kBlockSize = 16384;
+  // Process 16 lines of Y and 16 lines of U/V each time.
+  // We must pass at least 16 scanlines according to libjpeg documentation.
+  static const int kCompressBatchSize = 16;
+
+  // The buffer that holds the compressed result.
+  std::vector<JOCTET> result_buffer_;
+};
+
+}  // namespace arc
+
+#endif  // INCLUDE_ARC_JPEG_COMPRESSOR_H_
diff --git a/hardware/ntimespace/camera/camera.cpp b/hardware/ntimespace/camera/camera.cpp
new file mode 100644
index 0000000000..fae8c51fbb
--- /dev/null
+++ b/hardware/ntimespace/camera/camera.cpp
@@ -0,0 +1,643 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/Camera.cpp
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "v4l2_camera"
+
+#include "camera.h"
+
+#include <cstdlib>
+#include <memory>
+
+#include <hardware/camera3.h>
+#include <sync/sync.h>
+#include <system/camera_metadata.h>
+#include <system/graphics.h>
+#include "metadata/metadata_common.h"
+#include "static_properties.h"
+#include "flash.h"
+#include "debug.h"
+#define ATRACE_TAG (ATRACE_TAG_CAMERA | ATRACE_TAG_HAL)
+#include <utils/Trace.h>
+#define CAMERA_SYNC_TIMEOUT 5000 // in msecs
+
+namespace default_camera_hal {
+
+extern "C" {
+// Shim passed to the framework to close an opened device.
+static int close_device(hw_device_t* dev)
+{
+    camera3_device_t* cam_dev = reinterpret_cast<camera3_device_t*>(dev);
+    Camera* cam = static_cast<Camera*>(cam_dev->priv);
+    return cam->close();
+}
+} // extern "C"
+
+Camera::Camera(int id)
+  : mBusy(false),
+    mId(id),    
+    mSettingsSet(false),
+    mCallbackOps(NULL),
+    mInFlightTracker(new RequestTracker)
+{
+    memset(&mTemplates, 0, sizeof(mTemplates));
+    memset(&mDevice, 0, sizeof(mDevice));
+    mDevice.common.tag    = HARDWARE_DEVICE_TAG;
+    mDevice.common.version = CAMERA_DEVICE_API_VERSION_3_4;
+    mDevice.common.close  = close_device;
+    mDevice.ops           = const_cast<camera3_device_ops_t*>(&sOps);
+    mDevice.priv          = this;
+
+    getDebugLevel();
+}
+
+Camera::~Camera()
+{
+}
+
+int Camera::openDevice(const hw_module_t *module, hw_device_t **device)
+{
+    HAL_LOGI("%s:%d: Opening camera device", __func__, mId);
+    ATRACE_CALL();
+    getDebugLevel();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    if (mBusy) {
+        HAL_LOGE("%s:%d: Error! Camera device already opened", __func__, mId);
+        return -EBUSY;
+    }
+
+    int connectResult = connect();
+    if (connectResult != 0) {
+      return connectResult;
+    }
+    mBusy = true;
+    mDevice.common.module = const_cast<hw_module_t*>(module);
+    *device = &mDevice.common;
+
+    HAL_LOGI("%s:%d: Opening camera device done", __func__, mId);
+    
+    return 0;
+}
+
+int Camera::getInfo(struct camera_info *info)
+{
+    info->device_version = mDevice.common.version;
+    initDeviceInfo(info);
+    if (!mStaticInfo) {
+        int res = loadStaticInfo();
+        if (res) {
+            return res;
+        }
+    }
+    info->static_camera_characteristics = mStaticInfo->raw_metadata();
+    info->facing = mStaticInfo->facing();
+    info->orientation = mStaticInfo->orientation();
+
+    return 0;
+}
+
+int Camera::loadStaticInfo() {
+  // Using a lock here ensures |mStaticInfo| will only ever be set once,
+  // even in concurrent situations.
+  android::Mutex::Autolock sl(mStaticInfoLock);
+
+  if (mStaticInfo) {
+    return 0;
+  }
+
+  std::unique_ptr<android::CameraMetadata> static_metadata =
+      std::make_unique<android::CameraMetadata>();
+  int res = initStaticInfo(static_metadata.get());
+  if (res) {
+    HAL_LOGE("%s:%d: Failed to get static info from device.",
+          __func__, mId);
+    return res;
+  }
+
+  mStaticInfo.reset(StaticProperties::NewStaticProperties(
+      std::move(static_metadata)));
+  if (!mStaticInfo) {
+    HAL_LOGE("%s:%d: Failed to initialize static properties from device metadata.",
+          __func__, mId);
+    return -ENODEV;
+  }
+
+  return 0;
+}
+
+int Camera::close()   
+{     
+    HAL_LOGI("%s:%d: Closing camera device", __func__, mId);
+    ATRACE_CALL();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    if (!mBusy) {
+        HAL_LOGE("%s:%d: Error! Camera device not open", __func__, mId);
+        return -EINVAL;
+    }
+
+#if SUPPORT_FLASH    
+    if (qcamera::CameraFlash::getInstance().releaseFlashFromCamera(mId) != 0) {
+        HAL_LOGW("Failed to release flash for camera id: %d", mId);
+    }
+#endif
+
+    flush();
+    disconnect();
+    mBusy = false;
+    return 0;
+}
+
+int Camera::initialize(const camera3_callback_ops_t *callback_ops)
+{
+    HAL_LOGV("%s:%d: callback_ops=%p", __func__, mId, callback_ops);
+    mCallbackOps = callback_ops;
+    // per-device specific initialization
+    return 0;
+}
+
+int Camera::configureStreams(camera3_stream_configuration_t *stream_config)
+{
+    android::Mutex::Autolock dl(mDeviceLock);
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    HAL_LOGD("%s:%d: stream_config=%p", __func__, mId, stream_config);
+    ATRACE_CALL();
+
+    // Check that there are no in-flight requests.
+    /*
+    if (!mInFlightTracker->Empty()) {
+        HAL_LOGE("%s:%d: Can't configure streams while frames are in flight.",
+              __func__, mId);
+        return -EINVAL;
+    }
+    */
+    
+
+    // Verify the set of streams in aggregate, and perform configuration if valid.
+    int res = validateStreamConfiguration(stream_config);
+    if (res) {
+        HAL_LOGE("%s:%d: Failed to validate stream set", __func__, mId);
+    } else {
+        // Set up all streams. Since they've been validated,
+        // this should only result in fatal (-ENODEV) errors.
+        // This occurs after validation to ensure that if there
+        // is a non-fatal error, the stream configuration doesn't change states.
+        res = setupStreams(stream_config);
+        if (res) {
+            HAL_LOGE("%s:%d: Failed to setup stream set", __func__, mId);
+        }
+    }
+
+    // Set trackers based on result.
+    if (!res) {
+        // Success, set up the in-flight trackers for the new streams.
+        mInFlightTracker->SetStreamConfiguration(*stream_config);
+        // Must provide new settings for the new configuration.
+        mSettingsSet = false;
+    } else if (res != -EINVAL) {
+        // Fatal error, the old configuration is invalid.
+        mInFlightTracker->ClearStreamConfiguration();
+    }
+    // On a non-fatal error the old configuration, if any, remains valid.
+    return res;
+}
+
+int Camera::validateStreamConfiguration(
+    const camera3_stream_configuration_t* stream_config)
+{
+    // Check that the configuration is well-formed.
+    if (stream_config == nullptr) {
+        HAL_LOGE("%s:%d: NULL stream configuration array", __func__, mId);
+        return -EINVAL;
+    } else if (stream_config->num_streams == 0) {
+        HAL_LOGE("%s:%d: Empty stream configuration array", __func__, mId);
+        return -EINVAL;
+    } else if (stream_config->streams == nullptr) {
+        HAL_LOGE("%s:%d: NULL stream configuration streams", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Check that the configuration is supported.
+    // Make sure static info has been initialized before trying to use it.
+    if (!mStaticInfo) {
+        int res = loadStaticInfo();
+        if (res) {
+            return res;
+        }
+    }
+    if (!mStaticInfo->StreamConfigurationSupported(stream_config)) {
+        HAL_LOGE("%s:%d: Stream configuration does not match static "
+              "metadata restrictions.", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Dataspace support is poorly documented - unclear if the expectation
+    // is that a device supports ALL dataspaces that could match a given
+    // format. For now, defer to child class implementation.
+    // Rotation support isn't described by metadata, so must defer to device.
+    if (!validateDataspacesAndRotations(stream_config)) {
+        HAL_LOGE("%s:%d: Device can not handle configuration "
+              "dataspaces or rotations.", __func__, mId);
+        return -EINVAL;
+    }
+
+    return 0;
+}
+
+bool Camera::isValidTemplateType(int type)
+{
+    return type > 0 && type < CAMERA3_TEMPLATE_COUNT;
+}
+
+const camera_metadata_t* Camera::constructDefaultRequestSettings(int type)
+{
+    HAL_LOGV("%s:%d: type=%d", __func__, mId, type);
+
+    if (!isValidTemplateType(type)) {
+        HAL_LOGE("%s:%d: Invalid template request type: %d", __func__, mId, type);
+        return NULL;
+    }
+
+    if (!mTemplates[type]) {
+        // Check if the device has the necessary features
+        // for the requested template. If not, don't bother.
+        if (!mStaticInfo->TemplateSupported(type)) {
+            HAL_LOGW("%s:%d: Camera does not support template type %d",
+                  __func__, mId, type);
+            return NULL;
+        }
+
+        // Initialize this template if it hasn't been initialized yet.
+        std::unique_ptr<android::CameraMetadata> new_template =
+            std::make_unique<android::CameraMetadata>();
+        int res = initTemplate(type, new_template.get());
+        if (res || !new_template) {
+            HAL_LOGE("%s:%d: Failed to generate template of type: %d",
+                  __func__, mId, type);
+            return NULL;
+        }
+        mTemplates[type] = std::move(new_template);
+    }
+
+    // The "locking" here only causes non-const methods to fail,
+    // which is not a problem since the CameraMetadata being locked
+    // is already const. Destructing automatically "unlocks".
+    return mTemplates[type]->getAndLock();
+}
+
+int Camera::processCaptureRequest(camera3_capture_request_t *temp_request)
+{
+    int res;
+    // TODO(b/32917568): A capture request submitted or ongoing during a flush
+    // should be returned with an error; for now they are mutually exclusive.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    ATRACE_CALL();
+
+    if (temp_request == NULL) {
+        HAL_LOGE("stream:%d NULL request recieved", mId);
+        return -EINVAL;
+    }
+
+    // Make a persistent copy of request, since otherwise it won't live
+    // past the end of this method.
+    std::shared_ptr<CaptureRequest> request = std::make_shared<CaptureRequest>(temp_request);
+
+    HAL_LOGD("stream:%d frame: %d", mId, request->frame_number);
+    if (GetStreamStatus() == 0)
+    {
+        HAL_LOGE("stream:%d is off, can not process request", mId);
+        completeRequestWithError(request);
+        return 0;
+    }
+
+    if (!mInFlightTracker->CanAddRequest(*request)) {
+        // Streams are full or frame number is not unique.
+        HAL_LOGE("%s:%d: Can not add request.", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Null/Empty indicates use last settings
+    if (request->settings.isEmpty() && !mSettingsSet) {
+        HAL_LOGE("%s:%d: NULL settings without previous set Frame:%d",
+              __func__, mId, request->frame_number);
+        return -EINVAL;
+    }
+
+    if (request->input_buffer != NULL) {
+        HAL_LOGV("%s:%d: Reprocessing input buffer %p", __func__, mId,
+              request->input_buffer.get());
+    } else {
+        HAL_LOGV("%s:%d: Capturing new frame.", __func__, mId);
+    }
+#if 0
+    if (!isValidRequestSettings(request->settings)) {
+        HAL_LOGE("%s:%d: Invalid request settings.", __func__, mId);
+        return -EINVAL;
+    }
+#endif
+    // Pre-process output buffers.
+    if (request->output_buffers.size() <= 0) {
+        HAL_LOGE("%s:%d: Invalid number of output buffers: %zu", __func__, mId,
+              request->output_buffers.size());
+        return -EINVAL;
+    }
+    for (auto& output_buffer : request->output_buffers) {
+        res = preprocessCaptureBuffer(&output_buffer);
+        if (res)
+            return -ENODEV;
+    }
+
+    // Add the request to tracking.
+    if (!mInFlightTracker->Add(request)) {
+        HAL_LOGE("%s:%d: Failed to track request for frame %d.",
+              __func__, mId, request->frame_number);
+        return -ENODEV;
+    }
+
+    // Valid settings have been provided (mSettingsSet is a misnomer;
+    // all that matters is that a previous request with valid settings
+    // has been passed to the device, not that they've been set).
+    mSettingsSet = true;
+
+    // Send the request off to the device for completion.
+    enqueueRequest(request);
+
+    // Request is now in flight. The device will call completeRequest
+    // asynchronously when it is done filling buffers and metadata.
+    return 0;
+}
+
+void Camera::completeRequest(std::shared_ptr<CaptureRequest> request, int err)
+{
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    if (!mInFlightTracker->Remove(request)) {
+        HAL_LOGE("%s:%d: Completed request %p is not being tracked. "
+              "It may have been cleared out during a flush.",
+              __func__, mId, request.get());
+        return;
+    }
+
+    // Since |request| has been removed from the tracking, this method
+    // MUST call sendResult (can still return a result in an error state, e.g.
+    // through completeRequestWithError) so the frame doesn't get lost.
+
+    if (err) {
+      HAL_LOGE("%s:%d: Error completing request for frame %d.",
+            __func__, mId, request->frame_number);
+      completeRequestWithError(request);
+      return;
+    }
+
+    // Notify the framework with the shutter time (extracted from the result).
+    int64_t timestamp = systemTime();
+    // TODO(b/31360070): The general metadata methods should be part of the
+    // default_camera_hal namespace, not the v4l2_camera_hal namespace.
+    int res = v4l2_camera_hal::SingleTagValue(
+        request->settings, ANDROID_SENSOR_TIMESTAMP, &timestamp);
+    if (res) {
+        HAL_LOGE("%s:%d: Request for frame %d is missing required metadata.",
+              __func__, mId, request->frame_number);
+        // TODO(b/31653322): Send RESULT error.
+        // For now sending REQUEST error instead.
+        completeRequestWithError(request);
+        return;
+    }
+    notifyShutter(request->frame_number, timestamp);
+
+    // TODO(b/31653322): Check all returned buffers for errors
+    // (if any, send BUFFER error).
+
+    sendResult(request);
+}
+
+int Camera::flush()
+{
+    HAL_LOGV("%s:%d: Flushing.", __func__, mId);
+    // TODO(b/32917568): Synchronization. Behave "appropriately"                                                                                                                                          
+    // (i.e. according to camera3.h) if process_capture_request()
+    // is called concurrently with this (in either order).
+    // Since the callback to completeRequest also may happen on a separate
+    // thread, this function should behave nicely concurrently with that too.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    std::set<std::shared_ptr<CaptureRequest>> requests;
+    mInFlightTracker->Clear(&requests);
+    for (auto& request : requests) {
+        // TODO(b/31653322): See camera3.h. Should return different error
+        // depending on status of the request.
+        completeRequestWithError(request);
+    }
+
+    HAL_LOGD("%s:%d: Flushed %zu requests.", __func__, mId, requests.size());
+
+    // Call down into the device flushing.
+    return flushBuffers();
+}
+
+int Camera::flush_lite()
+{
+    HAL_LOGV("%s:%d: Flushing.", __func__, mId);
+
+    // TODO(b/32917568): Synchronization. Behave "appropriately"                                                                                                                                          
+    // (i.e. according to camera3.h) if process_capture_request()
+    // is called concurrently with this (in either order).
+    // Since the callback to completeRequest also may happen on a separate
+    // thread, this function should behave nicely concurrently with that too.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    std::set<std::shared_ptr<CaptureRequest>> requests;
+    mInFlightTracker->Clear(&requests);
+    for (auto& request : requests) {
+        // TODO(b/31653322): See camera3.h. Should return different error
+        // depending on status of the request.
+        completeRequestWithError(request);
+    }
+
+    HAL_LOGD("%s:%d: Flushed %zu requests.", __func__, mId, requests.size());
+
+    return 0;
+}
+
+int Camera::preprocessCaptureBuffer(camera3_stream_buffer_t *buffer)
+{
+    int res;
+    // TODO(b/29334616): This probably should be non-blocking; part
+    // of the asynchronous request processing.
+    if (buffer->acquire_fence != -1) {
+        res = sync_wait(buffer->acquire_fence, CAMERA_SYNC_TIMEOUT);
+        if (res == -ETIME) {
+            HAL_LOGE("%s:%d: Timeout waiting on buffer acquire fence",
+                    __func__, mId);
+            return res;
+        } else if (res) {
+            HAL_LOGE("%s:%d: Error waiting on buffer acquire fence: %s(%d)",
+                    __func__, mId, strerror(-res), res);
+            return res;
+        }
+        ::close(buffer->acquire_fence);
+    }
+
+    // Acquire fence has been waited upon.
+    buffer->acquire_fence = -1;
+    // No release fence waiting unless the device sets it.
+    buffer->release_fence = -1;
+
+    buffer->status = CAMERA3_BUFFER_STATUS_OK;
+    return 0;
+}
+
+void Camera::notifyShutter(uint32_t frame_number, uint64_t timestamp)
+{
+    camera3_notify_msg_t message;
+    memset(&message, 0, sizeof(message));
+    message.type = CAMERA3_MSG_SHUTTER;
+    message.message.shutter.frame_number = frame_number;
+    message.message.shutter.timestamp = timestamp;
+    mCallbackOps->notify(mCallbackOps, &message);
+}
+
+void Camera::completeRequestWithError(std::shared_ptr<CaptureRequest> request)
+{
+    // Send an error notification.
+    camera3_notify_msg_t message;
+    memset(&message, 0, sizeof(message));
+    message.type = CAMERA3_MSG_ERROR;
+    message.message.error.frame_number = request->frame_number;
+    message.message.error.error_stream = nullptr;
+    message.message.error.error_code = CAMERA3_MSG_ERROR_REQUEST;
+    mCallbackOps->notify(mCallbackOps, &message);
+
+    // TODO(b/31856611): Ensure all the buffers indicate their error status.
+
+    // Send the errored out result.
+    sendResult(request);
+}
+
+void Camera::sendResult(std::shared_ptr<CaptureRequest> request) {
+    // Fill in the result struct
+    // (it only needs to live until the end of the framework callback).
+    camera3_capture_result_t result {
+        request->frame_number,
+        request->settings.getAndLock(),
+        static_cast<uint32_t>(request->output_buffers.size()),
+        request->output_buffers.data(),
+        request->input_buffer.get(),
+        1,  // Total result; only 1 part.
+        0,  // Number of physical camera metadata.
+        nullptr,
+        nullptr
+    };
+    // Make the framework callback.
+    mCallbackOps->process_capture_result(mCallbackOps, &result);
+
+    ShowCallbackFPS();
+
+    HAL_LOGD("send result end, frame=%d", request->frame_number);
+
+}
+
+void Camera::dump(int fd)
+{
+    HAL_LOGV("%s:%d: Dumping to fd %d", __func__, mId, fd);
+    ATRACE_CALL();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    dprintf(fd, "Camera ID: %d (Busy: %d)\n", mId, mBusy);
+
+    // TODO: dump all settings
+}
+
+const char* Camera::templateToString(int type)
+{
+    switch (type) {
+    case CAMERA3_TEMPLATE_PREVIEW:
+        return "CAMERA3_TEMPLATE_PREVIEW";
+    case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        return "CAMERA3_TEMPLATE_STILL_CAPTURE";
+    case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        return "CAMERA3_TEMPLATE_VIDEO_RECORD";
+    case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        return "CAMERA3_TEMPLATE_VIDEO_SNAPSHOT";
+    case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        return "CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG";
+    }
+    // TODO: support vendor templates
+    return "Invalid template type!";
+}
+
+extern "C" {
+// Get handle to camera from device priv data
+static Camera *camdev_to_camera(const camera3_device_t *dev)
+{
+    return reinterpret_cast<Camera*>(dev->priv);
+}
+
+static int initialize(const camera3_device_t *dev,
+        const camera3_callback_ops_t *callback_ops)
+{
+    return camdev_to_camera(dev)->initialize(callback_ops);
+}
+
+static int configure_streams(const camera3_device_t *dev,
+        camera3_stream_configuration_t *stream_list)
+{
+    return camdev_to_camera(dev)->configureStreams(stream_list);
+}
+
+static const camera_metadata_t *construct_default_request_settings(
+        const camera3_device_t *dev, int type)
+{
+    return camdev_to_camera(dev)->constructDefaultRequestSettings(type);
+}
+
+static int process_capture_request(const camera3_device_t *dev,
+        camera3_capture_request_t *request)
+{
+    return camdev_to_camera(dev)->processCaptureRequest(request);
+}
+
+static void dump(const camera3_device_t *dev, int fd)
+{
+    camdev_to_camera(dev)->dump(fd);
+}
+
+static int flush(const camera3_device_t *dev)
+{
+    return camdev_to_camera(dev)->flush();
+}
+
+} // extern "C"
+
+const camera3_device_ops_t Camera::sOps = {
+    .initialize = default_camera_hal::initialize,
+    .configure_streams = default_camera_hal::configure_streams,
+    .register_stream_buffers = nullptr,
+    .construct_default_request_settings
+        = default_camera_hal::construct_default_request_settings,
+    .process_capture_request = default_camera_hal::process_capture_request,
+    .get_metadata_vendor_tag_ops = nullptr,
+    .dump = default_camera_hal::dump,
+    .flush = default_camera_hal::flush,
+    .reserved = {0},
+};
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/camera.h b/hardware/ntimespace/camera/camera.h
new file mode 100644
index 0000000000..a2ab39752d
--- /dev/null
+++ b/hardware/ntimespace/camera/camera.h
@@ -0,0 +1,151 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/Camera.h
+
+#ifndef DEFAULT_CAMERA_HAL_CAMERA_H_
+#define DEFAULT_CAMERA_HAL_CAMERA_H_
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/hardware.h>
+#include <hardware/camera3.h>
+#include <utils/Mutex.h>
+
+#include "capture_request.h"
+#include "metadata/metadata.h"
+#include "request_tracker.h"
+#include "static_properties.h"
+
+namespace default_camera_hal {
+// Camera represents a physical camera on a device.
+// This is constructed when the HAL module is loaded, one per physical camera.
+// TODO(b/29185945): Support hotplugging.
+// It is opened by the framework, and must be closed before it can be opened
+// again.
+// This is an abstract class, containing all logic and data shared between all
+// camera devices (front, back, etc) and common to the ISP.
+class Camera {
+    public:
+        // id is used to distinguish cameras. 0 <= id < NUM_CAMERAS.
+        // module is a handle to the HAL module, used when the device is opened.
+        Camera(int id);
+        virtual ~Camera();
+
+        // Common Camera Device Operations (see <hardware/camera_common.h>)
+        int openDevice(const hw_module_t *module, hw_device_t **device);
+        int getInfo(struct camera_info *info);
+        int close();
+
+        // Camera v3 Device Operations (see <hardware/camera3.h>)
+        int initialize(const camera3_callback_ops_t *callback_ops);
+        int configureStreams(camera3_stream_configuration_t *stream_list);
+        const camera_metadata_t *constructDefaultRequestSettings(int type);
+        int processCaptureRequest(camera3_capture_request_t *temp_request);
+        void dump(int fd);
+        int flush();
+        int flush_lite();
+        int getCameraId() {return mId;}
+        
+    protected:
+        // Connect to the device: open dev nodes, etc.
+        virtual int connect() = 0;
+        // Disconnect from the device: close dev nodes, etc.
+        virtual void disconnect() = 0;
+        // Initialize static camera characteristics for individual device
+        virtual int initStaticInfo(android::CameraMetadata* out) = 0;
+        // Initialize a template of the given type
+        virtual int initTemplate(int type, android::CameraMetadata* out) = 0;
+        // Initialize device info: resource cost and conflicting devices
+        // (/conflicting devices length)
+        virtual void initDeviceInfo(struct camera_info *info) = 0;
+        // Separate initialization method for individual devices when opened
+        virtual int initDevice() = 0;
+        // Verify stream configuration dataspaces and rotation values
+        virtual bool validateDataspacesAndRotations(
+            const camera3_stream_configuration_t* stream_config) = 0;
+        // Set up the streams, including seting usage & max_buffers
+        virtual int setupStreams(
+            camera3_stream_configuration_t* stream_config) = 0;
+        // Verify settings are valid for a capture or reprocessing
+        virtual bool isValidRequestSettings(
+            const android::CameraMetadata& settings) = 0;
+        // Enqueue a request to receive data from the camera
+        virtual int enqueueRequest(
+            std::shared_ptr<CaptureRequest> request) = 0;
+        // Flush in flight buffers.
+        virtual int flushBuffers() = 0;
+
+        virtual int GetStreamStatus() = 0;
+
+
+        // Callback for when the device has filled in the requested data.
+        // Fills in the result struct, validates the data, sends appropriate
+        // notifications, and returns the result to the framework.
+        void completeRequest(
+            std::shared_ptr<CaptureRequest> request, int err);
+        // Prettyprint template names
+        const char* templateToString(int type);
+        // Busy flag indicates camera is in use
+        bool mBusy;
+        
+    private:
+        // Camera device handle returned to framework for use
+        camera3_device_t mDevice;
+        // Get static info from the device and store it in mStaticInfo.
+        int loadStaticInfo();
+        // Confirm that a stream configuration is valid.
+        int validateStreamConfiguration(
+            const camera3_stream_configuration_t* stream_config);
+        // Verify settings are valid for reprocessing an input buffer
+        bool isValidReprocessSettings(const camera_metadata_t *settings);
+        // Pre-process an output buffer
+        int preprocessCaptureBuffer(camera3_stream_buffer_t *buffer);
+        // Send a shutter notify message with start of exposure time
+        void notifyShutter(uint32_t frame_number, uint64_t timestamp);
+        // Send an error message and return the errored out result.
+        void completeRequestWithError(std::shared_ptr<CaptureRequest> request);
+        // Send a capture result for a request.
+        void sendResult(std::shared_ptr<CaptureRequest> request);
+        // Is type a valid template type (and valid index into mTemplates)
+        bool isValidTemplateType(int type);
+
+        // Identifier used by framework to distinguish cameras
+        const int mId;
+        // CameraMetadata containing static characteristics
+        std::unique_ptr<StaticProperties> mStaticInfo;
+        // Flag indicating if settings have been set since
+        // the last configure_streams() call.
+        bool mSettingsSet;
+
+        // Camera device operations handle shared by all devices
+        const static camera3_device_ops_t sOps;
+        // Methods used to call back into the framework
+        const camera3_callback_ops_t *mCallbackOps;
+        // Lock protecting the Camera object for modifications
+        android::Mutex mDeviceLock;
+        // Lock protecting only static camera characteristics, which may
+        // be accessed without the camera device open
+        android::Mutex mStaticInfoLock;
+        // Standard camera settings templates
+        std::unique_ptr<const android::CameraMetadata> mTemplates[CAMERA3_TEMPLATE_COUNT];
+        // Track in flight requests.
+        std::unique_ptr<RequestTracker> mInFlightTracker;
+        android::Mutex mInFlightTrackerLock;
+};
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_CAMERA_H_
diff --git a/hardware/ntimespace/camera/camera_init.rc b/hardware/ntimespace/camera/camera_init.rc
new file mode 100644
index 0000000000..fd48a34efc
--- /dev/null
+++ b/hardware/ntimespace/camera/camera_init.rc
@@ -0,0 +1,5 @@
+
+
+on property:sys.boot_completed=1
+    exec root root -- /system/bin/sh -c /system/bin/camera_init.sh
+
diff --git a/hardware/ntimespace/camera/camera_init.sh b/hardware/ntimespace/camera/camera_init.sh
new file mode 100644
index 0000000000..2356a77b48
--- /dev/null
+++ b/hardware/ntimespace/camera/camera_init.sh
@@ -0,0 +1,13 @@
+!/system/bin/sh
+
+Camera_Tid=$(getprop ro.container.container_id)
+num0=$((Camera_Tid * 2 + 100))
+num1=$((Camera_Tid * 2 + 101))
+mv /dev/video${num0} /dev/camera0
+mv /dev/video${num1} /dev/camera1
+chmod 666 /dev/camera0
+chmod 666 /dev/camera1
+ps -ef | grep -i camera | grep -v grep | grep -v camera_init | awk '{print $2}' | xargs -r kill -9
+
+
+
diff --git a/hardware/ntimespace/camera/capture_request.cpp b/hardware/ntimespace/camera/capture_request.cpp
new file mode 100644
index 0000000000..5b8e037e7d
--- /dev/null
+++ b/hardware/ntimespace/camera/capture_request.cpp
@@ -0,0 +1,54 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "capture_request.h"
+
+namespace default_camera_hal {
+
+CaptureRequest::CaptureRequest() : CaptureRequest(nullptr) {}
+
+CaptureRequest::CaptureRequest(const camera3_capture_request_t* request) {
+  if (!request) {
+    return;
+  }
+
+  frame_number = request->frame_number;
+
+  // CameraMetadata makes copies of camera_metadata_t through the
+  // assignment operator (the constructor taking a camera_metadata_t*
+  // takes ownership instead).
+  settings = request->settings;
+
+  // camera3_stream_buffer_t can be default copy constructed,
+  // as its pointer values are handles, not ownerships.
+
+  // Copy the input buffer.
+  if (request->input_buffer) {
+    input_buffer =
+        std::make_unique<camera3_stream_buffer_t>(*request->input_buffer);
+  }
+
+  // Safely copy all the output buffers.
+  uint32_t num_output_buffers = request->num_output_buffers;
+  if (/*num_output_buffers < 0 ||*/ !request->output_buffers) {
+    num_output_buffers = 0;
+  }
+  output_buffers.insert(output_buffers.end(),
+                        request->output_buffers,
+                        request->output_buffers + num_output_buffers);
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/capture_request.h b/hardware/ntimespace/camera/capture_request.h
new file mode 100644
index 0000000000..0bbd967b03
--- /dev/null
+++ b/hardware/ntimespace/camera/capture_request.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
+#define DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
+
+#include <memory>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/camera3.h>
+
+namespace default_camera_hal {
+
+// A simple wrapper for camera3_capture_request_t,
+// with a constructor that makes a deep copy from the original struct.
+struct CaptureRequest {
+  uint32_t frame_number;
+  android::CameraMetadata settings;
+  std::unique_ptr<camera3_stream_buffer_t> input_buffer;
+  std::vector<camera3_stream_buffer_t> output_buffers;
+
+  CaptureRequest();
+  // Create a deep copy of |request|.
+  CaptureRequest(const camera3_capture_request_t* request);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
diff --git a/hardware/ntimespace/camera/common.h b/hardware/ntimespace/camera/common.h
new file mode 100644
index 0000000000..9a56e6faf9
--- /dev/null
+++ b/hardware/ntimespace/camera/common.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright 2015 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_COMMON_H_
+#define V4L2_CAMERA_HAL_COMMON_H_
+
+#include <log/log.h>
+extern int debug;
+#define V4L2_CAMERA_TAG "[v4l2_camera] "
+
+// Helpers of logging (showing function name and line number).
+#define HAL_LOGE(fmt, args...) do { \
+    ALOGE(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGE_IF(cond, fmt, args...) do { \
+    ALOGE_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGW(fmt, args...) do { \
+    ALOGW(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGW_IF(cond, fmt, args...) do { \
+    ALOGW_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGI(fmt, args...) do { \
+    ALOGI(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGI_IF(cond, fmt, args...) do { \
+    ALOGI_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGD(fmt, args...) if (debug >= 2) { \
+    do { \
+    ALOGD(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0); \
+  }
+
+#define HAL_LOGV(fmt, args...) if (debug >= 3) { \
+    do { \
+    ALOGV(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0); \
+  }
+
+// Log enter/exit of methods.
+#define HAL_LOG_ENTER() HAL_LOGV("enter")
+#define HAL_LOG_EXIT() HAL_LOGV("exit")
+
+#endif  // V4L2_CAMERA_HAL_COMMON_H_
diff --git a/hardware/ntimespace/camera/debug.cpp b/hardware/ntimespace/camera/debug.cpp
new file mode 100644
index 0000000000..7c237c8154
--- /dev/null
+++ b/hardware/ntimespace/camera/debug.cpp
@@ -0,0 +1,316 @@
+//#define LOG_NDEBUG 0
+#define LOG_TAG "v4l2_camera"
+
+#include "debug.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/time.h>
+#include "android-base/properties.h"
+#include <dlfcn.h>
+#include <utils/Timers.h>
+
+int debug = 0;
+
+uint64_t timeNanos() {
+  struct timespec spec;
+  clock_gettime(CLOCK_MONOTONIC, &spec);
+  return spec.tv_sec * 1000000000 + spec.tv_nsec;
+}
+
+uint32_t toMilliSeconds(uint64_t ns) {
+  return (uint32_t)(ns/1000000);
+}
+
+
+
+uint32_t dump_data_index;
+bool     data_dump;
+std::string  dump_data_path = "/data/local/bmp";
+
+
+int yuv_write(unsigned char *image, int imageWidth, int imageHeight, char *filename)
+{ 
+    //printf("yuv_write width %d height %d\n", imageWidth, imageHeight);
+    long file_size = (long)(imageWidth) * (long)imageHeight * 3/2;
+
+    FILE *fp;
+    if (!(fp = fopen(filename, "wb")))
+      return -1;
+ 
+    fwrite(image, sizeof(unsigned char), (size_t)(long)file_size, fp); 
+    fclose(fp);
+
+    return 0;
+}
+
+void dump_yuv(int index, unsigned char *image, int imageWidth, int imageHeight, int bufId, 
+              std::string prefix, int formatcc) {
+  data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGV("width %d height %d ", imageWidth, imageHeight);
+
+    char pc[256] = "";
+    sprintf(pc, "%s/%d_%d_%s_%s_%d_%d.yuv", dump_data_path.c_str(), index, bufId, prefix.c_str(), 
+            FormatToString(formatcc).c_str(), imageWidth, imageHeight);
+    HAL_LOGD("save_%s_yuv: %s \n ", prefix.c_str(), pc);
+    yuv_write(image, imageWidth, imageHeight, pc);
+  }
+}
+
+///////////////////////////////////////////////////////////
+int bmp_write(unsigned char *image, int imageWidth, int imageHeight, char *filename, bool padding)
+{ 
+#if 1
+    #define HEADER_SZ 54
+    /*bitmap file header(14B) + bitmap info header(40B)*/
+    unsigned char header[54] = {
+      0x42, 0x4d, 
+      0, 0, 0, 0, /*file size, LE*/
+      0, 0, 0, 0, /*reserve*/
+      54, 0, 0, 0,
+      /*bitmap info header*/
+      40, 0, 0, 0,  /*size*/
+      0, 0, 0, 0,   /*width*/
+      0, 0, 0, 0,   /*height*/
+      1, 0,         /*color plane, MUST 1*/
+      32, 0,        /*bit per pixel*/
+      0, 0, 0, 0,   /*compress methond*/
+      0, 0, 0, 0,   /*original size before compress*/
+      0, 0, 0, 0,   /*pixel per meter in width*/
+      0, 0, 0, 0,  
+      0, 0, 0, 0,  /*pattle color number*/
+      0, 0, 0, 0,
+    };
+#else
+#define BMP_HEADER 108
+#define FILE_HEADER 14
+#define HEADER_SZ (BMP_HEADER + FILE_HEADER)
+    /*bitmap file header(14B) + bitmap info header(108B)*/
+    unsigned char header[HEADER_SZ] = {
+      0x42, 0x4d, 
+      0, 0, 0, 0, /*file size, LE*/
+      0, 0, 0, 0, /*reserve*/
+      HEADER_SZ, 0, 0, 0,
+      /*bitmap info header*/
+      BMP_HEADER, 0, 0, 0,  /*size*/
+      0, 0, 0, 0,   /*width*/
+      0, 0, 0, 0,   /*height*/
+      1, 0,         /*color plane, MUST 1*/
+      32, 0,        /*bit per pixel*/
+      3, 0, 0, 0,   /*BI_BITFIELDS, no pixel array compression used*/
+      0, 0, 0, 0,   /*original size before compress*/
+      0, 0, 0, 0,   /*pixel per meter in width*/
+      0, 0, 0, 0,  
+      0, 0, 0, 0,  /*pattle color number*/
+      0, 0, 0, 0,  /*important colors*/
+      0xFF, 0, 0, 0, /*Red bitmask*/
+      0, 0xFF, 0, 0, /*Green bitmask*/
+      0, 0, 0xFF, 0, /*Blue bitmask*/
+      0, 0, 0, 0xFF, /*Alpha bitmask*/
+      0, 0, 0, 0, /*little-endian "Win "*/
+      0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,
+      0, 0, 0, 0,
+      0, 0, 0, 0,
+      0, 0, 0, 0
+    };
+#endif
+    long file_size = (long)imageWidth * (long)imageHeight * 4 + HEADER_SZ;
+    header[2] = (unsigned char)(file_size &0x000000ff);
+    header[3] = (file_size >> 8) & 0x000000ff;
+    header[4] = (file_size >> 16) & 0x000000ff;
+    header[5] = (file_size >> 24) & 0x000000ff;
+ 
+    long width = imageWidth;
+    header[18] = width & 0x000000ff;
+    header[19] = (width >> 8) &0x000000ff;
+    header[20] = (width >> 16) &0x000000ff;
+    header[21] = (width >> 24) &0x000000ff;
+ 
+    long height = imageHeight;
+    header[22] = height &0x000000ff;
+    header[23] = (height >> 8) &0x000000ff;
+    header[24] = (height >> 16) &0x000000ff;
+    header[25] = (height >> 24) &0x000000ff;
+ 
+    FILE *fp;
+    if (!(fp = fopen(filename, "wb")))
+      return -1;
+
+    fwrite(header, sizeof(unsigned char), HEADER_SZ, fp);
+ #if 0    
+    fwrite(image, sizeof(unsigned char), (size_t)(long)imageWidth * imageHeight * 4, fp);
+ #else
+    int curPos = 0;
+    // BMP 存储像素数据与y轴方向相反（即，位图是底朝上的）, b/g/r
+    for (int row = imageHeight - 1; row >= 0; row--)  // 遍历所有行
+    {
+      for (int col = 0; col < imageWidth; col++)   // 遍历所有列
+      {
+          curPos = (row * imageWidth + col) * 4;
+          fwrite((unsigned char *)(image + curPos + 2), sizeof(unsigned char), 1, fp); //B
+          fwrite((unsigned char *)(image + curPos + 1), sizeof(unsigned char), 1, fp); //G
+          fwrite((unsigned char *)(image + curPos), sizeof(unsigned char), 1, fp); //R
+          fwrite((unsigned char *)(image + curPos + 3), sizeof(unsigned char), 1, fp); //A
+      }
+
+      if (padding)
+        fwrite((unsigned char *)(image + curPos + 4), sizeof(unsigned char), Align32(imageWidth) - imageWidth, fp); 
+    }    
+ #endif
+
+    fclose(fp);
+    return 0;
+}
+
+void dump_bmp(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, int bufId, 
+              std::string prefix) {
+  data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGV("width %d height %d format %d ", imageWidth, imageHeight, formatcc);
+
+    if (!access(dump_data_path.c_str(), F_OK)) {
+      mkdir(dump_data_path.c_str(), 0777);
+    }
+
+    char pc[256] = "";
+    sprintf(pc, "%s/%d_%d_%s_%s_%d_%d.bmp", dump_data_path.c_str(), index, bufId, prefix.c_str(),
+        FormatToString(formatcc).c_str(), imageWidth, imageHeight);
+    HAL_LOGD("save_%s_bmp: %s ",  prefix.c_str(), pc);
+    bmp_write(image, imageWidth, imageHeight, pc, false);
+  }
+}
+
+void dump_data_init() {
+  dump_data_index = 0;
+  bool data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGE( "dump image data Flag found");  
+    if (access(dump_data_path.c_str(), F_OK) == 0) {
+      data_dump = true;
+      rmdir(dump_data_path.c_str());
+    }
+
+    mkdir(dump_data_path.c_str(), 0777);
+  }
+
+  return;
+}
+
+void dump_data(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, 
+               int bufId, std::string prefix)
+{  
+  if (image) {
+    if (formatcc == V4L2_PIX_FMT_RGB32)
+      dump_bmp(index, image, imageWidth, imageHeight, formatcc, bufId, prefix);  
+    else
+      dump_yuv(index, image, imageWidth, imageHeight, bufId, prefix, formatcc);
+  }
+}
+
+void get_gpu_pixel_alignment(){
+  int (*LINK_get_surface_pixel_alignment)();
+  uint32_t SurfaceStridePadding = 0;  
+  void * lib_surface_utils = dlopen("libadreno_utils.so", RTLD_NOW);
+  if (lib_surface_utils) {
+      *(void **)&LINK_get_surface_pixel_alignment =
+              dlsym(lib_surface_utils, "get_gpu_pixel_alignment");
+        if (LINK_get_surface_pixel_alignment) {
+            SurfaceStridePadding = LINK_get_surface_pixel_alignment();
+        }
+        dlclose(lib_surface_utils);
+  }
+
+  HAL_LOGI("%s: stride %d", __FUNCTION__, SurfaceStridePadding);
+}
+
+void getDebugLevel()
+{
+    debug = android::base::GetIntProperty("camera.debug.level", 0);
+}
+
+bool isDebug()
+{
+    return debug >= 1;
+}
+
+void ShowPreviewFPS()
+{
+    bool fps_dump = android::base::GetBoolProperty("camera.debug.fps", false);
+    if (fps_dump) {
+      static int n_pFrameCount = 0; 
+      static int n_pLastFrameCount = 0; 
+      static int64_t n_pLastFpsTime = 0; 
+      static double n_pFps = 0; 
+      n_pFrameCount++;
+      int64_t now = systemTime();
+      int64_t diff = now - n_pLastFpsTime;
+      if (diff > ms2ns(1000)) {
+          n_pFps = (double)(n_pFrameCount - n_pLastFrameCount);
+          HAL_LOGI("[fps] %.4f", n_pFps);
+          n_pLastFpsTime = now; 
+          n_pLastFrameCount = n_pFrameCount;
+      }    
+    }
+}
+
+void ShowCallbackFPS()
+{
+    bool fps_dump = android::base::GetBoolProperty("camera.debug.fps", false);
+    if (fps_dump) {
+      static int n_pFrameCount_cb = 0;
+      static int n_pLastFrameCount_cb = 0;
+      static int64_t n_pLastFpsTime_cb = 0;
+      static double n_pFps_cb = 0;
+      n_pFrameCount_cb++;
+      int64_t now = systemTime();
+      int64_t diff = now - n_pLastFpsTime_cb;
+      if (diff > ms2ns(1000)) {
+          n_pFps_cb = (double)(n_pFrameCount_cb - n_pLastFrameCount_cb);
+          HAL_LOGI("[callback fps] %.4f", n_pFps_cb);
+          n_pLastFpsTime_cb = now;
+          n_pLastFrameCount_cb = n_pFrameCount_cb;
+      }
+    }
+}
+
+int get_cpuoccupy(CPU_OCCUPY *cpust) 
+{  
+    FILE *fd;  
+    char buff[256];  
+    CPU_OCCUPY * occupy;  
+    occupy = cpust;  
+      
+    fd = fopen("/proc/stat", "r");  
+    fgets(buff, sizeof(buff), fd);  
+      
+    sscanf(buff, "%s %u %u %u %u %u %u %u", occupy->name, &occupy->user, &occupy->nice, &occupy->system, 
+      &occupy->idle, &occupy->lowait, &occupy->irq, &occupy->softirq);  
+    fclose(fd);  
+      
+    return 0;  
+}  
+  
+int cal_cpuoccupy(CPU_OCCUPY *o, CPU_OCCUPY *n)  
+{  
+    unsigned long od, nd;  
+    double cpu_use = 0;  
+      
+    od = (unsigned long)(o->user + o->nice + o->system + o->idle + o->lowait + o->irq + o->softirq); 
+    nd = (unsigned long)(n->user + n->nice + n->system + n->idle + n->lowait + n->irq + n->softirq);  
+    double sum = nd - od;  
+    double idle = n->idle - o->idle;  
+    cpu_use = 100 - idle * 100 / sum; 
+    //idle = n->user + n->system + n->nice - o->user - o->system - o->nice;  
+    return cpu_use;  
+}  
+
+void msleep(int msecs)
+{
+	const struct timespec ts = { msecs / 1000, (msecs % 1000) * 1000000L };
+	nanosleep(&ts, NULL);
+}
diff --git a/hardware/ntimespace/camera/debug.h b/hardware/ntimespace/camera/debug.h
new file mode 100644
index 0000000000..32cd5ad7c9
--- /dev/null
+++ b/hardware/ntimespace/camera/debug.h
@@ -0,0 +1,58 @@
+#ifndef V4L2_CAMERA_HAL_DEBUG_H_
+#define V4L2_CAMERA_HAL_DEBUG_H_
+
+#include <array>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <string>
+#include <vector>
+#include <android-base/unique_fd.h>
+#include "common.h"
+#include "arc/common.h"
+
+uint64_t timeNanos();
+uint32_t toMilliSeconds(uint64_t ns);
+
+
+extern uint32_t dump_data_index;
+extern bool     data_dump;
+extern std::string  dump_data_path;
+
+inline size_t Align64(size_t value) { return (value + 63) & ~63; };
+inline size_t Align32(size_t value) { return (value + 31) & ~31; };
+inline size_t Align16(size_t value) { return (value + 15) & ~15; }
+
+int bmp_write(unsigned char *image, int imageWidth, int imageHeight, char *filename, bool padding=true);
+int yuv_write(unsigned char *image, int imageWidth, int imageHeight, char *filename);
+
+void dump_data_init();
+void dump_data(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, int bufId, 
+               std::string prefix);
+
+void get_gpu_pixel_alignment();
+void ShowPreviewFPS();
+void ShowCallbackFPS();
+bool isDebug();
+void getDebugLevel();
+
+typedef struct _CPU_OCCUPY         //定义一个cpu occupy的结构体  
+{  
+    char name[256];      //定义一个char类型的数组名name有20个元素  
+    unsigned int user; //定义一个无符号的int类型的user  
+    unsigned int nice; //定义一个无符号的int类型的nice  
+    unsigned int system;//定义一个无符号的int类型的system  
+    unsigned int idle; //定义一个无符号的int类型的idle  
+    unsigned int lowait;  
+    unsigned int irq;  
+    unsigned int softirq;  
+} CPU_OCCUPY;  
+
+int get_cpuoccupy(CPU_OCCUPY *cpust);
+int cal_cpuoccupy(CPU_OCCUPY *o, CPU_OCCUPY *n);
+
+
+void msleep(int msecs);
+
+#endif
+
diff --git a/hardware/ntimespace/camera/flash.cpp b/hardware/ntimespace/camera/flash.cpp
new file mode 100644
index 0000000000..ebeaada953
--- /dev/null
+++ b/hardware/ntimespace/camera/flash.cpp
@@ -0,0 +1,340 @@
+/* Copyright (c) 2015-2016, The Linux Foundation. All rights reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*     * Neither the name of The Linux Foundation nor the names of its
+*       contributors may be used to endorse or promote products derived
+*       from this software without specific prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+* WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+* ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+* BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+* CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+* BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+* WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+* OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+* IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*
+*/
+
+// System dependencies
+#include <stdio.h>
+#include <fcntl.h>
+
+// Camera dependencies
+#include "flash.h"
+
+
+#define STRING_LENGTH_OF_64_BIT_NUMBER 21
+
+namespace qcamera {
+
+/*===========================================================================
+ * FUNCTION   : getInstance
+ *
+ * DESCRIPTION: Get and create the CameraFlash singleton.
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash& CameraFlash::getInstance()
+{
+    static CameraFlash flashInstance;
+    return flashInstance;
+}
+
+/*===========================================================================
+ * FUNCTION   : CameraFlash
+ *
+ * DESCRIPTION: default constructor of CameraFlash
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash::CameraFlash() : m_callbacks(NULL)
+{
+    memset(&m_flashOn, 0, sizeof(m_flashOn));
+    memset(&m_cameraOpen, 0, sizeof(m_cameraOpen));
+    for (int pos = 0; pos < MM_CAMERA_MAX_NUM_SENSORS; pos++) {
+        m_flashFds[pos] = -1;
+    }
+}
+
+/*===========================================================================
+ * FUNCTION   : ~CameraFlash
+ *
+ * DESCRIPTION: deconstructor of CameraFlash
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash::~CameraFlash()
+{
+    for (int pos = 0; pos < MM_CAMERA_MAX_NUM_SENSORS; pos++) {
+        if (m_flashFds[pos] >= 0)
+            {
+                setFlashMode(pos, false);
+                close(m_flashFds[pos]);
+                m_flashFds[pos] = -1;
+            }
+    }
+}
+
+/*===========================================================================
+ * FUNCTION   : registerCallbacks
+ *
+ * DESCRIPTION: provide flash module with reference to callbacks to framework
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+int32_t CameraFlash::registerCallbacks(
+        const camera_module_callbacks_t* callbacks)
+{
+    int32_t retVal = 0;
+    m_callbacks = callbacks;
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : initFlash
+ *
+ * DESCRIPTION: Reserve and initialize the flash unit associated with a
+ *              given camera id. This function is blocking until the
+ *              operation completes or fails. Each flash unit can be "inited"
+ *              by only one process at a time.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EBUSY   : The flash unit or the resource needed to turn on the
+ *              the flash is busy, typically because the flash is
+ *              already in use.
+ *   -EINVAL  : No flash present at camera_id.
+ *==========================================================================*/
+int32_t CameraFlash::initFlash(const int camera_id)
+{
+    int32_t retVal = 0;
+    bool hasFlash = true;
+    char flashPath[256] = "/dev/";
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        return -EINVAL;
+    }
+
+    sprintf(flashPath, "/dev/camera%d",  camera_id);
+
+    if (!hasFlash) {
+        HAL_LOGE("No flash available for camera id: %d", camera_id);
+        retVal = -ENOSYS;
+    } else if (m_cameraOpen[camera_id]) {
+        HAL_LOGE("Camera in use for camera id: %d", camera_id);
+        retVal = -EBUSY;
+    } else if (m_flashFds[camera_id] >= 0) {
+        HAL_LOGD("Flash is already inited for camera id: %d", camera_id);
+    } else {
+        m_flashFds[camera_id] = open(flashPath, O_RDONLY | O_NONBLOCK);
+
+        if (m_flashFds[camera_id] < 0) {
+            HAL_LOGE("Unable to open node '%s'", flashPath);
+            retVal = -EBUSY;
+        } 
+    }
+
+    HAL_LOGD("X, retVal = %d", retVal);
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : setFlashMode
+ *
+ * DESCRIPTION: Turn on or off the flash associated with a given handle.
+ *              This function is blocking until the operation completes or
+ *              fails.
+ *
+ * PARAMETERS :
+ *   @camera_id  : Camera id of the flash
+ *   @on         : Whether to turn flash on (true) or off (false)
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id, or it is not inited.
+ *   -EALREADY: Flash is already in requested state
+ *==========================================================================*/
+int32_t CameraFlash::setFlashMode(const int camera_id, const bool mode)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (mode == m_flashOn[camera_id]) {
+        HAL_LOGD("flash %d is already in requested state: %d",
+                camera_id,
+                mode);
+        retVal = -EALREADY;
+    } else if (m_flashFds[camera_id] < 0) {
+        HAL_LOGE("called for uninited flash: %d", camera_id);
+        retVal = -EINVAL;
+    }  else {
+        int cfg = mode ? 1 : 0;
+        retVal = ioctl(m_flashFds[camera_id], RFVIDEO_SET_FLASH_CFG, &cfg);
+        if (retVal < 0) {
+            HAL_LOGE("Unable to change flash mode to %d for camera id: %d",
+                     mode, camera_id);
+        } else
+        {
+            m_flashOn[camera_id] = mode;
+        }
+    }
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : deinitFlash
+ *
+ * DESCRIPTION: Release the flash unit associated with a given camera
+ *              position. This function is blocking until the operation
+ *              completes or fails.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *==========================================================================*/
+int32_t CameraFlash::deinitFlash(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (m_flashFds[camera_id] < 0) {
+        HAL_LOGE("called deinitFlash for uninited flash");
+        retVal = -EINVAL;
+    } else {
+        setFlashMode(camera_id, false);
+        close(m_flashFds[camera_id]);
+        m_flashFds[camera_id] = -1;
+    }
+
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : reserveFlashForCamera
+ *
+ * DESCRIPTION: Give control of the flash to the camera, and notify
+ *              framework that the flash has become unavailable.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *   -ENOSYS  : No callback available for torch_mode_status_change.
+ *==========================================================================*/
+int32_t CameraFlash::reserveFlashForCamera(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (m_cameraOpen[camera_id]) {
+        HAL_LOGD("Flash already reserved for camera id: %d", camera_id);
+    } else {
+        if (m_flashOn[camera_id]) {
+            setFlashMode(camera_id, false);
+            deinitFlash(camera_id);
+        }
+        m_cameraOpen[camera_id] = true;
+        bool hasFlash = true;
+
+        if (m_callbacks == NULL || m_callbacks->torch_mode_status_change == NULL) {
+            HAL_LOGE("Callback is not defined!");
+            retVal = -ENOSYS;
+        } else if (!hasFlash) {
+            HAL_LOGD("Suppressing callback "
+                    "because no flash exists for camera id: %d",
+                    camera_id);
+        } else {
+            char cameraIdStr[STRING_LENGTH_OF_64_BIT_NUMBER];
+            snprintf(cameraIdStr, STRING_LENGTH_OF_64_BIT_NUMBER, "%d", camera_id);
+            m_callbacks->torch_mode_status_change(m_callbacks,
+                    cameraIdStr,
+                    TORCH_MODE_STATUS_NOT_AVAILABLE);
+        }
+    }
+
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : releaseFlashFromCamera
+ *
+ * DESCRIPTION: Release control of the flash from the camera, and notify
+ *              framework that the flash has become available.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *   -ENOSYS  : No callback available for torch_mode_status_change.
+ *==========================================================================*/
+int32_t CameraFlash::releaseFlashFromCamera(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (!m_cameraOpen[camera_id]) {
+        HAL_LOGD("Flash not reserved for camera id: %d",
+                camera_id);
+    } else {
+        m_cameraOpen[camera_id] = false;
+        bool hasFlash = true;
+
+        if (m_callbacks == NULL ||
+                m_callbacks->torch_mode_status_change == NULL) {
+            HAL_LOGE("Callback is not defined!");
+            retVal = -ENOSYS;
+        } else if (!hasFlash) {
+            HAL_LOGD("Suppressing callback "
+                    "because no flash exists for camera id: %d",
+                    camera_id);
+        } else {
+            char cameraIdStr[STRING_LENGTH_OF_64_BIT_NUMBER];
+            snprintf(cameraIdStr, STRING_LENGTH_OF_64_BIT_NUMBER, "%d", camera_id);
+            m_callbacks->torch_mode_status_change(m_callbacks, cameraIdStr,
+                    TORCH_MODE_STATUS_AVAILABLE_OFF);
+        }
+    }
+
+    return retVal;
+}
+
+}; // namespace qcamera
diff --git a/hardware/ntimespace/camera/flash.h b/hardware/ntimespace/camera/flash.h
new file mode 100644
index 0000000000..89f9216547
--- /dev/null
+++ b/hardware/ntimespace/camera/flash.h
@@ -0,0 +1,70 @@
+/* Copyright (c) 2015-2016, The Linux Foundation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of The Linux Foundation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#ifndef __CAMERA_FLASH_H__
+#define __CAMERA_FLASH_H__
+
+// Camera dependencies
+#include "hardware/camera_common.h"
+#include "v4l2_camera_hal.h"
+
+#define SUPPORT_FLASH 0
+
+
+namespace qcamera {
+
+#define RFVIDEO_SET_FLASH_CFG   0x9F0FFF02
+#define RFVIDEO_GET_FLASH_CFG	0x9F0FFF03
+
+class CameraFlash {
+public:
+    static CameraFlash& getInstance();
+
+    int32_t registerCallbacks(const camera_module_callbacks_t* callbacks);
+    int32_t initFlash(const int camera_id);
+    int32_t setFlashMode(const int camera_id, const bool on);
+    int32_t deinitFlash(const int camera_id);
+    int32_t reserveFlashForCamera(const int camera_id);
+    int32_t releaseFlashFromCamera(const int camera_id);
+
+private:
+    CameraFlash();
+    virtual ~CameraFlash();
+    CameraFlash(const CameraFlash&);
+    CameraFlash& operator=(const CameraFlash&);
+
+    const camera_module_callbacks_t *m_callbacks;
+    int32_t m_flashFds[MM_CAMERA_MAX_NUM_SENSORS];
+    bool m_flashOn[MM_CAMERA_MAX_NUM_SENSORS];
+    bool m_cameraOpen[MM_CAMERA_MAX_NUM_SENSORS];
+};
+
+}; // namespace qcamera
+
+#endif /* __CAMERA_FLASH_H__ */
diff --git a/hardware/ntimespace/camera/format_metadata_factory.cpp b/hardware/ntimespace/camera/format_metadata_factory.cpp
new file mode 100644
index 0000000000..49ce25e6ee
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory.cpp
@@ -0,0 +1,271 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "FormatMetadataFactory"
+
+#include "format_metadata_factory.h"
+
+#include <algorithm>
+#include <set>
+
+#include "arc/image_processor.h"
+#include "common.h"
+#include "metadata/array_vector.h"
+#include "metadata/partial_metadata_factory.h"
+#include "metadata/property.h"
+
+namespace v4l2_camera_hal {
+
+static int GetHalFormats(const std::shared_ptr<V4L2Wrapper>& device,
+                         std::set<int32_t>* result_formats) {
+  if (!result_formats) {
+    HAL_LOGE("Null result formats pointer passed");
+    return -EINVAL;
+  }
+
+  std::set<uint32_t> v4l2_formats;
+  int res = device->GetFormats(&v4l2_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return res;
+  }
+
+  for (auto v4l2_format : v4l2_formats) {
+    int32_t hal_format = StreamFormat::V4L2ToHalPixelFormat(v4l2_format);
+    if (hal_format < 0) {
+      // Unrecognized/unused format. Skip it.
+      continue;
+    }
+    result_formats->insert(hal_format);
+  }
+
+  return 0;
+}
+
+static int FpsRangesCompare(std::array<int32_t, 2> a,
+                            std::array<int32_t, 2> b) {
+  if (a[1] == b[1]) {
+    return a[0] > b[0];
+  }
+  return a[1] > b[1];
+}
+
+int AddFormatComponents(
+    std::shared_ptr<V4L2Wrapper> device,
+    std::insert_iterator<PartialMetadataSet> insertion_point) {
+  HAL_LOG_ENTER();
+
+  // Get all supported formats.
+  std::set<int32_t> hal_formats;
+  int res = GetHalFormats(device, &hal_formats);
+  if (res) {
+    return res;
+  }
+
+  std::set<int32_t> unsupported_hal_formats;
+  if (hal_formats.find(HAL_PIXEL_FORMAT_YCbCr_420_888) == hal_formats.end()) {
+    HAL_LOGV("YCbCr_420_888 (0x%x) not directly supported by device.",
+             HAL_PIXEL_FORMAT_YCbCr_420_888);
+    hal_formats.insert(HAL_PIXEL_FORMAT_YCbCr_420_888);
+    unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_YCbCr_420_888);
+  }
+  if (hal_formats.find(HAL_PIXEL_FORMAT_BLOB) == hal_formats.end()) {
+    HAL_LOGV("JPEG (0x%x) not directly supported by device.",
+             HAL_PIXEL_FORMAT_BLOB);
+    hal_formats.insert(HAL_PIXEL_FORMAT_BLOB);
+    unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_BLOB);
+  }
+
+  // As hal_formats is populated by reading and converting V4L2 formats to the
+  // matching HAL formats, we will never see an implementation defined format in
+  // the list. We populate it ourselves and map it to a qualified format. If no
+  // qualified formats exist, this will be the first available format.
+  hal_formats.insert(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+  unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+
+  // Qualified formats are the set of formats supported by this camera that the
+  // image processor can translate into the YU12 format. We additionally check
+  // that the conversion from YU12 to the desired hal format is supported.
+  std::vector<uint32_t> qualified_formats;
+  res = device->GetQualifiedFormats(&qualified_formats);
+  if (res && unsupported_hal_formats.size() > 1) {
+    HAL_LOGE(
+        "Failed to retrieve qualified formats, cannot perform conversions.");
+    return res;
+  }
+
+  HAL_LOGI("Supports %zu qualified formats.", qualified_formats.size());
+
+  // Find sizes and frame/stall durations for all formats.
+  // We also want to find the smallest max frame duration amongst all formats,
+  // And the largest min frame duration amongst YUV (i.e. largest max frame rate
+  // supported by all YUV sizes).
+  // Stream configs are {format, width, height, direction} (input or output).
+  ArrayVector<int32_t, 4> stream_configs;
+  // Frame durations are {format, width, height, duration} (duration in ns).
+  ArrayVector<int64_t, 4> min_frame_durations;
+  // Stall durations are {format, width, height, duration} (duration in ns).
+  ArrayVector<int64_t, 4> stall_durations;
+  int64_t min_max_frame_duration = std::numeric_limits<int64_t>::max();
+  std::vector<std::array<int32_t, 2>> fps_ranges;
+  for (auto hal_format : hal_formats) {
+    // Get the corresponding V4L2 format.
+    uint32_t v4l2_format = StreamFormat::HalToV4L2PixelFormat(hal_format);
+    if (v4l2_format == 0) {
+      // Unrecognized/unused format. Should never happen since hal_formats
+      // came from translating a bunch of V4L2 formats above.
+      HAL_LOGE("Couldn't find V4L2 format for HAL format %d", hal_format);
+      return -ENODEV;
+    } else if (unsupported_hal_formats.find(hal_format) !=
+               unsupported_hal_formats.end()) {
+      if (hal_format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+        if (qualified_formats.size() != 0) {
+          v4l2_format = qualified_formats[0];
+        } else if (unsupported_hal_formats.size() == 1) {
+          v4l2_format = StreamFormat::HalToV4L2PixelFormat(
+              HAL_PIXEL_FORMAT_YCbCr_420_888);
+        } else {
+          // No-op. If there are no qualified formats, and implementation
+          // defined is not the only unsupported format, then other unsupported
+          // formats will throw an error.
+        }
+        HAL_LOGW(
+            "Implementation-defined format is set to V4L2 pixel format 0x%x",
+            v4l2_format);
+      } else if (qualified_formats.size() == 0) {
+        HAL_LOGE(
+            "Camera does not support required format: 0x%x, and there are no "
+            "qualified"
+            "formats to transform from.",
+            hal_format);
+        return -ENODEV;
+      } else if (!arc::ImageProcessor::SupportsConversion(V4L2_PIX_FMT_YUV420,
+                                                          v4l2_format)) {
+        HAL_LOGE(
+            "The image processor does not support conversion to required "
+            "format: 0x%x",
+            hal_format);
+        return -ENODEV;
+      } else {
+        v4l2_format = qualified_formats[0];
+        HAL_LOGW(
+            "Hal format 0x%x will be converted from V4L2 pixel format 0x%x",
+            hal_format, v4l2_format);
+      }
+    }
+
+    // Get the available sizes for this format.
+    std::set<std::array<int32_t, 2>> frame_sizes;
+    res = device->GetFormatFrameSizes(v4l2_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get all frame sizes for format %d", v4l2_format);
+      return res;
+    }
+
+    for (const auto& frame_size : frame_sizes) {
+      // Note the format and size combination in stream configs.
+      stream_configs.push_back(
+          {{hal_format,
+            frame_size[0],
+            frame_size[1],
+            ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}});
+
+      // Find the duration range for this format and size.
+      std::array<int64_t, 2> duration_range;
+      res = device->GetFormatFrameDurationRange(
+          v4l2_format, frame_size, &duration_range);
+      if (res) {
+        HAL_LOGE(
+            "Failed to get frame duration range for format %d, "
+            "size %u x %u",
+            v4l2_format,
+            frame_size[0],
+            frame_size[1]);
+        return res;
+      }
+      int64_t size_min_frame_duration = duration_range[0];
+      int64_t size_max_frame_duration = duration_range[1];
+      min_frame_durations.push_back({{hal_format,
+                                      frame_size[0],
+                                      frame_size[1],
+                                      size_min_frame_duration}});
+
+      // Note the stall duration for this format and size.
+      // Usually 0 for non-jpeg, non-zero for JPEG.
+      // Randomly choosing absurd 1 sec for JPEG. Unsure what this breaks.
+      int64_t stall_duration = 0;
+      if (hal_format == HAL_PIXEL_FORMAT_BLOB) {
+        stall_duration = 1000000000;
+      }
+      stall_durations.push_back(
+          {{hal_format, frame_size[0], frame_size[1], stall_duration}});
+
+      // Update our search for general min & max frame durations.
+      // In theory max frame duration (min frame rate) should be consistent
+      // between all formats, but we check and only advertise the smallest
+      // available max duration just in case.
+      if (size_max_frame_duration < min_max_frame_duration) {
+        min_max_frame_duration = size_max_frame_duration;
+      }
+      // ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES will contain all
+      // the fps ranges for YUV_420_888 only since YUV_420_888 format is
+      // the default camera format by Android.
+      if (hal_format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
+        // Convert from frame durations measured in ns.
+        // Min, max fps supported by all YUV formats.
+        const int32_t min_fps = 1000000000 / size_max_frame_duration;
+        const int32_t max_fps = 1000000000 / size_min_frame_duration;
+        if (std::find(fps_ranges.begin(), fps_ranges.end(),
+                      std::array<int32_t, 2>{{min_fps, max_fps}}) ==
+            fps_ranges.end()) {
+          fps_ranges.push_back({{min_fps, max_fps}});
+        }
+      }
+    }
+  }
+
+  // Sort fps ranges in descending order.
+  std::sort(fps_ranges.begin(), fps_ranges.end(), FpsRangesCompare);
+
+  // Construct the metadata components.
+  insertion_point = std::make_unique<Property<ArrayVector<int32_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+      std::move(stream_configs));
+
+  insertion_point = std::make_unique<Property<ArrayVector<int64_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS,
+      std::move(min_frame_durations));
+
+  insertion_point = std::make_unique<Property<ArrayVector<int64_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_STALL_DURATIONS, std::move(stall_durations));
+
+  //HAL_LOGE("min_max_frame_duration %d", min_max_frame_duration); 
+  insertion_point = std::make_unique<Property<int64_t>>(
+      ANDROID_SENSOR_INFO_MAX_FRAME_DURATION, min_max_frame_duration);
+
+  // TODO(b/31019725): This should probably not be a NoEffect control.
+ #if 0
+  insertion_point = NoEffectMenuControl<std::array<int32_t, 2>>(
+      ANDROID_CONTROL_AE_TARGET_FPS_RANGE,
+      ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES, fps_ranges,
+      {{CAMERA3_TEMPLATE_VIDEO_RECORD, fps_ranges.front()},
+       {OTHER_TEMPLATES, fps_ranges.back()}});
+#endif
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/format_metadata_factory.h b/hardware/ntimespace/camera/format_metadata_factory.h
new file mode 100644
index 0000000000..cd25f9c281
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory.h
@@ -0,0 +1,36 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
+#define V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
+
+#include <iterator>
+#include <memory>
+
+#include "metadata/metadata_common.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A factory method to construct all the format-related
+// partial metadata for a V4L2 device.
+int AddFormatComponents(
+    std::shared_ptr<V4L2Wrapper> device,
+    std::insert_iterator<PartialMetadataSet> insertion_point);
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
diff --git a/hardware/ntimespace/camera/format_metadata_factory_test.cpp b/hardware/ntimespace/camera/format_metadata_factory_test.cpp
new file mode 100644
index 0000000000..864553dc09
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory_test.cpp
@@ -0,0 +1,198 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "format_metadata_factory.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "metadata/test_common.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::AtLeast;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class FormatMetadataFactoryTest : public Test {
+ protected:
+  virtual void SetUp() { mock_device_.reset(new V4L2WrapperMock()); }
+
+  virtual void ExpectMetadataTagCount(const android::CameraMetadata& metadata,
+                                      uint32_t tag,
+                                      size_t count) {
+    camera_metadata_ro_entry_t entry = metadata.find(tag);
+    EXPECT_EQ(entry.count, count);
+  }
+
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+};
+
+TEST_F(FormatMetadataFactoryTest, GetFormatMetadata) {
+  std::set<uint32_t> formats{V4L2_PIX_FMT_JPEG, V4L2_PIX_FMT_YUV420,
+                             V4L2_PIX_FMT_YUYV};
+  std::map<uint32_t, std::set<std::array<int32_t, 2>>> sizes{
+      {V4L2_PIX_FMT_JPEG, {{{10, 20}}, {{30, 60}}, {{120, 240}}}},
+      {V4L2_PIX_FMT_YUV420, {{{1, 2}}, {{3, 6}}, {{12, 24}}}},
+      {V4L2_PIX_FMT_YUYV, {{{20, 40}}, {{80, 160}}, {{320, 640}}}}};
+  // These need to be on the correct order of magnitude,
+  // as there is a check for min fps > 15.
+  std::map<uint32_t, std::map<std::array<int32_t, 2>, std::array<int64_t, 2>>>
+      durations{{V4L2_PIX_FMT_JPEG,
+                 {{{{10, 20}}, {{100000000, 200000000}}},
+                  {{{30, 60}}, {{1000000000, 2000000000}}},
+                  {{{120, 240}}, {{700000000, 1200000000}}}}},
+                {V4L2_PIX_FMT_YUV420,
+                 {{{{1, 2}}, {{10000000000, 20000000000}}},
+                  {{{3, 6}}, {{11000000000, 21000000000}}},
+                  {{{12, 24}}, {{10500000000, 19000000000}}}}},
+                {V4L2_PIX_FMT_YUYV,
+                 {{{{20, 40}}, {{11000000000, 22000000000}}},
+                  {{{80, 160}}, {{13000000000, 25000000000}}},
+                  {{{320, 640}}, {{10100000000, 19000000000}}}}}};
+  // The camera must report at least one qualified format.
+  std::vector<uint32_t> qualified_formats = {V4L2_PIX_FMT_YUYV};
+
+  // Device must support IMPLEMENTATION_DEFINED (as well as JPEG & YUV).
+  // For USB cameras, we assume that this format will not be present, and it
+  // will default to a qualified format or one of the other required formats.
+
+  EXPECT_CALL(*mock_device_, GetFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(formats), Return(0)));
+
+  EXPECT_CALL(*mock_device_, GetQualifiedFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(qualified_formats), Return(0)));
+
+  for (auto format : formats) {
+    std::set<std::array<int32_t, 2>> format_sizes = sizes[format];
+    EXPECT_CALL(*mock_device_, GetFormatFrameSizes(format, _))
+        .Times(AtLeast(1))
+        .WillRepeatedly(DoAll(SetArgPointee<1>(format_sizes), Return(0)));
+    for (auto size : format_sizes) {
+      EXPECT_CALL(*mock_device_, GetFormatFrameDurationRange(format, size, _))
+          .Times(AtLeast(1))
+          .WillRepeatedly(
+              DoAll(SetArgPointee<2>(durations[format][size]), Return(0)));
+    }
+  }
+
+  PartialMetadataSet components;
+  ASSERT_EQ(AddFormatComponents(mock_device_,
+                                std::inserter(components, components.end())),
+            0);
+
+  for (auto& component : components) {
+    android::CameraMetadata metadata;
+    component->PopulateStaticFields(&metadata);
+    ASSERT_EQ(metadata.entryCount(), 1u);
+    int32_t tag = component->StaticTags()[0];
+    switch (tag) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS:  // Fall through.
+      case ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS:    // Fall through.
+      case ANDROID_SCALER_AVAILABLE_STALL_DURATIONS:        // Fall through.
+        // 3 sizes per format, 4 elements per config.
+        // # formats + 1 for IMPLEMENTATION_DEFINED.
+        ExpectMetadataTagCount(metadata, tag, (formats.size() + 1) * 3 * 4);
+        break;
+      case ANDROID_SENSOR_INFO_MAX_FRAME_DURATION:
+        // The lowest max duration from above.
+        ExpectMetadataEq(metadata, tag, 200000000);
+        break;
+      case ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES:
+        // 2 ranges ({min, max} and {max, max}), each with a min and max.
+        ExpectMetadataTagCount(metadata, tag, 4);
+        break;
+      default:
+        FAIL() << "Unexpected component created.";
+        break;
+    }
+  }
+}
+
+TEST_F(FormatMetadataFactoryTest, GetFormatMetadataMissingRequired) {
+  std::set<uint32_t> formats{V4L2_PIX_FMT_YUYV};
+  std::map<uint32_t, std::set<std::array<int32_t, 2>>> sizes{
+      {V4L2_PIX_FMT_YUYV, {{{640, 480}}, {{320, 240}}}}};
+  std::map<uint32_t, std::map<std::array<int32_t, 2>, std::array<int64_t, 2>>>
+      durations{{V4L2_PIX_FMT_YUYV,
+                 {{{{640, 480}}, {{100000000, 200000000}}},
+                  {{{320, 240}}, {{100000000, 200000000}}}}}};
+
+  EXPECT_CALL(*mock_device_, GetFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(formats), Return(0)));
+  // If a qualified format is present, we expect that required fields are
+  // populated as if they are supported.
+  std::vector<uint32_t> qualified_formats = {V4L2_PIX_FMT_YUYV};
+
+  EXPECT_CALL(*mock_device_, GetQualifiedFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(qualified_formats), Return(0)));
+
+  for (auto format : formats) {
+    std::set<std::array<int32_t, 2>> format_sizes = sizes[format];
+    EXPECT_CALL(*mock_device_, GetFormatFrameSizes(format, _))
+        .Times(AtLeast(1))
+        .WillRepeatedly(DoAll(SetArgPointee<1>(format_sizes), Return(0)));
+    for (auto size : format_sizes) {
+      EXPECT_CALL(*mock_device_, GetFormatFrameDurationRange(format, size, _))
+          .Times(AtLeast(1))
+          .WillRepeatedly(
+              DoAll(SetArgPointee<2>(durations[format][size]), Return(0)));
+    }
+  }
+
+  // Check that all required formats are present.
+  PartialMetadataSet components;
+  ASSERT_EQ(AddFormatComponents(mock_device_,
+                                std::inserter(components, components.end())),
+            0);
+
+  std::vector<std::array<int32_t, 2>> target_fps_ranges{{{5, 10}}, {{10, 10}}};
+  for (auto& component : components) {
+    android::CameraMetadata metadata;
+    component->PopulateStaticFields(&metadata);
+    ASSERT_EQ(metadata.entryCount(), 1u);
+    int32_t tag = component->StaticTags()[0];
+    switch (tag) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS:  // Fall through.
+      case ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS:    // Fall through.
+      case ANDROID_SCALER_AVAILABLE_STALL_DURATIONS:        // Fall through.
+        // Two sizes per format, four elements per config.
+        // # formats + 3 for YUV420, JPEG, IMPLEMENTATION_DEFINED.
+        ExpectMetadataTagCount(metadata, tag, (formats.size() + 3) * 2 * 4);
+        break;
+      case ANDROID_SENSOR_INFO_MAX_FRAME_DURATION:
+        // The lowest max duration from above.
+        ExpectMetadataEq(metadata, tag, 200000000);
+        break;
+      case ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES:
+        // 2 ranges ({min, max} and {max, max}), each with a min and max.
+        ExpectMetadataTagCount(metadata, tag, 4);
+        ExpectMetadataEq(metadata, tag, target_fps_ranges);
+        break;
+      default:
+        FAIL() << "Unexpected component created.";
+        break;
+    }
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/function_thread.h b/hardware/ntimespace/camera/function_thread.h
new file mode 100644
index 0000000000..44bf061821
--- /dev/null
+++ b/hardware/ntimespace/camera/function_thread.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
+#define V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
+
+#include <functional>
+
+#include <utils/Thread.h>
+
+namespace v4l2_camera_hal {
+
+class FunctionThread : public android::Thread {
+ public:
+  FunctionThread(std::function<bool()> function) : function_(function){};
+
+ private:
+  bool threadLoop() override {
+    bool result = function_();
+    return result;
+  };
+
+  std::function<bool()> function_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
diff --git a/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp b/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
new file mode 100644
index 0000000000..f19cb6eccf
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
@@ -0,0 +1,317 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "HandleImporter"
+#include "gralloc3_impl.h"
+#include <log/log.h>
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+
+using MapperErrorV2 = android::hardware::graphics::mapper::V2_0::Error;
+using MapperErrorV3 = android::hardware::graphics::mapper::V3_0::Error;
+using IMapperV3 = android::hardware::graphics::mapper::V3_0::IMapper;
+
+HandleImporter::HandleImporter() : mInitialized(false) {}
+
+void HandleImporter::initializeLocked() {
+    if (mInitialized) {
+        return;
+    }
+
+    mMapperV3 = IMapperV3::getService();
+    if (mMapperV3 != nullptr) {
+        mInitialized = true;
+        return;
+    }
+
+    mMapperV2 = IMapper::getService();
+    if (mMapperV2 == nullptr) {
+        ALOGE("%s: cannnot acccess graphics mapper HAL!", __FUNCTION__);
+        return;
+    }
+
+    mInitialized = true;
+    return;
+}
+
+void HandleImporter::cleanup() {
+    mMapperV3.clear();
+    mMapperV2.clear();
+    mInitialized = false;
+}
+
+template<class M, class E>
+bool HandleImporter::importBufferInternal(const sp<M> mapper, buffer_handle_t& handle, buffer_handle_t& outhandle) {
+    E error;
+    buffer_handle_t importedHandle;
+    auto ret = mapper->importBuffer(
+        hidl_handle(handle),
+        [&](const auto& tmpError, const auto& tmpBufferHandle) {
+            error = tmpError;
+            importedHandle = static_cast<buffer_handle_t>(tmpBufferHandle);
+        });
+
+    if (!ret.isOk()) {
+        ALOGE("%s: mapper importBuffer failed: %s",
+                __FUNCTION__, ret.description().c_str());
+        return false;
+    }
+
+    if (error != E::NONE) {
+        return false;
+    }
+
+    handle = importedHandle;  
+    outhandle = importedHandle;
+    return true;
+}
+
+template<class M, class E>
+YCbCrLayout HandleImporter::lockYCbCrInternal(const sp<M> mapper, buffer_handle_t& buf,
+        uint64_t cpuUsage, const IMapper::Rect& accessRegion) {
+    hidl_handle acquireFenceHandle;
+    auto buffer = const_cast<native_handle_t*>(buf);
+    YCbCrLayout layout = {};
+
+    typename M::Rect accessRegionCopy = {accessRegion.left, accessRegion.top,
+            accessRegion.width, accessRegion.height};
+    mapper->lockYCbCr(buffer, cpuUsage, accessRegionCopy, acquireFenceHandle,
+            [&](const auto& tmpError, const auto& tmpLayout) {
+                if (tmpError == E::NONE) {
+                    // Member by member copy from different versions of YCbCrLayout.
+                    layout.y = tmpLayout.y;
+                    layout.cb = tmpLayout.cb;
+                    layout.cr = tmpLayout.cr;
+                    layout.yStride = tmpLayout.yStride;
+                    layout.cStride = tmpLayout.cStride;
+                    layout.chromaStep = tmpLayout.chromaStep;
+                } else {
+                    ALOGE("%s: failed to lockYCbCr error %d!", __FUNCTION__, tmpError);
+                }
+           });
+
+
+
+
+
+
+
+
+
+
+
+    return layout;
+}
+
+template<class M, class E>
+int HandleImporter::unlockInternal(const sp<M> mapper, buffer_handle_t& buf) {
+    int releaseFence = -1;
+    auto buffer = const_cast<native_handle_t*>(buf);
+
+    mapper->unlock(
+        buffer, [&](const auto& tmpError, const auto& tmpReleaseFence) {
+            if (tmpError == E::NONE) {
+                auto fenceHandle = tmpReleaseFence.getNativeHandle();
+                if (fenceHandle) {
+                    if (fenceHandle->numInts != 0 || fenceHandle->numFds != 1) {
+                        ALOGE("%s: bad release fence numInts %d numFds %d",
+                                __FUNCTION__, fenceHandle->numInts, fenceHandle->numFds);
+                        return;
+                    }
+                    releaseFence = dup(fenceHandle->data[0]);
+                    if (releaseFence < 0) {
+                        ALOGE("%s: bad release fence FD %d",
+                                __FUNCTION__, releaseFence);
+                    }
+                }
+            } else {
+                ALOGE("%s: failed to unlock error %d!", __FUNCTION__, tmpError);
+            }
+        });
+    return releaseFence;
+}
+
+// In IComposer, any buffer_handle_t is owned by the caller and we need to
+// make a clone for hwcomposer2.  We also need to translate empty handle
+// to nullptr.  This function does that, in-place.
+bool HandleImporter::importBuffer(buffer_handle_t& handle, buffer_handle_t& outhandle) {
+    if (!handle->numFds && !handle->numInts) {
+        handle = nullptr;
+        return true;
+    }
+
+    Mutex::Autolock lock(mLock);
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    if (mMapperV3 != nullptr) {
+        return importBufferInternal<IMapperV3, MapperErrorV3>(mMapperV3, handle, outhandle);
+    }
+
+    if (mMapperV2 != nullptr) {
+        return importBufferInternal<IMapper, MapperErrorV2>(mMapperV2, handle, outhandle);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return false;
+}
+
+void HandleImporter::freeBuffer(buffer_handle_t handle) {
+    if (!handle) {
+        return;
+    }
+
+    Mutex::Autolock lock(mLock);
+    if (mMapperV3 == nullptr && mMapperV2 == nullptr) {
+        ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+        return;
+        }
+
+    if (mMapperV3 != nullptr) {
+        auto ret = mMapperV3->freeBuffer(const_cast<native_handle_t*>(handle));
+        if (!ret.isOk()) {
+            ALOGE("%s: mapper freeBuffer failed: %s",
+                    __FUNCTION__, ret.description().c_str());
+        }
+    } else {
+        auto ret = mMapperV2->freeBuffer(const_cast<native_handle_t*>(handle));
+        if (!ret.isOk()) {
+            ALOGE("%s: mapper freeBuffer failed: %s",
+                    __FUNCTION__, ret.description().c_str());
+        }
+    }
+}
+
+bool HandleImporter::importFence(const native_handle_t* handle, int& fd) const {
+    if (handle == nullptr || handle->numFds == 0) {
+        fd = -1;
+    } else if (handle->numFds == 1) {
+        fd = dup(handle->data[0]);
+        if (fd < 0) {
+            ALOGE("failed to dup fence fd %d", handle->data[0]);
+            return false;
+        }
+    } else {
+        ALOGE("invalid fence handle with %d file descriptors",
+                handle->numFds);
+        return false;
+    }
+
+    return true;
+}
+
+void HandleImporter::closeFence(int fd) const {
+    if (fd >= 0) {
+        close(fd);
+    }
+}
+
+void* HandleImporter::lock(buffer_handle_t& buf, uint64_t cpuUsage,
+                           const IMapper::Rect& accessRegion) {
+    Mutex::Autolock lock(mLock);
+
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    void* ret = nullptr;
+
+    if (mMapperV3 == nullptr && mMapperV2 == nullptr) {
+        ALOGE("%s: mMapperV3 and mMapperV2 are all null!", __FUNCTION__);
+        return ret;
+    }
+
+    hidl_handle acquireFenceHandle; 
+    auto buffer = const_cast<native_handle_t*>(buf);
+    if (mMapperV3 != nullptr) {
+        IMapperV3::Rect accessRegionV3{accessRegion.left, accessRegion.top, accessRegion.width,
+                                       accessRegion.height};
+
+        mMapperV3->lock(buffer, cpuUsage, accessRegionV3, acquireFenceHandle,
+                        [&](const auto& tmpError, const auto& tmpPtr, const auto& /*bytesPerPixel*/,
+                            const auto& /*bytesPerStride*/) {
+                            if (tmpError == MapperErrorV3::NONE) {
+                                ret = tmpPtr;
+                            } else {
+                                ALOGE("%s: failed to lock error %d!", __FUNCTION__, tmpError);
+                            }
+                        });
+    } else {
+        mMapperV2->lock(buffer, cpuUsage, accessRegion, acquireFenceHandle,
+                [&](const auto& tmpError, const auto& tmpPtr) {
+                    if (tmpError == MapperErrorV2::NONE) {
+                        ret = tmpPtr;
+                    } else {
+                        ALOGE("%s: failed to lock error %d!", __FUNCTION__, tmpError);
+                    }
+               });
+    }
+
+    ALOGV("%s: ptr %p accessRegion.top: %d accessRegion.left: %d accessRegion.width: %d "
+          "accessRegion.height: %d",
+          __FUNCTION__, ret, accessRegion.top, accessRegion.left, accessRegion.width,
+          accessRegion.height);
+    return ret;
+}
+
+YCbCrLayout HandleImporter::lockYCbCr(
+        buffer_handle_t& buf, uint64_t cpuUsage,
+        const IMapper::Rect& accessRegion) {
+    Mutex::Autolock lock(mLock);
+
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    if (mMapperV3 != nullptr) {
+        return lockYCbCrInternal<IMapperV3, MapperErrorV3>(
+                mMapperV3, buf, cpuUsage, accessRegion);
+    }
+
+    if (mMapperV2 != nullptr) {
+        return lockYCbCrInternal<IMapper, MapperErrorV2>(
+                mMapperV2, buf, cpuUsage, accessRegion);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return {};
+}
+
+
+int HandleImporter::unlock(buffer_handle_t& buf) {
+    if (mMapperV3 != nullptr) {
+        return unlockInternal<IMapperV3, MapperErrorV3>(mMapperV3, buf);
+    }
+    if (mMapperV2 != nullptr) {
+        return unlockInternal<IMapper, MapperErrorV2>(mMapperV2, buf);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return -1;
+}
+
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+} // namespace android
diff --git a/hardware/ntimespace/camera/gralloc/gralloc3_impl.h b/hardware/ntimespace/camera/gralloc/gralloc3_impl.h
new file mode 100644
index 0000000000..9406c8bf39
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/gralloc3_impl.h
@@ -0,0 +1,84 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef CAMERA_COMMON_1_0_HANDLEIMPORTED_H
+#define CAMERA_COMMON_1_0_HANDLEIMPORTED_H
+
+#include <utils/Mutex.h>
+#include <android/hardware/graphics/mapper/2.0/IMapper.h>
+#include <android/hardware/graphics/mapper/3.0/IMapper.h>
+#include <cutils/native_handle.h>
+
+using android::hardware::graphics::mapper::V2_0::IMapper;
+using android::hardware::graphics::mapper::V2_0::YCbCrLayout;
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+
+// Borrowed from graphics HAL. Use this until gralloc mapper HAL is working
+class HandleImporter {
+public:
+    HandleImporter();
+
+    // In IComposer, any buffer_handle_t is owned by the caller and we need to
+    // make a clone for hwcomposer2.  We also need to translate empty handle
+    // to nullptr.  This function does that, in-place.
+    bool importBuffer(buffer_handle_t& handle, buffer_handle_t& outhandle);
+    void freeBuffer(buffer_handle_t handle);
+    bool importFence(const native_handle_t* handle, int& fd) const;
+    void closeFence(int fd) const;
+
+    // Assume caller has done waiting for acquire fences
+    void* lock(buffer_handle_t& buf, uint64_t cpuUsage,
+                           const IMapper::Rect& accessRegion);
+
+    // Assume caller has done waiting for acquire fences
+    YCbCrLayout lockYCbCr(buffer_handle_t& buf, uint64_t cpuUsage,
+                          const IMapper::Rect& accessRegion);
+
+
+    int unlock(buffer_handle_t& buf); // returns release fence
+
+private:
+    void initializeLocked();
+    void cleanup();
+
+    template<class M, class E>
+    bool importBufferInternal(const sp<M> mapper, buffer_handle_t& handle, buffer_handle_t& outhandle);
+    template<class M, class E>
+    YCbCrLayout lockYCbCrInternal(const sp<M> mapper, buffer_handle_t& buf, uint64_t cpuUsage,
+            const IMapper::Rect& accessRegion);
+    template<class M, class E>
+    int unlockInternal(const sp<M> mapper, buffer_handle_t& buf);
+
+    Mutex mLock;
+    bool mInitialized;
+    sp<IMapper> mMapperV2;
+    sp<graphics::mapper::V3_0::IMapper> mMapperV3;
+};
+
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+} // namespace android
+
+#endif // CAMERA_COMMON_1_0_HANDLEIMPORTED_H
diff --git a/hardware/ntimespace/camera/gralloc/hal_public.h b/hardware/ntimespace/camera/gralloc/hal_public.h
new file mode 100644
index 0000000000..19910c10f7
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/hal_public.h
@@ -0,0 +1,215 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef HAL_PUBLIC_H
+#define HAL_PUBLIC_H
+
+#define PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE
+#define PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2
+
+#include "img_gralloc_common_public.h"
+
+/* Extension pixel formats used by Intel components */
+
+#undef  HAL_PIXEL_FORMAT_NV12
+
+#define HAL_PIXEL_FORMAT_UYVY                 0x107
+#define HAL_PIXEL_FORMAT_INTEL_YV12           0x108
+#define HAL_PIXEL_FORMAT_INTEL_ZSL            0x109
+#define HAL_PIXEL_FORMAT_NV12                 0x3231564E
+#define HAL_PIXEL_FORMAT_NV21                 0x3132564E
+#define HAL_PIXEL_FORMAT_I420                 0x30323449
+#define HAL_PIXEL_FORMAT_YUY2                 0x32595559
+#define HAL_PIXEL_FORMAT_NV12_VED             0x7FA00E00
+#define HAL_PIXEL_FORMAT_NV12_VEDT            0x7FA00F00
+
+/* Extension API used by Intel components */
+
+#define GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG  108
+#define GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG  109
+
+#define GRALLOC_GET_DISPLAY_DEVICE_IMG        1000
+#define GRALLOC_GET_DISPLAY_STATUS_IMG        1001
+
+#include "img_gralloc.h"
+#include "img_gralloc1.h"
+
+typedef const gralloc_module_t gralloc0_t;
+typedef gralloc1_device_t      gralloc1_t;
+
+static inline int gralloc_is_v1_img(const hw_module_t *m)
+{
+	return ((m->module_api_version >> 8) & 0xff) == 1;
+}
+
+static inline int gralloc_open_img(const hw_device_t **d)
+{
+	const hw_module_t *m;
+	int err;
+
+	err = hw_get_module(GRALLOC_HARDWARE_MODULE_ID, &m);
+	if (err)
+		return err;
+
+	if (gralloc_is_v1_img(m))
+		return gralloc1_open(m, (gralloc1_t **)d);
+	else
+		return gralloc_open(m, (alloc_device_t **)d);
+}
+
+static inline int gralloc_close_img(const hw_device_t *d)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_close((gralloc1_t *)d);
+	else
+		return gralloc_close((alloc_device_t *)d);
+}
+
+static inline int gralloc_register_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_register_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_register_img((gralloc0_t *)d->module, handle);
+}
+
+static inline int gralloc_unregister_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_unregister_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_unregister_img((gralloc0_t *)d->module, handle);
+}
+
+static inline int gralloc_device_alloc_img
+	(const hw_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	if (gralloc_is_v1_img(d->module)) {
+		usage = (usage | ((usage & 0x33) << 1)) & ~0x11;
+		return gralloc1_device_alloc_img((gralloc1_t *)d, w, h, format,
+										 usage, handle, stride);
+	} else
+		return gralloc0_device_alloc_img((alloc_device_t *)d, w, h, format,
+										 usage, handle, stride);
+}
+
+static inline int gralloc_device_free_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_device_free_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_device_free_img((alloc_device_t *)d, handle);
+}
+
+static inline int gralloc_lock_async_img
+	(const hw_device_t *d, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	if (gralloc_is_v1_img(d->module)) {
+		usage = (usage | ((usage & 0x33) << 1)) & ~0x11;
+		return gralloc1_lock_async_img((gralloc1_t *)d,
+									   handle, usage, r, vaddr, acquireFence);
+	} else
+		return gralloc0_lock_async_img((gralloc0_t *)d->module,
+									   handle, usage, r, vaddr, acquireFence);
+}
+
+static inline int gralloc_unlock_async_img
+	(const hw_device_t *d, buffer_handle_t handle, int *releaseFence)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_unlock_async_img((gralloc1_t *)d,
+										 handle, releaseFence);
+	else
+		return gralloc0_unlock_async_img((gralloc0_t *)d->module,
+										 handle, releaseFence);
+}
+
+static inline int gralloc_blit_handle_to_handle_img
+	(const hw_device_t *d, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_blit_handle_to_handle_img((gralloc1_t *)d,
+												  src, dest, w, h, x, y,
+												  transform, input_fence,
+												  output_fence);
+	else
+		return gralloc0_blit_handle_to_handle_img((gralloc0_t *)d->module,
+												  src, dest, w, h, x, y,
+												  transform, input_fence,
+												  output_fence);
+}
+
+
+static inline int gralloc_get_buffer_cpu_addresses_img
+	(const hw_device_t *d, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_buffer_cpu_addresses_img((gralloc1_t *)d,
+													 handle, vaddrs, sizes);
+	else
+		return gralloc0_get_buffer_cpu_addresses_img((gralloc0_t *)d->module,
+													 handle, vaddrs, sizes);
+}
+
+static inline int gralloc_put_buffer_cpu_addresses_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_put_buffer_cpu_addresses_img((gralloc1_t *)d,
+													 handle);
+	else
+		return gralloc0_put_buffer_cpu_addresses_img((gralloc0_t *)d->module,
+													 handle);
+}
+
+static inline int gralloc_get_display_device_img
+	(const hw_device_t *d, void **ppvDispDev)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_display_device_img((gralloc1_t *)d,
+											   ppvDispDev);
+	else
+		return gralloc0_get_display_device_img((gralloc0_t *)d->module,
+											   ppvDispDev);
+}
+
+static inline int gralloc_get_display_status_img
+	(const hw_device_t *d, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_display_status_img((gralloc1_t *)d,
+											   handle, pui32Status);
+	else
+		return gralloc0_get_display_status_img((gralloc0_t *)d->module,
+											   handle, pui32Status);
+}
+
+#endif /* HAL_PUBLIC_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc.h b/hardware/ntimespace/camera/gralloc/img_gralloc.h
new file mode 100644
index 0000000000..d9560fa83b
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc.h
@@ -0,0 +1,107 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC_H
+#define IMG_GRALLOC_H
+
+#include <hardware/gralloc.h>
+
+/* for gralloc1_rect_t */
+#include <hardware/gralloc1.h>
+
+static inline int gralloc0_register_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->registerBuffer(g, handle);
+}
+
+static inline int gralloc0_unregister_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->unregisterBuffer(g, handle);
+}
+
+static inline int gralloc0_device_alloc_img
+	(alloc_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	return d->alloc(d, w, h, format, usage, handle, stride);
+}
+
+static inline int gralloc0_device_free_img
+	(alloc_device_t *d, buffer_handle_t handle)
+{
+	return d->free(d, handle);
+}
+
+static inline int gralloc0_lock_async_img
+	(const gralloc_module_t *g, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	return g->lockAsync(g, handle, usage,
+						r->left, r->top, r->width, r->height,
+						vaddr, acquireFence);
+}
+
+static inline int gralloc0_unlock_async_img
+	(const gralloc_module_t *g, buffer_handle_t handle, int *releaseFence)
+{
+	return g->unlockAsync(g, handle, releaseFence);
+}
+
+static inline int gralloc0_blit_handle_to_handle_img
+	(const gralloc_module_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	return g->perform(g, GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG, src, dest, w, h,
+					  x, y, transform, input_fence, output_fence);
+}
+
+static inline int gralloc0_get_buffer_cpu_addresses_img
+	(const gralloc_module_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	return g->perform(g, GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG, handle, vaddrs,
+					  sizes);
+}
+
+static inline int gralloc0_put_buffer_cpu_addresses_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->perform(g, GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG, handle);
+}
+
+static inline int gralloc0_get_display_device_img
+	(const gralloc_module_t *g, void **ppvDispDev)
+{
+	return g->perform(g, GRALLOC_GET_DISPLAY_DEVICE_IMG, ppvDispDev);
+}
+
+static inline int gralloc0_get_display_status_img
+	(const gralloc_module_t *g, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	return g->perform(g, GRALLOC_GET_DISPLAY_STATUS_IMG, handle, pui32Status);
+}
+
+#endif /* IMG_GRALLOC_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc1.h b/hardware/ntimespace/camera/gralloc/img_gralloc1.h
new file mode 100644
index 0000000000..5e7659a6a0
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc1.h
@@ -0,0 +1,305 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC1_H
+#define IMG_GRALLOC1_H
+
+#include <hardware/gralloc1.h>
+
+#include <stdlib.h>
+
+#define GRALLOC1_FUNCTION_IMG_EXT_OFF 1000
+
+enum
+{
+	GRALLOC1_FUNCTION_BLIT_HANDLE_TO_HANDLE_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG),
+	GRALLOC1_FUNCTION_GET_BUFFER_CPU_ADDRESSES_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG),
+	GRALLOC1_FUNCTION_PUT_BUFFER_CPU_ADDRESSES_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG),
+	GRALLOC1_FUNCTION_GET_DISPLAY_DEVICE_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_DISPLAY_DEVICE_IMG),
+	GRALLOC1_FUNCTION_GET_DISPLAY_STATUS_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_DISPLAY_STATUS_IMG),
+};
+
+static inline int gralloc1_register_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_RETAIN f =
+		(GRALLOC1_PFN_RETAIN)
+			g->getFunction(g, GRALLOC1_FUNCTION_RETAIN);
+	int32_t err;
+
+	err = f(g, handle);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			return -EAGAIN;
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_unregister_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_RELEASE f =
+		(GRALLOC1_PFN_RELEASE)
+			g->getFunction(g, GRALLOC1_FUNCTION_RELEASE);
+	int32_t err;
+
+	err = f(g, handle);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_device_alloc_img
+	(gralloc1_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	GRALLOC1_PFN_ALLOCATE allocate =
+		(GRALLOC1_PFN_ALLOCATE)
+			d->getFunction(d, GRALLOC1_FUNCTION_ALLOCATE);
+	GRALLOC1_PFN_CREATE_DESCRIPTOR createDescriptor =
+		(GRALLOC1_PFN_CREATE_DESCRIPTOR)
+			d->getFunction(d, GRALLOC1_FUNCTION_CREATE_DESCRIPTOR);
+	GRALLOC1_PFN_DESTROY_DESCRIPTOR destroyDescriptor =
+		(GRALLOC1_PFN_DESTROY_DESCRIPTOR)
+			d->getFunction(d, GRALLOC1_FUNCTION_DESTROY_DESCRIPTOR);
+	GRALLOC1_PFN_SET_CONSUMER_USAGE setConsumerUsage =
+		(GRALLOC1_PFN_SET_CONSUMER_USAGE)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_CONSUMER_USAGE);
+	GRALLOC1_PFN_SET_DIMENSIONS setDimensions =
+		(GRALLOC1_PFN_SET_DIMENSIONS)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_DIMENSIONS);
+	GRALLOC1_PFN_SET_FORMAT setFormat =
+		(GRALLOC1_PFN_SET_FORMAT)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_FORMAT);
+	GRALLOC1_PFN_SET_PRODUCER_USAGE setProducerUsage =
+		(GRALLOC1_PFN_SET_PRODUCER_USAGE)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_PRODUCER_USAGE);
+	GRALLOC1_PFN_GET_STRIDE getStride =
+		(GRALLOC1_PFN_GET_STRIDE)
+			d->getFunction(d, GRALLOC1_FUNCTION_GET_STRIDE);
+	uint64_t producerUsage =
+		(usage & (GRALLOC1_PRODUCER_USAGE_CPU_READ_OFTEN    |
+		          GRALLOC1_PRODUCER_USAGE_CPU_WRITE_OFTEN   |
+		          GRALLOC1_PRODUCER_USAGE_GPU_RENDER_TARGET |
+		          GRALLOC1_PRODUCER_USAGE_PROTECTED         |
+		          GRALLOC1_PRODUCER_USAGE_CAMERA            |
+		          GRALLOC1_PRODUCER_USAGE_VIDEO_DECODER));
+	uint64_t consumerUsage =
+		(usage & (GRALLOC1_CONSUMER_USAGE_CPU_READ_OFTEN    |
+		          GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE       |
+		          GRALLOC1_CONSUMER_USAGE_HWCOMPOSER        |
+		          GRALLOC1_CONSUMER_USAGE_CLIENT_TARGET     |
+		          GRALLOC1_CONSUMER_USAGE_CURSOR            |
+		          GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER     |
+		          GRALLOC1_CONSUMER_USAGE_CAMERA            |
+		          GRALLOC1_CONSUMER_USAGE_RENDERSCRIPT));
+	gralloc1_buffer_descriptor_t descriptor;
+	uint32_t stride32;
+	int err = -EINVAL;
+	int32_t err32;
+
+	err32 = createDescriptor(d, &descriptor);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_out;
+
+	err32 = setDimensions(d, descriptor, w, h);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setFormat(d, descriptor, format);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setConsumerUsage(d, descriptor, consumerUsage);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setProducerUsage(d, descriptor, producerUsage);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = allocate(d, 1, &descriptor, handle);
+	switch (err32)
+	{
+		case GRALLOC1_ERROR_NOT_SHARED:
+		case GRALLOC1_ERROR_NONE:
+			break;
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			err = -EAGAIN;
+			goto err_destroy_descriptor;
+			break;			
+		default:
+			goto err_destroy_descriptor;
+	}
+
+	err32 = getStride(d, *handle, &stride32);
+	if (err32 != GRALLOC1_ERROR_NONE)
+	{
+		gralloc1_unregister_img(d, *handle);
+		goto err_destroy_descriptor;
+	}
+
+	*stride = (int)stride32;
+	err = 0;
+err_destroy_descriptor:
+	destroyDescriptor(d, descriptor);
+err_out:
+	return err;
+}
+
+static inline int gralloc1_device_free_img
+	(gralloc1_device_t *d, buffer_handle_t handle)
+{
+	return gralloc1_unregister_img(d, handle);
+}
+
+static inline int gralloc1_lock_async_img
+	(gralloc1_device_t *g, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	GRALLOC1_PFN_LOCK f =
+		(GRALLOC1_PFN_LOCK)
+			g->getFunction(g, GRALLOC1_FUNCTION_LOCK);
+	uint64_t producerUsage =
+		(usage & (GRALLOC1_PRODUCER_USAGE_CPU_READ_OFTEN |
+		          GRALLOC1_PRODUCER_USAGE_CPU_WRITE_OFTEN));
+	uint64_t consumerUsage =
+		(usage &  GRALLOC1_CONSUMER_USAGE_CPU_READ_OFTEN);
+	int32_t err;
+
+	err = f(g, handle, producerUsage, consumerUsage, r, vaddr, acquireFence);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			return -EAGAIN;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_unlock_async_img
+	(gralloc1_device_t *g, buffer_handle_t handle, int *releaseFence)
+{
+	GRALLOC1_PFN_UNLOCK f =
+		(GRALLOC1_PFN_UNLOCK)
+			g->getFunction(g, GRALLOC1_FUNCTION_UNLOCK);
+	int32_t err, releaseFence32;
+
+	err = f(g, handle, &releaseFence32);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			*releaseFence = releaseFence32;
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+typedef int (*GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG)
+	(gralloc1_device_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence);
+
+static inline int gralloc1_blit_handle_to_handle_img
+	(gralloc1_device_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG f =
+		(GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_BLIT_HANDLE_TO_HANDLE_IMG);
+
+	return f(g, src, dest, w, h, x, y, transform, input_fence, output_fence);
+}
+
+typedef int (*GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes);
+
+static inline int gralloc1_get_buffer_cpu_addresses_img
+	(gralloc1_device_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG f =
+		(GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_BUFFER_CPU_ADDRESSES_IMG);
+
+	return f(g, handle, vaddrs, sizes);
+}
+
+typedef int (*GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle);
+
+static inline int gralloc1_put_buffer_cpu_addresses_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG f =
+		(GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_PUT_BUFFER_CPU_ADDRESSES_IMG);
+
+	return f(g, handle);
+}
+
+typedef int (*GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG)
+	(gralloc1_device_t *g, void **ppvDispDev);
+
+static inline int gralloc1_get_display_device_img
+	(gralloc1_device_t *g, void **ppvDispDev)
+{
+	GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG f =
+		(GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_DISPLAY_DEVICE_IMG);
+
+	return f(g, ppvDispDev);
+}
+
+typedef int (*GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle, uint32_t *pui32Status);
+
+static inline int gralloc1_get_display_status_img
+	(gralloc1_device_t *g, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG f =
+		(GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_DISPLAY_STATUS_IMG);
+
+	return f(g, handle, pui32Status);
+}
+
+#endif /* IMG_GRALLOC1_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h b/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
new file mode 100644
index 0000000000..98f7e24117
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
@@ -0,0 +1,370 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC_COMMON_PUBLIC_H
+#define IMG_GRALLOC_COMMON_PUBLIC_H
+
+#include <cutils/native_handle.h>
+#include <system/graphics.h>
+#include <linux/ion.h>
+
+#define ALIGN(x,a)	((((x) + (a) - 1L) / (a)) * (a))
+#define HW_ALIGN	32
+
+/* Use bits [0-3] of "vendor format" bits as real format. Customers should
+ * use *only* the unassigned bits below for custom pixel formats, YUV or RGB.
+ *
+ * If there are no bits set in this part of the field, or other bits are set
+ * in the format outside of the "vendor format" mask, the non-extension format
+ * is used instead. Reserve 0 for this purpose.
+ */
+
+#define HAL_PIXEL_FORMAT_VENDOR_EXT(fmt) (0x100 | (fmt & 0xF))
+
+/*      Reserved ** DO NOT USE **    HAL_PIXEL_FORMAT_VENDOR_EXT(0) */
+#define HAL_PIXEL_FORMAT_BGRX_8888   HAL_PIXEL_FORMAT_VENDOR_EXT(1)
+#define HAL_PIXEL_FORMAT_sBGR_A_8888 HAL_PIXEL_FORMAT_VENDOR_EXT(2)
+#define HAL_PIXEL_FORMAT_sBGR_X_8888 HAL_PIXEL_FORMAT_VENDOR_EXT(3)
+/*      HAL_PIXEL_FORMAT_RGB_565     HAL_PIXEL_FORMAT_VENDOR_EXT(4) */
+/*      HAL_PIXEL_FORMAT_BGRA_8888   HAL_PIXEL_FORMAT_VENDOR_EXT(5) */
+#define HAL_PIXEL_FORMAT_NV12        HAL_PIXEL_FORMAT_VENDOR_EXT(6)
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(7) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(8) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(9) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(10) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(11) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(12) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(13) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(14) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(15) */
+
+/* One of the below compression modes is OR'ed into bits [4-6] of the 8 bit
+ * "vendor format" field. If no bits are set in this "compression mask", the
+ * normal memory format for the pixel format is used. Otherwise the pixel
+ * data will be compressed in memory with the Rogue framebuffer compressor.
+ */
+
+#define HAL_FB_COMPRESSION_NONE                0
+#define HAL_FB_COMPRESSION_DIRECT_8x8          1
+#define HAL_FB_COMPRESSION_DIRECT_16x4         2
+#define HAL_FB_COMPRESSION_DIRECT_32x2         3
+#define HAL_FB_COMPRESSION_INDIRECT_8x8        4
+#define HAL_FB_COMPRESSION_INDIRECT_16x4       5
+#define HAL_FB_COMPRESSION_INDIRECT_4TILE_8x8  6
+#define HAL_FB_COMPRESSION_INDIRECT_4TILE_16x4 7
+
+/* The memory layout is OR'ed into bit 7 (top bit) of the 8 bit "vendor
+ * format" field. Only STRIDED and TWIDDLED are supported; there is no space
+ * for PAGETILED.
+ */
+#define HAL_FB_MEMLAYOUT_STRIDED               0
+#define HAL_FB_MEMLAYOUT_TWIDDLED              1
+
+/* This can be tuned down as appropriate for the SOC.
+ *
+ * IMG formats are usually a single sub-alloc.
+ * Some OEM video formats are two sub-allocs (Y, UV planes).
+ * Future OEM video formats might be three sub-allocs (Y, U, V planes).
+ */
+#define MAX_SUB_ALLOCS (3)
+
+typedef struct
+{
+	native_handle_t base;
+
+	/* These fields can be sent cross process. They are also valid
+	 * to duplicate within the same process.
+	 *
+	 * A table is stored within the gralloc implementation's private data
+	 * structure (which is per-process) which maps stamps to a mapped
+	 * PVRSRV_MEMDESC in that process. Each map entry has a lock count
+	 * associated with it, satisfying the requirements of the gralloc API.
+	 * This also prevents us from leaking maps/allocations.
+	 */
+
+#define IMG_NATIVE_HANDLE_NUMFDS (MAX_SUB_ALLOCS)
+	/* The `fd' field is used to "export" a meminfo to another process. */
+	int fd[IMG_NATIVE_HANDLE_NUMFDS];
+
+	/* This define should represent the number of packed 'int's required to
+	 * represent the fields following it. If you add a data type that is
+	 * 64-bit, for example using 'unsigned long long', you should write that
+	 * as "sizeof(unsigned long long) / sizeof(int)". Please keep the order
+	 * of the additions the same as the defined field order.
+	 */
+#define IMG_NATIVE_HANDLE_NUMINTS \
+	(sizeof(unsigned long long) / sizeof(int) + \
+	 6 + MAX_SUB_ALLOCS + MAX_SUB_ALLOCS + \
+	 sizeof(unsigned long long) / sizeof(int) * MAX_SUB_ALLOCS + \
+	 1)
+	/* A KERNEL unique identifier for any exported kernel memdesc. Each
+	 * exported kernel memdesc will have a unique stamp, but note that in
+	 * userspace, several memdescs across multiple processes could have
+	 * the same stamp. As the native_handle can be dup(2)'d, there could be
+	 * multiple handles with the same stamp but different file descriptors.
+	 */
+	unsigned long long ui64Stamp;
+
+	/* This is used for buffer usage validation */
+	int usage;
+
+	/* In order to do efficient cache flushes we need the buffer dimensions,
+	 * format and bits per pixel. There are ANativeWindow queries for the
+	 * width, height and format, but the graphics HAL might have remapped the
+	 * request to different values at allocation time. These are the 'true'
+	 * values of the buffer allocation.
+	 */
+	int iWidth;
+	int iHeight;
+	int iFormat;
+	unsigned int uiBpp;
+
+	/* Planes are not the same as the `fd' suballocs. A multi-planar YUV
+	 * allocation has different planes (interleaved = 1, semi-planar = 2,
+	 * fully-planar = 3) but might be spread across 1, 2 or 3 independent
+	 * memory allocations (or not).
+	 */
+	int iPlanes;
+
+	/* For multi-planar allocations, there will be multiple hstrides */
+	int aiStride[MAX_SUB_ALLOCS];
+
+	/* For multi-planar allocations, there will be multiple vstrides */
+	int aiVStride[MAX_SUB_ALLOCS];
+
+	/* These byte offsets are reconciled with the number of sub-allocs used
+	 * for a multi-planar allocation. If there is a 1:1 mapping between the
+	 * number of planes and the number of sub-allocs, these will all be zero.
+	 *
+	 * Otherwise, normally the zeroth entry will be zero, and the latter
+	 * entries will be non-zero.
+	 */
+	unsigned long long aulPlaneOffset[MAX_SUB_ALLOCS];
+
+	/* This records the number of MAX_SUB_ALLOCS fds actually used by the
+	 * buffer allocation. File descriptors up to fd[iNumSubAllocs - 1] are
+	 * guaranteed to be valid. (This does not have any bearing on the aiStride,
+	 * aiVStride or aulPlaneOffset fields, as `iPlanes' of those arrays should
+	 * be initialized, not `iNumSubAllocs'.)
+	 */
+	int iNumSubAllocs;
+}
+__attribute__((aligned(sizeof(int)),packed)) IMG_native_handle_t;
+
+/* Channel encoding of buffer data.
+ *
+ * If the buffer has only one plane, the ENCODING bits should be interpreted
+ * as a definition of the interleaving pattern. Only two of the possible four
+ * permutations are defined; this is because the YVYU and VYUY patterns are
+ * not seen in the wild.
+ *
+ * If the buffer has more than one plane, the ENCODING bits should be
+ * interpreted as a definition of the plane order in memory. Assuming a YUV
+ * format, Y is always first, but U and V may be defined in 'V then U' or
+ * 'U then V' orders.
+ *
+ * Some bits are not used, to maximize compatibility with older DDKs which
+ * used them in semantically different ways.
+ */
+#define IMG_BFF_ENCODING_MASK                (3 << 0)
+/* For uiPlanes == 1 **********************************/
+/*   Reserved for VYUY (check IsYUV if used) (0 << 0) */
+#define IMG_BFF_ENCODING_INTERLEAVED_YUYV    (1 << 0)
+/*   Reserved for YVYU                       (2 << 0) */
+#define IMG_BFF_ENCODING_INTERLEAVED_UYVY    (3 << 0)
+/* For uiPlanes > 1 ***********************************/
+/*   Unused (check IsYUV if used)            (0 << 0) */
+#define IMG_BFF_ENCODING_VUCrCb              (1 << 0)
+/*   Unused                                  (2 << 0) */
+#define IMG_BFF_ENCODING_UVCbCr              (3 << 0)
+
+/* Whether the buffer should be cleared to zero from userspace, or via the
+ * PowerVR services at import time. This is deprecated functionality as most
+ * platforms use dma-buf or ion now, and for security reasons these allocators
+ * should never return uncleared memory.
+ */
+#define IMG_BFF_CPU_CLEAR                    (1 << 2)
+
+/* Deprecated, do not use */
+#define IMG_BFF_DONT_GPU_CLEAR               (1 << 3)
+
+/* Deprecated, do not use */
+#define IMG_BFF_PARTIAL_ALLOC                (1 << 4)
+
+/* Guarantee that GPU framebuffer compression is never used for buffers in
+ * this format, even if the format is supported by the compressor. This might
+ * be useful if the buffer is being fed to hardware blocks that cannot handle
+ * the framebuffer compression encoding, and the existing HAL overrides are
+ * not sufficiently expressive.
+ */
+#define IMG_BFF_NEVER_COMPRESS               (1 << 5)
+
+/* Indicates that the buffer should be mapped into the GPU 'tiling range'
+ * heaps, rather than the 'linear' general heap. This implies that the raw
+ * buffer data is tiled in physical memory. (The GPU BIF will de-tile it, so
+ * this is distinct from 'tiled texture' support.) The graphics HAL will
+ * select the correct 'tiling range' based on the buffer dimensions.
+ */
+#define IMG_BFF_BIFTILED                     (1 << 6)
+
+/* YUV subsampling encoding of buffer data.
+ * Many YUV formats have less chroma information than luma information. If
+ * this is not the case, use SUBSAMPLING_4_4_4. If each of the U and V channel
+ * data are 1/4 the size of the Y channel data, use SUBSAMPLING_4_2_0.
+ * Otherwise, use SUBSAMPLING_4_2_2.
+ */
+#define IMG_BFF_YUV_SUBSAMPLING_MASK         (3 << 7)
+#define IMG_BFF_YUV_SUBSAMPLING_4_2_0        (0 << 7)
+/* Unused: 4:1:1, 4:2:1, 4:1:0, 3:1:1?       (1 << 7) */
+#define IMG_BFF_YUV_SUBSAMPLING_4_2_2        (2 << 7)
+#define IMG_BFF_YUV_SUBSAMPLING_4_4_4        (3 << 7)
+
+/* Backwards compatibility */
+#define IMG_BFF_YUV             IMG_BFF_ENCODING_VUCrCb
+#define IMG_BFF_UVCbCrORDERING  IMG_BFF_ENCODING_UVCbCr
+
+/* Keep this in sync with SGX */
+typedef struct IMG_buffer_format_public_t
+{
+	/* Buffer formats are returned as a linked list */
+	struct IMG_buffer_format_public_t *psNext;
+
+	/* HAL_PIXEL_FORMAT_... enumerant */
+	int iHalPixelFormat;
+
+	/* IMG_PIXFMT_... enumerant */
+	int iIMGPixelFormat;
+
+	/* Friendly name for format */
+	const char *const szName;
+
+	/* Bits (not bytes) per pixel */
+	unsigned int uiBpp;
+
+	/* Supported HW usage bits. If this is GRALLOC_USAGE_HW_MASK, all usages
+	 * are supported. Used for HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED.
+	 */
+	int iSupportedUsage;
+
+	/* Allocation description flags */
+	unsigned int uiFlags;
+}
+IMG_buffer_format_public_t;
+
+typedef int ion_user_handle_t;
+
+typedef struct
+{
+	enum
+	{
+		IMG_BUFFER_HANDLE_TYPE_ION    = 0,
+		IMG_BUFFER_HANDLE_TYPE_DMABUF = 1,
+	}
+	eType;
+
+	union
+	{
+		ion_user_handle_t aiIonUserHandle[MAX_SUB_ALLOCS];
+		int aiDmaBufShareFd[MAX_SUB_ALLOCS];
+	};
+}
+IMG_buffer_handle_t;
+
+/* Public extensions, common to v0 and v1 HALs */
+
+#define GRALLOC_GET_BUFFER_FORMAT_IMG     1
+#define GRALLOC_GET_BUFFER_FORMATS_IMG    2
+#define GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG 3
+#define GRALLOC_BLIT_STAMP_TO_HANDLE_IMG  4
+#define GRALLOC_SET_DATA_SPACE_IMG        5
+#define GRALLOC_GET_ION_CLIENT_IMG        6
+#define GRALLOC_GET_BUFFER_HANDLE_IMG     7
+
+#if !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE)
+
+enum
+{
+	HAL_DATASPACE_SRGB_LINEAR         = 0x200,
+	HAL_DATASPACE_SRGB                = 0x201,
+	HAL_DATASPACE_BT601_625           = 0x102,
+	HAL_DATASPACE_BT601_525           = 0x103,
+	HAL_DATASPACE_BT709               = 0x104,
+};
+
+#endif /* !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE) */
+
+#if !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2)
+
+enum
+{
+	HAL_DATASPACE_STANDARD_SHIFT      = 16,
+	HAL_DATASPACE_TRANSFER_SHIFT      = 22,
+	HAL_DATASPACE_RANGE_SHIFT         = 27,
+
+	HAL_DATASPACE_STANDARD_BT2020     = 6 << HAL_DATASPACE_STANDARD_SHIFT,
+
+	HAL_DATASPACE_TRANSFER_SMPTE_170M = 3 << HAL_DATASPACE_TRANSFER_SHIFT,
+
+	HAL_DATASPACE_RANGE_MASK          = 7 << HAL_DATASPACE_RANGE_SHIFT,
+	HAL_DATASPACE_RANGE_FULL          = 1 << HAL_DATASPACE_RANGE_SHIFT,
+	HAL_DATASPACE_RANGE_LIMITED       = 2 << HAL_DATASPACE_RANGE_SHIFT,
+};
+
+#endif /* !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2) */
+
+/* We want to add BT.2020 and 'full range' versions of the existing dataspace
+ * enums. These are extensions, so define a new android_dataspace_ext_t.
+ * If you only have an android_dataspace_t, you can simply cast it.
+ */
+typedef enum
+{
+	/* Identical to upstream enum android_dataspace */
+	HAL_DATASPACE_EXT_UNKNOWN         = HAL_DATASPACE_UNKNOWN,
+	HAL_DATASPACE_EXT_SRGB_LINEAR     = HAL_DATASPACE_SRGB_LINEAR,
+	HAL_DATASPACE_EXT_SRGB            = HAL_DATASPACE_SRGB,
+	HAL_DATASPACE_EXT_BT601_625       = HAL_DATASPACE_BT601_625,
+	HAL_DATASPACE_EXT_BT601_525       = HAL_DATASPACE_BT601_525,
+	HAL_DATASPACE_EXT_BT709           = HAL_DATASPACE_BT709,
+
+	/* IMG extension for BT.2020 support */
+	HAL_DATASPACE_EXT_BT2020          = HAL_DATASPACE_STANDARD_BT2020     |
+	                                    HAL_DATASPACE_TRANSFER_SMPTE_170M |
+	                                    HAL_DATASPACE_RANGE_LIMITED,
+
+	/* IMG extensions for 'full range' versions of previous enums */
+	HAL_DATASPACE_EXT_BT601_625_FULL  = ( HAL_DATASPACE_BT601_625 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT601_525_FULL  = ( HAL_DATASPACE_BT601_525 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT709_FULL      = ( HAL_DATASPACE_BT709 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT2020_FULL     = ( HAL_DATASPACE_EXT_BT2020 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+}
+android_dataspace_ext_t;
+
+#endif /* IMG_GRALLOC_COMMON_PUBLIC_H */
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp b/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
new file mode 100644
index 0000000000..8a6dd294d6
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
@@ -0,0 +1,242 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *    Austin Yuan <austin.yuan@intel.com>
+ *
+ */
+
+#include "psb_gralloc.h"
+#include <log/log.h>
+#include <utils/threads.h>
+#include <ui/PixelFormat.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <hardware/hardware.h>
+#ifdef BAYTRAIL
+#include <ufo/gralloc.h>
+#else
+#include "hal_public.h"
+#include <sync/sync.h>
+#endif
+
+using namespace android;
+
+#ifdef  LOG_TAG
+#undef  LOG_TAG
+#endif
+
+#define LOG_TAG "v4l2_camera"
+
+#ifdef BAYTRAIL
+static const gralloc_module_t *mGralloc;
+#else
+static const hw_device_t *mGralloc;
+#endif
+
+int gralloc_lock(buffer_handle_t handle,
+                 int usage, int left, int top, int width, int height,
+                 void** vaddr)
+{
+    int err;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized. Should initialize it first", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__, GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+#ifdef BAYTRAIL
+    err = mGralloc->lock(mGralloc, handle, usage,
+                         left, top, width, height,
+                         vaddr);
+#else
+    const gralloc1_rect_t r = {
+        .left   = left,
+        .top    = top,
+        .width  = width,
+        .height = height
+    };
+    err = gralloc_lock_async_img(mGralloc, handle, usage, &r, vaddr, -1);
+#endif
+    ALOGV("gralloc_lock: handle is %p, usage is %x, vaddr is %p.\n", handle, usage, *vaddr);
+    if (err){
+        ALOGE("lock(...) failed %d (%s).\n", err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("lock returned with address %p\n", *vaddr);
+    }
+
+    return err;
+}
+
+int gralloc_unlock(buffer_handle_t handle)
+{
+    int err;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized. Should initialize it first", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__, GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+#ifdef BAYTRAIL
+    err = mGralloc->unlock(mGralloc, handle);
+#else
+    int releaseFence = -1;
+    err = gralloc_unlock_async_img(mGralloc, handle, &releaseFence);
+    if (releaseFence >= 0) {
+        sync_wait(releaseFence, -1);
+        close(releaseFence);
+    }
+#endif
+    if (err) {
+        ALOGE("unlock(...) failed %d (%s)", err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unlock returned\n");
+    }
+
+    return err;
+}
+
+int gralloc_register(buffer_handle_t handle)
+{
+    int err = 0;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized.", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__,
+                    GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+    err = gralloc_register_img(mGralloc, handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("registered buffer %p successfully\n", handle);
+    }
+
+    return err;
+}
+
+int gralloc_unregister(buffer_handle_t handle)
+{
+    int err = 0;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized.", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__,
+                    GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+    err = gralloc_unregister_img(mGralloc, handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unregistered buffer %p successfully\n", handle);
+    }
+
+    return err;
+}
+
+int gralloc_init(void)
+{
+    int err;
+
+#ifdef BAYTRAIL
+    err = hw_get_module(GRALLOC_HW_MODULE_ID, (const hw_module_t **)&mGralloc);
+#else
+    err = gralloc_open_img(&mGralloc);
+#endif
+    if (err) {
+        ALOGE("FATAL: can't find the %s module", GRALLOC_HARDWARE_MODULE_ID);
+        return -1;
+    } else
+        ALOGD("hw_get_module returned OK\n");
+
+    return 0;
+}
+
+int gralloc_getdisplaystatus(buffer_handle_t handle,  int* status)
+{
+    int err;
+
+#ifdef BAYTRAIL
+    *status = mGralloc->perform(mGralloc, INTEL_UFO_GRALLOC_MODULE_PERFORM_GET_BO_STATUS, handle);
+    err = 0;
+#else
+    uint32_t _status = 0U;
+    err = gralloc_get_display_status_img(mGralloc, handle, &_status);
+    *status = (int)_status;
+#endif
+    if (err){
+        ALOGE("gralloc_getdisplaystatus(...) failed %d (%s).\n", err, strerror(-err));
+        return -1;
+    }
+
+    return err;
+}
+
+int gralloc_getbuffd(buffer_handle_t handle)
+{
+    return ((IMG_native_handle_t*)handle)->fd[0];
+}
+
+
+#define GRALLOC_ALIGN(value, base) (((value) + ((base)-1)) & ~((base)-1))
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h)
+{
+    (void)format;
+    (void)buf_w;
+    (void)buf_h;
+
+    void *addr = 0;
+    int err;
+
+    ALOGV("handle %p, usage 0x%x", handle, usage);
+
+    err = gralloc_lock(handle, usage, x, y, w, h, &addr);
+    if (err)
+        return err;
+
+    ycbcr->y = addr;
+
+    return 0;
+}
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc.h b/hardware/ntimespace/camera/gralloc/psb_gralloc.h
new file mode 100644
index 0000000000..6de28cb824
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc.h
@@ -0,0 +1,60 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *
+ */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <hardware/gralloc.h>
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+int gralloc_lock(buffer_handle_t handle, int usage,
+        int left, int top, int width, int height, void** vaddr);
+
+int gralloc_unlock(buffer_handle_t handle);
+
+int gralloc_register(buffer_handle_t handle);
+
+int gralloc_unregister(buffer_handle_t handle);
+
+int gralloc_init(void);
+
+int gralloc_getdisplaystatus(buffer_handle_t handle,  int* status);
+
+int gralloc_getbuffd(buffer_handle_t handle);
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h);
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp b/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
new file mode 100644
index 0000000000..4f860c6da0
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
@@ -0,0 +1,151 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *    Austin Yuan <austin.yuan@intel.com>
+ *
+ */
+
+#include <log/log.h>
+#include <utils/threads.h>
+#include <ui/PixelFormat.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <hardware/hardware.h>
+#include <sync/sync.h>
+#include "gralloc3_impl.h"
+#include "psb_gralloc3.h"
+
+#include <memory>
+#include <unordered_map>
+#include <utility>
+
+#undef  LOG_NDEBUG
+//#define LOG_NDEBUG 0
+
+using namespace android;
+using hardware::camera::common::V1_0::helper::HandleImporter;
+
+#ifdef  LOG_TAG
+#undef  LOG_TAG
+#endif
+
+#define LOG_TAG "v4l2_camera"
+
+
+// static
+HandleImporter * GetInstance() {
+    static HandleImporter instance;    
+    return &instance;
+}
+
+int gralloc_lock(buffer_handle_t handle,
+                 int usage, int left, int top, int width, int height,
+                 void** vaddr)
+{
+    IMapper::Rect outRect {left, top, static_cast<int32_t>(width), static_cast<int32_t>(height)};    
+    *vaddr = GetInstance()->lock(handle, (uint64_t)usage, outRect);
+    ALOGV("gralloc_lock: handle is %p, fd %d usage is %x, vaddr is %p.\n", handle, handle->data[0], usage, *vaddr);
+    if (*vaddr == NULL){
+        ALOGE("lock(...) failed.\n");
+        return -1;
+    } else {
+        ALOGV("lock returned with address %p\n", *vaddr);
+    }
+
+    return 0;
+}
+
+int gralloc_unlock(buffer_handle_t handle)
+{
+    int releaseFence = -1;
+
+    ALOGV("%s fd %d new fd %d  \n", __func__, handle->data[0], handle->data[0]);
+    releaseFence = GetInstance()->unlock(handle);
+    ALOGV("unlock fence %d", releaseFence);
+    if (releaseFence >= 0) {
+        sync_wait(releaseFence, -1);
+        close(releaseFence);
+    }   
+    
+    return 0;
+}
+
+int gralloc_register(buffer_handle_t & handle)
+{
+    ALOGV("%s fd %d.\n", __func__, handle->data[0]);
+
+    buffer_handle_t outhandle;
+    bool ret = GetInstance()->importBuffer(handle, outhandle);
+    if (!ret) {
+        ALOGE("%s failed.\n", __func__);
+        return -1;     
+    } else {
+        ALOGV("registered buffer %p with new fd %d successfully\n", handle, outhandle->data[0]);
+    }
+   
+    ALOGV("%s new handle fd %d.\n", __func__, handle->data[0]);
+    
+    return ret ? 0 : -1;
+}
+
+int gralloc_unregister(buffer_handle_t handle)
+{
+    int err = 0;
+
+    ALOGV("%s fd %d \n", __func__, handle->data[0]);
+    GetInstance()->freeBuffer(handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unregistered buffer %p with fd %d successfully\n", handle, handle->data[0]);
+    }    
+
+    return err;
+}
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h)
+{
+    (void)format;
+    (void)buf_w;
+    (void)buf_h;
+
+    YCbCrLayout layout;
+
+    ALOGV("%s fd %d \n", __func__, handle->data[0]);
+    IMapper::Rect outRect {x, y, static_cast<int32_t>(w), static_cast<int32_t>(h)};
+    layout = GetInstance()->lockYCbCr(handle, usage, outRect);
+    if (layout.y == nullptr)
+    {
+        ALOGE("layout.y error");
+        return -1;
+    }
+
+    ycbcr->y = layout.y;
+
+    return 0;
+}
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc3.h b/hardware/ntimespace/camera/gralloc/psb_gralloc3.h
new file mode 100644
index 0000000000..67abd0dd5f
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc3.h
@@ -0,0 +1,55 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *
+ */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <hardware/gralloc.h>
+#include "gralloc3_impl.h"
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+int gralloc_lock(buffer_handle_t handle, int usage,
+        int left, int top, int width, int height, void** vaddr);
+
+int gralloc_unlock(buffer_handle_t handle);
+
+int gralloc_register(buffer_handle_t & handle);
+
+int gralloc_unregister(buffer_handle_t handle);
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h);
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/hardware/ntimespace/camera/hardware/hw_converter.h b/hardware/ntimespace/camera/hardware/hw_converter.h
new file mode 100644
index 0000000000..e2e61c76ae
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/hw_converter.h
@@ -0,0 +1,94 @@
+#ifndef __V4L2_HARDWARE_CONVERTER_HEADER
+#define __V4L2_HARDWARE_CONVERTER_HEADER
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <sys/mman.h>
+#include <pthread.h>
+#include <semaphore.h>
+#include <linux/videodev2.h>
+#include <dlfcn.h>
+#include <vector>
+#include <utils/Log.h>
+#include "debug.h"
+#include "android-base/properties.h"
+#include "metadata/camera_metadata.h"
+#include "arc/frame_buffer.h"
+
+#ifdef HAS_C2D2
+#include "C2DColorConverter.h"
+#endif
+
+namespace hw_conv {
+using android::CameraMetadata;
+using arc::FrameBuffer;
+
+
+class hw_conv
+{
+    public:
+        hw_conv();
+        virtual ~hw_conv();
+        virtual bool init() = 0;
+        //virtual bool convert(int src_fd, void *src_base, void *src_viraddr,
+        //        int dest_fd, void *dest_base, void *dest_viraddr) = 0;
+        virtual bool deinit() = 0;
+};
+
+#ifdef HAS_C2D2
+class qc_c2d_conv: public hw_conv
+{
+    public:
+        qc_c2d_conv();
+        ~qc_c2d_conv();
+        bool init() { return true;}
+        bool deinit() { return true;}        
+        bool convert(int src_fd, void *src_base, void *src_viraddr, int dest_fd, void *dest_base, void *dest_viraddr);
+        bool setResolution(size_t srcWidth, size_t srcHeight,
+                                      size_t dstWidth, size_t dstHeight,
+                                      ColorConvertFormat srcFormat,
+                                      ColorConvertFormat dstFormat,
+                                      int32_t flags, size_t srcStride);
+
+        void updateSavedResolution(size_t srcWidth, size_t srcHeight,
+                                        size_t dstWidth, size_t dstHeight,
+                                        ColorConvertFormat srcFormat,
+                                        ColorConvertFormat dstFormat,
+                                        int32_t flags, size_t srcStride);
+
+        C2DColorConverter c2dcc;
+        //pthread_mutex_t c_lock;
+
+        size_t srcWidth_;
+        size_t srcHeight_;
+        size_t dstWidth_; 
+        size_t dstHeight_;                                
+        ColorConvertFormat srcFormat_;
+        ColorConvertFormat dstFormat_;
+        int32_t flags_; 
+        size_t srcStride_;        
+};
+#endif
+
+#ifdef HAS_RGA
+class rk_rga_conv: public hw_conv
+{
+    public:
+        rk_rga_conv();
+        ~rk_rga_conv();
+        bool init() { return true;}
+        bool deinit() { return true;}        
+        bool convert(int src_fd, void *src_base, void *src_viraddr,
+                    int dest_fd, void *dest_base, void *dest_viraddr,
+                    int src_width, int src_height,
+                    int src_wstride, int src_hstride,
+                    int dst_width, int dst_height,
+                    int srcFormat, int dstFormat);
+};
+#endif
+
+int convert_format(const CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame);
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height);
+
+}
+#endif
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp b/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
new file mode 100644
index 0000000000..5c3e546d06
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
@@ -0,0 +1,252 @@
+#include <inttypes.h>
+#include <string.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <sys/prctl.h>
+#include <sys/ioctl.h>
+#include "common.h"
+#include "hw_converter.h"
+#include "arc/image_processor.h"
+
+namespace hw_conv {
+
+using android::CameraMetadata;
+
+hw_conv:: hw_conv() {};
+hw_conv:: ~hw_conv() {};
+
+qc_c2d_conv::qc_c2d_conv()
+{
+    LOGF(ERROR) << "convert perf";
+    //pthread_mutex_init(&c_lock, NULL);
+    updateSavedResolution(0, 0, 0, 0, NO_COLOR_FORMAT, NO_COLOR_FORMAT, 0, 0);
+}
+
+void qc_c2d_conv::updateSavedResolution(size_t srcWidth, size_t srcHeight,
+                                size_t dstWidth, size_t dstHeight,
+                                ColorConvertFormat srcFormat,
+                                ColorConvertFormat dstFormat,
+                                int32_t flags, size_t srcStride) {
+    srcWidth_ = srcWidth;
+    srcHeight_ = srcHeight;
+    dstWidth_ = dstWidth; 
+    dstHeight_ = dstHeight;                                
+    srcFormat_ = srcFormat;
+    dstFormat_ = dstFormat;
+    flags_ = flags;  
+    srcStride_ = srcStride;     
+}
+
+bool qc_c2d_conv::setResolution(size_t srcWidth, size_t srcHeight,
+                                size_t dstWidth, size_t dstHeight,
+                                ColorConvertFormat srcFormat,
+                                ColorConvertFormat dstFormat,
+                                int32_t flags, size_t srcStride)
+{
+    if ( srcWidth_ != srcWidth || srcHeight_ != srcHeight || srcFormat_ != srcFormat
+      || dstWidth_ != dstWidth || dstHeight_ != dstHeight || dstFormat_ != dstFormat
+      || flags_ != flags || srcStride_ != srcStride) {
+        updateSavedResolution(srcWidth, srcHeight, dstWidth, dstHeight, srcFormat, dstFormat, flags, srcStride);
+        c2dcc.setConversionNeeded(true);
+        if (!c2dcc.setResolution(srcWidth, srcHeight, dstWidth, dstHeight, srcFormat, dstFormat, flags, srcStride)) {
+            LOGF(ERROR) << "C2D2 setResolution failed";
+            return false;
+        } 
+      }
+
+    return true; 
+}
+
+bool qc_c2d_conv::convert(int src_fd, void *src_base, void *src_viraddr,
+                          int dest_fd, void *dest_base, void *dest_viraddr)
+{
+    bool result;
+    if (!src_viraddr || !dest_viraddr || !src_base || !dest_base) {
+        HAL_LOGE("Invalid arguments qc_c2d_conv::convert");
+        return false;
+    }
+
+    //pthread_mutex_lock(&c_lock);
+    result =  c2dcc.convertC2D(src_fd, src_base, src_viraddr, dest_fd, dest_base, dest_viraddr);
+    //pthread_mutex_unlock(&c_lock);
+
+    HAL_LOGV("Color convert status %s", result ? "OK" : "Fail");
+    return result;
+}
+
+qc_c2d_conv::~qc_c2d_conv()
+{
+    //pthread_mutex_destroy(&c_lock);
+}
+
+qc_c2d_conv c2d_conv;
+
+int convert_format(const CameraMetadata& /*metadata*/, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+    /*
+    LOGF(INFO) << "[C2D2] in_frame: " << FormatToString(in_frame.GetFourcc())
+                << " " << in_frame.GetFourcc()
+                << " width " << in_frame.GetWidth()
+                << " height " << in_frame.GetHeight()
+                << " size " << in_frame.GetDataSize();   
+
+    LOGF(INFO) << "[C2D2] out_frame: " << FormatToString(out_frame->GetFourcc())
+                << " " << out_frame->GetFourcc()
+                << " width " << out_frame->GetWidth()
+                << " height " << out_frame->GetHeight()
+                << " size " << out_frame->GetDataSize();              
+    */
+
+    if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+      LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                  << " x " << in_frame.GetHeight() << ")";
+      return -EINVAL;
+    }
+
+    if (in_frame.GetFourcc() == out_frame->GetFourcc() && in_frame.GetWidth() == out_frame->GetWidth() &&
+        in_frame.GetHeight() == out_frame->GetHeight())
+    {
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+
+    size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+    if (out_frame->SetDataSize(data_size)) {
+      LOGF(ERROR) << "Set data size failed";
+      return -EINVAL;
+    }
+  #if 0
+    if (true){
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+  #endif
+    ColorConvertFormat src_fmt;
+    ColorConvertFormat dst_fmt;
+    int ystride = 0;
+    
+    if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUV420) { //YU12
+      src_fmt = YCbCr420P;
+      // V4L2_PIX_FMT_YVU420 is YV12. I420 is usually referred to YU12
+      // (V4L2_PIX_FMT_YUV420), and YV12 is similar to YU12 except that U/V
+      // planes are swapped.
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = YCbCr420SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT; 
+        }   
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT; 
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+      src_fmt = RGBA8888;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:  // YU12
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        break;
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = YCbCr420SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT;      
+        }
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }           
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+      src_fmt = YCbCr420SP;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:   //yu12, I420
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }      
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_YVU420) {
+      src_fmt = YCrCb420P;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:   //yu12, I420
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_NV12:  
+        {  
+          dst_fmt = YCbCr420SP;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }      
+        default:
+          goto UNSUPPORT;
+      }
+    }
+
+    UNSUPPORT:
+      return -EINVAL; 
+
+    DO_CONVERT:
+      if (!c2d_conv.setResolution(in_frame.GetWidth(),in_frame.GetHeight(), 
+                                  out_frame->GetWidth(),out_frame->GetHeight(),
+                                  src_fmt, dst_fmt, 0, ystride)) {
+          return -EINVAL;
+      }
+      if (!c2d_conv.convert(in_frame.GetFd(), in_frame.GetData(), in_frame.GetData(), 
+                            out_frame->GetFd(), out_frame->GetData(), out_frame->GetData())) {
+          return -EINVAL;
+      } 
+
+    return 0;
+}
+
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height) {
+    return arc::ImageProcessor::GetConvertedSize(fourcc, width, height);
+}
+
+}
diff --git a/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp b/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
new file mode 100644
index 0000000000..baf7dac138
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
@@ -0,0 +1,159 @@
+#include <inttypes.h>
+#include <string.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <sys/prctl.h>
+#include <sys/ioctl.h>
+#include "common.h"
+#include "hw_converter.h"
+#include "arc/image_processor.h"
+#include "hw_converter.h"
+#include "RgaApi.h"
+
+namespace hw_conv {
+
+using android::CameraMetadata;
+
+hw_conv:: hw_conv() {};
+hw_conv:: ~hw_conv() {};
+
+rk_rga_conv::rk_rga_conv()
+{
+    //LOGF(ERROR) << "convert perf";
+}
+
+bool rk_rga_conv::convert(int src_fd, void *src_base, void *src_viraddr,
+                            int dest_fd, void *dest_base, void *dest_viraddr,
+                            int src_width, int src_height,
+                            int src_wstride, int src_hstride,
+                            int dst_width, int dst_height,
+                            int srcFormat, int dstFormat)
+{
+    (void)src_base;
+    (void)dest_base;
+    (void)src_viraddr;
+    (void)dest_viraddr;
+
+    int ret = 0;
+    static int g_rga_init = 0;    
+    void *rgaCtx = NULL;
+    rga_info_t rgasrc, rgadst;
+
+    if (!g_rga_init) {
+        RgaInit(&rgaCtx);
+        g_rga_init = 1;
+        HAL_LOGD("init rga ctx done");
+    } 
+
+    memset(&rgasrc, 0, sizeof(rga_info_t));
+    rgasrc.fd = src_fd;
+
+    memset(&rgadst, 0, sizeof(rga_info_t));
+    rgadst.fd = dest_fd;
+
+    rga_set_rect(&rgasrc.rect, 0, 0, src_width, src_height,
+                 src_wstride, src_hstride, srcFormat);
+    rga_set_rect(&rgadst.rect, 0, 0, dst_width, dst_height,
+                 src_wstride, src_hstride, dstFormat);
+
+    ret = RgaBlit(&rgasrc, &rgadst, NULL);
+    if (ret) {
+        HAL_LOGE("failed to rga blit ret %d", ret);
+        return false;
+    }
+
+    return true;
+}
+
+rk_rga_conv::~rk_rga_conv()
+{
+}
+
+rk_rga_conv rga_conv;
+
+int convert_format(const CameraMetadata& /*metadata*/, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+    LOGF(INFO) << "[RGA] in_frame: " << FormatToString(in_frame.GetFourcc())
+                << " " << in_frame.GetFourcc()
+                << " width " << in_frame.GetWidth()
+                << " height " << in_frame.GetHeight()
+                << " size " << in_frame.GetDataSize();   
+
+    LOGF(INFO) << "[RGA] out_frame: " << FormatToString(out_frame->GetFourcc())
+                << " " << out_frame->GetFourcc()
+                << " width " << out_frame->GetWidth()
+                << " height " << out_frame->GetHeight()
+                << " size " << out_frame->GetDataSize();              
+
+    if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+      LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                  << " x " << in_frame.GetHeight() << ")";
+      return -EINVAL;
+    }
+
+    if (in_frame.GetFourcc() == out_frame->GetFourcc() && in_frame.GetWidth() == out_frame->GetWidth() &&
+        in_frame.GetHeight() == out_frame->GetHeight())
+    {
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+
+    size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+    if (out_frame->SetDataSize(data_size)) {
+      LOGF(ERROR) << "Set data size failed";
+      return -EINVAL;
+    }
+
+    int src_fmt;
+    int dst_fmt;
+    int ystride = 0;
+    
+    if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+      src_fmt = RK_FORMAT_RGBA_8888;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = RK_FORMAT_YCbCr_420_SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT;      
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+      src_fmt = RK_FORMAT_YCbCr_420_SP;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RK_FORMAT_RGBA_8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } 
+
+    UNSUPPORT:
+      LOGF(ERROR) << "RGA don't support the convert"; 
+      return -EINVAL; 
+
+    DO_CONVERT:
+      if (!rga_conv.convert(in_frame.GetFd(), in_frame.GetData(), in_frame.GetData(), 
+                            out_frame->GetFd(), out_frame->GetData(), out_frame->GetData(),
+                            in_frame.GetWidth(), in_frame.GetHeight(),
+                            ystride, in_frame.GetHeight(),
+                            out_frame->GetWidth(), out_frame->GetHeight(),
+                            src_fmt, dst_fmt)) {
+          return -EINVAL;
+      } 
+
+    return 0;
+}
+
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height) {
+    return arc::ImageProcessor::GetConvertedSize(fourcc, width, height);
+}
+
+}
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/metadata/array_vector.h b/hardware/ntimespace/camera/metadata/array_vector.h
new file mode 100644
index 0000000000..0481ed4424
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/array_vector.h
@@ -0,0 +1,52 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
+#define V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
+
+#include <array>
+#include <vector>
+
+namespace v4l2_camera_hal {
+// ArrayVector behaves like a std::vector of fixed length C arrays,
+// with push_back accepting std::arrays to standardize length.
+// Specific methods to get number of arrays/number of elements
+// are provided and an ambiguous "size" is not, to avoid accidental
+// incorrect use.
+template <class T, size_t N>
+class ArrayVector {
+ public:
+  const T* data() const { return mItems.data(); }
+  // The number of arrays.
+  size_t num_arrays() const { return mItems.size() / N; }
+  // The number of elements amongst all arrays.
+  size_t total_num_elements() const { return mItems.size(); }
+
+  // Access the ith array.
+  const T* operator[](int i) const { return mItems.data() + (i * N); }
+  T* operator[](int i) { return mItems.data() + (i * N); }
+
+  void push_back(const std::array<T, N>& values) {
+    mItems.insert(mItems.end(), values.begin(), values.end());
+  }
+
+ private:
+  std::vector<T> mItems;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
diff --git a/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp b/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
new file mode 100644
index 0000000000..b0544a892a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
@@ -0,0 +1,47 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "BoottimeStateDelegate"
+
+#include "boottime_state_delegate.h"
+
+#include <unistd.h>
+#include <time.h>
+
+#include <cerrno>
+#include <cstring>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+int BoottimeStateDelegate::GetValue(int64_t* value) {
+  struct timespec ts;
+
+  int res = clock_gettime(CLOCK_BOOTTIME, &ts);
+  if (res) {
+    HAL_LOGE("Failed to get BOOTTIME for state delegate: %d (%s)",
+             errno,
+             strerror(errno));
+    return -errno;
+  }
+  *value = ts.tv_sec * 1000000000ULL + ts.tv_nsec;
+
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/boottime_state_delegate.h b/hardware/ntimespace/camera/metadata/boottime_state_delegate.h
new file mode 100644
index 0000000000..e31e12f9ee
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/boottime_state_delegate.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
+
+#include <cstdint>
+
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A StateDelegate is simply a dynamic value that can be queried.
+// The value may change between queries.
+class BoottimeStateDelegate : public StateDelegateInterface<int64_t> {
+ public:
+  BoottimeStateDelegate(){};
+  ~BoottimeStateDelegate(){};
+
+  int GetValue(int64_t* value) override;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/camera_metadata.cpp b/hardware/ntimespace/camera/metadata/camera_metadata.cpp
new file mode 100644
index 0000000000..0692fdef3e
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/camera_metadata.cpp
@@ -0,0 +1,565 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+
+#define LOG_TAG "CamComm1.0-MD"
+#include <log/log.h>
+#include <utils/Errors.h>
+#include "camera_metadata.h"
+
+
+namespace android {
+#if 0
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+#endif
+
+#define ALIGN_TO(val, alignment) \
+    (((uintptr_t)(val) + ((alignment) - 1)) & ~((alignment) - 1))
+
+CameraMetadata::CameraMetadata() :
+        mBuffer(NULL), mLocked(false) {
+}
+
+CameraMetadata::CameraMetadata(size_t entryCapacity, size_t dataCapacity) :
+        mLocked(false)
+{
+    mBuffer = allocate_camera_metadata(entryCapacity, dataCapacity);
+}
+
+CameraMetadata::CameraMetadata(const CameraMetadata &other) :
+        mLocked(false) {
+    mBuffer = clone_camera_metadata(other.mBuffer);
+}
+
+CameraMetadata::CameraMetadata(camera_metadata_t *buffer) :
+        mBuffer(NULL), mLocked(false) {
+    acquire(buffer);
+}
+
+CameraMetadata &CameraMetadata::operator=(const CameraMetadata &other) {
+    return operator=(other.mBuffer);
+}
+
+CameraMetadata &CameraMetadata::operator=(const camera_metadata_t *buffer) {
+    if (mLocked) {
+        HAL_LOGE("%s: Assignment to a locked CameraMetadata!", __FUNCTION__);
+        return *this;
+    }
+
+    if (CC_LIKELY(buffer != mBuffer)) {
+        camera_metadata_t *newBuffer = clone_camera_metadata(buffer);
+        clear();
+        mBuffer = newBuffer;
+    }
+    return *this;
+}
+
+CameraMetadata::~CameraMetadata() {
+    mLocked = false;
+    clear();
+}
+
+const camera_metadata_t* CameraMetadata::getAndLock() const {
+    mLocked = true;
+    return mBuffer;
+}
+
+status_t CameraMetadata::unlock(const camera_metadata_t *buffer) const {
+    if (!mLocked) {
+        HAL_LOGE("%s: Can't unlock a non-locked CameraMetadata!", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if (buffer != mBuffer) {
+        HAL_LOGE("%s: Can't unlock CameraMetadata with wrong pointer!",
+                __FUNCTION__);
+        return BAD_VALUE;
+    }
+    mLocked = false;
+    return OK;
+}
+
+camera_metadata_t* CameraMetadata::release() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return NULL;
+    }
+    camera_metadata_t *released = mBuffer;
+    mBuffer = NULL;
+    return released;
+}
+
+void CameraMetadata::clear() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    if (mBuffer) {
+        free_camera_metadata(mBuffer);
+        mBuffer = NULL;
+    }
+}
+
+void CameraMetadata::acquire(camera_metadata_t *buffer) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    clear();
+    mBuffer = buffer;
+
+    HAL_LOGE_IF(validate_camera_metadata_structure(mBuffer, /*size*/NULL) != OK,
+             "%s: Failed to validate metadata structure %p",
+             __FUNCTION__, buffer);
+}
+
+void CameraMetadata::acquire(CameraMetadata &other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    acquire(other.release());
+}
+
+status_t CameraMetadata::append(const CameraMetadata &other) {
+    return append(other.mBuffer);
+}
+
+status_t CameraMetadata::append(const camera_metadata_t* other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    size_t extraEntries = get_camera_metadata_entry_count(other);
+    size_t extraData = get_camera_metadata_data_count(other);
+    resizeIfNeeded(extraEntries, extraData);
+
+    return append_camera_metadata(mBuffer, other);
+}
+
+size_t CameraMetadata::entryCount() const {
+    return (mBuffer == NULL) ? 0 :
+            get_camera_metadata_entry_count(mBuffer);
+}
+
+bool CameraMetadata::isEmpty() const {
+    return entryCount() == 0;
+}
+
+status_t CameraMetadata::sort() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    return sort_camera_metadata(mBuffer);
+}
+
+status_t CameraMetadata::checkType(uint32_t tag, uint8_t expectedType) {
+    int tagType = get_local_camera_metadata_tag_type(tag, mBuffer);
+    if ( CC_UNLIKELY(tagType == -1)) {
+        HAL_LOGE("Update metadata entry: Unknown tag %d", tag);
+        return INVALID_OPERATION;
+    }
+    if ( CC_UNLIKELY(tagType != expectedType) ) {
+        HAL_LOGE("Mismatched tag type when updating entry %s (%d) of type %s; "
+              "got type %s data instead ",
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag,
+              camera_metadata_type_names[tagType], camera_metadata_type_names[expectedType]);
+        return INVALID_OPERATION;
+    }
+    return OK;
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const int32_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_INT32)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const uint8_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_BYTE)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const float *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_FLOAT)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const int64_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_INT64)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const double *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_DOUBLE)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const camera_metadata_rational_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_RATIONAL)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const String8 &string) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_BYTE)) != OK) {
+        return res;
+    }
+    // string.size() doesn't count the null termination character.
+    return updateImpl(tag, (const void*)string.string(), string.size() + 1);
+}
+
+status_t CameraMetadata::update(const camera_metadata_ro_entry &entry) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(entry.tag, entry.type)) != OK) {
+        return res;
+    }
+    return updateImpl(entry.tag, (const void*)entry.data.u8, entry.count);
+}
+
+status_t CameraMetadata::updateImpl(uint32_t tag, const void *data,
+        size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    int type = get_local_camera_metadata_tag_type(tag, mBuffer);
+    if (type == -1) {
+        HAL_LOGE("%s: Tag %d not found", __FUNCTION__, tag);
+        return BAD_VALUE;
+    }
+    // Safety check - ensure that data isn't pointing to this metadata, since
+    // that would get invalidated if a resize is needed
+    size_t bufferSize = get_camera_metadata_size(mBuffer);
+    uintptr_t bufAddr = reinterpret_cast<uintptr_t>(mBuffer);
+    uintptr_t dataAddr = reinterpret_cast<uintptr_t>(data);
+    if (dataAddr > bufAddr && dataAddr < (bufAddr + bufferSize)) {
+        HAL_LOGE("%s: Update attempted with data from the same metadata buffer!",
+                __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+
+    size_t data_size = calculate_camera_metadata_entry_data_size(type,
+            data_count);
+
+    res = resizeIfNeeded(1, data_size);
+
+    if (res == OK) {
+        camera_metadata_entry_t entry;
+        res = find_camera_metadata_entry(mBuffer, tag, &entry);
+        if (res == NAME_NOT_FOUND) {
+            res = add_camera_metadata_entry(mBuffer,
+                    tag, data, data_count);
+        } else if (res == OK) {
+            res = update_camera_metadata_entry(mBuffer,
+                    entry.index, data, data_count, NULL);
+        }
+    }
+
+    if (res != OK) {
+        HAL_LOGE("%s: Unable to update metadata entry %s.%s (%x): %s (%d)", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+    }
+
+    IF_ALOGV() {
+        HAL_LOGE_IF(validate_camera_metadata_structure(mBuffer, /*size*/NULL) !=
+                 OK,
+
+                 "%s: Failed to validate metadata structure after update %p",
+                 __FUNCTION__, mBuffer);
+    }
+
+    return res;
+}
+
+bool CameraMetadata::exists(uint32_t tag) const {
+    camera_metadata_ro_entry entry;
+    return find_camera_metadata_ro_entry(mBuffer, tag, &entry) == 0;
+}
+
+camera_metadata_entry_t CameraMetadata::find(uint32_t tag) {
+    status_t res;
+    camera_metadata_entry entry;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        entry.count = 0;
+        return entry;
+    }
+    res = find_camera_metadata_entry(mBuffer, tag, &entry);
+    if (CC_UNLIKELY( res != OK )) {
+        entry.count = 0;
+        entry.data.u8 = NULL;
+    }
+    return entry;
+}
+
+camera_metadata_ro_entry_t CameraMetadata::find(uint32_t tag) const {
+    status_t res;
+    camera_metadata_ro_entry entry;
+    res = find_camera_metadata_ro_entry(mBuffer, tag, &entry);
+    if (CC_UNLIKELY( res != OK )) {
+        entry.count = 0;
+        entry.data.u8 = NULL;
+    }
+    return entry;
+}
+
+status_t CameraMetadata::erase(uint32_t tag) {
+    camera_metadata_entry_t entry;
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    res = find_camera_metadata_entry(mBuffer, tag, &entry);
+    if (res == NAME_NOT_FOUND) {
+        return OK;
+    } else if (res != OK) {
+        HAL_LOGE("%s: Error looking for entry %s.%s (%x): %s %d", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+        return res;
+    }
+    res = delete_camera_metadata_entry(mBuffer, entry.index);
+    if (res != OK) {
+        HAL_LOGE("%s: Error deleting entry %s.%s (%x): %s %d", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+    }
+    return res;
+}
+
+void CameraMetadata::dump(int fd, int verbosity, int indentation) const {
+    dump_indented_camera_metadata(mBuffer, fd, verbosity, indentation);
+}
+
+status_t CameraMetadata::resizeIfNeeded(size_t extraEntries, size_t extraData) {
+    if (mBuffer == NULL) {
+        mBuffer = allocate_camera_metadata(extraEntries * 2, extraData * 2);
+        if (mBuffer == NULL) {
+            HAL_LOGE("%s: Can't allocate larger metadata buffer", __FUNCTION__);
+            return NO_MEMORY;
+        }
+    } else {
+        size_t currentEntryCount = get_camera_metadata_entry_count(mBuffer);
+        size_t currentEntryCap = get_camera_metadata_entry_capacity(mBuffer);
+        size_t newEntryCount = currentEntryCount +
+                extraEntries;
+        newEntryCount = (newEntryCount > currentEntryCap) ?
+                newEntryCount * 2 : currentEntryCap;
+
+        size_t currentDataCount = get_camera_metadata_data_count(mBuffer);
+        size_t currentDataCap = get_camera_metadata_data_capacity(mBuffer);
+        size_t newDataCount = currentDataCount +
+                extraData;
+        newDataCount = (newDataCount > currentDataCap) ?
+                newDataCount * 2 : currentDataCap;
+
+        if (newEntryCount > currentEntryCap ||
+                newDataCount > currentDataCap) {
+            camera_metadata_t *oldBuffer = mBuffer;
+            mBuffer = allocate_camera_metadata(newEntryCount,
+                    newDataCount);
+            if (mBuffer == NULL) {
+                HAL_LOGE("%s: Can't allocate larger metadata buffer", __FUNCTION__);
+                return NO_MEMORY;
+            }
+            append_camera_metadata(mBuffer, oldBuffer);
+            free_camera_metadata(oldBuffer);
+        }
+    }
+    return OK;
+}
+
+void CameraMetadata::swap(CameraMetadata& other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    } else if (other.mLocked) {
+        HAL_LOGE("%s: Other CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+
+    camera_metadata* thisBuf = mBuffer;
+    camera_metadata* otherBuf = other.mBuffer;
+
+    other.mBuffer = thisBuf;
+    mBuffer = otherBuf;
+}
+#if 0
+status_t CameraMetadata::getTagFromName(const char *name,
+        const VendorTagDescriptor* vTags, uint32_t *tag) {
+
+    if (name == nullptr || tag == nullptr) return BAD_VALUE;
+
+    size_t nameLength = strlen(name);
+
+    const SortedVector<String8> *vendorSections;
+    size_t vendorSectionCount = 0;
+
+    if (vTags != NULL) {
+        vendorSections = vTags->getAllSectionNames();
+        vendorSectionCount = vendorSections->size();
+    }
+
+    // First, find the section by the longest string match
+    const char *section = NULL;
+    size_t sectionIndex = 0;
+    size_t sectionLength = 0;
+    size_t totalSectionCount = ANDROID_SECTION_COUNT + vendorSectionCount;
+    for (size_t i = 0; i < totalSectionCount; ++i) {
+
+        const char *str = (i < ANDROID_SECTION_COUNT) ? camera_metadata_section_names[i] :
+                (*vendorSections)[i - ANDROID_SECTION_COUNT].string();
+
+        HAL_LOGV("%s: Trying to match against section '%s'", __FUNCTION__, str);
+
+        if (strstr(name, str) == name) { // name begins with the section name
+            size_t strLength = strlen(str);
+
+            HAL_LOGV("%s: Name begins with section name", __FUNCTION__);
+
+            // section name is the longest we've found so far
+            if (section == NULL || sectionLength < strLength) {
+                section = str;
+                sectionIndex = i;
+                sectionLength = strLength;
+
+                HAL_LOGV("%s: Found new best section (%s)", __FUNCTION__, section);
+            }
+        }
+    }
+
+    if (section == NULL) {
+        return NAME_NOT_FOUND;
+    } else {
+        HAL_LOGV("%s: Found matched section '%s' (%zu)",
+              __FUNCTION__, section, sectionIndex);
+    }
+
+    // Get the tag name component of the name
+    const char *nameTagName = name + sectionLength + 1; // x.y.z -> z
+    if (sectionLength + 1 >= nameLength) {
+        return BAD_VALUE;
+    }
+
+    // Match rest of name against the tag names in that section only
+    uint32_t candidateTag = 0;
+    if (sectionIndex < ANDROID_SECTION_COUNT) {
+        // Match built-in tags (typically android.*)
+        uint32_t tagBegin, tagEnd; // [tagBegin, tagEnd)
+        tagBegin = camera_metadata_section_bounds[sectionIndex][0];
+        tagEnd = camera_metadata_section_bounds[sectionIndex][1];
+
+        for (candidateTag = tagBegin; candidateTag < tagEnd; ++candidateTag) {
+            const char *tagName = get_camera_metadata_tag_name(candidateTag);
+
+            if (strcmp(nameTagName, tagName) == 0) {
+                HAL_LOGV("%s: Found matched tag '%s' (%d)",
+                      __FUNCTION__, tagName, candidateTag);
+                break;
+            }
+        }
+
+        if (candidateTag == tagEnd) {
+            return NAME_NOT_FOUND;
+        }
+    } else if (vTags != NULL) {
+        // Match vendor tags (typically com.*)
+        const String8 sectionName(section);
+        const String8 tagName(nameTagName);
+
+        status_t res = OK;
+        if ((res = vTags->lookupTag(tagName, sectionName, &candidateTag)) != OK) {
+            return NAME_NOT_FOUND;
+        }
+    }
+
+    *tag = candidateTag;
+    return OK;
+}
+#endif
+#if 0
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+#endif
+} // namespace android
diff --git a/hardware/ntimespace/camera/metadata/camera_metadata.h b/hardware/ntimespace/camera/metadata/camera_metadata.h
new file mode 100644
index 0000000000..472af5693a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/camera_metadata.h
@@ -0,0 +1,234 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef CAMERA_COMMON_1_0_CAMERAMETADATA_H
+#define CAMERA_COMMON_1_0_CAMERAMETADATA_H
+
+#include "system/camera_metadata.h"
+
+#include <utils/String8.h>
+#include <utils/Vector.h>
+#include "common.h"
+
+namespace android {
+#if 0
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+#endif
+//class VendorTagDescriptor;
+
+/**
+ * A convenience wrapper around the C-based camera_metadata_t library.
+ */
+class CameraMetadata {
+  public:
+    /** Creates an empty object; best used when expecting to acquire contents
+     * from elsewhere */
+    CameraMetadata();
+    /** Creates an object with space for entryCapacity entries, with
+     * dataCapacity extra storage */
+    CameraMetadata(size_t entryCapacity, size_t dataCapacity = 10);
+
+    ~CameraMetadata();
+
+    /** Takes ownership of passed-in buffer */
+    CameraMetadata(camera_metadata_t *buffer);
+    /** Clones the metadata */
+    CameraMetadata(const CameraMetadata &other);
+
+    /**
+     * Assignment clones metadata buffer.
+     */
+    CameraMetadata &operator=(const CameraMetadata &other);
+    CameraMetadata &operator=(const camera_metadata_t *buffer);
+
+    /**
+     * Get reference to the underlying metadata buffer. Ownership remains with
+     * the CameraMetadata object, but non-const CameraMetadata methods will not
+     * work until unlock() is called. Note that the lock has nothing to do with
+     * thread-safety, it simply prevents the camera_metadata_t pointer returned
+     * here from being accidentally invalidated by CameraMetadata operations.
+     */
+    const camera_metadata_t* getAndLock() const;
+
+    /**
+     * Unlock the CameraMetadata for use again. After this unlock, the pointer
+     * given from getAndLock() may no longer be used. The pointer passed out
+     * from getAndLock must be provided to guarantee that the right object is
+     * being unlocked.
+     */
+    status_t unlock(const camera_metadata_t *buffer) const;
+
+    /**
+     * Release a raw metadata buffer to the caller. After this call,
+     * CameraMetadata no longer references the buffer, and the caller takes
+     * responsibility for freeing the raw metadata buffer (using
+     * free_camera_metadata()), or for handing it to another CameraMetadata
+     * instance.
+     */
+    camera_metadata_t* release();
+
+    /**
+     * Clear the metadata buffer and free all storage used by it
+     */
+    void clear();
+
+    /**
+     * Acquire a raw metadata buffer from the caller. After this call,
+     * the caller no longer owns the raw buffer, and must not free or manipulate it.
+     * If CameraMetadata already contains metadata, it is freed.
+     */
+    void acquire(camera_metadata_t* buffer);
+
+    /**
+     * Acquires raw buffer from other CameraMetadata object. After the call, the argument
+     * object no longer has any metadata.
+     */
+    void acquire(CameraMetadata &other);
+
+    /**
+     * Append metadata from another CameraMetadata object.
+     */
+    status_t append(const CameraMetadata &other);
+
+    /**
+     * Append metadata from a raw camera_metadata buffer
+     */
+    status_t append(const camera_metadata* other);
+
+    /**
+     * Number of metadata entries.
+     */
+    size_t entryCount() const;
+
+    /**
+     * Is the buffer empty (no entires)
+     */
+    bool isEmpty() const;
+
+    /**
+     * Sort metadata buffer for faster find
+     */
+    status_t sort();
+
+    /**
+     * Update metadata entry. Will create entry if it doesn't exist already, and
+     * will reallocate the buffer if insufficient space exists. Overloaded for
+     * the various types of valid data.
+     */
+    status_t update(uint32_t tag,
+            const uint8_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const int32_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const float *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const int64_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const double *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const camera_metadata_rational_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const String8 &string);
+    status_t update(const camera_metadata_ro_entry &entry);
+
+
+    template<typename T>
+    status_t update(uint32_t tag, Vector<T> data) {
+        return update(tag, data.array(), data.size());
+    }
+
+    /**
+     * Check if a metadata entry exists for a given tag id
+     *
+     */
+    bool exists(uint32_t tag) const;
+
+    /**
+     * Get metadata entry by tag id
+     */
+    camera_metadata_entry find(uint32_t tag);
+
+    /**
+     * Get metadata entry by tag id, with no editing
+     */
+    camera_metadata_ro_entry find(uint32_t tag) const;
+
+    /**
+     * Delete metadata entry by tag
+     */
+    status_t erase(uint32_t tag);
+
+    /**
+     * Swap the underlying camera metadata between this and the other
+     * metadata object.
+     */
+    void swap(CameraMetadata &other);
+
+    /**
+     * Dump contents into FD for debugging. The verbosity levels are
+     * 0: Tag entry information only, no data values
+     * 1: Level 0 plus at most 16 data values per entry
+     * 2: All information
+     *
+     * The indentation parameter sets the number of spaces to add to the start
+     * each line of output.
+     */
+    void dump(int fd, int verbosity = 1, int indentation = 0) const;
+#if 0
+    /**
+     * Find tag id for a given tag name, also checking vendor tags if available.
+     * On success, returns OK and writes the tag id into tag.
+     *
+     * This is a slow method.
+     */
+    static status_t getTagFromName(const char *name,
+            const VendorTagDescriptor* vTags, uint32_t *tag);
+#endif
+  private:
+    camera_metadata_t *mBuffer;
+    mutable bool       mLocked;
+
+    /**
+     * Check if tag has a given type
+     */
+    status_t checkType(uint32_t tag, uint8_t expectedType);
+
+    /**
+     * Base update entry method
+     */
+    status_t updateImpl(uint32_t tag, const void *data, size_t data_count);
+
+    /**
+     * Resize metadata buffer if needed by reallocating it and copying it over.
+     */
+    status_t resizeIfNeeded(size_t extraEntries, size_t extraData);
+
+};
+
+#if 0
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+#endif
+} // namespace android
+
+#endif
diff --git a/hardware/ntimespace/camera/metadata/control.h b/hardware/ntimespace/camera/metadata/control.h
new file mode 100644
index 0000000000..3b7086fa1c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control.h
@@ -0,0 +1,221 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_H_
+
+#include <vector>
+
+#include <android-base/macros.h>
+#include <system/camera_metadata.h>
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+#include "tagged_control_delegate.h"
+#include "tagged_control_options.h"
+//#include <utils/CallStack.h>
+
+namespace v4l2_camera_hal {
+
+// A Control is a PartialMetadata with values that can be gotten/set.
+template <typename T>
+class Control : public PartialMetadataInterface {
+ public:
+  // Options are optional (i.e. nullable), delegate is not.
+  Control(std::unique_ptr<TaggedControlDelegate<T>> delegate,
+          std::unique_ptr<TaggedControlOptions<T>> options = nullptr);
+
+  virtual std::vector<int32_t> StaticTags() const override;
+  virtual std::vector<int32_t> ControlTags() const override;
+  virtual std::vector<int32_t> DynamicTags() const override;
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const override;
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const override;
+  virtual int SetRequestValues(
+      const android::CameraMetadata& metadata) override;
+
+ private:
+  std::unique_ptr<TaggedControlDelegate<T>> delegate_;
+  std::unique_ptr<TaggedControlOptions<T>> options_;
+
+  DISALLOW_COPY_AND_ASSIGN(Control);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+Control<T>::Control(std::unique_ptr<TaggedControlDelegate<T>> delegate,
+                    std::unique_ptr<TaggedControlOptions<T>> options)
+    : delegate_(std::move(delegate)), options_(std::move(options)) {}
+
+template <typename T>
+std::vector<int32_t> Control<T>::StaticTags() const {
+  std::vector<int32_t> result;
+  if (options_ && options_->tag() != DO_NOT_REPORT_OPTIONS) {
+    result.push_back(options_->tag());
+  }
+  return result;
+}
+
+template <typename T>
+std::vector<int32_t> Control<T>::ControlTags() const {
+  return {delegate_->tag()};
+}
+
+template <typename T>
+std::vector<int32_t> Control<T>::DynamicTags() const {
+  return {delegate_->tag()};
+}
+
+template <typename T>
+int Control<T>::PopulateStaticFields(android::CameraMetadata* metadata) const {
+  if (!options_) {
+    HAL_LOGV("No options for control %d, nothing to populate.",
+             delegate_->tag());
+    return 0;
+  } else if (options_->tag() == DO_NOT_REPORT_OPTIONS) {
+    HAL_LOGV(
+        "Options for control %d are not reported, "
+        "probably are set values defined and already known by the API.",
+        delegate_->tag());
+    return 0;
+  }
+
+  return UpdateMetadata(
+      metadata, options_->tag(), options_->MetadataRepresentation());
+}
+
+template <typename T>
+int Control<T>::PopulateDynamicFields(android::CameraMetadata* metadata) const {
+  // Populate the current setting.
+  T value;
+  int res = delegate_->GetValue(&value);
+  if (res) {
+    return res;
+  }
+  return UpdateMetadata(metadata, delegate_->tag(), value);
+}
+
+template <typename T>
+int Control<T>::PopulateTemplateRequest(
+    int template_type, android::CameraMetadata* metadata) const {
+  // Populate with a default.
+  T value;
+  int res;
+  if (options_) {
+    res = options_->DefaultValueForTemplate(template_type, &value);
+  } else {
+    // If there's no options (and thus no default option),
+    // fall back to whatever the current value is.
+    res = delegate_->GetValue(&value);
+  }
+  if (res) {
+    return res;
+  }
+
+  return UpdateMetadata(metadata, delegate_->tag(), value);
+}
+
+template <typename T>
+bool Control<T>::SupportsRequestValues(
+    const android::CameraMetadata& metadata) const {
+  if (metadata.isEmpty()) {
+    // Implicitly supported.
+    return true;
+  }
+
+  HAL_LOGV("Checking tag %d", delegate_->tag());
+
+  // Get the requested setting for this control.
+  T requested;
+  int res = SingleTagValue(metadata, delegate_->tag(), &requested);
+  if (res == -ENOENT) {
+    // Nothing requested of this control, that's fine.
+    return true;
+  } else if (res) {
+    HAL_LOGE("Failure while searching for request value for tag %d",
+             delegate_->tag());
+    return false;
+  }
+
+  // Check that the requested setting is in the supported options.
+  if (!options_) {
+    HAL_LOGV("No options for control %d; request implicitly supported.",
+             delegate_->tag());
+    return true;
+  }
+
+  bool ret = options_->IsSupported(requested);
+  if (!ret) {
+      /*
+      android::CallStack stack;
+      stack.update( );
+      stack.log("stack:");
+      */
+      HAL_LOGE("Checking tag %d fail, not supported.", delegate_->tag());
+      /*
+      HAL_LOGE("Dump metadata: /data/local/metadata.log");
+      
+      if (access("/data/local/metadata.log", F_OK|R_OK|W_OK) == 0) {
+          unlink("/data/local/metadata.log");
+      }
+      int fp = open("/data/local/metadata.log", O_CREAT |O_RDWR | O_CLOEXEC, 0);
+      if (fp != -1) {
+        metadata.dump(fp);
+      }
+      close(fp);
+      */
+  }
+
+  return ret;
+}
+
+template <typename T>
+int Control<T>::SetRequestValues(const android::CameraMetadata& metadata) {
+  if (metadata.isEmpty()) {
+    // No changes necessary.
+    return 0;
+  }
+
+  // Get the requested value.
+  T requested;
+  int res = SingleTagValue(metadata, delegate_->tag(), &requested);
+  if (res == -ENOENT) {
+    // Nothing requested of this control, nothing to do.
+    return 0;
+  } else if (res) {
+    HAL_LOGE("Failure while searching for request value for tag %d",
+             delegate_->tag());
+    return res;
+  }
+
+  // Check that the value is supported.
+  if (options_ && !options_->IsSupported(requested)) {
+    HAL_LOGE("Unsupported value requested for control %d.", delegate_->tag());
+    return -EINVAL;
+  }
+
+  return delegate_->SetValue(requested);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_H_
diff --git a/hardware/ntimespace/camera/metadata/control_delegate_interface.h b/hardware/ntimespace/camera/metadata/control_delegate_interface.h
new file mode 100644
index 0000000000..8896e7255e
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_delegate_interface.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
+
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A ControlDelegate extends StateDelegate with a setter method.
+template <typename T>
+class ControlDelegateInterface : public StateDelegateInterface<T> {
+ public:
+  virtual ~ControlDelegateInterface(){};
+
+  // ControlDelegates are allowed to be unreliable, so SetValue is best-effort;
+  // GetValue immediately after may not match (SetValue may, for example,
+  // automatically replace invalid values with valid ones,
+  // or have a delay before setting the requested value).
+  // Returns 0 on success, error code on failure.
+  virtual int SetValue(const T& value) = 0;
+  // Children must also override GetValue from StateDelegateInterface.
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h b/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
new file mode 100644
index 0000000000..9a0ca0446f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for control delegate interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
+
+#include "control_delegate_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class ControlDelegateInterfaceMock : public ControlDelegateInterface<T> {
+ public:
+  ControlDelegateInterfaceMock(){};
+  MOCK_METHOD1_T(GetValue, int(T*));
+  MOCK_METHOD1_T(SetValue, int(const T&));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/control_options_interface.h b/hardware/ntimespace/camera/metadata/control_options_interface.h
new file mode 100644
index 0000000000..438cefa502
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_options_interface.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
+
+#include <vector>
+
+namespace v4l2_camera_hal {
+
+// A ControlOptions defines acceptable values for a control.
+template <typename T>
+class ControlOptionsInterface {
+ public:
+  virtual ~ControlOptionsInterface(){};
+
+  // Get a metadata-acceptable representation of the options.
+  // For enums this will be a list of values, for ranges this
+  // will be min and max, etc.
+  virtual std::vector<T> MetadataRepresentation() = 0;
+  // Get whether or not a given value is acceptable.
+  virtual bool IsSupported(const T& option);
+  // Get a default option for a given template type, from the available options.
+  // Because a default must be available, any ControlOptions should have at
+  // least one supported value.
+  virtual int DefaultValueForTemplate(int template_type, T* default_value);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/control_options_interface_mock.h b/hardware/ntimespace/camera/metadata/control_options_interface_mock.h
new file mode 100644
index 0000000000..2492880c6f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_options_interface_mock.h
@@ -0,0 +1,39 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for control options interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
+
+#include "control_options_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class ControlOptionsInterfaceMock : public ControlOptionsInterface<T> {
+ public:
+  ControlOptionsInterfaceMock(){};
+  MOCK_METHOD0_T(MetadataRepresentation, std::vector<T>());
+  MOCK_METHOD1_T(IsSupported, bool(const T&));
+  MOCK_METHOD2_T(DefaultValueForTemplate, int(int, T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/control_test.cpp b/hardware/ntimespace/camera/metadata/control_test.cpp
new file mode 100644
index 0000000000..d7ebe3212b
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_test.cpp
@@ -0,0 +1,458 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "control.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_delegate_interface_mock.h"
+#include "control_options_interface_mock.h"
+#include "metadata_common.h"
+#include "test_common.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class ControlTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new ControlDelegateInterfaceMock<uint8_t>());
+    mock_options_.reset(new ControlOptionsInterfaceMock<uint8_t>());
+    // Nullify control so an error will be thrown if a test doesn't call
+    // PrepareControl.
+    control_.reset();
+  }
+
+  virtual void PrepareControl() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the mocks
+    // to the device.
+    std::unique_ptr<TaggedControlDelegate<uint8_t>> delegate =
+        std::make_unique<TaggedControlDelegate<uint8_t>>(
+            delegate_tag_, std::move(mock_delegate_));
+    std::unique_ptr<TaggedControlOptions<uint8_t>> options =
+        std::make_unique<TaggedControlOptions<uint8_t>>(
+            report_options_ ? options_tag_ : DO_NOT_REPORT_OPTIONS,
+            std::move(mock_options_));
+    if (use_options_) {
+      control_.reset(
+          new Control<uint8_t>(std::move(delegate), std::move(options)));
+    } else {
+      control_.reset(new Control<uint8_t>(std::move(delegate)));
+    }
+  }
+
+  virtual void ExpectTags() {
+    if (use_options_ && report_options_) {
+      ASSERT_EQ(control_->StaticTags().size(), 1u);
+      EXPECT_EQ(control_->StaticTags()[0], options_tag_);
+    } else {
+      EXPECT_TRUE(control_->StaticTags().empty());
+    }
+    // Controls use the same delgate, and thus tag, for getting and setting.
+    ASSERT_EQ(control_->ControlTags().size(), 1u);
+    EXPECT_EQ(control_->ControlTags()[0], delegate_tag_);
+    ASSERT_EQ(control_->DynamicTags().size(), 1u);
+    EXPECT_EQ(control_->DynamicTags()[0], delegate_tag_);
+  }
+
+  virtual void ExpectOptions(const std::vector<uint8_t>& options) {
+    // Options should be available.
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateStaticFields(&metadata), 0);
+    if (use_options_ && report_options_) {
+      EXPECT_EQ(metadata.entryCount(), 1u);
+      ExpectMetadataEq(metadata, options_tag_, options);
+    } else {
+      EXPECT_EQ(metadata.entryCount(), 0u);
+      // Shouldn't be expecting any options.
+      EXPECT_TRUE(options.empty());
+    }
+  }
+
+  virtual void ExpectValue(uint8_t value) {
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateDynamicFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, delegate_tag_, value);
+  }
+
+  std::unique_ptr<Control<uint8_t>> control_;
+  std::unique_ptr<ControlDelegateInterfaceMock<uint8_t>> mock_delegate_;
+  std::unique_ptr<ControlOptionsInterfaceMock<uint8_t>> mock_options_;
+  bool use_options_ = true;
+  bool report_options_ = true;
+
+  // Need tags that match the data type (uint8_t) being passed.
+  const int32_t delegate_tag_ = ANDROID_COLOR_CORRECTION_ABERRATION_MODE;
+  const int32_t options_tag_ =
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES;
+};
+
+TEST_F(ControlTest, Tags) {
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, TagsNoOptions) {
+  use_options_ = false;
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, TagsUnreportedOptions) {
+  report_options_ = false;
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, PopulateStatic) {
+  std::vector<uint8_t> expected{1, 10, 20};
+  EXPECT_CALL(*mock_options_, MetadataRepresentation())
+      .WillOnce(Return(expected));
+  PrepareControl();
+  ExpectOptions(expected);
+}
+
+TEST_F(ControlTest, PopulateStaticNoOptions) {
+  use_options_ = false;
+  PrepareControl();
+  ExpectOptions({});
+}
+
+TEST_F(ControlTest, PopulateStaticUnreportedOptions) {
+  report_options_ = false;
+  PrepareControl();
+  ExpectOptions({});
+}
+
+TEST_F(ControlTest, PopulateDynamic) {
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicNoOptions) {
+  // Lack of options shouldn't change anything for PopulateDynamic.
+  use_options_ = false;
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicUnreportedOptions) {
+  // Lack of reported options shouldn't change anything for PopulateDynamic.
+  report_options_ = false;
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicFail) {
+  int err = -99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateDynamicFields(&metadata), err);
+
+  // Should not have added an entry.
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(ControlTest, PopulateTemplate) {
+  int template_type = 3;
+  uint8_t default_value = 123;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, default_value);
+}
+
+TEST_F(ControlTest, PopulateTemplateFail) {
+  int template_type = 3;
+  int err = 10;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, PopulateTemplateOptionless) {
+  use_options_ = false;
+  int template_type = 3;
+  uint8_t value = 12;
+  // Should use delegate instead of options if no options.
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, value);
+}
+
+TEST_F(ControlTest, PopulateTemplateOptionlessFail) {
+  use_options_ = false;
+  int template_type = 3;
+  int err = 10;
+  // Should use delegate instead of options if no options.
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, PopulateTemplateUnreportedOptions) {
+  report_options_ = false;
+  int template_type = 3;
+  uint8_t default_value = 123;
+  // Unreported options should behave just like reported ones for templating.
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, default_value);
+}
+
+TEST_F(ControlTest, PopulateTemplateUnreportedOptionsFail) {
+  report_options_ = false;
+  int template_type = 3;
+  int err = 10;
+  // Unreported options should behave just like reported ones for templating.
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, SupportsRequest) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(true));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestNoOptions) {
+  use_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestUnreportedOptions) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(true));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestUnreportedOptionsFail) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // Unreported options should still be checked against.
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestInvalidNumber) {
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+  PrepareControl();
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestInvalidNumberNoOptions) {
+  use_options_ = false;
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+  PrepareControl();
+  // Not having any explicit options does not exempt a control
+  // from requiring the right number of values.
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestEmpty) {
+  android::CameraMetadata metadata;
+  PrepareControl();
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SetRequest) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestNoOptions) {
+  use_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // No options, no validation check.
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option)).WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestUnreportedOptions) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // Unreported options still get a validation check.
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestSettingFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  int err = 99;
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SetRequestValues(metadata), err);
+}
+
+TEST_F(ControlTest, SetRequestValidationFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestInvalidNumber) {
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+
+  PrepareControl();
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestInvalidNumberNoOptions) {
+  use_options_ = false;
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+
+  PrepareControl();
+  // Not having explicit options does not change that an incorrect
+  // number of values is invalid.
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestEmpty) {
+  // Should do nothing.
+  android::CameraMetadata metadata;
+  PrepareControl();
+  EXPECT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/converter_interface.h b/hardware/ntimespace/camera/metadata/converter_interface.h
new file mode 100644
index 0000000000..fa960e910d
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/converter_interface.h
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
+
+namespace v4l2_camera_hal {
+
+// A ConverterInterface converts metadata values to V4L2 values vice-versa.
+template <typename TMetadata, typename TV4L2>
+class ConverterInterface {
+ public:
+  virtual ~ConverterInterface(){};
+
+  // Convert.
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) = 0;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/converter_interface_mock.h b/hardware/ntimespace/camera/metadata/converter_interface_mock.h
new file mode 100644
index 0000000000..19d618ada6
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/converter_interface_mock.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for converter interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
+
+#include "converter_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename TMetadata, typename TV4L2>
+class ConverterInterfaceMock : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  ConverterInterfaceMock(){};
+  MOCK_METHOD2_T(MetadataToV4L2, int(TMetadata, TV4L2*));
+  MOCK_METHOD2_T(V4L2ToMetadata, int(TV4L2, TMetadata*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate.h b/hardware/ntimespace/camera/metadata/default_option_delegate.h
new file mode 100644
index 0000000000..d3d66c5ca8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate.h
@@ -0,0 +1,60 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
+
+#include <map>
+
+#include <hardware/camera3.h>
+
+namespace v4l2_camera_hal {
+
+// A constant that can be used to identify an overall default.
+static constexpr int OTHER_TEMPLATES = CAMERA3_TEMPLATE_COUNT;
+
+// DefaultingOptionDelegate provides an interface to get default options from.
+template <typename T>
+class DefaultOptionDelegate {
+ public:
+  // |defaults| maps template types to default values
+  DefaultOptionDelegate(std::map<int, T> defaults)
+      : defaults_(std::move(defaults)){};
+  virtual ~DefaultOptionDelegate(){};
+
+  // Get a default value for a template type. Returns false if no default
+  // provided.
+  virtual bool DefaultValueForTemplate(int template_type, T* default_value) {
+    if (defaults_.count(template_type) > 0) {
+      // Best option is template-specific.
+      *default_value = defaults_[template_type];
+      return true;
+    } else if (defaults_.count(OTHER_TEMPLATES)) {
+      // Fall back to a general default.
+      *default_value = defaults_[OTHER_TEMPLATES];
+      return true;
+    }
+
+    return false;
+  };
+
+ private:
+  std::map<int, T> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h b/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
new file mode 100644
index 0000000000..6b80071880
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for default option delegates.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
+
+#include "default_option_delegate.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class DefaultOptionDelegateMock : public DefaultOptionDelegate<T> {
+ public:
+  DefaultOptionDelegateMock() : DefaultOptionDelegate<T>({}){};
+  MOCK_METHOD2_T(DefaultValueForTemplate, bool(int, T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp b/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
new file mode 100644
index 0000000000..7b61dd454a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
@@ -0,0 +1,62 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "default_option_delegate.h"
+
+#include <memory>
+
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class DefaultOptionDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    dut_.reset(new DefaultOptionDelegate<int>(defaults_));
+  }
+
+  std::unique_ptr<DefaultOptionDelegate<int>> dut_;
+  std::map<int, int> defaults_{{CAMERA3_TEMPLATE_STILL_CAPTURE, 10},
+                               {OTHER_TEMPLATES, 20},
+                               {CAMERA3_TEMPLATE_VIDEO_SNAPSHOT, 30}};
+};
+
+TEST_F(DefaultOptionDelegateTest, SpecificDefault) {
+  int actual = 0;
+  EXPECT_TRUE(
+      dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_STILL_CAPTURE, &actual));
+  EXPECT_EQ(actual, defaults_[CAMERA3_TEMPLATE_STILL_CAPTURE]);
+}
+
+TEST_F(DefaultOptionDelegateTest, GeneralDefault) {
+  int actual = 0;
+  // No ZSL default; should fall back to the OTHER_TEMPLATES default.
+  EXPECT_TRUE(dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+                                            &actual));
+  EXPECT_EQ(actual, defaults_[OTHER_TEMPLATES]);
+}
+
+TEST_F(DefaultOptionDelegateTest, NoDefaults) {
+  dut_.reset(new DefaultOptionDelegate<int>({}));
+  int actual = 0;
+  EXPECT_FALSE(dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+                                             &actual));
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/enum_converter.cpp b/hardware/ntimespace/camera/metadata/enum_converter.cpp
new file mode 100644
index 0000000000..580e7e1a1a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter.cpp
@@ -0,0 +1,81 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "EnumConverter"
+
+#include "enum_converter.h"
+
+#include <cerrno>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+EnumConverter::EnumConverter(
+    const std::multimap<int32_t, uint8_t>& v4l2_to_metadata)
+    : v4l2_to_metadata_(v4l2_to_metadata) {
+  HAL_LOG_ENTER();
+}
+
+int EnumConverter::MetadataToV4L2(uint8_t value, int32_t* conversion) {
+  // Unfortunately no bi-directional map lookup in C++.
+  // Breaking on second, not first found so that a warning
+  // can be given if there are multiple values.
+  size_t count = 0;
+  for (auto kv : v4l2_to_metadata_) {
+    if (kv.second == value) {
+      ++count;
+      if (count == 1) {
+        // First match.
+        *conversion = kv.first;
+      } else {
+        // second match.
+        break;
+      }
+    }
+  }
+
+  if (count == 0) {
+    HAL_LOGV("Couldn't find V4L2 conversion of metadata value %d.", value);
+    return -EINVAL;
+  } else if (count > 1) {
+    HAL_LOGV(
+        "Multiple V4L2 conversions found for metadata value %d, using first.",
+        value);
+  }
+  return 0;
+}
+
+int EnumConverter::V4L2ToMetadata(int32_t value, uint8_t* conversion) {
+  auto element_range = v4l2_to_metadata_.equal_range(value);
+  if (element_range.first == element_range.second) {
+    HAL_LOGV("Couldn't find metadata conversion of V4L2 value %d.", value);
+    return -EINVAL;
+  }
+
+  auto element = element_range.first;
+  *conversion = element->second;
+
+  if (++element != element_range.second) {
+    HAL_LOGV(
+        "Multiple metadata conversions found for V4L2 value %d, using first.",
+        value);
+  }
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/enum_converter.h b/hardware/ntimespace/camera/metadata/enum_converter.h
new file mode 100644
index 0000000000..855f4306a7
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
+
+#include <map>
+
+#include <android-base/macros.h>
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An EnumConverter converts between enum values.
+class EnumConverter : public ConverterInterface<uint8_t, int32_t> {
+ public:
+  EnumConverter(const std::multimap<int32_t, uint8_t>& v4l2_to_metadata);
+
+  virtual int MetadataToV4L2(uint8_t value, int32_t* conversion) override;
+  virtual int V4L2ToMetadata(int32_t value, uint8_t* conversion) override;
+
+ private:
+  const std::multimap<int32_t, uint8_t> v4l2_to_metadata_;
+
+  DISALLOW_COPY_AND_ASSIGN(EnumConverter);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/enum_converter_test.cpp b/hardware/ntimespace/camera/metadata/enum_converter_test.cpp
new file mode 100644
index 0000000000..1f27884bdb
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter_test.cpp
@@ -0,0 +1,99 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "enum_converter.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class EnumConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(
+        new EnumConverter({{one_to_one_v4l2_, one_to_one_metadata_},
+                           {one_to_many_v4l2_, many_to_one_metadata_1_},
+                           {one_to_many_v4l2_, many_to_one_metadata_2_},
+                           {many_to_one_v4l2_1_, one_to_many_metadata_},
+                           {many_to_one_v4l2_2_, one_to_many_metadata_},
+                           {unused_v4l2_, unused_metadata_}}));
+  }
+
+  std::unique_ptr<EnumConverter> converter_;
+
+  const int32_t one_to_one_v4l2_ = 12;
+  const int32_t one_to_many_v4l2_ = 34;
+  const int32_t many_to_one_v4l2_1_ = 56;
+  const int32_t many_to_one_v4l2_2_ = 78;
+  const int32_t unused_v4l2_ = 910;
+  const uint8_t one_to_one_metadata_ = 109;
+  const uint8_t one_to_many_metadata_ = 87;
+  const uint8_t many_to_one_metadata_1_ = 65;
+  const uint8_t many_to_one_metadata_2_ = 43;
+  const uint8_t unused_metadata_ = 21;
+};
+
+// Convert single.
+TEST_F(EnumConverterTest, OneToOneConversion) {
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(one_to_one_v4l2_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_one_metadata_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(one_to_one_metadata_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_one_v4l2_);
+}
+
+TEST_F(EnumConverterTest, OneToManyConversion) {
+  // Should be one of the acceptable values.
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(one_to_many_v4l2_, &metadata_val), 0);
+  EXPECT_TRUE(metadata_val == many_to_one_metadata_1_ ||
+              metadata_val == many_to_one_metadata_2_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(one_to_many_metadata_, &v4l2_val), 0);
+  EXPECT_TRUE(v4l2_val == many_to_one_v4l2_1_ ||
+              v4l2_val == many_to_one_v4l2_2_);
+}
+
+TEST_F(EnumConverterTest, ManyToOneConversion) {
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(many_to_one_v4l2_1_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_many_metadata_);
+  metadata_val = 1;  // Reset.
+  ASSERT_EQ(converter_->V4L2ToMetadata(many_to_one_v4l2_2_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_many_metadata_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(many_to_one_metadata_1_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_many_v4l2_);
+  v4l2_val = 1;  // Reset.
+  ASSERT_EQ(converter_->MetadataToV4L2(many_to_one_metadata_2_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_many_v4l2_);
+}
+
+TEST_F(EnumConverterTest, InvalidConversion) {
+  uint8_t metadata_val = 1;
+  EXPECT_EQ(converter_->V4L2ToMetadata(1, &metadata_val), -EINVAL);
+
+  int32_t v4l2_val = 1;
+  EXPECT_EQ(converter_->MetadataToV4L2(1, &v4l2_val), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/ignored_control_delegate.h b/hardware/ntimespace/camera/metadata/ignored_control_delegate.h
new file mode 100644
index 0000000000..dce457b1df
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ignored_control_delegate.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An IgnoredControlDelegate, as the name implies,
+// has a fixed value and ignores all requests to set it.
+template <typename T>
+class IgnoredControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  IgnoredControlDelegate(T value) : value_(value){};
+
+  int GetValue(T* value) override {
+    *value = value_;
+    return 0;
+  };
+  int SetValue(const T& /*value*/) override { return 0; };
+
+ private:
+  const T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
new file mode 100644
index 0000000000..80c30df93c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "ignored_control_delegate.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+TEST(IgnoredControlDelegateTest, DefaultGet) {
+  int32_t value = 12;
+  IgnoredControlDelegate<int32_t> control(value);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST(IgnoredControlDelegateTest, GetAndSet) {
+  int32_t value = 12;
+  IgnoredControlDelegate<int32_t> control(value);
+  int32_t new_value = 13;
+  ASSERT_EQ(control.SetValue(new_value), 0);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  // Should still be the default.
+  EXPECT_EQ(actual, value);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/map_converter.h b/hardware/ntimespace/camera/metadata/map_converter.h
new file mode 100644
index 0000000000..aa11981898
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/map_converter.h
@@ -0,0 +1,139 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
+
+#include <cerrno>
+#include <map>
+#include <memory>
+
+#include <android-base/macros.h>
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A MapConverter fits values converted by a wrapped converter
+// to a map entry corresponding to the key with the nearest value.
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+class MapConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  MapConverter(
+      std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter,
+      std::map<TMapKey, TV4L2> conversion_map);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter_;
+  std::map<TMapKey, TV4L2> conversion_map_;
+
+  DISALLOW_COPY_AND_ASSIGN(MapConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+MapConverter<TMetadata, TV4L2, TMapKey>::MapConverter(
+    std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter,
+    std::map<TMapKey, TV4L2> conversion_map)
+    : wrapped_converter_(std::move(wrapped_converter)),
+      conversion_map_(conversion_map) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+int MapConverter<TMetadata, TV4L2, TMapKey>::MetadataToV4L2(TMetadata value,
+                                                            TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  if (conversion_map_.empty()) {
+    HAL_LOGE("Empty conversion map.");
+    return -EINVAL;
+  }
+
+  TMapKey raw_conversion = 0;
+  int res = wrapped_converter_->MetadataToV4L2(value, &raw_conversion);
+  if (res) {
+    HAL_LOGE("Failed to perform underlying conversion.");
+    return res;
+  }
+
+  // Find nearest key.
+  auto kv = conversion_map_.lower_bound(raw_conversion);
+  // lower_bound finds the first >= element.
+  if (kv == conversion_map_.begin()) {
+    // Searching for less than the smallest key, so that will be the nearest.
+    *conversion = kv->second;
+  } else if (kv == conversion_map_.end()) {
+    // Searching for greater than the largest key, so that will be the nearest.
+    --kv;
+    *conversion = kv->second;
+  } else {
+    // Since kv points to the first >= element, either that or the previous
+    // element will be nearest.
+    *conversion = kv->second;
+    TMapKey diff = kv->first - raw_conversion;
+
+    // Now compare to the previous. This element will be < raw conversion,
+    // so reverse the order of the subtraction.
+    --kv;
+    if (raw_conversion - kv->first < diff) {
+      *conversion = kv->second;
+    }
+  }
+
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+int MapConverter<TMetadata, TV4L2, TMapKey>::V4L2ToMetadata(
+    TV4L2 value, TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  // Unfortunately no bi-directional map lookup in C++.
+  // Breaking on second, not first found so that a warning
+  // can be given if there are multiple values.
+  size_t count = 0;
+  int res;
+  for (auto kv : conversion_map_) {
+    if (kv.second == value) {
+      ++count;
+      if (count == 1) {
+        // First match.
+        res = wrapped_converter_->V4L2ToMetadata(kv.first, conversion);
+      } else {
+        // second match.
+        break;
+      }
+    }
+  }
+
+  if (count == 0) {
+    HAL_LOGE("Couldn't find map conversion of V4L2 value %d.", value);
+    return -EINVAL;
+  } else if (count > 1) {
+    HAL_LOGW("Multiple map conversions found for V4L2 value %d, using first.",
+             value);
+  }
+  return res;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/map_converter_test.cpp b/hardware/ntimespace/camera/metadata/map_converter_test.cpp
new file mode 100644
index 0000000000..0361810725
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/map_converter_test.cpp
@@ -0,0 +1,110 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "map_converter.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MapConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(new ConverterInterfaceMock<int, int32_t>());
+    dut_.reset(new MapConverter<int, int32_t, int32_t>(converter_, map_));
+  }
+
+  virtual void ExpectConvertToV4L2(int32_t converted, int32_t expected) {
+    int initial = 99;
+    EXPECT_CALL(*converter_, MetadataToV4L2(initial, _))
+        .WillOnce(DoAll(SetArgPointee<1>(converted), Return(0)));
+
+    int32_t actual = expected + 1;  // Initialize to non-expected value.
+    ASSERT_EQ(dut_->MetadataToV4L2(initial, &actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+
+  std::shared_ptr<ConverterInterfaceMock<int, int32_t>> converter_;
+  std::unique_ptr<MapConverter<int, int32_t, int32_t>> dut_;
+
+  const std::map<int32_t, int32_t> map_{{10, 1}, {40, 4}, {20, 2}, {30, 3}};
+};
+
+TEST_F(MapConverterTest, NormalConversionToV4L2) {
+  // A value that matches the map perfectly.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first, kv->second);
+}
+
+TEST_F(MapConverterTest, RoundingDownConversionToV4L2) {
+  // A value that's in range but not an exact key value.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first + 1, kv->second);
+}
+
+TEST_F(MapConverterTest, RoundingUpConversionToV4L2) {
+  // A value that's in range but not an exact key value.
+  auto kv = map_.begin();
+  ++kv;
+  ExpectConvertToV4L2(kv->first - 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ClampUpConversionToV4L2) {
+  // A value that's below range.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first - 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ClampDownConversionToV4L2) {
+  // A value that's above range (even after fitting to step).
+  auto kv = map_.rbegin();
+  ExpectConvertToV4L2(kv->first + 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ConversionErrorToV4L2) {
+  int initial = 99;
+  int err = -99;
+  EXPECT_CALL(*converter_, MetadataToV4L2(initial, _)).WillOnce(Return(err));
+
+  int32_t unused;
+  EXPECT_EQ(dut_->MetadataToV4L2(initial, &unused), err);
+}
+
+TEST_F(MapConverterTest, NormalConversionToMetadata) {
+  auto kv = map_.begin();
+  int expected = 99;
+  EXPECT_CALL(*converter_, V4L2ToMetadata(kv->first, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(0)));
+
+  int actual = expected + 1;  // Initialize to non-expected value.
+  ASSERT_EQ(dut_->V4L2ToMetadata(kv->second, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MapConverterTest, NotFoundConversionToMetadata) {
+  int unused;
+  ASSERT_EQ(dut_->V4L2ToMetadata(100, &unused), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/menu_control_options.h b/hardware/ntimespace/camera/metadata/menu_control_options.h
new file mode 100644
index 0000000000..03f31aec04
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/menu_control_options.h
@@ -0,0 +1,77 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
+
+#include <cerrno>
+
+#include "common.h"
+#include "control_options_interface.h"
+#include "default_option_delegate.h"
+
+namespace v4l2_camera_hal {
+
+// MenuControlOptions offer a fixed list of acceptable values.
+template <typename T>
+class MenuControlOptions : public ControlOptionsInterface<T> {
+ public:
+  // |options| must be non-empty.
+  MenuControlOptions(std::vector<T> options,
+                     std::shared_ptr<DefaultOptionDelegate<T>> defaults)
+      : options_(options), defaults_(defaults){};
+  MenuControlOptions(std::vector<T> options, std::map<int, T> defaults)
+      : options_(options),
+        defaults_(std::make_shared<DefaultOptionDelegate<T>>(defaults)){};
+
+  virtual std::vector<T> MetadataRepresentation() override { return options_; };
+  virtual bool IsSupported(const T& option) override {
+    HAL_LOG_ENTER();
+    bool ret = (std::find(options_.begin(), options_.end(), option) !=
+            options_.end());
+    if (!ret) {
+      HAL_LOGV("fail");
+    }
+
+    return ret;
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    // Default to the first option.
+    if (options_.empty()) {
+      HAL_LOGE("Can't get default value, options are empty.");
+      return -ENODEV;
+    }
+
+    // Try to get it from the defaults delegate.
+    if (defaults_->DefaultValueForTemplate(template_type, default_value) &&
+        IsSupported(*default_value)) {
+      return 0;
+    }
+
+    // Fall back to the first available.
+    *default_value = options_[0];
+    return 0;
+  };
+
+ private:
+  std::vector<T> options_;
+  std::shared_ptr<DefaultOptionDelegate<T>> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
diff --git a/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp b/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
new file mode 100644
index 0000000000..b8eea74a82
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
@@ -0,0 +1,108 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "menu_control_options.h"
+
+#include <memory>
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "default_option_delegate_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MenuControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_defaults_.reset(new DefaultOptionDelegateMock<int>());
+    dut_.reset(new MenuControlOptions<int>(options_, mock_defaults_));
+  }
+
+  std::unique_ptr<MenuControlOptions<int>> dut_;
+  const std::vector<int> options_{1, 10, 19, 30};
+  std::shared_ptr<DefaultOptionDelegateMock<int>> mock_defaults_;
+};
+
+TEST_F(MenuControlOptionsTest, MetadataRepresentation) {
+  // Technically order doesn't matter, but this is faster to write,
+  // and still passes.
+  EXPECT_EQ(dut_->MetadataRepresentation(), options_);
+}
+
+TEST_F(MenuControlOptionsTest, IsSupported) {
+  for (auto option : options_) {
+    EXPECT_TRUE(dut_->IsSupported(option));
+  }
+  // And at least one unsupported.
+  EXPECT_FALSE(dut_->IsSupported(99));
+}
+
+TEST_F(MenuControlOptionsTest, DelegateDefaultValue) {
+  int template_index = 3;
+  int expected = options_[2];
+  ASSERT_TRUE(dut_->IsSupported(expected));
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(true)));
+  int actual = expected - 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MenuControlOptionsTest, InvalidDelegateDefaultValue) {
+  // -1 is not a supported option.
+  int template_index = 3;
+  int default_val = -1;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  // Should just give any supported option instead.
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(MenuControlOptionsTest, NoDelegateDefaultValue) {
+  int template_index = 3;
+  int actual = -1;
+  ASSERT_FALSE(dut_->IsSupported(actual));
+
+  // Have delegate error.
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(Return(false));
+
+  // Should still give *some* supported value.
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(MenuControlOptionsTest, NoDefaultValue) {
+  // Invalid options don't have a valid default.
+  MenuControlOptions<int> bad_options({}, mock_defaults_);
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    int value = -1;
+    EXPECT_EQ(bad_options.DefaultValueForTemplate(i, &value), -ENODEV);
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata.cpp b/hardware/ntimespace/camera/metadata/metadata.cpp
new file mode 100644
index 0000000000..503faba5a0
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata.cpp
@@ -0,0 +1,232 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Metadata"
+
+#include "metadata.h"
+
+#include <hardware/camera3.h>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+Metadata::Metadata(PartialMetadataSet components)
+    : components_(std::move(components)) {
+  HAL_LOG_ENTER();
+}
+
+Metadata::~Metadata() {
+  HAL_LOG_ENTER();
+}
+
+int Metadata::FillStaticMetadata(android::CameraMetadata* metadata) {
+  HAL_LOG_ENTER();
+  if (!metadata) {
+    HAL_LOGE("Can't fill null metadata.");
+    return -EINVAL;
+  }
+
+  std::vector<int32_t> static_tags;
+  std::vector<int32_t> control_tags;
+  std::vector<int32_t> dynamic_tags;
+  int res = 0;
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    // Populate the fields.
+    res = component->PopulateStaticFields(&additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all static properties.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all static properties.");
+        return res;
+      }
+    }
+
+    // Note what tags the component adds.
+    std::vector<int32_t> tags = component->StaticTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(static_tags, static_tags.end()));
+    tags = component->ControlTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(control_tags, control_tags.end()));
+    tags = component->DynamicTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(dynamic_tags, dynamic_tags.end()));
+  }
+
+  // Populate the meta fields.
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS, control_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add request keys meta key.");
+    return -ENODEV;
+  }
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_RESULT_KEYS, dynamic_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add result keys meta key.");
+    return -ENODEV;
+  }
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS, static_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add characteristics keys meta key.");
+    return -ENODEV;
+  }
+
+  // TODO(b/31018853): cache result.
+  return 0;
+}
+
+bool Metadata::IsValidRequest(const android::CameraMetadata& metadata) {
+  HAL_LOG_ENTER();
+
+  // Empty means "use previous settings", which are inherently valid.
+  if (metadata.isEmpty())
+    return true;
+
+  for (auto& component : components_) {
+    // Check that all components support the values requested of them.
+    bool valid_request = component->SupportsRequestValues(metadata);
+    if (!valid_request) {
+      // Exit early if possible.
+      return false;
+    }
+  }
+
+  return true;
+}
+
+int Metadata::GetRequestTemplate(int template_type,
+                                 android::CameraMetadata* template_metadata) {
+  HAL_LOG_ENTER();
+  if (!template_metadata) {
+    HAL_LOGE("Can't fill null template.");
+    return -EINVAL;
+  }
+
+  // Templates are numbered 1 through COUNT-1 for some reason.
+  if (template_type < 1 || template_type >= CAMERA3_TEMPLATE_COUNT) {
+    HAL_LOGE("Unrecognized template type %d.", template_type);
+    return -EINVAL;
+  }
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    int res =
+        component->PopulateTemplateRequest(template_type, &additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all default request fields.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = template_metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all default request fields.");
+        return res;
+      }
+    }
+  }
+
+  // TODO(b/31018853): cache result.
+  return 0;
+}
+
+int Metadata::SetRequestSettings(const android::CameraMetadata& metadata) {
+  HAL_LOG_ENTER();
+
+  // Empty means "use previous settings".
+  if (metadata.isEmpty()) {
+    HAL_LOGV("warning: metadata isEmpty");
+    return 0;
+  }
+
+#if 0
+  for (auto& component : components_) {
+    int res = component->SetRequestValues(metadata);
+    if (res) {
+      HAL_LOGE("Failed to set all requested settings.");
+      return res;
+    }
+  }
+#endif
+
+  return 0;
+}
+
+int Metadata::FillResultMetadata(android::CameraMetadata* metadata) {
+  HAL_LOG_ENTER();
+  if (!metadata) {
+    HAL_LOGE("Can't fill null metadata.");
+    return -EINVAL;
+  }
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    int res = component->PopulateDynamicFields(&additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all dynamic result fields.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all dynamic result fields.");
+        return res;
+      }
+    }
+  }
+
+  return 0;
+}
+
+int Metadata::Dump(std::string file) {
+  HAL_LOG_ENTER();
+  android::CameraMetadata metadata;
+
+  FillStaticMetadata(&metadata);
+  int fp = open(file.c_str(), O_CREAT |O_RDWR | O_CLOEXEC, 0);
+  if (fp != -1) {
+    metadata.dump(fp);
+  }
+  else {
+    HAL_LOGE("Dump metadata failed: %s", file.c_str());
+  }
+  ::close(fp);
+
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata.h b/hardware/ntimespace/camera/metadata/metadata.h
new file mode 100644
index 0000000000..c92628b0ce
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_H_
+#define V4L2_CAMERA_HAL_METADATA_H_
+
+#include <android-base/macros.h>
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+
+#include "metadata_common.h"
+
+namespace v4l2_camera_hal {
+class Metadata {
+ public:
+  Metadata(PartialMetadataSet components);
+  virtual ~Metadata();
+
+  int FillStaticMetadata(android::CameraMetadata* metadata);
+  bool IsValidRequest(const android::CameraMetadata& metadata);
+  int GetRequestTemplate(int template_type,
+                         android::CameraMetadata* template_metadata);
+  int SetRequestSettings(const android::CameraMetadata& metadata);
+  int FillResultMetadata(android::CameraMetadata* metadata);
+  int Dump(std::string file);
+
+ private:
+  // The overall metadata is broken down into several distinct pieces.
+  // Note: it is undefined behavior if multiple components share tags.
+  PartialMetadataSet components_;
+
+  DISALLOW_COPY_AND_ASSIGN(Metadata);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_METADATA_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_common.h b/hardware/ntimespace/camera/metadata/metadata_common.h
new file mode 100644
index 0000000000..ba266a61c8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_common.h
@@ -0,0 +1,323 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
+#define V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
+
+#include <array>
+#include <memory>
+#include <set>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include "array_vector.h"
+#include "common.h"
+#include "partial_metadata_interface.h"
+
+namespace v4l2_camera_hal {
+
+typedef std::set<std::unique_ptr<PartialMetadataInterface>> PartialMetadataSet;
+
+// Templated helper functions effectively extending android::CameraMetadata.
+// Will cause a compile-time errors if CameraMetadata doesn't support
+// using the templated type. Templates are provided to extend this support
+// to std::arrays, std::vectors, and ArrayVectors of supported types as
+// appropriate.
+
+// UpdateMetadata(metadata, tag, data):
+//
+// Updates the entry for |tag| in |metadata| (functionally similar to
+// android::CameraMetadata::update).
+//
+// Args:
+//   metadata: the android::CameraMetadata to update.
+//   tag: the tag within |metadata| to update.
+//   data: A reference to the data to update |tag| with.
+//
+// Returns:
+//   0: Success.
+//   -ENODEV: The type of |data| does not match the expected type for |tag|,
+//     or another error occured. Note: no errors are given for updating a
+//     metadata entry with an incorrect amount of data (e.g. filling a tag
+//     that expects to have only one value with multiple values), as this
+//     information is not encoded in the type associated with the tag by
+//     get_camera_metadata_tag_type (from <system/camera_metadata.h>).
+
+// Generic (pointer & size).
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const T* data,
+                          size_t count) {
+  int res = metadata->update(tag, data, count);
+  if (res) {
+    HAL_LOGE("Failed to update metadata tag %d", tag);
+    return -ENODEV;
+  }
+  return 0;
+}
+
+// Generic (single item reference).
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const T& val) {
+  return UpdateMetadata(metadata, tag, &val, 1);
+}
+
+// Specialization for vectors.
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::vector<T>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), val.size());
+}
+
+// Specialization for arrays.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::array<T, N>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), N);
+}
+
+// Specialization for ArrayVectors.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const ArrayVector<T, N>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), val.total_num_elements());
+}
+
+// Specialization for vectors of arrays.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::vector<std::array<T, N>>& val) {
+  // Convert to array vector so we know all the elements are contiguous.
+  ArrayVector<T, N> array_vector;
+  for (const auto& array : val) {
+    array_vector.push_back(array);
+  }
+  return UpdateMetadata(metadata, tag, array_vector);
+}
+
+// GetDataPointer(entry, val)
+//
+// A helper for other methods in this file.
+// Gets the data pointer of a given metadata entry into |*val|.
+
+template <typename T>
+inline void GetDataPointer(camera_metadata_ro_entry_t&, const T**);
+
+template <>
+inline void GetDataPointer<uint8_t>(camera_metadata_ro_entry_t& entry,
+                           const uint8_t** val) {
+  *val = entry.data.u8;
+}
+
+template <>
+inline void GetDataPointer<int32_t>(camera_metadata_ro_entry_t& entry,
+                           const int32_t** val) {
+  *val = entry.data.i32;
+}
+
+template <>
+inline void GetDataPointer<float>(camera_metadata_ro_entry_t& entry,
+                           const float** val) {
+  *val = entry.data.f;
+}
+
+template <>
+inline void GetDataPointer<int64_t>(camera_metadata_ro_entry_t& entry,
+                           const int64_t** val) {
+  *val = entry.data.i64;
+}
+
+template <>
+inline void GetDataPointer<double>(camera_metadata_ro_entry_t& entry,
+                           const double** val) {
+  *val = entry.data.d;
+}
+
+template <>
+inline void GetDataPointer<camera_metadata_rational_t>(camera_metadata_ro_entry_t& entry,
+                           const camera_metadata_rational_t** val) {
+  *val = entry.data.r;
+}
+
+// SingleTagValue(metadata, tag, val)
+//
+// Get the value of the |tag| entry in |metadata|.
+// |tag| is expected to refer to an entry with a single item
+// of the templated type (a "single item" is exactly N values
+// if the templated type is an array of size N). An error will be
+// returned if it the wrong number of items are present.
+//
+// Returns:
+//   -ENOENT: The tag couldn't be found or was empty.
+//   -EINVAL: The tag contained more than one item, or |val| is null.
+//   -ENODEV: The tag claims to be non-empty, but the data pointer is null.
+//   0: Success. |*val| will contain the value for |tag|.
+
+// Singleton.
+template <typename T>
+static int SingleTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          T* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to SingleTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENOENT;
+  } else if (entry.count != 1) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain exactly 1 value "
+        "(had %zu).",
+        tag,
+        entry.count);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENODEV;
+  }
+  *val = *data;
+  return 0;
+}
+
+// Specialization for std::array.
+template <typename T, size_t N>
+static int SingleTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::array<T, N>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to SingleTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENOENT;
+  } else if (entry.count != N) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain a single array of "
+        "exactly %zu values (had %zu).",
+        tag,
+        N,
+        entry.count);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENODEV;
+  }
+  // Fill in the array.
+  for (size_t i = 0; i < N; ++i) {
+    (*val)[i] = data[i];
+  }
+  return 0;
+}
+
+// VectorTagValue(metadata, tag, val)
+//
+// Get the value of the |tag| entry in |metadata|.
+// |tag| is expected to refer to an entry with a vector
+// of the templated type. For arrays, an error will be
+// returned if it the wrong number of items are present.
+//
+// Returns:
+//   -ENOENT: The tag couldn't be found or was empty. While technically an
+//            empty vector may be valid, this error is returned for consistency
+//            with SingleTagValue.
+//   -EINVAL: The tag contained an invalid number of entries (e.g. 6 entries for
+//            a vector of length 4 arrays), or |val| is null.
+//   -ENODEV: The tag claims to be non-empty, but the data pointer is null.
+//   0: Success. |*val| will contain the values for |tag|.
+template <typename T>
+static int VectorTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::vector<T>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to VectorTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    return -ENOENT;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d claims to have elements but is empty.", tag);
+    return -ENODEV;
+  }
+  // Copy the data for |tag| into the output vector.
+  *val = std::vector<T>(data, data + entry.count);
+  return 0;
+}
+
+// Specialization for std::array.
+template <typename T, size_t N>
+static int VectorTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::vector<std::array<T, N>>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to VectorTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    return -ENOENT;
+  }
+  if (entry.count % N != 0) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain a vector of arrays of "
+        "length %zu (had %zu entries, which is not divisible by %zu).",
+        tag,
+        N,
+        entry.count,
+        N);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d claims to have elements but is empty.", tag);
+    return -ENODEV;
+  }
+  // Copy the data for |tag| into separate arrays for the output vector.
+  size_t num_arrays = entry.count / N;
+  *val = std::vector<std::array<T, N>>(num_arrays);
+  for (size_t i = 0; i < num_arrays; ++i) {
+    for (size_t j = 0; j < N; ++j) {
+      val->at(i)[j] = data[i * N + j];
+    }
+  }
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader.cpp b/hardware/ntimespace/camera/metadata/metadata_reader.cpp
new file mode 100644
index 0000000000..2556f9c449
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader.cpp
@@ -0,0 +1,297 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "MetadataReader"
+
+#include "metadata_reader.h"
+
+#include <log/log.h>
+#include <system/camera.h>
+
+#include "metadata_common.h"
+
+namespace default_camera_hal {
+
+MetadataReader::MetadataReader(
+    std::unique_ptr<const android::CameraMetadata> metadata)
+    : metadata_(std::move(metadata)) {}
+
+MetadataReader::~MetadataReader() {}
+
+int MetadataReader::Facing(int* facing) const {
+  uint8_t metadata_facing = 0;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_LENS_FACING, &metadata_facing);
+  if (res) {
+    HAL_LOGE("%s: Failed to get facing from static metadata.", __func__);
+    return res;
+  }
+
+  switch (metadata_facing) {
+    case (ANDROID_LENS_FACING_FRONT):
+      *facing = CAMERA_FACING_FRONT;
+      break;
+    case (ANDROID_LENS_FACING_BACK):
+      *facing = CAMERA_FACING_BACK;
+      break;
+    case (ANDROID_LENS_FACING_EXTERNAL):
+      *facing = CAMERA_FACING_EXTERNAL;
+      break;
+    default:
+      HAL_LOGE("%s: Invalid facing from static metadata: %d.",
+            __func__,
+            metadata_facing);
+      return -EINVAL;
+  }
+
+  HAL_LOGE("%s: facing from static metadata: %d.",
+            __func__,
+            metadata_facing);
+  return 0;
+}
+
+int MetadataReader::Orientation(int* orientation) const {
+  HAL_LOG_ENTER();
+  int32_t metadata_orientation = 0;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_SENSOR_ORIENTATION, &metadata_orientation);
+  if (res) {
+    HAL_LOGE("%s: Failed to get orientation from static metadata.", __func__);
+    return res;
+  }
+
+  // Orientation must be 0, 90, 180, or 270.
+  if (metadata_orientation < 0 || metadata_orientation > 270 ||
+      metadata_orientation % 90 != 0) {
+    HAL_LOGE(
+        "%s: Invalid orientation %d "
+        "(must be a 90-degree increment in [0, 360)).",
+        __func__,
+        metadata_orientation);
+    return -EINVAL;
+  }
+
+  *orientation = static_cast<int>(metadata_orientation);
+  HAL_LOGE(
+        "%s: orientation %d "
+        "(must be a 90-degree increment in [0, 360)).",
+        __func__,
+        metadata_orientation);
+  return 0;
+}
+
+int MetadataReader::MaxInputStreams(int32_t* max_input) const {
+  HAL_LOG_ENTER();
+
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, max_input);
+  if (res == -ENOENT) {
+    // Not required; default to 0.
+    *max_input = 0;
+  } else if (res) {
+    HAL_LOGE("%s: Failed to get max output streams from static metadata.",
+          __func__);
+    return res;
+  }
+
+  return 0;
+}
+
+int MetadataReader::MaxOutputStreams(int32_t* max_raw,
+                                     int32_t* max_non_stalling,
+                                     int32_t* max_stalling) const {
+  HAL_LOG_ENTER();                                
+                            
+  std::array<int32_t, 3> max_output_streams;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS, &max_output_streams);
+  if (res) {
+    HAL_LOGE("%s: Failed to get max output streams from static metadata.",
+          __func__);
+    return res;
+  }
+  *max_raw = max_output_streams[2];
+  *max_non_stalling = max_output_streams[1];
+  *max_stalling = max_output_streams[0];
+
+  return 0;
+}
+
+int MetadataReader::RequestCapabilities(std::set<uint8_t>* capabilities) const {
+  HAL_LOG_ENTER();
+  std::vector<uint8_t> raw_capabilities;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_, ANDROID_REQUEST_AVAILABLE_CAPABILITIES, &raw_capabilities);
+  if (res) {
+    HAL_LOGE("%s: Failed to get request capabilities from static metadata.",
+          __func__);
+    return res;
+  }
+
+  // Move from vector to set.
+  capabilities->insert(raw_capabilities.begin(), raw_capabilities.end());
+  return 0;
+}
+
+int MetadataReader::StreamConfigurations(
+    std::vector<StreamConfiguration>* configs) const {
+  HAL_LOG_ENTER();
+  std::vector<RawStreamConfiguration> raw_stream_configs;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_,
+      ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+      &raw_stream_configs);
+  if (res) {
+    HAL_LOGE("%s: Failed to get stream configs from static metadata.", __func__);
+    return res;
+  }
+
+  // TODO(b/31384253): check for required configs.
+
+  // Convert from raw.
+  configs->insert(
+      configs->end(), raw_stream_configs.begin(), raw_stream_configs.end());
+
+  // Check that all configs are valid.
+  for (const auto& config : *configs) {
+    HAL_LOGV("%s: format: %d width: %d height: %d direction: %d.",
+              __func__,
+              config.spec.format,
+              config.spec.width,
+              config.spec.height,
+              config.direction);
+    // Must have positive dimensions.
+    if (config.spec.width < 1 || config.spec.height < 1) {
+      HAL_LOGE("%s: Invalid stream config: non-positive dimensions (%d, %d).",
+            __func__,
+            config.spec.width,
+            config.spec.height);
+      return -EINVAL;
+    }
+    // Must have a known direction enum.
+    switch (config.direction) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT:
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT:
+        break;
+      default:
+        HAL_LOGE("%s: Invalid stream config direction: %d.",
+              __func__,
+              config.direction);
+        return -EINVAL;
+    }
+  }
+  return 0;
+}
+
+int MetadataReader::StreamStallDurations(
+    std::vector<StreamStallDuration>* stalls) const {
+  HAL_LOG_ENTER();
+  std::vector<RawStreamStallDuration> raw_stream_stall_durations;
+  int res =
+      v4l2_camera_hal::VectorTagValue(*metadata_,
+                                      ANDROID_SCALER_AVAILABLE_STALL_DURATIONS,
+                                      &raw_stream_stall_durations);
+  if (res) {
+    HAL_LOGE("%s: Failed to get stall durations from static metadata.", __func__);
+    return res;
+  }
+
+  // Convert from raw.
+  stalls->insert(stalls->end(),
+                 raw_stream_stall_durations.begin(),
+                 raw_stream_stall_durations.end());
+  // Check that all stalls are valid.
+  for (const auto& stall : *stalls) {
+    HAL_LOGE("%s: stream format: %d width: %d height: %d.",
+              __func__,
+              stall.spec.format,
+              stall.spec.width,
+              stall.spec.height); 
+
+    // Must have positive dimensions.
+    if (stall.spec.width < 1 || stall.spec.height < 1) {
+      HAL_LOGE("%s: Invalid stall duration: non-positive dimensions (%d, %d).",
+            __func__,
+            stall.spec.width,
+            stall.spec.height);
+      return -EINVAL;
+    }
+    // Must have a non-negative stall.
+    if (stall.duration < 0) {
+      HAL_LOGE("%s: Invalid stall duration: negative stall %lld.",
+            __func__,
+            static_cast<long long>(stall.duration));
+      return -EINVAL;
+    }
+    // TODO(b/31384253): YUV_420_888, RAW10, RAW12, RAW_OPAQUE,
+    // and IMPLEMENTATION_DEFINED must have 0 stall duration.
+  }
+
+  return 0;
+}
+
+int MetadataReader::ReprocessFormats(ReprocessFormatMap* reprocess_map) const {
+  HAL_LOG_ENTER();
+  std::vector<int32_t> input_output_formats;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_,
+      ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP,
+      &input_output_formats);
+  if (res) {
+    HAL_LOGE("%s: Failed to get input output format map from static metadata.",
+          __func__);
+    return res;
+  }
+
+  // Convert from the raw vector.
+  for (size_t i = 0; i < input_output_formats.size();) {
+    // The map is represented as variable-length entries of the format
+    // input, num_outputs, <outputs>.
+
+    // Get the input format.
+    int32_t input_format = input_output_formats[i++];
+
+    // Find the output begin and end for this format.
+    int32_t num_output_formats = input_output_formats[i++];
+    if (num_output_formats < 1) {
+      HAL_LOGE(
+          "%s: No output formats for input format %d.", __func__, input_format);
+      return -EINVAL;
+    }
+    size_t outputs_end = i + num_output_formats;
+    if (outputs_end > input_output_formats.size()) {
+      HAL_LOGE("%s: Input format %d requests more data than available.",
+            __func__,
+            input_format);
+      return -EINVAL;
+    }
+
+    // Copy all the output formats into the map.
+    (*reprocess_map)[input_format].insert(
+        input_output_formats.data() + i,
+        input_output_formats.data() + outputs_end);
+
+    // Move on to the next entry.
+    i = outputs_end;
+  }
+
+  // TODO(b/31384253): check for required mappings.
+
+  return 0;
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader.h b/hardware/ntimespace/camera/metadata/metadata_reader.h
new file mode 100644
index 0000000000..58a206107a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader.h
@@ -0,0 +1,76 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
+#define DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
+
+#include <memory>
+#include <set>
+#include <vector>
+
+#include <android-base/macros.h>
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include "types.h"
+
+namespace default_camera_hal {
+
+// A MetadataReader reads and converts/validates various metadata entries.
+class MetadataReader {
+ public:
+  MetadataReader(std::unique_ptr<const android::CameraMetadata> metadata);
+  virtual ~MetadataReader();
+
+  // Get a pointer to the underlying metadata being read.
+  // The pointer is valid only as long as this object is alive.
+  // The "locking" here only causes non-const methods to fail,
+  // which is not a problem since the CameraMetadata being locked
+  // is already const. This could be a problem if the metadata was
+  // shared more widely, but |metadata_| is a unique_ptr,
+  // guaranteeing the safety of this. Destructing automatically "unlocks".
+  virtual const camera_metadata_t* raw_metadata() const {
+    return metadata_->getAndLock();
+  }
+
+  // All accessor methods must be given a valid pointer. They will return:
+  // 0: Success.
+  // -ENOENT: The necessary entry is missing.
+  // -EINVAL: The entry value is invalid.
+  // -ENODEV: Some other error occured.
+
+  // The |facing| returned will be one of the enum values from system/camera.h.
+  virtual int Facing(int* facing) const;
+  virtual int Orientation(int* orientation) const;
+  virtual int MaxInputStreams(int32_t* max_input_streams) const;
+  virtual int MaxOutputStreams(int32_t* max_raw_output_streams,
+                               int32_t* max_non_stalling_output_streams,
+                               int32_t* max_stalling_output_streams) const;
+  virtual int RequestCapabilities(std::set<uint8_t>* capabilites) const;
+  virtual int StreamConfigurations(
+      std::vector<StreamConfiguration>* configs) const;
+  virtual int StreamStallDurations(
+      std::vector<StreamStallDuration>* stalls) const;
+  virtual int ReprocessFormats(ReprocessFormatMap* reprocess_map) const;
+
+ private:
+  std::unique_ptr<const android::CameraMetadata> metadata_;
+
+  DISALLOW_COPY_AND_ASSIGN(MetadataReader);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader_mock.h b/hardware/ntimespace/camera/metadata/metadata_reader_mock.h
new file mode 100644
index 0000000000..3a91d172ca
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader_mock.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for metadata readers.
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
+#define DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
+
+#include "metadata_reader.h"
+
+#include <gmock/gmock.h>
+
+namespace default_camera_hal {
+
+class MetadataReaderMock : public MetadataReader {
+ public:
+  MetadataReaderMock() : MetadataReader(nullptr){};
+  MOCK_CONST_METHOD0(raw_metadata, const camera_metadata_t*());
+  MOCK_CONST_METHOD1(Facing, int(int*));
+  MOCK_CONST_METHOD1(Orientation, int(int*));
+  MOCK_CONST_METHOD1(MaxInputStreams, int(int32_t*));
+  MOCK_CONST_METHOD3(MaxOutputStreams, int(int32_t*, int32_t*, int32_t*));
+  MOCK_CONST_METHOD1(RequestCapabilities, int(std::set<uint8_t>*));
+  MOCK_CONST_METHOD1(StreamConfigurations,
+                     int(std::vector<StreamConfiguration>*));
+  MOCK_CONST_METHOD1(StreamStallDurations,
+                     int(std::vector<StreamStallDuration>*));
+  MOCK_CONST_METHOD1(ReprocessFormats, int(ReprocessFormatMap*));
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp b/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
new file mode 100644
index 0000000000..45865214c2
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
@@ -0,0 +1,368 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "metadata_reader.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include <system/camera.h>
+
+#include "array_vector.h"
+#include "metadata_common.h"
+
+using testing::Test;
+
+namespace default_camera_hal {
+
+class MetadataReaderTest : public Test {
+ protected:
+  void SetUp() {
+    ResetMetadata();
+    // FillDUT should be called before using the device under test.
+    dut_.reset();
+  }
+
+  void ResetMetadata() {
+    metadata_ = std::make_unique<android::CameraMetadata>();
+  }
+
+  void FillDUT() {
+    dut_ = std::make_unique<MetadataReader>(std::move(metadata_));
+    ResetMetadata();
+  }
+
+  std::unique_ptr<MetadataReader> dut_;
+  std::unique_ptr<android::CameraMetadata> metadata_;
+
+  const int32_t facing_tag_ = ANDROID_LENS_FACING;
+  const int32_t orientation_tag_ = ANDROID_SENSOR_ORIENTATION;
+  const int32_t max_inputs_tag_ = ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS;
+  const int32_t max_outputs_tag_ = ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS;
+  const int32_t configs_tag_ = ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS;
+  const int32_t stalls_tag_ = ANDROID_SCALER_AVAILABLE_STALL_DURATIONS;
+  const int32_t reprocess_formats_tag_ =
+      ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP;
+
+  const std::vector<int32_t> valid_orientations_ = {0, 90, 180, 270};
+  // TODO(b/31384253): check for required configs/reprocess formats.
+};
+
+TEST_F(MetadataReaderTest, FacingTranslations) {
+  // Check that the enums are converting properly.
+  std::map<uint8_t, int> translations{
+      {ANDROID_LENS_FACING_FRONT, CAMERA_FACING_FRONT},
+      {ANDROID_LENS_FACING_BACK, CAMERA_FACING_BACK},
+      {ANDROID_LENS_FACING_EXTERNAL, CAMERA_FACING_EXTERNAL}};
+  for (const auto& translation : translations) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), facing_tag_, translation.first),
+              0);
+    FillDUT();
+
+    int expected = translation.second;
+    int actual = expected + 1;
+    EXPECT_EQ(dut_->Facing(&actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+}
+
+TEST_F(MetadataReaderTest, InvalidFacing) {
+  uint8_t invalid = 99;
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), facing_tag_, invalid),
+      0);
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Facing(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyFacing) {
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Facing(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, ValidOrientations) {
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation),
+              0);
+    FillDUT();
+
+    int actual = orientation + 1;
+    EXPECT_EQ(dut_->Orientation(&actual), 0);
+    EXPECT_EQ(actual, orientation);
+  }
+}
+
+TEST_F(MetadataReaderTest, InvalidOrientations) {
+  // High.
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation + 1),
+              0);
+    FillDUT();
+    int actual = 0;
+    EXPECT_EQ(dut_->Orientation(&actual), -EINVAL);
+  }
+  // Low.
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation - 1),
+              0);
+    FillDUT();
+    int actual = 0;
+    EXPECT_EQ(dut_->Orientation(&actual), -EINVAL);
+  }
+}
+
+TEST_F(MetadataReaderTest, EmptyOrientation) {
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Orientation(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, MaxInputs) {
+  int32_t expected = 12;
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_inputs_tag_, expected),
+            0);
+  FillDUT();
+  int32_t actual = expected + 1;
+  ASSERT_EQ(dut_->MaxInputStreams(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, EmptyMaxInputs) {
+  FillDUT();
+  // Max inputs is an optional key; if not present the default is 0.
+  int32_t expected = 0;
+  int32_t actual = expected + 1;
+  ASSERT_EQ(dut_->MaxInputStreams(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, MaxOutputs) {
+  std::array<int32_t, 3> expected = {{12, 34, 56}};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_outputs_tag_, expected),
+            0);
+  FillDUT();
+  std::array<int32_t, 3> actual;
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual[0], &actual[1], &actual[2]), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, InvalidMaxOutputs) {
+  // Must be a 3-tuple to be valid.
+  std::array<int32_t, 4> invalid = {{12, 34, 56, 78}};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_outputs_tag_, invalid),
+            0);
+  FillDUT();
+  int32_t actual;
+  // Don't mind the aliasing since we don't care about the value.
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual, &actual, &actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyMaxOutputs) {
+  FillDUT();
+  int32_t actual;
+  // Don't mind the aliasing since we don't care about the value.
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual, &actual, &actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, StreamConfigurations) {
+  v4l2_camera_hal::ArrayVector<int32_t, 4> configs;
+  std::array<int32_t, 4> config1{
+      {1, 2, 3, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}};
+  std::array<int32_t, 4> config2{
+      {5, 6, 7, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}};
+  configs.push_back(config1);
+  configs.push_back(config2);
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, configs),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), 0);
+  ASSERT_EQ(actual.size(), configs.num_arrays());
+  EXPECT_EQ(actual[0].spec.format, config1[0]);
+  EXPECT_EQ(actual[0].spec.width, config1[1]);
+  EXPECT_EQ(actual[0].spec.height, config1[2]);
+  EXPECT_EQ(actual[0].direction, config1[3]);
+  EXPECT_EQ(actual[1].spec.format, config2[0]);
+  EXPECT_EQ(actual[1].spec.width, config2[1]);
+  EXPECT_EQ(actual[1].spec.height, config2[2]);
+  EXPECT_EQ(actual[1].direction, config2[3]);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationDirection) {
+  // -1 is not a valid direction.
+  std::array<int32_t, 4> config{{1, 2, 3, -1}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationSize) {
+  // Both size dimensions must be > 0.
+  std::array<int32_t, 4> config{
+      {1, 2, 0, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationNumElements) {
+  // Should be a multiple of 4.
+  std::array<int32_t, 5> config{
+      {1, 2, 3, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT, 5}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+// TODO(b/31384253): Test that failure occurs if
+// required configurations are not present.
+
+TEST_F(MetadataReaderTest, NoStreamConfigurations) {
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, StreamStallDurations) {
+  v4l2_camera_hal::ArrayVector<int64_t, 4> stalls;
+  std::array<int64_t, 4> stall1{{1, 2, 3, 4}};
+  std::array<int64_t, 4> stall2{{5, 6, 7, 8}};
+  stalls.push_back(stall1);
+  stalls.push_back(stall2);
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stalls), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), 0);
+  ASSERT_EQ(actual.size(), stalls.num_arrays());
+  EXPECT_EQ(actual[0].spec.format, stall1[0]);
+  EXPECT_EQ(actual[0].spec.width, stall1[1]);
+  EXPECT_EQ(actual[0].spec.height, stall1[2]);
+  EXPECT_EQ(actual[0].duration, stall1[3]);
+  EXPECT_EQ(actual[1].spec.format, stall2[0]);
+  EXPECT_EQ(actual[1].spec.width, stall2[1]);
+  EXPECT_EQ(actual[1].spec.height, stall2[2]);
+  EXPECT_EQ(actual[1].duration, stall2[3]);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationDuration) {
+  // -1 is not a valid duration.
+  std::array<int64_t, 4> stall{{1, 2, 3, -1}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationSize) {
+  // Both size dimensions must be > 0.
+  std::array<int64_t, 4> stall{{1, 2, 0, 3}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationNumElements) {
+  // Should be a multiple of 4.
+  std::array<int64_t, 5> stall{{1, 2, 3, 4, 5}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+// TODO(b/31384253): Test that failure occurs if
+// YUV_420_888, RAW10, RAW12, RAW_OPAQUE, or IMPLEMENTATION_DEFINED
+// formats have stall durations > 0.
+
+TEST_F(MetadataReaderTest, NoStreamStallDurations) {
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormats) {
+  ReprocessFormatMap expected{{1, {4}}, {2, {5, 6}}, {3, {7, 8, 9}}};
+  std::vector<int32_t> raw;
+  for (const auto& input_outputs : expected) {
+    raw.push_back(input_outputs.first);
+    raw.push_back(input_outputs.second.size());
+    raw.insert(
+        raw.end(), input_outputs.second.begin(), input_outputs.second.end());
+  }
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormatsNoOutputs) {
+  // 0 indicates that there are 0 output formats for input format 1,
+  // which is not ok.
+  std::vector<int32_t> raw{1, 0};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormatsPastEnd) {
+  // 3 indicates that there are 3 output formats for input format 1,
+  // which is not ok since there are only 2 here.
+  std::vector<int32_t> raw{1, 3, 0, 0};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyReprocessFormats) {
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -ENOENT);
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata_test.cpp b/hardware/ntimespace/camera/metadata/metadata_test.cpp
new file mode 100644
index 0000000000..d753dd7a22
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_test.cpp
@@ -0,0 +1,322 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "metadata.h"
+
+#include <memory>
+#include <set>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "metadata_common.h"
+#include "partial_metadata_interface_mock.h"
+
+using testing::AtMost;
+using testing::Return;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MetadataTest : public Test {
+ protected:
+  virtual void SetUp() {
+    // Clear the DUT. AddComponents must be called before using it.
+    dut_.reset();
+
+    component1_.reset(new PartialMetadataInterfaceMock());
+    component2_.reset(new PartialMetadataInterfaceMock());
+    metadata_.reset(new android::CameraMetadata());
+    non_empty_metadata_.reset(new android::CameraMetadata());
+    uint8_t val = 1;
+    non_empty_metadata_->update(ANDROID_COLOR_CORRECTION_MODE, &val, 1);
+  }
+
+  // Once the component mocks have had expectations set,
+  // add them to the device under test.
+  virtual void AddComponents() {
+    // Don't mind moving; Gmock/Gtest fails on leaked mocks unless disabled by
+    // runtime flags.
+    PartialMetadataSet components;
+    components.insert(std::move(component1_));
+    components.insert(std::move(component2_));
+    dut_.reset(new Metadata(std::move(components)));
+  }
+
+  virtual void CompareTags(const std::set<int32_t>& expected,
+                           const camera_metadata_entry_t& actual) {
+    ASSERT_EQ(expected.size(), actual.count);
+    for (size_t i = 0; i < actual.count; ++i) {
+      EXPECT_NE(expected.find(actual.data.i32[i]), expected.end());
+    }
+  }
+
+  // Device under test.
+  std::unique_ptr<Metadata> dut_;
+  // Mocks.
+  std::unique_ptr<PartialMetadataInterfaceMock> component1_;
+  std::unique_ptr<PartialMetadataInterfaceMock> component2_;
+  // Metadata.
+  std::unique_ptr<android::CameraMetadata> metadata_;
+  std::unique_ptr<android::CameraMetadata> non_empty_metadata_;
+  // An empty vector to use as necessary.
+  std::vector<int32_t> empty_tags_;
+};
+
+TEST_F(MetadataTest, FillStaticSuccess) {
+  // Should populate all the component static pieces.
+  EXPECT_CALL(*component1_, PopulateStaticFields(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateStaticFields(_)).WillOnce(Return(0));
+
+  // Should populate the meta keys, by polling each component's keys.
+  std::vector<int32_t> static_tags_1({1, 2});
+  std::vector<int32_t> static_tags_2({3, 4});
+  std::vector<int32_t> control_tags_1({5, 6});
+  std::vector<int32_t> control_tags_2({7, 8});
+  std::vector<int32_t> dynamic_tags_1({9, 10});
+  std::vector<int32_t> dynamic_tags_2({11, 12});
+  EXPECT_CALL(*component1_, StaticTags()).WillOnce(Return(static_tags_1));
+  EXPECT_CALL(*component1_, ControlTags()).WillOnce(Return(control_tags_1));
+  EXPECT_CALL(*component1_, DynamicTags()).WillOnce(Return(dynamic_tags_1));
+  EXPECT_CALL(*component2_, StaticTags()).WillOnce(Return(static_tags_2));
+  EXPECT_CALL(*component2_, ControlTags()).WillOnce(Return(control_tags_2));
+  EXPECT_CALL(*component2_, DynamicTags()).WillOnce(Return(dynamic_tags_2));
+
+  AddComponents();
+  // Should succeed. If it didn't, no reason to continue checking output.
+  ASSERT_EQ(dut_->FillStaticMetadata(metadata_.get()), 0);
+
+  // Meta keys should be filled correctly.
+  // Note: sets are used here, but it is undefined behavior if
+  // the class has multiple componenets reporting overlapping tags.
+
+  // Get the expected tags = combined tags of all components.
+  std::set<int32_t> static_tags(static_tags_1.begin(), static_tags_1.end());
+  static_tags.insert(static_tags_2.begin(), static_tags_2.end());
+  std::set<int32_t> control_tags(control_tags_1.begin(), control_tags_1.end());
+  control_tags.insert(control_tags_2.begin(), control_tags_2.end());
+  std::set<int32_t> dynamic_tags(dynamic_tags_1.begin(), dynamic_tags_1.end());
+  dynamic_tags.insert(dynamic_tags_2.begin(), dynamic_tags_2.end());
+
+  // Static tags includes not only all component static tags, but also
+  // the meta AVAILABLE_*_KEYS (* = [REQUEST, RESULT, CHARACTERISTICS]).
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS);
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS);
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS);
+
+  // Check against what was filled in in the metadata.
+  CompareTags(static_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS));
+  CompareTags(control_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS));
+  CompareTags(dynamic_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS));
+}
+
+TEST_F(MetadataTest, FillStaticFail) {
+  int err = -99;
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateStaticFields(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateStaticFields(_)).WillOnce(Return(err));
+
+  // May or may not exit early, may still try to populate meta tags.
+  EXPECT_CALL(*component1_, StaticTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component1_, ControlTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component1_, DynamicTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, StaticTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, ControlTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, DynamicTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+
+  AddComponents();
+  // If any component errors, error should be returned
+  EXPECT_EQ(dut_->FillStaticMetadata(metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, FillStaticNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->FillStaticMetadata(nullptr), -EINVAL);
+}
+
+TEST_F(MetadataTest, IsValidSuccess) {
+  // Should check if all the component request values are valid.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_)).WillOnce(Return(true));
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).WillOnce(Return(true));
+
+  AddComponents();
+  // Should succeed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_TRUE(dut_->IsValidRequest(*non_empty_metadata_));
+}
+
+TEST_F(MetadataTest, IsValidFail) {
+  // Should check if all the component request values are valid.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(true));
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).WillOnce(Return(false));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_FALSE(dut_->IsValidRequest(*non_empty_metadata_));
+}
+
+TEST_F(MetadataTest, IsValidEmpty) {
+  // Setting null settings is a special case indicating to use the
+  // previous (valid) settings. As such it is inherently valid.
+  // Should not try to check any components.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_)).Times(0);
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).Times(0);
+
+  AddComponents();
+  EXPECT_TRUE(dut_->IsValidRequest(*metadata_));
+}
+
+TEST_F(MetadataTest, GetTemplateSuccess) {
+  int template_type = 3;
+
+  // Should check if all the components fill the template successfully.
+  EXPECT_CALL(*component1_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), 0);
+}
+
+TEST_F(MetadataTest, GetTemplateFail) {
+  int err = -99;
+  int template_type = 3;
+
+  // Should check if all the components fill the template successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateTemplateRequest(template_type, _))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, GetTemplateNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->GetRequestTemplate(1, nullptr), -EINVAL);
+}
+
+TEST_F(MetadataTest, GetTemplateInvalid) {
+  int template_type = 99;  // Invalid template type.
+
+  AddComponents();
+  // Should fail fast since template type is invalid.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), -EINVAL);
+}
+
+TEST_F(MetadataTest, SetSettingsSuccess) {
+  // Should check if all the components set successfully.
+  EXPECT_CALL(*component1_, SetRequestValues(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, SetRequestValues(_)).WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_EQ(dut_->SetRequestSettings(*non_empty_metadata_), 0);
+}
+
+TEST_F(MetadataTest, SetSettingsFail) {
+  int err = -99;
+
+  // Should check if all the components set successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, SetRequestValues(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, SetRequestValues(_)).WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_EQ(dut_->SetRequestSettings(*non_empty_metadata_), err);
+}
+
+TEST_F(MetadataTest, SetSettingsEmpty) {
+  // Setting null settings is a special case indicating to use the
+  // previous settings. Should not try to set any components.
+  EXPECT_CALL(*component1_, SetRequestValues(_)).Times(0);
+  EXPECT_CALL(*component2_, SetRequestValues(_)).Times(0);
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->SetRequestSettings(*metadata_), 0);
+}
+
+TEST_F(MetadataTest, FillResultSuccess) {
+  // Should check if all the components fill results successfully.
+  EXPECT_CALL(*component1_, PopulateDynamicFields(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateDynamicFields(_)).WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->FillResultMetadata(metadata_.get()), 0);
+}
+
+TEST_F(MetadataTest, FillResultFail) {
+  int err = -99;
+
+  // Should check if all the components fill results successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateDynamicFields(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateDynamicFields(_)).WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  EXPECT_EQ(dut_->FillResultMetadata(metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, FillResultNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->FillResultMetadata(nullptr), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h b/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
new file mode 100644
index 0000000000..e1936f1160
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A NoEffectControlDelegate, as the name implies, has no effect.
+// The value can be gotten and set, but it does nothing.
+template <typename T>
+class NoEffectControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  NoEffectControlDelegate(T default_value) : value_(default_value){};
+
+  int GetValue(T* value) override {
+    *value = value_;
+    return 0;
+  };
+  int SetValue(const T& value) override {
+    value_ = value;
+    return 0;
+  };
+
+ private:
+  T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
new file mode 100644
index 0000000000..0a7a24c823
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "no_effect_control_delegate.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+TEST(NoEffectControlDelegateTest, DefaultGet) {
+  int32_t value = 12;
+  NoEffectControlDelegate<int32_t> control(value);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST(NoEffectControlDelegateTest, GetAndSet) {
+  int32_t value = 12;
+  NoEffectControlDelegate<int32_t> control(value);
+  int32_t new_value = 13;
+  ASSERT_EQ(control.SetValue(new_value), 0);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, new_value);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_factory.h b/hardware/ntimespace/camera/metadata/partial_metadata_factory.h
new file mode 100644
index 0000000000..75aba25fcc
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_factory.h
@@ -0,0 +1,335 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
+
+#include "common.h"
+#include "control.h"
+#include "menu_control_options.h"
+#include "no_effect_control_delegate.h"
+#include "ranged_converter.h"
+#include "slider_control_options.h"
+#include "state.h"
+#include "tagged_control_delegate.h"
+#include "tagged_control_options.h"
+#include "v4l2_control_delegate.h"
+
+namespace v4l2_camera_hal {
+
+enum class ControlType { kMenu, kSlider };
+
+// Static functions to create partial metadata. Nullptr is returned on failures.
+
+// FixedState: A state that doesn't change.
+template <typename T>
+static std::unique_ptr<State<T>> FixedState(int32_t tag, T value);
+
+// NoEffectOptionlessControl: A control that accepts any value,
+// and has no effect. A default value is given.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectOptionlessControl(
+    int32_t delegate_tag, T default_value);
+
+// NoEffectMenuControl: Some menu options, but they have no effect.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectMenuControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    const std::vector<T>& options,
+    std::map<int, T> default_values = {});
+
+// NoEffectSliderControl: A slider of options, but they have no effect.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectSliderControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T min,
+    T max,
+    std::map<int, T> default_values = {});
+
+// NoEffectControl: A control with no effect and only a single allowable
+// value. Chooses an appropriate ControlOptionsInterface depending on type.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectControl(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T value,
+    std::map<int, T> default_values = {});
+
+// V4L2Control: A control corresponding to a V4L2 control.
+template <typename T>
+static std::unique_ptr<Control<T>> V4L2Control(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    std::map<int, T> default_values = {});
+
+// V4L2ControlOrDefault: Like V4L2Control, but if the V4L2Control fails to
+// initialize for some reason, this method will fall back to NoEffectControl
+// with an initial value defined by |fallback_default|.
+template <typename T>
+static std::unique_ptr<Control<T>> V4L2ControlOrDefault(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    T fallback_default,
+    std::map<int, T> default_values = {});
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+std::unique_ptr<State<T>> FixedState(int32_t tag, T value) {
+  HAL_LOG_ENTER();
+
+  // Take advantage of ControlDelegate inheriting from StateDelegate;
+  // This will only expose GetValue, not SetValue, so the default will
+  // always be returned.
+  return std::make_unique<State<T>>(
+      tag, std::make_unique<NoEffectControlDelegate<T>>(value));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectOptionlessControl(int32_t delegate_tag,
+                                                      T default_value) {
+  HAL_LOG_ENTER();
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<NoEffectControlDelegate<T>>(default_value)),
+      nullptr);
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectMenuControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    const std::vector<T>& options,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  if (options.empty()) {
+    HAL_LOGE("At least one option must be provided.");
+    return nullptr;
+  }
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<NoEffectControlDelegate<T>>(options[0])),
+      std::make_unique<TaggedControlOptions<T>>(
+          options_tag,
+          std::make_unique<MenuControlOptions<T>>(options, default_values)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectSliderControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T min,
+    T max,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag, std::make_unique<NoEffectControlDelegate<T>>(min)),
+      std::make_unique<TaggedControlOptions<T>>(
+          options_tag,
+          std::make_unique<SliderControlOptions<T>>(min, max, default_values)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectControl(ControlType type,
+                                            int32_t delegate_tag,
+                                            int32_t options_tag,
+                                            T value,
+                                            std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  switch (type) {
+    case ControlType::kMenu:
+      return NoEffectMenuControl<T>(
+          delegate_tag, options_tag, {value}, default_values);
+    case ControlType::kSlider:
+      return NoEffectSliderControl(
+          delegate_tag, options_tag, value, value, default_values);
+  }
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> V4L2Control(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  // Query the device.
+  v4l2_query_ext_ctrl control_query;
+  int res = device->QueryControl(control_id, &control_query);
+  if (res) {
+    HAL_LOGE("Failed to query control %d.", control_id);
+    return nullptr;
+  }
+
+  int32_t control_min = static_cast<int32_t>(control_query.minimum);
+  int32_t control_max = static_cast<int32_t>(control_query.maximum);
+  int32_t control_step = static_cast<int32_t>(control_query.step);
+  if (control_min > control_max) {
+    HAL_LOGE("No acceptable values (min %d is greater than max %d).",
+             control_min,
+             control_max);
+    return nullptr;
+  }
+
+  // Variables needed by the various switch statements.
+  std::vector<T> options;
+  T metadata_val;
+  T metadata_min;
+  T metadata_max;
+  // Set up the result converter and result options based on type.
+  std::shared_ptr<ConverterInterface<T, int32_t>> result_converter(converter);
+  std::unique_ptr<ControlOptionsInterface<T>> result_options;
+  switch (control_query.type) {
+    case V4L2_CTRL_TYPE_BOOLEAN:
+      if (type != ControlType::kMenu) {
+        HAL_LOGE(
+            "V4L2 control %d is of type %d, which isn't compatible with "
+            "desired metadata control type %d",
+            control_id,
+            control_query.type,
+            type);
+        return nullptr;
+      }
+
+      // Convert each available option,
+      // ignoring ones without a known conversion.
+      for (int32_t i = control_min; i <= control_max; i += control_step) {
+        res = converter->V4L2ToMetadata(i, &metadata_val);
+        if (res == -EINVAL) {
+          HAL_LOGV("V4L2 value %d for control %d has no metadata equivalent.",
+                   i,
+                   control_id);
+          continue;
+        } else if (res) {
+          HAL_LOGE("Error converting value %d for control %d.", i, control_id);
+          return nullptr;
+        }
+        options.push_back(metadata_val);
+      }
+      // Check to make sure there's at least one option.
+      if (options.empty()) {
+        HAL_LOGE("No valid options for control %d.", control_id);
+        return nullptr;
+      }
+
+      result_options.reset(new MenuControlOptions<T>(options, default_values));
+      // No converter changes necessary.
+      break;
+    case V4L2_CTRL_TYPE_INTEGER:
+      if (type != ControlType::kSlider) {
+        HAL_LOGE(
+            "V4L2 control %d is of type %d, which isn't compatible with "
+            "desired metadata control type %d",
+            control_id,
+            control_query.type,
+            type);
+        return nullptr;
+      }
+
+      // Upgrade to a range/step-clamping converter.
+      result_converter.reset(new RangedConverter<T, int32_t>(
+          converter, control_min, control_max, control_step));
+
+      // Convert the min and max.
+      res = result_converter->V4L2ToMetadata(control_min, &metadata_min);
+      if (res) {
+        HAL_LOGE(
+            "Failed to convert V4L2 min value %d for control %d to metadata.",
+            control_min,
+            control_id);
+        return nullptr;
+      }
+      res = result_converter->V4L2ToMetadata(control_max, &metadata_max);
+      if (res) {
+        HAL_LOGE(
+            "Failed to convert V4L2 max value %d for control %d to metadata.",
+            control_max,
+            control_id);
+        return nullptr;
+      }
+      result_options.reset(new SliderControlOptions<T>(
+          metadata_min, metadata_max, default_values));
+      break;
+    default:
+      HAL_LOGE("Control %d (%s) is of unsupported type %d",
+               control_id,
+               control_query.name,
+               control_query.type);
+      return nullptr;
+  }
+
+  // Construct the control.
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<V4L2ControlDelegate<T>>(
+              device, control_id, result_converter)),
+      std::make_unique<TaggedControlOptions<T>>(options_tag,
+                                                std::move(result_options)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> V4L2ControlOrDefault(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    T fallback_default,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  std::unique_ptr<Control<T>> result = V4L2Control(type,
+                                                   delegate_tag,
+                                                   options_tag,
+                                                   device,
+                                                   control_id,
+                                                   converter,
+                                                   default_values);
+  if (!result) {
+    result = NoEffectControl(
+        type, delegate_tag, options_tag, fallback_default, default_values);
+  }
+  return result;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp b/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
new file mode 100644
index 0000000000..8e0b6f2f41
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
@@ -0,0 +1,456 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "partial_metadata_factory.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+#include "metadata_common.h"
+#include "test_common.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class PartialMetadataFactoryTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_device_.reset(new V4L2WrapperMock());
+    mock_converter_.reset(new ConverterInterfaceMock<uint8_t, int32_t>());
+    // Nullify control so an error will be thrown
+    // if a test doesn't construct it.
+    control_.reset();
+  }
+
+  virtual void ExpectControlTags() {
+    ASSERT_EQ(control_->StaticTags().size(), 1u);
+    EXPECT_EQ(control_->StaticTags()[0], options_tag_);
+    ASSERT_EQ(control_->ControlTags().size(), 1u);
+    EXPECT_EQ(control_->ControlTags()[0], delegate_tag_);
+    ASSERT_EQ(control_->DynamicTags().size(), 1u);
+    EXPECT_EQ(control_->DynamicTags()[0], delegate_tag_);
+  }
+
+  virtual void ExpectControlOptions(const std::vector<uint8_t>& options) {
+    // Options should be available.
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateStaticFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, options_tag_, options);
+  }
+
+  virtual void ExpectControlValue(uint8_t value) {
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateDynamicFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, delegate_tag_, value);
+  }
+
+  std::unique_ptr<Control<uint8_t>> control_;
+  std::shared_ptr<ConverterInterfaceMock<uint8_t, int32_t>> mock_converter_;
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+
+  // Need tags that match the data type (uint8_t) being passed.
+  const int32_t delegate_tag_ = ANDROID_COLOR_CORRECTION_ABERRATION_MODE;
+  const int32_t options_tag_ =
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES;
+};
+
+class DISABLED_PartialMetadataFactoryTest : public PartialMetadataFactoryTest {
+};
+
+TEST_F(PartialMetadataFactoryTest, FixedState) {
+  uint8_t value = 13;
+  std::unique_ptr<State<uint8_t>> state = FixedState(delegate_tag_, value);
+
+  ASSERT_EQ(state->StaticTags().size(), 0u);
+  ASSERT_EQ(state->ControlTags().size(), 0u);
+  ASSERT_EQ(state->DynamicTags().size(), 1u);
+  EXPECT_EQ(state->DynamicTags()[0], delegate_tag_);
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state->PopulateDynamicFields(&metadata), 0);
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  ExpectMetadataEq(metadata, delegate_tag_, value);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectMenu) {
+  std::vector<uint8_t> test_options = {9, 8, 12};
+  control_ =
+      NoEffectMenuControl<uint8_t>(delegate_tag_, options_tag_, test_options);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions(test_options);
+  // Default value should be test_options[0].
+  ExpectControlValue(test_options[0]);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectGenericMenu) {
+  uint8_t default_val = 9;
+  control_ = NoEffectControl<uint8_t>(
+      ControlType::kMenu, delegate_tag_, options_tag_, default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions({default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectSlider) {
+  std::vector<uint8_t> test_range = {9, 12};
+  control_ = NoEffectSliderControl<uint8_t>(
+      delegate_tag_, options_tag_, test_range[0], test_range[1]);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Single option should be available.
+  ExpectControlOptions(test_range);
+  // Default value should be the minimum (test_range[0]).
+  ExpectControlValue(test_range[0]);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectGenericSlider) {
+  uint8_t default_val = 9;
+  control_ = NoEffectControl<uint8_t>(
+      ControlType::kSlider, delegate_tag_, options_tag_, default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Range containing only |default_val| should be available.
+  ExpectControlOptions({default_val, default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryFail) {
+  int control_id = 55;
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryBadType) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_CTRL_CLASS;
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryBadRange) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 10;
+  query_result.maximum = 1;  // Less than minimum.
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryTypeRequestMenuMismatch) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+
+  // If you ask for a Menu, but the V4L2 control is a slider type, that's bad.
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryTypeRequestSliderMismatch) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+
+  // If you ask for a Slider and get a Menu, that's bad.
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenu) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Should convert values.
+  std::vector<uint8_t> expected_options;
+  for (auto kv : conversion_map) {
+    EXPECT_CALL(*mock_converter_, V4L2ToMetadata(kv.first, _))
+        .WillOnce(DoAll(SetArgPointee<1>(kv.second), Return(0)));
+    expected_options.push_back(kv.second);
+  }
+  // Will fail to convert 7 with -EINVAL, shouldn't matter.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(7, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+  ExpectControlOptions(expected_options);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenuConversionFail) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Conversion fails with non-EINVAL error.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(_, _)).WillOnce(Return(-1));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenuNoConversions) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 1;
+  query_result.step = 1;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Conversion fails with -EINVAL error.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(1, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Since there were no convertable options, should fail.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryInteger) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1 & 7.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {7, 70}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Should convert values.
+  std::vector<uint8_t> expected_options;
+  for (auto kv : conversion_map) {
+    EXPECT_CALL(*mock_converter_, V4L2ToMetadata(kv.first, _))
+        .WillOnce(DoAll(SetArgPointee<1>(kv.second), Return(0)));
+    expected_options.push_back(kv.second);
+  }
+
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+  ExpectControlOptions(expected_options);
+
+  // Should be fitting converted values to steps.
+  uint8_t set_val = 10;
+  android::CameraMetadata metadata;
+  EXPECT_EQ(UpdateMetadata(&metadata, delegate_tag_, set_val), 0);
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(set_val, _))
+      .WillOnce(DoAll(SetArgPointee<1>(4), Return(0)));
+  // When it calls into the device, the 4 returned above should be
+  // rounded down to the step value of 3.
+  EXPECT_CALL(*mock_device_, SetControl(control_id, 3, _)).WillOnce(Return(0));
+  EXPECT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryIntegerFailedConversion) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Fail to convert a value. Even -EINVAL is bad in this case.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(1, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FallbackMenu) {
+  uint8_t default_val = 9;
+  int control_id = 55;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+
+  // Shouldn't fail, should fall back to menu control.
+  control_ = V4L2ControlOrDefault<uint8_t>(ControlType::kMenu,
+                                           delegate_tag_,
+                                           options_tag_,
+                                           mock_device_,
+                                           control_id,
+                                           mock_converter_,
+                                           default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions({default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FallbackSlider) {
+  uint8_t default_val = 9;
+  int control_id = 55;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+
+  // Shouldn't fail, should fall back to slider control.
+  control_ = V4L2ControlOrDefault<uint8_t>(ControlType::kSlider,
+                                           delegate_tag_,
+                                           options_tag_,
+                                           mock_device_,
+                                           control_id,
+                                           mock_converter_,
+                                           default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Range containing only |default_val| should be available.
+  ExpectControlOptions({default_val, default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_interface.h b/hardware/ntimespace/camera/metadata/partial_metadata_interface.h
new file mode 100644
index 0000000000..a72e33a312
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_interface.h
@@ -0,0 +1,64 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
+
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+
+namespace v4l2_camera_hal {
+
+// A subset of metadata.
+class PartialMetadataInterface {
+ public:
+  virtual ~PartialMetadataInterface(){};
+
+  // The metadata tags this partial metadata is responsible for.
+  // See system/media/camera/docs/docs.html for descriptions of each tag.
+  virtual std::vector<int32_t> StaticTags() const = 0;
+  virtual std::vector<int32_t> ControlTags() const = 0;
+  virtual std::vector<int32_t> DynamicTags() const = 0;
+
+  // Add all the static properties this partial metadata
+  // is responsible for to |metadata|.
+  virtual int PopulateStaticFields(android::CameraMetadata* metadata) const = 0;
+  // Add all the dynamic states this partial metadata
+  // is responsible for to |metadata|.
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const = 0;
+  // Add default request values for a given template type for all the controls
+  // this partial metadata owns.
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const = 0;
+  // Check if the requested control values from |metadata| (for controls
+  // this partial metadata owns) are supported. Empty/null values for owned
+  // control tags indicate no change, and are thus inherently supported.
+  // If |metadata| is empty all controls are implicitly supported.
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const = 0;
+  // Set all the controls this partial metadata
+  // is responsible for from |metadata|. Empty/null values for owned control
+  // tags indicate no change. If |metadata| is empty no controls should
+  // be changed.
+  virtual int SetRequestValues(const android::CameraMetadata& metadata) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h b/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
new file mode 100644
index 0000000000..289b978522
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
@@ -0,0 +1,45 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for partial metadata interfaces.
+
+#ifndef V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
+
+#include "partial_metadata_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+class PartialMetadataInterfaceMock : public PartialMetadataInterface {
+ public:
+  PartialMetadataInterfaceMock() : PartialMetadataInterface(){};
+  MOCK_CONST_METHOD0(StaticTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD0(ControlTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD0(DynamicTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD1(PopulateStaticFields, int(android::CameraMetadata*));
+  MOCK_CONST_METHOD1(PopulateDynamicFields, int(android::CameraMetadata*));
+  MOCK_CONST_METHOD2(PopulateTemplateRequest,
+                     int(int, android::CameraMetadata*));
+  MOCK_CONST_METHOD1(SupportsRequestValues,
+                     bool(const android::CameraMetadata&));
+  MOCK_METHOD1(SetRequestValues, int(const android::CameraMetadata&));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/property.h b/hardware/ntimespace/camera/metadata/property.h
new file mode 100644
index 0000000000..b5a996cb0f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/property.h
@@ -0,0 +1,69 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
+#define V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
+
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A Property is a PartialMetadata that only has a single static tag.
+template <typename T>
+class Property : public PartialMetadataInterface {
+ public:
+  Property(int32_t tag, T value) : tag_(tag), value_(std::move(value)){};
+
+  virtual std::vector<int32_t> StaticTags() const override { return {tag_}; };
+
+  virtual std::vector<int32_t> ControlTags() const override { return {}; };
+
+  virtual std::vector<int32_t> DynamicTags() const override { return {}; };
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override {
+    return UpdateMetadata(metadata, tag_, value_);
+  };
+
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* /*metadata*/) const override {
+    return 0;
+  };
+
+  virtual int PopulateTemplateRequest(
+      int /*template_type*/, android::CameraMetadata* /*metadata*/) const override {
+    return 0;
+  };
+
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& /*metadata*/) const override {
+    return true;
+  };
+
+  virtual int SetRequestValues(
+      const android::CameraMetadata& /*metadata*/) override {
+    return 0;
+  };
+
+ private:
+  int32_t tag_;
+  T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
diff --git a/hardware/ntimespace/camera/metadata/property_test.cpp b/hardware/ntimespace/camera/metadata/property_test.cpp
new file mode 100644
index 0000000000..5c3107ee1a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/property_test.cpp
@@ -0,0 +1,156 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "property.h"
+
+#include <array>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "array_vector.h"
+#include "metadata_common.h"
+#include "test_common.h"
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class PropertyTest : public Test {
+ protected:
+  // Need tags that match the data types being passed.
+  static constexpr int32_t byte_tag_ = ANDROID_CONTROL_SCENE_MODE_OVERRIDES;
+  static constexpr int32_t float_tag_ = ANDROID_COLOR_CORRECTION_GAINS;
+  static constexpr int32_t int_tag_ = ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION;
+  static constexpr int32_t int_tag2_ = ANDROID_JPEG_ORIENTATION;
+};
+
+TEST_F(PropertyTest, Tags) {
+  Property<int32_t> property(int_tag_, 1);
+
+  // Should have only the single tag it was constructed with.
+  EXPECT_EQ(property.ControlTags().size(), 0u);
+  EXPECT_EQ(property.DynamicTags().size(), 0u);
+  ASSERT_EQ(property.StaticTags().size(), 1u);
+  // The macro doesn't like the int_tag_ variable being passed in directly.
+  int32_t expected_tag = int_tag_;
+  EXPECT_EQ(property.StaticTags()[0], expected_tag);
+}
+
+TEST_F(PropertyTest, PopulateStaticSingleNumber) {
+  // Set up a fixed property.
+  int32_t data = 1234;
+  Property<int32_t> property(int_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, int_tag_, data);
+}
+
+// TODO(b/30839858): These tests are really testing the metadata_common.h
+// UpdateMetadata methods, and shouldn't be conducted here.
+TEST_F(PropertyTest, PopulateStaticVector) {
+  // Set up a fixed property.
+  std::vector<float> data({0.1, 2.3, 4.5, 6.7});
+  Property<std::vector<float>> property(float_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, float_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateStaticArray) {
+  // Set up a fixed property.
+  std::array<float, 4> data({{0.1, 2.3, 4.5, 6.7}});
+  Property<std::array<float, 4>> property(float_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, float_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateStaticArrayVector) {
+  // Set up a fixed property.
+  ArrayVector<uint8_t, 3> data;
+  data.push_back({{1, 2, 3}});
+  data.push_back({{4, 5, 6}});
+  Property<ArrayVector<uint8_t, 3>> property(byte_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, byte_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateDynamic) {
+  Property<int32_t> property(int_tag_, 1);
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.PopulateDynamicFields(&metadata), 0);
+
+  // Shouldn't have added anything.
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(PropertyTest, PopulateTemplate) {
+  Property<int32_t> property(int_tag_, 1);
+
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    android::CameraMetadata metadata;
+    EXPECT_EQ(property.PopulateTemplateRequest(i, &metadata), 0);
+    // Shouldn't have added anything.
+    EXPECT_TRUE(metadata.isEmpty());
+  }
+}
+
+TEST_F(PropertyTest, SupportsRequest) {
+  Property<int32_t> property(int_tag_, 1);
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.SupportsRequestValues(metadata), true);
+}
+
+TEST_F(PropertyTest, SetRequest) {
+  Property<int32_t> property(int_tag_, 1);
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/ranged_converter.h b/hardware/ntimespace/camera/metadata/ranged_converter.h
new file mode 100644
index 0000000000..abfe370533
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ranged_converter.h
@@ -0,0 +1,103 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
+
+#include <memory>
+
+#include <android-base/macros.h>
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An RangedConverter fits values converted by a wrapped converter
+// to a stepped range (when going from metadata -> v4l2. The other
+// direction remains unchanged).
+template <typename TMetadata, typename TV4L2>
+class RangedConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  RangedConverter(
+      std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter,
+      TV4L2 min,
+      TV4L2 max,
+      TV4L2 step);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter_;
+  const TV4L2 min_;
+  const TV4L2 max_;
+  const TV4L2 step_;
+
+  DISALLOW_COPY_AND_ASSIGN(RangedConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2>
+RangedConverter<TMetadata, TV4L2>::RangedConverter(
+    std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter,
+    TV4L2 min,
+    TV4L2 max,
+    TV4L2 step)
+    : wrapped_converter_(std::move(wrapped_converter)),
+      min_(min),
+      max_(max),
+      step_(step) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2>
+int RangedConverter<TMetadata, TV4L2>::MetadataToV4L2(TMetadata value,
+                                                      TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  TV4L2 raw_conversion = 0;
+  int res = wrapped_converter_->MetadataToV4L2(value, &raw_conversion);
+  if (res) {
+    HAL_LOGE("Failed to perform underlying conversion.");
+    return res;
+  }
+
+  // Round down to step (steps start at min_).
+  raw_conversion -= (raw_conversion - min_) % step_;
+
+  // Clamp to range.
+  if (raw_conversion < min_) {
+    raw_conversion = min_;
+  } else if (raw_conversion > max_) {
+    raw_conversion = max_;
+  }
+
+  *conversion = raw_conversion;
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2>
+int RangedConverter<TMetadata, TV4L2>::V4L2ToMetadata(TV4L2 value,
+                                                      TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  return wrapped_converter_->V4L2ToMetadata(value, conversion);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp b/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
new file mode 100644
index 0000000000..2b5ccc63ea
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
@@ -0,0 +1,86 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "ranged_converter.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class RangedConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(new ConverterInterfaceMock<int, int32_t>());
+    dut_.reset(
+        new RangedConverter<int, int32_t>(converter_, min_, max_, step_));
+  }
+
+  virtual void ExpectConvert(int32_t converted, int32_t expected) {
+    int initial = 99;
+    EXPECT_CALL(*converter_, MetadataToV4L2(initial, _))
+        .WillOnce(DoAll(SetArgPointee<1>(converted), Return(0)));
+
+    int32_t actual = expected + 1;  // Initialize to non-expected value.
+    ASSERT_EQ(dut_->MetadataToV4L2(initial, &actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+
+  std::shared_ptr<ConverterInterfaceMock<int, int32_t>> converter_;
+  std::unique_ptr<RangedConverter<int, int32_t>> dut_;
+
+  const int32_t min_ = -11;
+  const int32_t max_ = 10;
+  const int32_t step_ = 3;
+};
+
+TEST_F(RangedConverterTest, NormalConversion) {
+  // A value that's in range and on step.
+  ExpectConvert(max_ - step_, max_ - step_);
+}
+
+TEST_F(RangedConverterTest, RoundingConversion) {
+  // A value that's in range but off step.
+  ExpectConvert(max_ - step_ + 1, max_ - step_);
+}
+
+TEST_F(RangedConverterTest, ClampUpConversion) {
+  // A value that's below range.
+  ExpectConvert(min_ - 1, min_);
+}
+
+TEST_F(RangedConverterTest, ClampDownConversion) {
+  // A value that's above range (even after fitting to step).
+  ExpectConvert(max_ + step_, max_);
+}
+
+TEST_F(RangedConverterTest, ConversionError) {
+  int initial = 99;
+  int err = -99;
+  EXPECT_CALL(*converter_, MetadataToV4L2(initial, _)).WillOnce(Return(err));
+
+  int32_t unused;
+  EXPECT_EQ(dut_->MetadataToV4L2(initial, &unused), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/scaling_converter.h b/hardware/ntimespace/camera/metadata/scaling_converter.h
new file mode 100644
index 0000000000..bddf1f40d5
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/scaling_converter.h
@@ -0,0 +1,75 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
+
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An ScalingConverter scales values up or down.
+template <typename TMetadata, typename TV4L2>
+class ScalingConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  ScalingConverter(TMetadata v4l2_to_metadata_numerator,
+                   TMetadata v4l2_to_metadata_denominator);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  const TMetadata v4l2_to_metadata_numerator_;
+  const TMetadata v4l2_to_metadata_denominator_;
+
+  DISALLOW_COPY_AND_ASSIGN(ScalingConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2>
+ScalingConverter<TMetadata, TV4L2>::ScalingConverter(
+    TMetadata v4l2_to_metadata_numerator,
+    TMetadata v4l2_to_metadata_denominator)
+    : v4l2_to_metadata_numerator_(v4l2_to_metadata_numerator),
+      v4l2_to_metadata_denominator_(v4l2_to_metadata_denominator) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2>
+int ScalingConverter<TMetadata, TV4L2>::MetadataToV4L2(TMetadata value,
+                                                       TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  *conversion = static_cast<TV4L2>(value * v4l2_to_metadata_denominator_ /
+                                   v4l2_to_metadata_numerator_);
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2>
+int ScalingConverter<TMetadata, TV4L2>::V4L2ToMetadata(TV4L2 value,
+                                                       TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  *conversion = static_cast<TMetadata>(value) * v4l2_to_metadata_numerator_ /
+                v4l2_to_metadata_denominator_;
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/slider_control_options.h b/hardware/ntimespace/camera/metadata/slider_control_options.h
new file mode 100644
index 0000000000..b23ba34c02
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/slider_control_options.h
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
+
+#include <cerrno>
+#include <vector>
+
+#include "common.h"
+#include "control_options_interface.h"
+#include "default_option_delegate.h"
+
+namespace v4l2_camera_hal {
+
+// SliderControlOptions offer a range of acceptable values, inclusive.
+template <typename T>
+class SliderControlOptions : public ControlOptionsInterface<T> {
+ public:
+  // |min| must be <= |max|.
+  SliderControlOptions(const T& min,
+                       const T& max,
+                       std::shared_ptr<DefaultOptionDelegate<T>> defaults)
+      : min_(min), max_(max), defaults_(defaults){};
+  SliderControlOptions(const T& min, const T& max, std::map<int, T> defaults)
+      : min_(min),
+        max_(max),
+        defaults_(std::make_shared<DefaultOptionDelegate<T>>(defaults)){};
+
+  virtual std::vector<T> MetadataRepresentation() override {
+    return {min_, max_};
+  };
+  virtual bool IsSupported(const T& option) override {    
+    HAL_LOG_ENTER();
+    return option >= min_ && option <= max_;
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    if (min_ > max_) {
+      HAL_LOGE("No valid default slider option, min is greater than max.");
+      return -ENODEV;
+    }
+
+    if (defaults_->DefaultValueForTemplate(template_type, default_value)) {
+      // Get as close as we can to the desired value.
+      if (*default_value < min_) {
+        *default_value = min_;
+      } else if (*default_value > max_) {
+        *default_value = max_;
+      }
+      return 0;
+    }
+
+    // No default given, just fall back to the min of the range.
+    *default_value = min_;
+    return 0;
+  };
+
+ private:
+  T min_;
+  T max_;
+  std::shared_ptr<DefaultOptionDelegate<T>> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
diff --git a/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp b/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
new file mode 100644
index 0000000000..7f3a64364c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
@@ -0,0 +1,128 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "slider_control_options.h"
+
+#include <memory>
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "default_option_delegate_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class SliderControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_defaults_.reset(new DefaultOptionDelegateMock<int>());
+    dut_.reset(new SliderControlOptions<int>(min_, max_, mock_defaults_));
+  }
+
+  std::unique_ptr<SliderControlOptions<int>> dut_;
+  std::shared_ptr<DefaultOptionDelegateMock<int>> mock_defaults_;
+  const int min_ = 1;
+  const int max_ = 10;
+};
+
+TEST_F(SliderControlOptionsTest, MetadataRepresentation) {
+  // Technically order doesn't matter, but this is faster to write,
+  // and still passes.
+  std::vector<int> expected{min_, max_};
+  EXPECT_EQ(dut_->MetadataRepresentation(), expected);
+}
+
+TEST_F(SliderControlOptionsTest, IsSupported) {
+  for (int i = min_; i <= max_; ++i) {
+    EXPECT_TRUE(dut_->IsSupported(i));
+  }
+  // Out of range unsupported.
+  EXPECT_FALSE(dut_->IsSupported(min_ - 1));
+  EXPECT_FALSE(dut_->IsSupported(max_ + 1));
+}
+
+TEST_F(SliderControlOptionsTest, DelegateDefaultValue) {
+  int template_index = 3;
+  int expected = max_ - 1;
+  ASSERT_TRUE(dut_->IsSupported(expected));
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(true)));
+  int actual = expected - 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, LowDelegateDefaultValue) {
+  int template_index = 3;
+  // min - 1 is below the valid range.
+  int default_val = min_ - 1;
+  // Should get bumped up into range.
+  int expected = min_;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+  ASSERT_TRUE(dut_->IsSupported(expected));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, HighDelegateDefaultValue) {
+  int template_index = 3;
+  // max + 1 is above the valid range.
+  int default_val = max_ + 1;
+  // Should get bumped down into range.
+  int expected = max_;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+  ASSERT_TRUE(dut_->IsSupported(expected));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, NoDelegateDefaultValue) {
+  int template_index = 3;
+  int actual = min_ - 1;
+  ASSERT_FALSE(dut_->IsSupported(actual));
+
+  // Have delegate error.
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(Return(false));
+
+  // Should still give *some* supported value.
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(SliderControlOptionsTest, NoDefaultValue) {
+  // Invalid options don't have a valid default.
+  SliderControlOptions<int> bad_options(10, 9, mock_defaults_);  // min > max.
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    int value = -1;
+    EXPECT_EQ(bad_options.DefaultValueForTemplate(i, &value), -ENODEV);
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/state.h b/hardware/ntimespace/camera/metadata/state.h
new file mode 100644
index 0000000000..3fd844761f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state.h
@@ -0,0 +1,96 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_H_
+
+#include "common.h"
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A State is a PartialMetadata that only has a single dynamic value.
+template <typename T>
+class State : public PartialMetadataInterface {
+ public:
+  State(int32_t tag, std::unique_ptr<StateDelegateInterface<T>> delegate)
+      : tag_(tag), delegate_(std::move(delegate)){};
+
+  virtual std::vector<int32_t> StaticTags() const override { return {}; };
+  virtual std::vector<int32_t> ControlTags() const override { return {}; };
+  virtual std::vector<int32_t> DynamicTags() const override { return {tag_}; };
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const override;
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const override;
+  virtual int SetRequestValues(
+      const android::CameraMetadata& metadata) override;
+
+ private:
+  int32_t tag_;
+  std::unique_ptr<StateDelegateInterface<T>> delegate_;
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+int State<T>::PopulateStaticFields(android::CameraMetadata* /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return 0;
+}
+
+template <typename T>
+int State<T>::PopulateDynamicFields(android::CameraMetadata* metadata) const {
+  HAL_LOG_ENTER();
+
+  T value;
+  int res = delegate_->GetValue(&value);
+  if (res) {
+    return res;
+  }
+  return UpdateMetadata(metadata, tag_, value);
+};
+
+template <typename T>
+int State<T>::PopulateTemplateRequest(int /*template_type*/,
+                                      android::CameraMetadata* /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return 0;
+};
+
+template <typename T>
+bool State<T>::SupportsRequestValues(
+    const android::CameraMetadata& /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return true;
+};
+
+template <typename T>
+int State<T>::SetRequestValues(const android::CameraMetadata& /*metadata*/) {
+  HAL_LOG_ENTER();
+  return 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_STATE_H_
diff --git a/hardware/ntimespace/camera/metadata/state_delegate_interface.h b/hardware/ntimespace/camera/metadata/state_delegate_interface.h
new file mode 100644
index 0000000000..c18ee3ce47
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_delegate_interface.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
+
+namespace v4l2_camera_hal {
+
+// A StateDelegate is simply a dynamic value that can be queried.
+// The value may change between queries.
+template <typename T>
+class StateDelegateInterface {
+ public:
+  virtual ~StateDelegateInterface(){};
+  // Returns 0 on success, error code on failure.
+  virtual int GetValue(T* value) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h b/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
new file mode 100644
index 0000000000..e9698f1601
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for state delegate interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_MOCK_H_
+
+#include "state_delegate_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class StateDelegateInterfaceMock : public StateDelegateInterface<T> {
+ public:
+  StateDelegateInterfaceMock(){};
+  MOCK_METHOD1_T(GetValue, int(T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/state_test.cpp b/hardware/ntimespace/camera/metadata/state_test.cpp
new file mode 100644
index 0000000000..7360bc9bb8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_test.cpp
@@ -0,0 +1,117 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "state.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "metadata_common.h"
+#include "state_delegate_interface_mock.h"
+#include "test_common.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class StateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new StateDelegateInterfaceMock<uint8_t>());
+    // Nullify state so an error will be thrown if a test doesn't call
+    // PrepareState.
+    state_.reset();
+  }
+
+  virtual void PrepareState() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the mocks
+    // to the device.
+    state_.reset(new State<uint8_t>(tag_, std::move(mock_delegate_)));
+  }
+
+  std::unique_ptr<State<uint8_t>> state_;
+  std::unique_ptr<StateDelegateInterfaceMock<uint8_t>> mock_delegate_;
+
+  // Need tag that matches the data type (uint8_t) being passed.
+  const int32_t tag_ = ANDROID_CONTROL_AF_STATE;
+};
+
+TEST_F(StateTest, Tags) {
+  PrepareState();
+  EXPECT_TRUE(state_->StaticTags().empty());
+  EXPECT_TRUE(state_->ControlTags().empty());
+  ASSERT_EQ(state_->DynamicTags().size(), 1u);
+  EXPECT_EQ(state_->DynamicTags()[0], tag_);
+}
+
+TEST_F(StateTest, PopulateStatic) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateStaticFields(&metadata), 0);
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(StateTest, PopulateDynamic) {
+  uint8_t expected = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(expected), Return(0)));
+
+  PrepareState();
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateDynamicFields(&metadata), 0);
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  ExpectMetadataEq(metadata, tag_, expected);
+}
+
+TEST_F(StateTest, PopulateDynamicFail) {
+  int err = 123;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+
+  PrepareState();
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateDynamicFields(&metadata), err);
+}
+
+TEST_F(StateTest, PopulateTemplate) {
+  int template_type = 3;
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateTemplateRequest(template_type, &metadata), 0);
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(StateTest, SupportsRequest) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  EXPECT_TRUE(state_->SupportsRequestValues(metadata));
+}
+
+TEST_F(StateTest, SetRequest) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_delegate.h b/hardware/ntimespace/camera/metadata/tagged_control_delegate.h
new file mode 100644
index 0000000000..40677f938c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_delegate.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_DELEGATE_H_
+
+#include <memory>
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A TaggedControlDelegate wraps a ControlDelegate and adds a tag.
+template <typename T>
+class TaggedControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  TaggedControlDelegate(int32_t tag,
+                        std::unique_ptr<ControlDelegateInterface<T>> delegate)
+      : tag_(tag), delegate_(std::move(delegate)){};
+
+  int32_t tag() { return tag_; };
+
+  virtual int GetValue(T* value) override {
+    return delegate_->GetValue(value);
+  };
+  virtual int SetValue(const T& value) override {
+    return delegate_->SetValue(value);
+  };
+
+ private:
+  const int32_t tag_;
+  std::unique_ptr<ControlDelegateInterface<T>> delegate_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
new file mode 100644
index 0000000000..ba29ab7b44
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
@@ -0,0 +1,90 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "tagged_control_delegate.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_delegate_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class TaggedControlDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new ControlDelegateInterfaceMock<uint8_t>());
+    // Nullify dut so an error will be thrown if a test doesn't call PrepareDUT.
+    dut_.reset();
+  }
+
+  virtual void PrepareDUT() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the
+    // delegate
+    // to the device.
+    dut_.reset(
+        new TaggedControlDelegate<uint8_t>(tag_, std::move(mock_delegate_)));
+  }
+
+  std::unique_ptr<TaggedControlDelegate<uint8_t>> dut_;
+  std::unique_ptr<ControlDelegateInterfaceMock<uint8_t>> mock_delegate_;
+  const int32_t tag_ = 123;
+};
+
+TEST_F(TaggedControlDelegateTest, GetTag) {
+  PrepareDUT();
+  EXPECT_EQ(dut_->tag(), tag_);
+}
+
+TEST_F(TaggedControlDelegateTest, GetSuccess) {
+  uint8_t expected = 3;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(expected), Return(0)));
+  PrepareDUT();
+  uint8_t actual = expected + 1;  // Initialize to an incorrect value.
+  ASSERT_EQ(dut_->GetValue(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(TaggedControlDelegateTest, GetFailure) {
+  int err = 3;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareDUT();
+  uint8_t unused = 0;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(TaggedControlDelegateTest, SetSuccess) {
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_delegate_, SetValue(value)).WillOnce(Return(0));
+  PrepareDUT();
+  ASSERT_EQ(dut_->SetValue(value), 0);
+}
+
+TEST_F(TaggedControlDelegateTest, SetFailure) {
+  int err = 3;
+  uint8_t value = 12;
+  EXPECT_CALL(*mock_delegate_, SetValue(value)).WillOnce(Return(err));
+  PrepareDUT();
+  ASSERT_EQ(dut_->SetValue(value), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_options.h b/hardware/ntimespace/camera/metadata/tagged_control_options.h
new file mode 100644
index 0000000000..3d900ae9e1
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_options.h
@@ -0,0 +1,61 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_OPTIONS_H_
+
+#include <memory>
+
+#include "control_options_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A constant tag with a value not used as a real tag
+// (since all real tags are unsigned),  to indicate options
+// that should not be reported.
+// Any class working with TaggedControlOptions should check
+// the tag against this value before using it.
+static int32_t DO_NOT_REPORT_OPTIONS = -1;
+
+// A TaggedControlOptions wraps a ControlOptions and adds a tag.
+template <typename T>
+class TaggedControlOptions : public ControlOptionsInterface<T> {
+ public:
+  TaggedControlOptions(int32_t tag,
+                       std::unique_ptr<ControlOptionsInterface<T>> options)
+      : tag_(tag), options_(std::move(options)){};
+
+  int32_t tag() { return tag_; };
+
+  virtual std::vector<T> MetadataRepresentation() override {
+    return options_->MetadataRepresentation();
+  };
+  virtual bool IsSupported(const T& value) override {
+    return options_->IsSupported(value);
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    return options_->DefaultValueForTemplate(template_type, default_value);
+  }
+
+ private:
+  const int32_t tag_;
+  std::unique_ptr<ControlOptionsInterface<T>> options_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp b/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
new file mode 100644
index 0000000000..845426a914
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
@@ -0,0 +1,102 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "tagged_control_options.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_options_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class TaggedControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_options_.reset(new ControlOptionsInterfaceMock<uint8_t>());
+    // Nullify dut so an error will be thrown if a test doesn't call PrepareDUT.
+    dut_.reset();
+  }
+
+  virtual void PrepareDUT() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the
+    // options
+    // to the device.
+    dut_.reset(
+        new TaggedControlOptions<uint8_t>(tag_, std::move(mock_options_)));
+  }
+
+  std::unique_ptr<TaggedControlOptions<uint8_t>> dut_;
+  std::unique_ptr<ControlOptionsInterfaceMock<uint8_t>> mock_options_;
+  const int32_t tag_ = 123;
+};
+
+TEST_F(TaggedControlOptionsTest, GetTag) {
+  PrepareDUT();
+  EXPECT_EQ(dut_->tag(), tag_);
+}
+
+TEST_F(TaggedControlOptionsTest, MetadataRepresentation) {
+  std::vector<uint8_t> expected{3, 4, 5};
+  EXPECT_CALL(*mock_options_, MetadataRepresentation())
+      .WillOnce(Return(expected));
+  PrepareDUT();
+  ASSERT_EQ(dut_->MetadataRepresentation(), expected);
+}
+
+TEST_F(TaggedControlOptionsTest, IsSupportedTrue) {
+  bool supported = true;
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_options_, IsSupported(value)).WillOnce(Return(supported));
+  PrepareDUT();
+  ASSERT_EQ(dut_->IsSupported(value), supported);
+}
+
+TEST_F(TaggedControlOptionsTest, IsSupportedFalse) {
+  bool supported = false;
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_options_, IsSupported(value)).WillOnce(Return(supported));
+  PrepareDUT();
+  ASSERT_EQ(dut_->IsSupported(value), supported);
+}
+
+TEST_F(TaggedControlOptionsTest, DefaultValue) {
+  uint8_t value = 99;
+  int template_id = 3;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(value), Return(0)));
+  PrepareDUT();
+  uint8_t actual = value + 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_id, &actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST_F(TaggedControlOptionsTest, DefaultValueFail) {
+  int err = 12;
+  int template_id = 3;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_id, _))
+      .WillOnce(Return(err));
+  PrepareDUT();
+  uint8_t unused;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_id, &unused), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/test_common.h b/hardware/ntimespace/camera/metadata/test_common.h
new file mode 100644
index 0000000000..35a7681390
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/test_common.h
@@ -0,0 +1,96 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
+#define V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
+
+#include <array>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include "array_vector.h"
+#include "metadata_common.h"
+
+namespace v4l2_camera_hal {
+
+// Check that metadata of a given tag matches expectations.
+// Generic.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const T* expected,
+                             size_t size) {
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  ASSERT_EQ(entry.count, size);
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  ASSERT_NE(data, nullptr);
+  for (size_t i = 0; i < size; ++i) {
+    EXPECT_EQ(data[i], expected[i]);
+  }
+}
+
+// Single item.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             T expected) {
+  ExpectMetadataEq(metadata, tag, &expected, 1);
+}
+
+// Vector of items.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::vector<T>& expected) {
+  ExpectMetadataEq(metadata, tag, expected.data(), expected.size());
+}
+
+// Array of items.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::array<T, N>& expected) {
+  ExpectMetadataEq(metadata, tag, expected.data(), N);
+}
+
+// ArrayVector.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const ArrayVector<T, N>& expected) {
+  ExpectMetadataEq(
+      metadata, tag, expected.data(), expected.total_num_elements());
+}
+
+// Vector of arrays.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::vector<std::array<T, N>>& expected) {
+  // Convert to array vector so we know all the elements are contiguous.
+  ArrayVector<T, N> array_vector;
+  for (const auto& array : expected) {
+    array_vector.push_back(array);
+  }
+  ExpectMetadataEq(metadata, tag, array_vector);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
diff --git a/hardware/ntimespace/camera/metadata/types.h b/hardware/ntimespace/camera/metadata/types.h
new file mode 100644
index 0000000000..093fe011dd
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/types.h
@@ -0,0 +1,82 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
+#define DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
+
+#include <array>
+#include <map>
+#include <set>
+
+#include <hardware/camera3.h>
+
+namespace default_camera_hal {
+
+// A variety of Structs describing more complex metadata entries.
+
+// StreamSpec describe the attributes of a single stream.
+struct StreamSpec {
+  int32_t format;
+  int32_t width;
+  int32_t height;
+
+  StreamSpec(int32_t f, int32_t w, int32_t h)
+      : format(f), width(w), height(h) {}
+  StreamSpec(const camera3_stream_t* stream)
+      : format(stream->format), width(stream->width), height(stream->height) {}
+
+  struct Compare {
+    bool operator()(const StreamSpec& left, const StreamSpec& right) const {
+      // Base equality/comparison first on format, then on width, then height.
+      return left.format < right.format ||
+             (left.format == right.format &&
+              (left.width < right.width ||
+               (left.width == right.width && left.height < right.height)));
+    }
+  };
+};
+
+// StreamConfigurations indicate a possible direction configuration for
+// a given set of stream specifications.
+typedef std::array<int32_t, 4> RawStreamConfiguration;
+struct StreamConfiguration {
+  StreamSpec spec;
+  int32_t direction;
+
+  StreamConfiguration(const RawStreamConfiguration& raw)
+      : spec({raw[0], raw[1], raw[2]}), direction(raw[3]) {}
+};
+
+// StreamStallDurations indicate the stall duration (in ns) for
+// when a stream with a given set of specifications is used as output.
+typedef std::array<int64_t, 4> RawStreamStallDuration;
+struct StreamStallDuration {
+  StreamSpec spec;
+  int64_t duration;
+
+  StreamStallDuration(const RawStreamStallDuration& raw)
+      : spec({static_cast<int32_t>(raw[0]),
+              static_cast<int32_t>(raw[1]),
+              static_cast<int32_t>(raw[2])}),
+        duration(raw[3]) {}
+};
+
+// Map input formats to their supported reprocess output formats.
+typedef std::map<int32_t, std::set<int32_t>> ReprocessFormatMap;
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
diff --git a/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h b/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
new file mode 100644
index 0000000000..b52c252e24
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
@@ -0,0 +1,66 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+#include "converter_interface.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A V4L2ControlDelegate routes getting and setting through V4L2
+template <typename TMetadata, typename TV4L2 = int32_t>
+class V4L2ControlDelegate : public ControlDelegateInterface<TMetadata> {
+ public:
+  V4L2ControlDelegate(
+      std::shared_ptr<V4L2Wrapper> device,
+      int control_id,
+      std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> converter)
+      : device_(std::move(device)),
+        control_id_(control_id),
+        converter_(std::move(converter)){};
+
+  int GetValue(TMetadata* value) override {
+    TV4L2 v4l2_value;
+    int res = device_->GetControl(control_id_, &v4l2_value);
+    if (res) {
+      HAL_LOGE("Failed to get device value for control %d.", control_id_);
+      return res;
+    }
+    return converter_->V4L2ToMetadata(v4l2_value, value);
+  };
+
+  int SetValue(const TMetadata& value) override {
+    TV4L2 v4l2_value;
+    int res = converter_->MetadataToV4L2(value, &v4l2_value);
+    if (res) {
+      HAL_LOGE("Failed to convert metadata value to V4L2.");
+      return res;
+    }
+    return device_->SetControl(control_id_, v4l2_value);
+  };
+
+ private:
+  std::shared_ptr<V4L2Wrapper> device_;
+  int control_id_;
+  std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> converter_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
new file mode 100644
index 0000000000..63ad0f60f4
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
@@ -0,0 +1,109 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "v4l2_control_delegate.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "converter_interface_mock.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class V4L2ControlDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_device_.reset(new V4L2WrapperMock());
+    mock_converter_.reset(new ConverterInterfaceMock<uint8_t, int32_t>());
+    dut_.reset(new V4L2ControlDelegate<uint8_t>(
+        mock_device_, control_id_, mock_converter_));
+  }
+
+  std::unique_ptr<V4L2ControlDelegate<uint8_t>> dut_;
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+  std::shared_ptr<ConverterInterfaceMock<uint8_t, int32_t>> mock_converter_;
+  const int control_id_ = 123;
+};
+
+TEST_F(V4L2ControlDelegateTest, GetSuccess) {
+  int32_t device_result = 99;
+  uint8_t conversion_result = 10;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _))
+      .WillOnce(DoAll(SetArgPointee<1>(device_result), Return(0)));
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(device_result, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+
+  uint8_t actual = conversion_result + 1;  // Something incorrect.
+  ASSERT_EQ(dut_->GetValue(&actual), 0);
+  EXPECT_EQ(actual, conversion_result);
+}
+
+TEST_F(V4L2ControlDelegateTest, GetConverterFailure) {
+  int32_t device_result = 99;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _))
+      .WillOnce(DoAll(SetArgPointee<1>(device_result), Return(0)));
+  int err = -99;
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(device_result, _))
+      .WillOnce(Return(err));
+
+  uint8_t unused = 1;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, GetDeviceFailure) {
+  int err = -99;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _)).WillOnce(Return(err));
+
+  uint8_t unused = 1;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetSuccess) {
+  uint8_t input = 10;
+  int32_t conversion_result = 99;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+  EXPECT_CALL(*mock_device_, SetControl(control_id_, conversion_result, _))
+      .WillOnce(Return(0));
+
+  ASSERT_EQ(dut_->SetValue(input), 0);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetConverterFailure) {
+  uint8_t input = 10;
+  int err = 12;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _)).WillOnce(Return(err));
+  ASSERT_EQ(dut_->SetValue(input), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetDeviceFailure) {
+  uint8_t input = 10;
+  int32_t conversion_result = 99;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+  int err = 66;
+  EXPECT_CALL(*mock_device_, SetControl(control_id_, conversion_result, _))
+      .WillOnce(Return(err));
+
+  ASSERT_EQ(dut_->SetValue(input), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/request_tracker.cpp b/hardware/ntimespace/camera/request_tracker.cpp
new file mode 100644
index 0000000000..3cd5208d08
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker.cpp
@@ -0,0 +1,159 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "RequestTracker"
+
+#include "request_tracker.h"
+
+#include <log/log.h>
+
+namespace default_camera_hal {
+
+RequestTracker::RequestTracker() {}
+
+RequestTracker::~RequestTracker() {}
+
+void RequestTracker::SetStreamConfiguration(
+    const camera3_stream_configuration_t& config) {
+  // Clear the old configuration.
+  ClearStreamConfiguration();
+  // Add an entry to the buffer tracking map for each configured stream.
+  for (size_t i = 0; i < config.num_streams; ++i) {
+    buffers_in_flight_.emplace(config.streams[i], 0);
+  }
+}
+
+void RequestTracker::ClearStreamConfiguration() {
+  // The keys of the in flight buffer map are the configured streams.
+  buffers_in_flight_.clear();
+}
+
+// Helper: get the streams used by a request.
+std::set<camera3_stream_t*> RequestStreams(const CaptureRequest& request) {
+  std::set<camera3_stream_t*> result;
+  if (request.input_buffer) {
+    result.insert(request.input_buffer->stream);
+  }
+  for (const auto& output_buffer : request.output_buffers) {
+    result.insert(output_buffer.stream);
+  }
+  return result;
+}
+
+bool RequestTracker::Add(std::shared_ptr<CaptureRequest> request) {
+  if (!CanAddRequest(*request)) {
+    return false;
+  }
+
+  // Add to the count for each stream used.
+  for (const auto stream : RequestStreams(*request)) {
+    ++buffers_in_flight_[stream];
+  }
+
+  // Store the request.
+  frames_in_flight_[request->frame_number] = request;
+
+  return true;
+}
+
+bool RequestTracker::Remove(std::shared_ptr<CaptureRequest> request) {
+  if (!request) {
+    return false;
+  }
+
+  // Get the request.
+  const auto frame_number_request =
+      frames_in_flight_.find(request->frame_number);
+  if (frame_number_request == frames_in_flight_.end()) {
+    HAL_LOGE("%s: Frame %u is not in flight.", __func__, request->frame_number);
+    return false;
+  } else if (request != frame_number_request->second) {
+    HAL_LOGE(
+        "%s: Request for frame %u cannot be removed: "
+        "does not matched the stored request.",
+        __func__,
+        request->frame_number);
+    return false;
+  }
+
+  frames_in_flight_.erase(frame_number_request);
+
+  // Decrement the counts of used streams.
+  for (const auto stream : RequestStreams(*request)) {
+    --buffers_in_flight_[stream];
+  }
+
+  return true;
+}
+
+void RequestTracker::Clear(
+    std::set<std::shared_ptr<CaptureRequest>>* requests) {
+  // If desired, extract all the currently in-flight requests.
+  if (requests) {
+    for (auto& frame_number_request : frames_in_flight_) {
+      requests->insert(frame_number_request.second);
+    }
+  }
+
+  // Clear out all tracking.
+  frames_in_flight_.clear();
+  // Maintain the configuration, but reset counts.
+  for (auto& stream_count : buffers_in_flight_) {
+    stream_count.second = 0;
+  }
+}
+
+bool RequestTracker::CanAddRequest(const CaptureRequest& request) const {
+  // Check that it's not a duplicate.
+  if (frames_in_flight_.count(request.frame_number) > 0) {
+    HAL_LOGE("%s: Already tracking a request with frame number %d.",
+          __func__,
+          request.frame_number);
+    return false;
+  }
+
+  // Check that each stream has space
+  // (which implicitly checks if it is configured).
+  for (const auto stream : RequestStreams(request)) {
+    if (StreamFull(stream)) {
+      HAL_LOGE("%s: Stream %p is full.", __func__, stream);
+      return false;
+    }
+  }
+  return true;
+}
+
+bool RequestTracker::StreamFull(const camera3_stream_t* handle) const {
+  const auto it = buffers_in_flight_.find(handle);
+  if (it == buffers_in_flight_.end()) {
+    // Unconfigured streams are implicitly full.
+    HAL_LOGE("%s: Stream %p is not a configured stream.", __func__, handle);
+    return true;
+  } else {
+    return it->second >= it->first->max_buffers;
+  }
+}
+
+bool RequestTracker::InFlight(uint32_t frame_number) const {
+  return frames_in_flight_.count(frame_number) > 0;
+}
+
+bool RequestTracker::Empty() const {
+  return frames_in_flight_.empty();
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/request_tracker.h b/hardware/ntimespace/camera/request_tracker.h
new file mode 100644
index 0000000000..19004b719d
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker.h
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
+#define DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
+
+#include <map>
+#include <memory>
+#include <set>
+
+#include <android-base/macros.h>
+#include <hardware/camera3.h>
+#include "capture_request.h"
+#include "common.h"
+
+
+
+namespace default_camera_hal {
+
+// Keep track of what requests and streams are in flight.
+class RequestTracker {
+ public:
+  RequestTracker();
+  virtual ~RequestTracker();
+
+  // Configuration methods. Both have undefined effects on in-flight requests,
+  // and should only be called when empty.
+  // Add configured streams. Replaces the previous configuration if any.
+  virtual void SetStreamConfiguration(
+      const camera3_stream_configuration_t& config);
+  // Reset to no configured streams.
+  virtual void ClearStreamConfiguration();
+
+  // Tracking methods.
+  // Track a request.
+  // False if a request of the same frame number is already being tracked
+  virtual bool Add(std::shared_ptr<CaptureRequest> request);
+  // Stop tracking a request.
+  // False if the given request is not being tracked.
+  virtual bool Remove(std::shared_ptr<CaptureRequest> request = nullptr);
+  // Empty out all requests being tracked.
+  virtual void Clear(
+      std::set<std::shared_ptr<CaptureRequest>>* requests = nullptr);
+
+  // Accessors to check availability.
+  // Check that a request isn't already in flight, and won't overflow any
+  // streams.
+  virtual bool CanAddRequest(const CaptureRequest& request) const;
+  // True if the given stream is already at max capacity.
+  virtual bool StreamFull(const camera3_stream_t* handle) const;
+  // True if a request is being tracked for the given frame number.
+  virtual bool InFlight(uint32_t frame_number) const;
+  // True if no requests being tracked.
+  virtual bool Empty() const;
+
+ private:
+  // Track for each stream, how many buffers are in flight.
+  std::map<const camera3_stream_t*, size_t> buffers_in_flight_;
+  // Track the frames in flight.
+  std::map<uint32_t, std::shared_ptr<CaptureRequest>> frames_in_flight_;
+
+  DISALLOW_COPY_AND_ASSIGN(RequestTracker);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
diff --git a/hardware/ntimespace/camera/request_tracker_test.cpp b/hardware/ntimespace/camera/request_tracker_test.cpp
new file mode 100644
index 0000000000..a7e377c072
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker_test.cpp
@@ -0,0 +1,259 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "request_tracker.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace default_camera_hal {
+
+class RequestTrackerTest : public Test {
+ protected:
+  void SetUp() {
+    stream1_.max_buffers = 3;
+    stream2_.max_buffers = 3;
+    dut_.reset(new RequestTracker());
+    streams_ = {&stream1_, &stream2_};
+    camera3_stream_configuration_t config{
+        static_cast<uint32_t>(streams_.size()),
+        streams_.data(),
+        0,
+        nullptr};
+    dut_->SetStreamConfiguration(config);
+  }
+
+  std::shared_ptr<CaptureRequest> GenerateCaptureRequest(
+      uint32_t frame, std::vector<camera3_stream_t*> streams) {
+    std::shared_ptr<CaptureRequest> request =
+        std::make_shared<CaptureRequest>();
+
+    // Set the frame number and buffers.
+    request->frame_number = frame;
+    for (const auto stream : streams) {
+      // All we really care about for the buffers is which stream they're for.
+      camera3_stream_buffer_t buffer{stream, nullptr, 0, -1, -1};
+      request->output_buffers.push_back(buffer);
+    }
+
+    return request;
+  }
+
+  void AddRequest(uint32_t frame,
+                  std::vector<camera3_stream_t*> streams,
+                  bool expected = true) {
+    std::shared_ptr<CaptureRequest> request =
+        GenerateCaptureRequest(frame, streams);
+    EXPECT_EQ(dut_->CanAddRequest(*request), expected);
+    if (expected) {
+      EXPECT_FALSE(dut_->InFlight(frame));
+    }
+    EXPECT_EQ(dut_->Add(request), expected);
+    if (expected) {
+      EXPECT_TRUE(dut_->InFlight(frame));
+    }
+  }
+
+  camera3_stream_t stream1_;
+  camera3_stream_t stream2_;
+  std::vector<camera3_stream_t*> streams_;
+  std::shared_ptr<RequestTracker> dut_;
+};
+
+TEST_F(RequestTrackerTest, AddValid) {
+  uint32_t frame = 34;
+  EXPECT_FALSE(dut_->InFlight(frame));
+  AddRequest(frame, {&stream1_});
+}
+
+TEST_F(RequestTrackerTest, AddInput) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  std::shared_ptr<CaptureRequest> expected = GenerateCaptureRequest(frame, {});
+  // Set the input buffer instead of any outputs.
+  expected->input_buffer.reset(
+      new camera3_stream_buffer_t{&stream1_, nullptr, 0, -1, -1});
+  stream1_.max_buffers = 1;
+
+  EXPECT_TRUE(dut_->Add(expected));
+  EXPECT_TRUE(dut_->InFlight(frame));
+  // Should have added to the count of buffers for stream 1.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+}
+
+TEST_F(RequestTrackerTest, AddMultipleStreams) {
+  stream1_.max_buffers = 1;
+  stream2_.max_buffers = 1;
+
+  EXPECT_FALSE(dut_->StreamFull(&stream1_));
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Add a request using both streams.
+  AddRequest(99, {&stream1_, &stream2_});
+
+  // Should both have been counted.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  EXPECT_TRUE(dut_->StreamFull(&stream2_));
+}
+
+TEST_F(RequestTrackerTest, AddUnconfigured) {
+  camera3_stream_t stream;
+  // Unconfigured should be considered full.
+  EXPECT_TRUE(dut_->StreamFull(&stream));
+  AddRequest(1, {&stream}, false);
+}
+
+TEST_F(RequestTrackerTest, AddPastCapacity) {
+  // Set the limit of stream 2 to 1.
+  stream2_.max_buffers = 1;
+
+  for (size_t i = 0; i < stream1_.max_buffers; ++i) {
+    EXPECT_FALSE(dut_->StreamFull(&stream1_));
+    EXPECT_FALSE(dut_->StreamFull(&stream2_));
+    AddRequest(i, {&stream1_});
+  }
+  // Filled up stream 1.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  // Stream 2 should still not be full since nothing was added.
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Limit has been hit, can't add more.
+  AddRequest(stream1_.max_buffers, {&stream1_, &stream2_}, false);
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  // Should not have added to the count of stream 2.
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+}
+
+TEST_F(RequestTrackerTest, AddDuplicate) {
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  // Can't add a duplicate.
+  AddRequest(frame, {&stream2_}, false);
+}
+
+TEST_F(RequestTrackerTest, RemoveValid) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  std::shared_ptr<CaptureRequest> request =
+      GenerateCaptureRequest(frame, {&stream1_});
+  EXPECT_TRUE(dut_->Add(request));
+  EXPECT_TRUE(dut_->InFlight(frame));
+  AddRequest(frame + 1, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Remove it.
+  EXPECT_TRUE(dut_->Remove(request));
+  // Should have removed only the desired request.
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveInvalidFrame) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Try to remove a different one.
+  uint32_t bad_frame = frame + 1;
+  std::shared_ptr<CaptureRequest> bad_request =
+      GenerateCaptureRequest(bad_frame, {&stream1_});
+  EXPECT_FALSE(dut_->InFlight(bad_frame));
+  EXPECT_FALSE(dut_->Remove(bad_request));
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveInvalidData) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Try to remove a different one.
+  // Even though this request looks the same, that fact that it is
+  // a pointer to a different object means it should fail.
+  std::shared_ptr<CaptureRequest> bad_request =
+      GenerateCaptureRequest(frame, {&stream1_});
+  EXPECT_TRUE(dut_->InFlight(frame));
+  EXPECT_FALSE(dut_->Remove(bad_request));
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveNull) {
+  EXPECT_FALSE(dut_->Remove(nullptr));
+}
+
+TEST_F(RequestTrackerTest, ClearRequests) {
+  // Create some requests.
+  uint32_t frame1 = 42;
+  uint32_t frame2 = frame1 + 1;
+  std::shared_ptr<CaptureRequest> request1 =
+      GenerateCaptureRequest(frame1, {&stream1_});
+  std::shared_ptr<CaptureRequest> request2 =
+      GenerateCaptureRequest(frame2, {&stream2_});
+  std::set<std::shared_ptr<CaptureRequest>> expected;
+  expected.insert(request1);
+  expected.insert(request2);
+
+  // Insert them.
+  EXPECT_TRUE(dut_->Add(request1));
+  EXPECT_TRUE(dut_->Add(request2));
+  EXPECT_TRUE(dut_->InFlight(frame1));
+  EXPECT_TRUE(dut_->InFlight(frame2));
+  EXPECT_FALSE(dut_->Empty());
+  std::set<std::shared_ptr<CaptureRequest>> actual;
+
+  // Clear them out.
+  dut_->Clear(&actual);
+  EXPECT_TRUE(dut_->Empty());
+  EXPECT_EQ(actual, expected);
+
+  // Configuration (max values) should not have been cleared.
+  EXPECT_TRUE(dut_->Add(request1));
+}
+
+TEST_F(RequestTrackerTest, ClearRequestsNoResult) {
+  // Add some requests.
+  EXPECT_TRUE(dut_->Empty());
+  AddRequest(1, {&stream1_});
+  AddRequest(2, {&stream2_});
+  EXPECT_FALSE(dut_->Empty());
+  // Don't bother getting the cleared requests.
+  dut_->Clear();
+  EXPECT_TRUE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, ClearConfiguration) {
+  EXPECT_FALSE(dut_->StreamFull(&stream1_));
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Clear the configuration.
+  dut_->ClearStreamConfiguration();
+
+  // Both streams should be considered full now, since neither is configured.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  EXPECT_TRUE(dut_->StreamFull(&stream2_));
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/static_properties.cpp b/hardware/ntimespace/camera/static_properties.cpp
new file mode 100644
index 0000000000..72038bcea2
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties.cpp
@@ -0,0 +1,503 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "StaticProperties"
+
+#include "static_properties.h"
+
+#include <log/log.h>
+#include <hardware/camera3.h>
+#include <system/camera.h>
+
+#include "metadata/metadata_reader.h"
+
+namespace default_camera_hal {
+
+// Build stream capabilities from configs + stall durations.
+static bool ConstructStreamCapabilities(
+    const std::vector<StreamConfiguration>& configs,
+    const std::vector<StreamStallDuration>& stalls,
+    StaticProperties::CapabilitiesMap* capabilities) {
+  HAL_LOG_ENTER();
+  // Extract directional capabilities from the configs.
+  for (const auto& config : configs) {
+    switch (config.direction) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT:
+        (*capabilities)[config.spec].output_supported = true;
+        break;
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT:
+        (*capabilities)[config.spec].input_supported = true;
+        break;
+      default:
+        // Should never happen when using the MetadataReader;
+        // it should validate directions.
+        HAL_LOGE("%s: Unrecognized stream config direction %d.",
+              __func__,
+              config.direction);
+        return false;
+    }
+  }
+
+  // Extract stall durations from the stalls.
+  for (const auto& stall : stalls) {
+    (*capabilities)[stall.spec].stall_duration = stall.duration;
+  }
+
+  return true;
+}
+
+// Check that each output config has a valid corresponding stall duration
+// (extra durations not matching any output config are ignored).
+static bool ValidateStreamCapabilities(
+    StaticProperties::CapabilitiesMap capabilities) {
+  HAL_LOG_ENTER();
+  for (const auto& spec_capabilities : capabilities) {
+    // Only non-negative stall durations are valid. This should only happen
+    // due to output streams without an associated stall duration, as
+    // MetadataReader validates the metadata stall durations.
+    if (spec_capabilities.second.output_supported &&
+        spec_capabilities.second.stall_duration < 0) {
+      HAL_LOGE(
+          "%s: Static metadata does not have a stall duration for "
+          "each output configuration. ",
+          __func__);
+      return false;
+    }
+  }
+  return true;
+}
+
+// Validate that the input/output formats map matches up with
+// the capabilities listed for all formats.
+bool ValidateReprocessFormats(
+    const StaticProperties::CapabilitiesMap& capabilities,
+    const ReprocessFormatMap& reprocess_map) {
+  HAL_LOG_ENTER();
+  // Get input formats.
+  std::set<int32_t> all_input_formats;
+  std::set<int32_t> all_output_formats;
+  for (const auto& spec_capabilities : capabilities) {
+    if (spec_capabilities.second.input_supported) {
+      all_input_formats.insert(spec_capabilities.first.format);
+    }
+    if (spec_capabilities.second.output_supported) {
+      all_output_formats.insert(spec_capabilities.first.format);
+    }
+  }
+
+  // Must be at least one input format.
+  if (all_input_formats.size() < 1) {
+    HAL_LOGE("%s: No input formats, reprocessing can't be supported.", __func__);
+    return false;
+  }
+
+  // Check that the reprocess map input formats are exactly all available
+  // input formats (check size here, then checking for actual value
+  // matches will happen as part of the loop below).
+  if (all_input_formats.size() != reprocess_map.size()) {
+    HAL_LOGE(
+        "%s: Stream configuration input formats do not match "
+        "input/output format map input formats.",
+        __func__);
+    return false;
+  }
+
+  // Check that each input format has at least one matching output format.
+  for (const auto& input_format : all_input_formats) {
+    const auto input_outputs_iterator = reprocess_map.find(input_format);
+    if (input_outputs_iterator == reprocess_map.end()) {
+      HAL_LOGE(
+          "%s: No output formats for input format %d.", __func__, input_format);
+      return false;
+    }
+    // No need to check that the output formats vector is non-empty;
+    // MetadataReader validates this. Instead just check that
+    // all outputs are actually output formats.
+    for (const auto& output_format : input_outputs_iterator->second) {
+      if (all_output_formats.count(output_format) < 1) {
+        HAL_LOGE(
+            "%s: Output format %d for input format %d "
+            "is not a supported output format.",
+            __func__,
+            input_format,
+            output_format);
+        return false;
+      }
+    }
+  }
+
+  return true;
+}
+
+StaticProperties* StaticProperties::NewStaticProperties(
+    std::unique_ptr<const MetadataReader> metadata_reader) {
+  HAL_LOG_ENTER();
+  int facing = 0;
+  int orientation = 0;
+  int32_t max_input_streams = 0;
+  int32_t max_raw_output_streams = 0;
+  int32_t max_non_stalling_output_streams = 0;
+  int32_t max_stalling_output_streams = 0;
+  std::set<uint8_t> request_capabilities;
+  std::vector<StreamConfiguration> configs;
+  std::vector<StreamStallDuration> stalls;
+  CapabilitiesMap stream_capabilities;
+  ReprocessFormatMap reprocess_map;
+
+  // If reading any data returns an error, something is wrong.
+  if (metadata_reader->Facing(&facing) ||
+      metadata_reader->Orientation(&orientation) ||
+      metadata_reader->MaxInputStreams(&max_input_streams) ||
+      metadata_reader->MaxOutputStreams(&max_raw_output_streams,
+                                        &max_non_stalling_output_streams,
+                                        &max_stalling_output_streams) ||
+      metadata_reader->RequestCapabilities(&request_capabilities) ||
+      metadata_reader->StreamConfigurations(&configs) ||
+      metadata_reader->StreamStallDurations(&stalls) ||
+      !ConstructStreamCapabilities(configs, stalls, &stream_capabilities) ||
+      // MetadataReader validates configs and stall seperately,
+      // but not that they match.
+      !ValidateStreamCapabilities(stream_capabilities) ||
+      // Reprocessing metadata only necessary if input streams are allowed.
+      (max_input_streams > 0 &&
+       (metadata_reader->ReprocessFormats(&reprocess_map) ||
+        // MetadataReader validates configs and the reprocess map seperately,
+        // but not that they match.
+        !ValidateReprocessFormats(stream_capabilities, reprocess_map)))) {
+    HAL_LOGE("%s: failed", __func__);
+    return nullptr;
+  }
+
+  return new StaticProperties(std::move(metadata_reader),
+                              facing,
+                              orientation,
+                              max_input_streams,
+                              max_raw_output_streams,
+                              max_non_stalling_output_streams,
+                              max_stalling_output_streams,
+                              std::move(request_capabilities),
+                              std::move(stream_capabilities),
+                              std::move(reprocess_map));
+}
+
+StaticProperties::StaticProperties(
+    std::unique_ptr<const MetadataReader> metadata_reader,
+    int facing,
+    int orientation,
+    int32_t max_input_streams,
+    int32_t max_raw_output_streams,
+    int32_t max_non_stalling_output_streams,
+    int32_t max_stalling_output_streams,
+    std::set<uint8_t> request_capabilities,
+    CapabilitiesMap stream_capabilities,
+    ReprocessFormatMap supported_reprocess_outputs)
+    : metadata_reader_(std::move(metadata_reader)),
+      facing_(facing),
+      orientation_(orientation),
+      max_input_streams_(max_input_streams),
+      max_raw_output_streams_(max_raw_output_streams),
+      max_non_stalling_output_streams_(max_non_stalling_output_streams),
+      max_stalling_output_streams_(max_stalling_output_streams),
+      request_capabilities_(std::move(request_capabilities)),
+      stream_capabilities_(std::move(stream_capabilities)),
+      supported_reprocess_outputs_(std::move(supported_reprocess_outputs)) {}
+
+bool StaticProperties::TemplateSupported(int type) {
+  HAL_LOGE("%s: type: %d", __func__, type);
+  uint8_t required_capability = 0;
+  switch (type) {
+    case CAMERA3_TEMPLATE_PREVIEW:
+      // Preview is always supported.
+      return true;
+    case CAMERA3_TEMPLATE_MANUAL:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR;
+      break;
+    /*
+    case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING;
+      break;
+    */
+    default:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE;
+      return true;
+  }
+
+  return request_capabilities_.count(required_capability) > 0;
+}
+
+// Helper functions for checking stream properties when verifying support.
+static bool IsInputType(int stream_type) {
+  return stream_type == CAMERA3_STREAM_INPUT ||
+         stream_type == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+static bool IsOutputType(int stream_type) {
+  return stream_type == CAMERA3_STREAM_OUTPUT ||
+         stream_type == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+static bool IsRawFormat(int format) {
+  return format == HAL_PIXEL_FORMAT_RAW10 || format == HAL_PIXEL_FORMAT_RAW12 ||
+         format == HAL_PIXEL_FORMAT_RAW16 ||
+         format == HAL_PIXEL_FORMAT_RAW_OPAQUE;
+}
+
+bool StaticProperties::StreamConfigurationSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  return SanityCheckStreamConfiguration(stream_config) &&
+         InputStreamsSupported(stream_config) &&
+         OutputStreamsSupported(stream_config) &&
+         OperationModeSupported(stream_config);
+}
+
+bool StaticProperties::SanityCheckStreamConfiguration(
+    const camera3_stream_configuration_t* stream_config) {
+  // Check for null/empty values.
+  if (stream_config == nullptr) {
+    HAL_LOGE("%s: NULL stream configuration array", __func__);
+    return false;
+  } else if (stream_config->num_streams == 0) {
+    HAL_LOGE("%s: Empty stream configuration array", __func__);
+    return false;
+  } else if (stream_config->streams == nullptr) {
+    HAL_LOGE("%s: NULL stream configuration streams", __func__);
+    return false;
+  }
+
+  // Check that all streams are either inputs or outputs (or both).
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (stream == nullptr) {
+      HAL_LOGE("%s: Stream %zu is null", __func__, i);
+      return false;
+    } else if (!IsInputType(stream->stream_type) &&
+               !IsOutputType(stream->stream_type)) {
+      HAL_LOGE("%s: Stream %zu type %d is neither an input nor an output type",
+            __func__,
+            i,
+            stream->stream_type);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+bool StaticProperties::InputStreamsSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  // Find the input stream(s).
+  int32_t num_input_streams = 0;
+  int input_format = -1;
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (IsInputType(stream->stream_type)) {
+      // Check that this stream is valid as an input.
+      const auto capabilities_iterator = stream_capabilities_.find(stream);
+      if (capabilities_iterator == stream_capabilities_.end() ||
+          !capabilities_iterator->second.input_supported) {
+        HAL_LOGE("%s: %d x %d stream of format %d is not a supported input setup.",
+              __func__,
+              stream->width,
+              stream->height,
+              stream->format);
+        return false;
+      }
+
+      // Valid input stream; count it.
+      ++num_input_streams;
+      input_format = stream->format;
+    }
+  }
+
+  // Check the count.
+  if (num_input_streams > max_input_streams_) {
+    HAL_LOGE(
+        "%s: Requested number of input streams %d is greater than "
+        "the maximum number supported by the device (%d).",
+        __func__,
+        num_input_streams,
+        max_input_streams_);
+    return false;
+  }
+  if (num_input_streams > 1) {
+    HAL_LOGE("%s: Camera HAL 3.4 only supports 1 input stream max.", __func__);
+    return false;
+  }
+
+  // If there's an input stream, the configuration must have at least one
+  // supported output format for reprocessing that input.
+  if (num_input_streams > 0) {
+    const auto input_output_formats_iterator =
+        supported_reprocess_outputs_.find(input_format);
+    if (input_output_formats_iterator == supported_reprocess_outputs_.end()) {
+      // Should never happen; factory should verify that all valid inputs
+      // have one or more valid outputs.
+      HAL_LOGE("%s: No valid output formats for input format %d.",
+            __func__,
+            input_format);
+      return false;
+    }
+    bool match_found = false;
+    // Go through outputs looking for a supported one.
+    for (size_t i = 0; i < stream_config->num_streams; ++i) {
+      const camera3_stream_t* stream = stream_config->streams[i];
+      if (IsOutputType(stream->stream_type)) {
+        if (input_output_formats_iterator->second.count(stream->format) > 0) {
+          match_found = true;
+          break;
+        }
+      }
+    }
+    if (!match_found) {
+      HAL_LOGE("%s: No supported output format provided for input format %d.",
+            __func__,
+            input_format);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+bool StaticProperties::OutputStreamsSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  // Find and count output streams.
+  int32_t num_raw = 0;
+  int32_t num_stalling = 0;
+  int32_t num_non_stalling = 0;
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (IsOutputType(stream->stream_type)) {
+      // Check that this stream is valid as an output.
+      const auto capabilities_iterator = stream_capabilities_.find(stream);
+      if (capabilities_iterator == stream_capabilities_.end() ||
+          !capabilities_iterator->second.output_supported) {
+        HAL_LOGE(
+            "%s: %d x %d stream of format %d "
+            "is not a supported output setup.",
+            __func__,
+            stream->width,
+            stream->height,
+            stream->format);
+        return false;
+      }
+
+      // Valid output; count it.
+      if (IsRawFormat(stream->format)) {
+        ++num_raw;
+      } else if (capabilities_iterator->second.stall_duration > 0) {
+        ++num_stalling;
+      } else {
+        ++num_non_stalling;
+      }
+    }
+  }
+
+  // Check that the counts are within bounds.
+  if (num_raw > max_raw_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "raw output streams %d (requested %d).",
+        __func__,
+        max_raw_output_streams_,
+        num_raw);
+    return false;
+  } else if (num_stalling > max_stalling_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "stalling output streams %d (requested %u).",
+        __func__,
+        max_stalling_output_streams_,
+        num_stalling);
+    return false;
+  } else if (num_non_stalling > max_non_stalling_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "non-stalling output streams %d (requested %d).",
+        __func__,
+        max_non_stalling_output_streams_,
+        num_non_stalling);
+    return false;
+  }
+
+  return true;
+}
+
+bool StaticProperties::OperationModeSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  switch (stream_config->operation_mode) {
+    case CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE:
+      return true;
+    case CAMERA3_STREAM_CONFIGURATION_CONSTRAINED_HIGH_SPEED_MODE:
+      // TODO(b/31370792): Check metadata for high speed support,
+      // check that requested streams have support for high speed.
+      HAL_LOGE("%s: Support for CONSTRAINED_HIGH_SPEED not implemented", __func__);
+      return false;
+    default:
+      HAL_LOGE("%s: Unrecognized stream configuration mode: %d",
+            __func__,
+            stream_config->operation_mode);
+      return false;
+  }
+}
+
+bool StaticProperties::ReprocessingSupported(
+    const camera3_stream_t* input_stream,
+    const std::set<const camera3_stream_t*>& output_streams) {
+  // There must be an input.
+  if (!input_stream) {
+    HAL_LOGE("%s: No input stream.", __func__);
+    return false;
+  }
+  // There must be an output.
+  if (output_streams.size() < 1) {
+    HAL_LOGE("%s: No output stream.", __func__);
+    return false;
+  }
+
+  const auto input_output_formats =
+      supported_reprocess_outputs_.find(input_stream->format);
+  if (input_output_formats == supported_reprocess_outputs_.end()) {
+    // Should never happen for a valid input stream.
+    HAL_LOGE("%s: Input format %d does not support any output formats.",
+          __func__,
+          input_stream->format);
+    return false;
+  }
+
+  // Check that all output streams can be outputs for the input stream.
+  const std::set<int32_t>& supported_output_formats =
+      input_output_formats->second;
+  for (const auto output_stream : output_streams) {
+    if (supported_output_formats.count(output_stream->format) < 1) {
+      HAL_LOGE(
+          "%s: Output format %d is not a supported output "
+          "for request input format %d.",
+          __func__,
+          output_stream->format,
+          input_stream->format);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/static_properties.h b/hardware/ntimespace/camera/static_properties.h
new file mode 100644
index 0000000000..565118d682
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties.h
@@ -0,0 +1,120 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
+#define DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
+
+#include <memory>
+#include <set>
+
+#include <hardware/camera3.h>
+#include "common.h"
+#include "metadata/metadata_reader.h"
+#include "metadata/types.h"
+
+namespace default_camera_hal {
+
+// StaticProperties provides a wrapper around useful static metadata entries.
+class StaticProperties {
+ public:
+  // Helpful types for interpreting some static properties.
+  struct StreamCapabilities {
+    int64_t stall_duration;
+    int32_t input_supported;
+    int32_t output_supported;
+    // Default constructor ensures no support
+    // and an invalid stall duration.
+    StreamCapabilities()
+        : stall_duration(-1), input_supported(0), output_supported(0) {}
+  };
+  // Map stream spec (format, size) to their
+  // capabilities (input, output, stall).
+  typedef std::map<StreamSpec, StreamCapabilities, StreamSpec::Compare>
+      CapabilitiesMap;
+
+  // Use this method to create StaticProperties objects.
+  // Functionally equivalent to "new StaticProperties",
+  // except that it may return nullptr in case of failure (missing entries).
+  static StaticProperties* NewStaticProperties(
+      std::unique_ptr<const MetadataReader> metadata_reader);
+  static StaticProperties* NewStaticProperties(
+      std::unique_ptr<android::CameraMetadata> metadata) {
+    return NewStaticProperties(
+        std::make_unique<MetadataReader>(std::move(metadata)));
+  }
+  virtual ~StaticProperties(){};
+
+  // Simple accessors.
+  int facing() const { return facing_; };
+  int orientation() const { return orientation_; };
+  // Carrying on the promise of the underlying reader,
+  // the returned pointer is valid only as long as this object is alive.
+  const camera_metadata_t* raw_metadata() const {
+    return metadata_reader_->raw_metadata();
+  };
+
+  // Check if a given template type is supported.
+  bool TemplateSupported(int type);
+  // Validators (check that values are consistent with the capabilities
+  // this object represents/base requirements of the camera HAL).
+  bool StreamConfigurationSupported(
+      const camera3_stream_configuration_t* stream_config);
+  // Check that the inputs and outputs for a request don't conflict.
+  bool ReprocessingSupported(
+      const camera3_stream_t* input_stream,
+      const std::set<const camera3_stream_t*>& output_streams);
+
+ private:
+  // Constructor private to allow failing on bad input.
+  // Use NewStaticProperties instead.
+  StaticProperties(std::unique_ptr<const MetadataReader> metadata_reader,
+                   int facing,
+                   int orientation,
+                   int32_t max_input_streams,
+                   int32_t max_raw_output_streams,
+                   int32_t max_non_stalling_output_streams,
+                   int32_t max_stalling_output_streams,
+                   std::set<uint8_t> request_capabilities,
+                   CapabilitiesMap stream_capabilities,
+                   ReprocessFormatMap supported_reprocess_outputs);
+
+  // Helper functions for StreamConfigurationSupported.
+  bool SanityCheckStreamConfiguration(
+      const camera3_stream_configuration_t* stream_config);
+  bool InputStreamsSupported(
+      const camera3_stream_configuration_t* stream_config);
+  bool OutputStreamsSupported(
+      const camera3_stream_configuration_t* stream_config);
+  bool OperationModeSupported(
+      const camera3_stream_configuration_t* stream_config);
+
+  const std::unique_ptr<const MetadataReader> metadata_reader_;
+  const int facing_;
+  const int orientation_;
+  const int32_t max_input_streams_;
+  const int32_t max_raw_output_streams_;
+  const int32_t max_non_stalling_output_streams_;
+  const int32_t max_stalling_output_streams_;
+  const std::set<uint8_t> request_capabilities_;
+  const CapabilitiesMap stream_capabilities_;
+  const ReprocessFormatMap supported_reprocess_outputs_;
+
+  DISALLOW_COPY_AND_ASSIGN(StaticProperties);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
diff --git a/hardware/ntimespace/camera/static_properties_test.cpp b/hardware/ntimespace/camera/static_properties_test.cpp
new file mode 100644
index 0000000000..13b9e964b1
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties_test.cpp
@@ -0,0 +1,674 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "static_properties.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include <system/camera.h>
+
+#include "metadata/metadata_reader_mock.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace default_camera_hal {
+
+class StaticPropertiesTest : public Test {
+ protected:
+  virtual void SetUp() {
+    // Ensure tests will probably fail if PrepareDUT isn't called.
+    dut_.reset();
+    mock_reader_ = std::make_unique<MetadataReaderMock>();
+  }
+
+  void PrepareDUT() {
+    dut_.reset(StaticProperties::NewStaticProperties(std::move(mock_reader_)));
+  }
+
+  void PrepareDefaultDUT() {
+    SetDefaultExpectations();
+    PrepareDUT();
+    ASSERT_NE(dut_, nullptr);
+  }
+
+  void SetDefaultExpectations() {
+    EXPECT_CALL(*mock_reader_, Facing(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_facing_), Return(0)));
+    EXPECT_CALL(*mock_reader_, Orientation(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_orientation_), Return(0)));
+    EXPECT_CALL(*mock_reader_, MaxInputStreams(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_max_inputs_), Return(0)));
+    EXPECT_CALL(*mock_reader_, MaxOutputStreams(_, _, _))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_max_raw_outputs_),
+                        SetArgPointee<1>(test_max_non_stalling_outputs_),
+                        SetArgPointee<2>(test_max_stalling_outputs_),
+                        Return(0)));
+    EXPECT_CALL(*mock_reader_, RequestCapabilities(_))
+        .Times(AtMost(1))
+        .WillOnce(
+            DoAll(SetArgPointee<0>(test_request_capabilities_), Return(0)));
+    EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_configs_), Return(0)));
+    EXPECT_CALL(*mock_reader_, StreamStallDurations(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_stalls_), Return(0)));
+    EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_reprocess_map_), Return(0)));
+  }
+
+  camera3_stream_t MakeStream(int32_t format,
+                              bool output = true,
+                              bool input = false,
+                              int32_t width = kWidth,
+                              int32_t height = kHeight) {
+    int type = -1;
+    if (output && input) {
+      type = CAMERA3_STREAM_BIDIRECTIONAL;
+    } else if (output) {
+      type = CAMERA3_STREAM_OUTPUT;
+    } else if (input) {
+      type = CAMERA3_STREAM_INPUT;
+    }
+    camera3_stream_t stream;
+    stream.stream_type = type;
+    stream.width = width;
+    stream.height = height;
+    stream.format = format;
+    return stream;
+  }
+
+  void ExpectConfigurationSupported(std::vector<camera3_stream_t>& streams,
+                                    bool expected) {
+    std::vector<camera3_stream_t*> stream_addresses;
+    for (size_t i = 0; i < streams.size(); ++i) {
+      stream_addresses.push_back(&streams[i]);
+    }
+    camera3_stream_configuration_t config = {
+        static_cast<uint32_t>(stream_addresses.size()),
+        stream_addresses.data(),
+        CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE,
+        nullptr};
+    PrepareDefaultDUT();
+    EXPECT_EQ(dut_->StreamConfigurationSupported(&config), expected);
+  }
+
+  std::unique_ptr<StaticProperties> dut_;
+  std::unique_ptr<MetadataReaderMock> mock_reader_;
+
+  // Some helper values used for stream testing.
+  static constexpr int32_t kWidth = 320;
+  static constexpr int32_t kHeight = 240;
+  static constexpr int32_t kAlternateWidth = 640;
+  static constexpr int32_t kAlternateHeight = 480;
+
+  const int test_facing_ = CAMERA_FACING_FRONT;
+  const int test_orientation_ = 90;
+  const int32_t test_max_inputs_ = 3;
+  const int32_t test_max_raw_outputs_ = 1;
+  const int32_t test_max_non_stalling_outputs_ = 2;
+  const int32_t test_max_stalling_outputs_ = 3;
+  const std::set<uint8_t> test_request_capabilities_ = {
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE,
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR,
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING};
+
+  // Some formats for various purposes (in various combinations,
+  // these types should be capable of testing all failure conditions).
+  const int32_t output_multisize_non_stalling_ = 1;
+  const int32_t bidirectional_self_supporting_stalling_ = 2;
+  const int32_t bidirectional_raw_ = HAL_PIXEL_FORMAT_RAW10;
+  const int32_t input_ = 3;
+  const int32_t other = input_;
+
+  const std::vector<StreamConfiguration> test_configs_ = {
+      {{{output_multisize_non_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{output_multisize_non_stalling_,
+         kAlternateWidth,
+         kAlternateHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{bidirectional_self_supporting_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}},
+      {{{bidirectional_self_supporting_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{bidirectional_raw_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}},
+      {{{bidirectional_raw_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{input_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}}};
+  // Raw having a stall duration shouldn't matter,
+  // it should still be counted as the raw type.
+  const std::vector<StreamStallDuration> test_stalls_ = {
+      {{{output_multisize_non_stalling_, kWidth, kHeight, 0}}},
+      {{{output_multisize_non_stalling_,
+         kAlternateWidth,
+         kAlternateHeight,
+         0}}},
+      {{{bidirectional_self_supporting_stalling_, kWidth, kHeight, 10}}},
+      {{{bidirectional_raw_, kWidth, kHeight, 15}}}};
+  // Format 2 can go to itself or 1. 3 and RAW can only go to 1.
+  const ReprocessFormatMap test_reprocess_map_ = {
+      {bidirectional_self_supporting_stalling_,
+       {output_multisize_non_stalling_,
+        bidirectional_self_supporting_stalling_}},
+      {bidirectional_raw_, {output_multisize_non_stalling_}},
+      {input_, {output_multisize_non_stalling_}}};
+  // Codify the above information about format capabilities in some helpful
+  // vectors.
+  int32_t multi_size_format_ = 1;
+  const std::vector<int32_t> input_formats_ = {2, 3, HAL_PIXEL_FORMAT_RAW10};
+  const std::vector<int32_t> output_formats_ = {1, 2, HAL_PIXEL_FORMAT_RAW10};
+};
+
+TEST_F(StaticPropertiesTest, FactorySuccess) {
+  PrepareDefaultDUT();
+  EXPECT_EQ(dut_->facing(), test_facing_);
+  EXPECT_EQ(dut_->orientation(), test_orientation_);
+
+  // Stream configurations tested seperately.
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedFacing) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, Facing(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedOrientation) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, Orientation(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedMaxInputs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, MaxInputStreams(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedMaxOutputs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, MaxOutputStreams(_, _, _)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedRequestCapabilities) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, RequestCapabilities(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedStreamConfigs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedStallDurations) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, StreamStallDurations(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedReprocessFormats) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryNoReprocessFormats) {
+  // If there are no inputs allowed, the reprocess formats shouldn't matter.
+  SetDefaultExpectations();
+  // Override max inputs.
+  EXPECT_CALL(*mock_reader_, MaxInputStreams(_))
+      .WillOnce(DoAll(SetArgPointee<0>(0), Return(0)));
+  // Override reprocess formats with a failure expectation.
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(99));
+  PrepareDUT();
+  // Should be ok.
+  EXPECT_NE(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryInvalidCapabilities) {
+  SetDefaultExpectations();
+  // Override configs with an extra output format.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  configs.push_back(
+      {{{5,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}});
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because not every output has a stall.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessNoInputs) {
+  SetDefaultExpectations();
+  // Override configs by removing all inputs.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  for (auto it = configs.begin(); it != configs.end();) {
+    if ((*it).direction ==
+        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT) {
+      it = configs.erase(it);
+    } else {
+      ++it;
+    }
+  }
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because inputs are supported but there are no input formats.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessExtraInput) {
+  SetDefaultExpectations();
+  // Override configs with an extra input format.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  configs.push_back({{{5,
+                       kWidth,
+                       kHeight,
+                       ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}});
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because no reprocess outputs are listed for the extra input.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessExtraMapEntry) {
+  SetDefaultExpectations();
+  // Override the reprocess map with an extra entry.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map[5] = {1};
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because the extra map entry doesn't correspond to an input.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessWrongMapEntries) {
+  SetDefaultExpectations();
+  // Override the reprocess map replacing the entry for the
+  // input-only format with the output-only format.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map.erase(input_);
+  reprocess_map[output_multisize_non_stalling_] = {1};
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because not all input formats are present/
+  // one of the map "input" formats is output only.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessNotAnOutput) {
+  SetDefaultExpectations();
+  // Override the reprocess map with a non-output output entry.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map[input_].insert(input_);
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because a specified output format doesn't support output.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, TemplatesValid) {
+  PrepareDefaultDUT();
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    EXPECT_TRUE(dut_->TemplateSupported(i));
+  }
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSingleOutput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureMultipleOutputs) {
+  std::vector<camera3_stream_t> streams;
+  // 2 outputs, of different sizes.
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // Use the alternate size.
+  streams.push_back(MakeStream(output_multisize_non_stalling_,
+                               true,
+                               false,
+                               kAlternateWidth,
+                               kAlternateHeight));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureInput) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> different output.
+  streams.push_back(MakeStream(input_, false, true));
+  // Use the alternate size, it should be ok.
+  streams.push_back(MakeStream(output_multisize_non_stalling_,
+                               true,
+                               false,
+                               kAlternateWidth,
+                               kAlternateHeight));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureBidirectional) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> same output.
+  streams.push_back(
+      MakeStream(bidirectional_self_supporting_stalling_, true, true));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureMultipleReprocess) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> multiple outputs.
+  streams.push_back(
+      MakeStream(bidirectional_self_supporting_stalling_, true, true));
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNull) {
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(nullptr));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureEmptyStreams) {
+  std::vector<camera3_stream_t*> streams(1);
+  camera3_stream_configuration_t config = {
+      0, streams.data(), CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE, nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNullStreams) {
+  std::vector<camera3_stream_t*> streams(2, nullptr);
+  camera3_stream_configuration_t config = {
+      static_cast<uint32_t>(streams.size()),
+      streams.data(),
+      CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE,
+      nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNullStreamVector) {
+  // Even if the camera claims to have multiple streams, check for null.
+  camera3_stream_configuration_t config = {
+      3, nullptr, CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE, nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNoOutput) {
+  std::vector<camera3_stream_t> streams;
+  // Only an input stream, no output.
+  streams.push_back(MakeStream(input_, false, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureInvalidType) {
+  std::vector<camera3_stream_t> streams;
+  // Not input, output, or bidirectional.
+  streams.push_back(MakeStream(output_multisize_non_stalling_, false, false));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSpecFormatDoesNotExist) {
+  std::vector<camera3_stream_t> streams;
+  // Format 99 is not supported in any form.
+  streams.push_back(MakeStream(99));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSpecSizeDoesNotExist) {
+  std::vector<camera3_stream_t> streams;
+  // Size 99 x 99 not supported for the output format.
+  streams.push_back(
+      MakeStream(output_multisize_non_stalling_, true, false, 99, 99));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNotAnInput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  // Can't use output-only format as an input.
+  streams.push_back(MakeStream(output_multisize_non_stalling_, false, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNotAnOutput) {
+  std::vector<camera3_stream_t> streams;
+  // Can't use input-only format as an output.
+  streams.push_back(MakeStream(input_));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyInputs) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_inputs_; ++i) {
+    streams.push_back(MakeStream(input_, false, true));
+  }
+  // Have a valid output still.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, false);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_inputs_; ++i) {
+    streams.push_back(MakeStream(input_, false, true));
+  }
+  // Have a valid output still.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyRaw) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_raw_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_raw_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_raw_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_raw_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyStalling) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_self_supporting_stalling_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_self_supporting_stalling_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyNonStalling) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_non_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(output_multisize_non_stalling_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_non_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(output_multisize_non_stalling_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnuspportedInput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(input_, false, true));
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // No matching output format for input.
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnsupportedOutput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(input_, false, true));
+  // The universal output does match input.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  // Raw does not match input.
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // Input is matched; it's ok that raw doesn't match (only the actual
+  // requests care).
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnsupportedBidirectional) {
+  std::vector<camera3_stream_t> streams;
+  // The test raw format, while supporting both input and output,
+  // does not actually support itself.
+  streams.push_back(MakeStream(bidirectional_raw_, true, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureBadOperationMode) {
+  // A valid stream set.
+  camera3_stream_t stream = MakeStream(output_multisize_non_stalling_);
+  camera3_stream_t* stream_address = &stream;
+  // But not a valid config.
+  camera3_stream_configuration_t config = {
+      1,
+      &stream_address,
+      99, // Not a valid operation mode.
+      nullptr
+  };
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingSingleOutput) {
+  camera3_stream_t input_stream = MakeStream(input_);
+  camera3_stream_t output_stream = MakeStream(output_multisize_non_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_TRUE(dut_->ReprocessingSupported(&input_stream, {&output_stream}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingMultipleOutputs) {
+  camera3_stream_t input_stream =
+      MakeStream(bidirectional_self_supporting_stalling_, false, true);
+  // Bi-directional self-supporting supports the universal output and itself.
+  camera3_stream_t output_stream1 = MakeStream(output_multisize_non_stalling_);
+  camera3_stream_t output_stream2 =
+      MakeStream(bidirectional_self_supporting_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_TRUE(dut_->ReprocessingSupported(&input_stream,
+                                          {&output_stream1, &output_stream2}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingNoInput) {
+  camera3_stream_t output_stream = MakeStream(output_multisize_non_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(nullptr, {&output_stream}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingNoOutput) {
+  camera3_stream_t input_stream = MakeStream(input_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(&input_stream, {}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingInvalidOutput) {
+  camera3_stream_t input_stream = MakeStream(input_, false, true);
+  // The universal output does match input.
+  camera3_stream_t output_stream1 = MakeStream(output_multisize_non_stalling_);
+  // Raw does not match input.
+  camera3_stream_t output_stream2 = MakeStream(bidirectional_raw_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(&input_stream,
+                                           {&output_stream1, &output_stream2}));
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/stream_format.cpp b/hardware/ntimespace/camera/stream_format.cpp
new file mode 100644
index 0000000000..a2be8b9a80
--- /dev/null
+++ b/hardware/ntimespace/camera/stream_format.cpp
@@ -0,0 +1,242 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "StreamFormat"
+
+#include "stream_format.h"
+
+#include <system/graphics.h>
+#include "arc/image_processor.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+
+static const std::vector<uint32_t> GetSupportedFourCCs() {
+  // The preference of supported fourccs in the list is from high to low.
+  static const std::vector<uint32_t> kSupportedFourCCs = {V4L2_PIX_FMT_RGB32,
+                                                          V4L2_PIX_FMT_NV12,
+                                                          V4L2_PIX_FMT_YUYV,
+                                                          V4L2_PIX_FMT_MJPEG};
+  return kSupportedFourCCs;
+}
+
+StreamFormat::StreamFormat(int format, uint32_t width, uint32_t height) 
+    // TODO(b/30000211): multiplanar support.
+    : type_(V4L2_BUF_TYPE_VIDEO_CAPTURE),
+      v4l2_pixel_format_(StreamFormat::HalToV4L2PixelFormat(format)),
+      width_(width),
+      height_(height),
+      bytes_per_line_(0) {}
+
+StreamFormat::StreamFormat(const v4l2_format& format)
+    : type_(format.type),
+      // TODO(b/30000211): multiplanar support.
+      v4l2_pixel_format_(format.fmt.pix.pixelformat),
+      width_(format.fmt.pix.width),
+      height_(format.fmt.pix.height),
+      bytes_per_line_(format.fmt.pix.bytesperline) {}
+
+StreamFormat::StreamFormat(const arc::SupportedFormat& format)
+    : type_(V4L2_BUF_TYPE_VIDEO_CAPTURE),
+      v4l2_pixel_format_(format.fourcc),
+      width_(format.width),
+      height_(format.height),
+      bytes_per_line_(0) {}
+
+void StreamFormat::FillFormatRequest(v4l2_format* format) const {
+  memset(format, 0, sizeof(*format));
+  format->type = type_;
+  format->fmt.pix.pixelformat = v4l2_pixel_format_;
+  format->fmt.pix.width = width_;
+  format->fmt.pix.height = height_;
+  // Bytes per line and min buffer size are outputs set by the driver,
+  // not part of the request.
+}
+
+FormatCategory StreamFormat::Category() const {
+  switch (v4l2_pixel_format_) {
+    case V4L2_PIX_FMT_JPEG:
+      return kFormatCategoryStalling;
+    case V4L2_PIX_FMT_YUV420:  // Fall through.
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      return kFormatCategoryNonStalling;
+    default:
+      // Note: currently no supported RAW formats.
+      return kFormatCategoryUnknown;
+  }
+}
+
+bool StreamFormat::operator==(const StreamFormat& other) const {
+  // Used to check that a requested format was actually set, so
+  // don't compare bytes per line or min buffer size.
+  return (type_ == other.type_ &&
+          v4l2_pixel_format_ == other.v4l2_pixel_format_ &&
+          width_ == other.width_ && height_ == other.height_);
+}
+
+bool StreamFormat::operator!=(const StreamFormat& other) const {
+  return !(*this == other);
+}
+
+int StreamFormat::V4L2ToHalPixelFormat(uint32_t v4l2_pixel_format) {
+  HAL_LOGV("[format_mapping]v4l2_pixel_format: 0x%x", v4l2_pixel_format);
+  // Translate V4L2 format to HAL format.
+  switch (v4l2_pixel_format) {
+    case V4L2_PIX_FMT_BGR32:
+      return HAL_PIXEL_FORMAT_RGBA_8888;
+    case V4L2_PIX_FMT_JPEG:
+      return HAL_PIXEL_FORMAT_BLOB;
+    case V4L2_PIX_FMT_NV21:
+      return HAL_PIXEL_FORMAT_YCbCr_420_888;
+      //return HAL_PIXEL_FORMAT_YCrCb_420_SP;
+    case V4L2_PIX_FMT_NV12:
+      #if HAS_RGA
+        return HAL_PIXEL_FORMAT_YCbCr_420_888;
+      #else
+        return HAL_PIXEL_FORMAT_YCRCB_420_SP;
+      #endif
+    case V4L2_PIX_FMT_YUV420:
+      return HAL_PIXEL_FORMAT_YCbCr_420_888;
+    case V4L2_PIX_FMT_YUYV:
+      return HAL_PIXEL_FORMAT_YCbCr_422_I;
+    case V4L2_PIX_FMT_YVU420:
+      return HAL_PIXEL_FORMAT_YV12;
+    case V4L2_PIX_FMT_RGB32:
+      return HAL_PIXEL_FORMAT_RGBA_8888;
+    default:
+      // Unrecognized format.
+      HAL_LOGE("Unrecognized v4l2 pixel format 0x%x", v4l2_pixel_format);
+      break;
+  }
+  return -1;
+}
+
+uint32_t StreamFormat::HalToV4L2PixelFormat(int hal_pixel_format) {
+  HAL_LOGV("[format_mapping]hal_pixel_format: 0x%x", hal_pixel_format);
+  switch (hal_pixel_format) {
+    case HAL_PIXEL_FORMAT_BLOB:
+      return V4L2_PIX_FMT_JPEG;
+    case HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED:  // Fall-through
+    case HAL_PIXEL_FORMAT_RGBA_8888:
+      return V4L2_PIX_FMT_RGB32;
+      //return V4L2_PIX_FMT_BGR32;
+    case HAL_PIXEL_FORMAT_YCbCr_420_888:
+      // This is a flexible YUV format that depends on platform. Different
+      // platform may have different format. It can be YVU420 or NV12. Now we
+      // return YVU420 first.
+      // TODO(): call drm_drv.get_fourcc() to get correct format.
+      #if HAS_RGA
+        return V4L2_PIX_FMT_NV12;
+      #else
+        return V4L2_PIX_FMT_NV21;
+      #endif
+      //return V4L2_PIX_FMT_YUV420;
+      //return V4L2_PIX_FMT_NV12;      
+    case HAL_PIXEL_FORMAT_YCbCr_422_I:
+      return V4L2_PIX_FMT_YUYV;
+    case HAL_PIXEL_FORMAT_YCrCb_420_SP:
+      return V4L2_PIX_FMT_NV21;
+    case HAL_PIXEL_FORMAT_YV12:
+      return V4L2_PIX_FMT_YVU420;
+    default:
+      HAL_LOGE("Pixel format 0x%x is unsupported.", hal_pixel_format);
+      break;
+  }
+  return -1;
+}
+
+// Copy the qualified format into out_format and return true if there is a
+// proper and fitting format in the given format lists.
+bool StreamFormat::FindBestFitFormat(const SupportedFormats& supported_formats,
+                                     const SupportedFormats& qualified_formats,
+                                     uint32_t fourcc, uint32_t width,
+                                     uint32_t height,
+                                     SupportedFormat* out_format) {
+  // Match exact format and resolution if possible.
+  for (const auto& format : supported_formats) {
+    if (format.fourcc == fourcc && format.width == width &&
+        format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  // All conversions will be done through CachedFrame for now, which will
+  // immediately convert the qualified format into YU12 (YUV420). We check
+  // here that the conversion between YU12 and |fourcc| is supported.
+  if (!arc::ImageProcessor::SupportsConversion(V4L2_PIX_FMT_YUV420, fourcc)) {
+    HAL_LOGE("Conversion between YU12 and 0x%x not supported.", fourcc);
+    return false;
+  }
+
+  // Choose the qualified format with a matching resolution.
+  for (const auto& format : qualified_formats) {
+    if (format.width == width && format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  return false;
+}
+
+// Copy corresponding format into out_format and return true by matching
+// resolution |width|x|height| in |formats|.
+bool StreamFormat::FindFormatByResolution(const SupportedFormats& formats,
+                                          uint32_t width, uint32_t height,
+                                          SupportedFormat* out_format) {
+  for (const auto& format : formats) {
+    if (format.width == width && format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  return false;
+}
+
+SupportedFormats StreamFormat::GetQualifiedFormats(
+    const SupportedFormats& supported_formats) {
+  // The preference of supported fourccs in the list is from high to low.
+  const std::vector<uint32_t> supported_fourccs = GetSupportedFourCCs();
+  SupportedFormats qualified_formats;
+  for (const auto& supported_fourcc : supported_fourccs) {
+    for (const auto& supported_format : supported_formats) {
+      if (supported_format.fourcc != supported_fourcc) {
+        continue;
+      }
+
+      // Skip if |qualified_formats| already has the same resolution with a more
+      // preferred fourcc.
+      if (FindFormatByResolution(qualified_formats, supported_format.width,
+                                 supported_format.height, NULL)) {
+        continue;
+      }
+      qualified_formats.push_back(supported_format);
+    }
+  }
+  return qualified_formats;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/stream_format.h b/hardware/ntimespace/camera/stream_format.h
new file mode 100644
index 0000000000..3f0c514614
--- /dev/null
+++ b/hardware/ntimespace/camera/stream_format.h
@@ -0,0 +1,83 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_STREAM_FORMAT_H_
+#define V4L2_CAMERA_HAL_STREAM_FORMAT_H_
+
+#include <cstring>
+
+#include <linux/videodev2.h>
+#include "arc/common_types.h"
+
+namespace v4l2_camera_hal {
+
+enum FormatCategory {
+  kFormatCategoryRaw,
+  kFormatCategoryStalling,
+  kFormatCategoryNonStalling,
+  kFormatCategoryUnknown,
+};
+
+class StreamFormat {
+ public:
+  StreamFormat(int format, uint32_t width, uint32_t height);
+  StreamFormat(const v4l2_format& format);
+  StreamFormat(const arc::SupportedFormat& format);
+  virtual ~StreamFormat() = default;
+  // Only uint32_t members, use default generated copy and assign.
+
+  void FillFormatRequest(v4l2_format* format) const;
+  FormatCategory Category() const;
+
+  // Accessors.
+  inline uint32_t type() const { return type_; };
+  inline uint32_t width() const { return width_; };
+  inline uint32_t height() const { return height_; };
+  inline uint32_t v4l2_pixel_format() const { return v4l2_pixel_format_; }
+  inline uint32_t bytes_per_line() const { return bytes_per_line_; };
+
+  bool operator==(const StreamFormat& other) const;
+  bool operator!=(const StreamFormat& other) const;
+
+  // HAL <-> V4L2 conversions
+  // Returns 0 for unrecognized.
+  static uint32_t HalToV4L2PixelFormat(int hal_pixel_format);
+  // Returns -1 for unrecognized.
+  static int V4L2ToHalPixelFormat(uint32_t v4l2_pixel_format);
+
+  // ARC++ SupportedFormat Helpers
+  static bool FindBestFitFormat(const arc::SupportedFormats& supported_formats,
+                                const arc::SupportedFormats& qualified_formats,
+                                uint32_t fourcc, uint32_t width,
+                                uint32_t height,
+                                arc::SupportedFormat* out_format);
+  static bool FindFormatByResolution(const arc::SupportedFormats& formats,
+                                     uint32_t width, uint32_t height,
+                                     arc::SupportedFormat* out_format);
+  static arc::SupportedFormats GetQualifiedFormats(
+      const arc::SupportedFormats& supported_formats);
+
+ private:
+  uint32_t type_;
+  uint32_t v4l2_pixel_format_;
+  uint32_t width_;
+  uint32_t height_;
+  uint32_t bytes_per_line_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_STREAM_FORMAT_H_
diff --git a/hardware/ntimespace/camera/v4l2_camera.cpp b/hardware/ntimespace/camera/v4l2_camera.cpp
new file mode 100644
index 0000000000..670a256235
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera.cpp
@@ -0,0 +1,912 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Camera"
+
+#include "v4l2_camera.h"
+#include <cstdlib>
+#include <fcntl.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/camera3.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "common.h"
+#include "function_thread.h"
+#include "metadata/metadata_common.h"
+#include "stream_format.h"
+#include "v4l2_metadata_factory.h"
+#include "arc/format_convert_test.h"
+//#include <utils/CallStack.h>
+#include "debug.h"
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(*(a)))
+
+namespace v4l2_camera_hal {
+
+V4L2Camera* V4L2Camera::NewV4L2Camera(int id, const std::string path) {
+  HAL_LOG_ENTER();
+  HAL_LOGE("path: %s.", path.c_str());
+
+  std::shared_ptr<V4L2Wrapper> v4l2_wrapper(V4L2Wrapper::NewV4L2Wrapper(path, id));
+  if (!v4l2_wrapper) {
+    HAL_LOGE("Failed to initialize V4L2 wrapper.");
+    return nullptr;
+  }
+
+  std::unique_ptr<Metadata> metadata;
+  int res = GetV4L2Metadata(v4l2_wrapper, &metadata);
+  if (res) {
+    HAL_LOGE("Failed to initialize V4L2 metadata: %d", res);
+    return nullptr;
+  }
+  //metadata->Dump("/data/local/metadata_GetV4L2Metadata.log");
+
+  return new V4L2Camera(id, std::move(v4l2_wrapper), std::move(metadata));
+}
+
+V4L2Camera::V4L2Camera(int id,
+                       std::shared_ptr<V4L2Wrapper> v4l2_wrapper,
+                       std::unique_ptr<Metadata> metadata)
+    : default_camera_hal::Camera(id),
+      device_(std::move(v4l2_wrapper)),
+      metadata_(std::move(metadata)),
+      buffer_enqueuer_(new FunctionThread(
+          std::bind(&V4L2Camera::enqueueRequestBuffers, this))),
+      buffer_dequeuer_(new FunctionThread(
+          std::bind(&V4L2Camera::dequeueRequestBuffers, this))),
+      unit_tester_(new FunctionThread(
+          std::bind(&V4L2Camera::unitTest, this))),          
+      max_input_streams_(0),
+      max_output_streams_({{0, 0, 0}}) {
+  HAL_LOG_ENTER();
+}
+
+V4L2Camera::~V4L2Camera() {
+  HAL_LOG_ENTER();
+}
+
+int V4L2Camera::connect() {
+  HAL_LOG_ENTER();
+
+  if (connection_) {
+    HAL_LOGE("Already connected. Please disconnect and try again.");
+    return -EIO;
+  }
+
+  connection_.reset(new V4L2Wrapper::Connection(device_));
+  if (connection_->status()) {
+    HAL_LOGE("Failed to connect to device.");
+    return connection_->status();
+  }
+
+//  initDevice();
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at |device_|'s path may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so connect() is never called on an unsupported camera)
+
+  // TODO(b/29158098): Inform service of any flashes that are no longer
+  // available because this camera is in use.
+  return 0;
+}
+
+void V4L2Camera::disconnect() {
+  HAL_LOG_ENTER();
+
+  StopQueue();
+  connection_.reset();
+  // TODO(b/29158098): Inform service of any flashes that are available again
+  // because this camera is no longer in use.
+}
+
+int V4L2Camera::flushBuffers() {
+  HAL_LOG_ENTER();
+
+  device_->StreamOff();
+  requests_available_.notify_one();
+  return 0;
+}
+
+int V4L2Camera::UpdateVendorStaticInfo(android::CameraMetadata* metadata)
+{
+    int32_t max_input_streams = 1;
+    metadata->update(ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS,
+                      &max_input_streams,
+                      1);
+
+    int32_t MAX_STALLING_STREAMS = 1;
+    int32_t MAX_PROCESSED_STREAMS = 2;
+    int32_t MAX_RAW_STREAMS = 0;
+    int32_t max_output_streams[] = {
+            MAX_STALLING_STREAMS,
+            MAX_PROCESSED_STREAMS,
+            MAX_RAW_STREAMS};
+    metadata->update(ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+            max_output_streams,
+            sizeof(max_output_streams)/sizeof(max_output_streams[0]));
+
+    /* format of the map is : input format, num_output_formats, outputFormat1,..,outputFormatN */
+    int32_t io_format_map[] = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 1, HAL_PIXEL_FORMAT_YCbCr_420_888,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1, HAL_PIXEL_FORMAT_YCbCr_420_888
+    };
+    metadata->update(ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP,
+                      io_format_map, sizeof(io_format_map)/sizeof(io_format_map[0]));
+
+    //for reprocess check
+    int32_t max_stall_duration = 0;
+    metadata->update(ANDROID_REPROCESS_MAX_CAPTURE_STALL, &max_stall_duration, 1);
+
+    std::vector<uint8_t> available_capabilities;
+    available_capabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS);
+    if (/*supportBurst*/0) {
+        available_capabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE);
+    }
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
+    metadata->update(ANDROID_REQUEST_AVAILABLE_CAPABILITIES,
+            &available_capabilities[0],
+            available_capabilities.size());   
+
+#if 0
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,  
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,   
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,            
+
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,  
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,      
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,                               
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+    };
+#elif 0
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,  
+          
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,  
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,      
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,                               
+    };
+#else
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,   
+
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+    };    
+#endif
+
+    metadata->update(ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+            &availableStreamConfigurations[0],
+            availableStreamConfigurations.size());
+
+    uint8_t lensFacing = (getCameraId() == 1 ? ANDROID_LENS_FACING_FRONT : ANDROID_LENS_FACING_BACK);
+    metadata->update(ANDROID_LENS_FACING, &lensFacing, 1);
+
+    int32_t lensOrientation = (getCameraId() == 1 ? 270 : 90); 
+    metadata->update(ANDROID_SENSOR_ORIENTATION, &lensOrientation, 1);
+
+    int32_t jpegOrientation = (getCameraId() == 1 ? 270 : 90); 
+    metadata->update(ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+    /* android.control */
+    int32_t aeTargetFpsRange[2] = {
+        15, 30
+    };
+    metadata->update(ANDROID_CONTROL_AE_TARGET_FPS_RANGE, aeTargetFpsRange, 2);          
+
+    static const int32_t availableTargetFpsRanges[] = {
+        15, 30
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES,
+            availableTargetFpsRanges,
+            sizeof(availableTargetFpsRanges)/sizeof(int32_t));
+
+    const uint8_t controlMode = ANDROID_CONTROL_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_MODE, &controlMode, 1);
+
+    static const uint8_t effectMode = ANDROID_CONTROL_EFFECT_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_EFFECT_MODE, &effectMode, 1);
+
+    //const uint8_t sceneMode = ANDROID_CONTROL_SCENE_MODE_FACE_PRIORITY;
+    //metadata->update(ANDROID_CONTROL_SCENE_MODE, &sceneMode, 1);
+
+    const uint8_t aeMode = ANDROID_CONTROL_AE_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_AE_MODE, &aeMode, 1);
+#if 0
+    static const uint8_t aeLock = ANDROID_CONTROL_AE_LOCK_OFF;
+    metadata->update(ANDROID_CONTROL_AE_LOCK, &aeLock, 1);
+#endif    
+    static const int32_t controlRegions[5] = {
+        0, 0, 0, 0, 0
+    };
+    metadata->update(ANDROID_CONTROL_AE_REGIONS, controlRegions, 5);
+
+    static const int32_t aeExpCompensation = 0;
+    metadata->update(ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION, &aeExpCompensation, 1);
+
+    static const uint8_t aeAntibandingMode =
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO;
+    metadata->update(ANDROID_CONTROL_AE_ANTIBANDING_MODE, &aeAntibandingMode, 1);
+
+    static const uint8_t aePrecaptureTrigger = ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_IDLE;
+    metadata->update(ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER, &aePrecaptureTrigger, 1);
+
+    const uint8_t awbMode = ANDROID_CONTROL_AWB_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_AWB_MODE, &awbMode, 1);
+
+    static const uint8_t awbLock = ANDROID_CONTROL_AWB_LOCK_OFF;
+    metadata->update(ANDROID_CONTROL_AWB_LOCK, &awbLock, 1);
+
+    uint8_t afMode[] = {ANDROID_CONTROL_AF_MODE_OFF, ANDROID_CONTROL_AF_MODE_AUTO};
+    metadata->update(ANDROID_CONTROL_AF_MODE, afMode, 2);
+
+    metadata->update(ANDROID_CONTROL_AF_REGIONS, controlRegions, 5);
+#if 0
+    static const uint8_t afTrigger = ANDROID_CONTROL_AF_TRIGGER_IDLE;
+    metadata->update(ANDROID_CONTROL_AF_TRIGGER, &afTrigger, 1);
+
+    static const uint8_t vstabMode =
+            ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+                    &vstabMode, 1);
+#endif
+    static const uint8_t availableSceneModes[] = {
+            ANDROID_CONTROL_SCENE_MODE_DISABLED
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+            availableSceneModes, sizeof(availableSceneModes));
+
+    static const uint8_t availableEffects[] = {
+            ANDROID_CONTROL_EFFECT_MODE_OFF
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_EFFECTS,
+            availableEffects, sizeof(availableEffects));
+
+    static const int32_t max3aRegions[] = {/*AE*/ 0,/*AWB*/ 0,/*AF*/ 0};
+    metadata->update(ANDROID_CONTROL_MAX_REGIONS,
+            max3aRegions, sizeof(max3aRegions)/sizeof(max3aRegions[0]));
+
+    static const uint8_t availableAeModes[] = {
+            ANDROID_CONTROL_AE_MODE_OFF,
+            ANDROID_CONTROL_AE_MODE_ON
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_MODES,
+            availableAeModes, sizeof(availableAeModes));
+
+    static const camera_metadata_rational exposureCompensationStep = {
+            1, 3
+    };
+    metadata->update(ANDROID_CONTROL_AE_COMPENSATION_STEP,
+            &exposureCompensationStep, 1);
+
+    int32_t exposureCompensationRange[] = {-9, 9};
+    metadata->update(ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+            exposureCompensationRange,
+            sizeof(exposureCompensationRange)/sizeof(int32_t));
+
+    static const uint8_t availableAntibandingModes[] = {
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF,
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+            availableAntibandingModes, sizeof(availableAntibandingModes));
+
+    static const uint8_t availableAwbModes[] = {
+            ANDROID_CONTROL_AWB_MODE_OFF,
+            ANDROID_CONTROL_AWB_MODE_AUTO,
+            ANDROID_CONTROL_AWB_MODE_INCANDESCENT,
+            ANDROID_CONTROL_AWB_MODE_FLUORESCENT,
+            ANDROID_CONTROL_AWB_MODE_DAYLIGHT,
+            ANDROID_CONTROL_AWB_MODE_SHADE
+    };
+    metadata->update(ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+            availableAwbModes, sizeof(availableAwbModes));
+
+    static const uint8_t availableAfModesBack[] = {
+            ANDROID_CONTROL_AF_MODE_OFF,
+            ANDROID_CONTROL_AF_MODE_AUTO,
+            ANDROID_CONTROL_AF_MODE_MACRO,
+            ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO,
+            ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE
+    };
+
+    metadata->update(ANDROID_CONTROL_AF_AVAILABLE_MODES,
+                availableAfModesBack, sizeof(availableAfModesBack));
+
+    static const uint8_t availableVstabModes[] = {
+            ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+            availableVstabModes, sizeof(availableVstabModes));
+
+    static const uint8_t blackLevelLock = ANDROID_BLACK_LEVEL_LOCK_OFF;
+    metadata->update(ANDROID_BLACK_LEVEL_LOCK, &blackLevelLock, 1);
+
+    /*
+    static const uint8_t lensShadingMapMode =
+            ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF;
+    metadata->update(ANDROID_STATISTICS_LENS_SHADING_MAP_MODE,
+                    &lensShadingMapMode, 1);
+    */
+    static const uint8_t aberrationMode =
+            ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST;
+    metadata->update(ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+                    &aberrationMode, 1);
+
+  /* android.jpeg */
+  int32_t android_jpeg_available_thumbnail_sizes[] = {0, 0, 128, 96};
+  metadata->update(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+          android_jpeg_available_thumbnail_sizes,
+          ARRAY_SIZE(android_jpeg_available_thumbnail_sizes));
+
+  int32_t android_jpeg_max_size[] = {13 * 1024 * 1024}; // 13MB
+  metadata->update(ANDROID_JPEG_MAX_SIZE,
+          android_jpeg_max_size,
+          ARRAY_SIZE(android_jpeg_max_size));
+#if 0
+  /* android.lens */
+  float android_lens_info_available_focal_lengths[] = {1.0};
+  metadata->addFloat(ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
+          ARRAY_SIZE(android_lens_info_available_focal_lengths),
+          android_lens_info_available_focal_lengths);
+#endif
+
+  /** android.sensor */
+  const int64_t USEC = 1000LL;
+  const int64_t MSEC = USEC * 1000LL;
+  static const int64_t exposureTime = 10 * MSEC;
+  metadata->update(ANDROID_SENSOR_EXPOSURE_TIME, &exposureTime, 1);
+
+  static const int64_t frameDuration = 33333333L; // 1/30 s
+  metadata->update(ANDROID_SENSOR_FRAME_DURATION, &frameDuration, 1);
+
+  static const int32_t sensitivity = 100;
+  metadata->update(ANDROID_SENSOR_SENSITIVITY, &sensitivity, 1);
+
+  //if (hasCapability(MANUAL_SENSOR)) 
+  {
+    const nsecs_t kExposureTimeRange[2] =
+      {1000L, 300000000L} ; // 1 us - 0.3 sec
+    const nsecs_t kFrameDurationRange[2] =
+      {33331760L, 300000000L}; // ~1/30 s - 0.3 sec
+    const int32_t kSensitivityRange[2] = {100, 1600};
+
+      metadata->update(ANDROID_SENSOR_INFO_EXPOSURE_TIME_RANGE,
+              kExposureTimeRange, 2);
+
+      metadata->update(ANDROID_SENSOR_INFO_MAX_FRAME_DURATION,
+              &kFrameDurationRange[1], 1);
+
+      metadata->update(ANDROID_SENSOR_INFO_SENSITIVITY_RANGE,
+              kSensitivityRange,
+              sizeof(kSensitivityRange)
+              /sizeof(int32_t));
+
+      metadata->update(ANDROID_SENSOR_MAX_ANALOG_SENSITIVITY,
+              &kSensitivityRange[1], 1);
+  }
+
+  /** android.lens */
+  static const float focalLength = 5.0f;
+  metadata->update(ANDROID_LENS_FOCAL_LENGTH, &focalLength, 1);
+
+  //if (hasCapability(BACKWARD_COMPATIBLE)) 
+  {
+      static const float focusDistance = 0;
+      metadata->update(ANDROID_LENS_FOCUS_DISTANCE, &focusDistance, 1);
+
+      static const float aperture = 2.8f;
+      metadata->update(ANDROID_LENS_APERTURE, &aperture, 1);
+
+      static const float filterDensity = 0;
+      metadata->update(ANDROID_LENS_FILTER_DENSITY, &filterDensity, 1);
+
+      static const uint8_t opticalStabilizationMode =
+              ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF;
+      metadata->update(ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+              &opticalStabilizationMode, 1);
+  }
+
+  return 0;
+}
+
+int V4L2Camera::initStaticInfo(android::CameraMetadata* out) {
+  HAL_LOG_ENTER();
+
+  int res = metadata_->FillStaticMetadata(out);
+  if (res) {
+    HAL_LOGE("Failed to get static metadata.");
+    return res;
+  }
+
+  UpdateVendorStaticInfo(out);
+
+  // Extract max streams for use in verifying stream configs.
+  res = SingleTagValue(
+      *out, ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, &max_input_streams_);
+  if (res) {
+    HAL_LOGE("Failed to get max num input streams from static metadata.");
+    return res;
+  }
+  res = SingleTagValue(
+      *out, ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS, &max_output_streams_);
+  if (res) {
+    HAL_LOGE("Failed to get max num output streams from static metadata.");
+    return res;
+  }
+
+  HAL_LOGE("Get max num input/output streams [%d/%d/%d/%d] from static metadata.", max_input_streams_, 
+  max_output_streams_[0], max_output_streams_[1], max_output_streams_[2]);
+
+  return 0;
+}
+
+int V4L2Camera::initTemplate(int type, android::CameraMetadata* out) {
+  HAL_LOG_ENTER();
+
+  return metadata_->GetRequestTemplate(type, out);
+}
+
+void V4L2Camera::initDeviceInfo(camera_info_t* info) {
+  HAL_LOG_ENTER();
+
+  // TODO(b/31044975): move this into device interface.
+  // For now, just constants.
+  info->resource_cost = 100;
+  info->conflicting_devices = nullptr;
+  info->conflicting_devices_length = 0;
+}
+
+int V4L2Camera::initDevice() {
+  HAL_LOG_ENTER();
+
+  // Start the buffer enqueue/dequeue threads if they're not already running.
+  if (!buffer_enqueuer_->isRunning()) {
+    android::status_t res = buffer_enqueuer_->run("Enqueue buffers");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start buffer enqueue thread: %d", res);
+      return -ENODEV;
+    }
+  }
+  if (!buffer_dequeuer_->isRunning()) {
+    android::status_t res = buffer_dequeuer_->run("Dequeue buffers");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start buffer dequeue thread: %d", res);
+      return -ENODEV;
+    }
+  }
+
+  if (!unit_tester_->isRunning()) {
+    android::status_t res = unit_tester_->run("Unit Tester");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start unit test thread: %d", res);
+      return -ENODEV;
+    }
+  }
+
+  HAL_LOGD("Queue thread Running");
+
+  return 0;
+}
+
+int V4L2Camera::StopQueue()
+{
+    HAL_LOG_ENTER();
+
+    if (buffer_enqueuer_->isRunning()) {
+        buffer_enqueuer_->requestExitAndWait();
+    }
+    HAL_LOGD("enqueue buffers thread stoped!");
+
+    if (buffer_dequeuer_->isRunning()){
+        buffer_dequeuer_->requestExitAndWait();
+    }
+
+    HAL_LOGD("deuqueue buffers thread stoped!");
+
+    if (unit_tester_->isRunning())
+        unit_tester_->requestExit();
+    HAL_LOGD("Stop Queue done");
+
+    {
+    std::lock_guard<std::mutex> guard(request_queue_lock_);
+    //clear request_queue_ 
+    while(!request_queue_.empty())
+        request_queue_.pop();
+    }
+
+    return 0;
+}
+
+int V4L2Camera::enqueueRequest(
+    std::shared_ptr<default_camera_hal::CaptureRequest> request) {
+  HAL_LOG_ENTER();
+
+    if (device_->get_stream_status() == 0)
+    {
+        flush_lite();
+        return 0;
+    }
+  // Assume request validated before calling this function.
+  // (For now, always exactly 1 output buffer, no inputs).
+  {
+    std::lock_guard<std::mutex> guard(request_queue_lock_);
+    request_queue_.push(request);
+    requests_available_.notify_one();
+  }
+
+  return 0;
+}
+
+void dump_metadata(const android::CameraMetadata& metadata, std::string file) {
+    HAL_LOGE("Dump metadata start: %s", file.c_str());
+    
+    int fp = open(file.c_str(), O_CREAT |O_RDWR | O_CLOEXEC, 0);
+    if (fp != -1) {
+      metadata.dump(fp);
+    }
+    else {
+      HAL_LOGE("Dump metadata failed: %s", file.c_str());
+    }
+    ::close(fp);
+}
+
+std::shared_ptr<default_camera_hal::CaptureRequest>
+V4L2Camera::dequeueRequest() {
+  std::unique_lock<std::mutex> lock(request_queue_lock_);
+  while (request_queue_.empty() && device_->get_stream_status() == 1) {
+    HAL_LOGV("request_queue_ empty, wait");
+    requests_available_.wait_for(lock, std::chrono::seconds(10));
+//    requests_available_.wait(lock);
+  }
+
+  if (device_->get_stream_status() == 0)
+    return NULL;
+
+  std::shared_ptr<default_camera_hal::CaptureRequest> request =
+      request_queue_.front();
+  request_queue_.pop();
+
+  return request;
+}
+
+bool V4L2Camera::enqueueRequestBuffers() {
+  HAL_LOG_ENTER();
+
+    if (device_->get_stream_status() == 0)
+        return false;
+    // Actually enqueue the buffer for capture.
+    int res = device_->EnqueueRequest();
+    if (res) {
+      HAL_LOGD("Device failed to enqueue buffer.");
+//      completeRequest(request, res);
+      return true;
+    }
+
+  return true;
+}
+
+bool V4L2Camera::dequeueRequestBuffers() {
+  HAL_LOG_ENTER();
+  // Dequeue a buffer.
+  //std::shared_ptr<default_camera_hal::CaptureRequest> request;
+  int res;
+
+  if (device_->get_stream_status() == 0)
+    return false;
+
+  // Get a request from the queue (blocks this thread until one is available).
+  std::shared_ptr<default_camera_hal::CaptureRequest> request =
+      dequeueRequest();
+  if (!request)
+    return false;
+
+  // Assume request validated before being added to the queue
+  // (For now, always exactly 1 output buffer, no inputs).
+
+  // Setting and getting settings are best effort here,
+  // since there's no way to know through V4L2 exactly what
+  // settings are used for a buffer unless we were to enqueue them
+  // one at a time, which would be too slow.
+
+  //metadata_->Dump("/data/local/metadata_enqueueRequestBuffers_meata_0.log");
+  //dump_metadata(request->settings, "/data/local/metadata_enqueueRequestBuffers_request_0.log");
+
+  // Set the requested settings
+  res = metadata_->SetRequestSettings(request->settings);
+  if (res) {
+    HAL_LOGE("Failed to set metadata");
+    completeRequest(request, res);
+    return true;
+  }
+
+  // Replace the requested settings with a snapshot of
+  // the used settings/state immediately before enqueue.
+  res = metadata_->FillResultMetadata(&request->settings);
+  if (res) {
+    // Note: since request is a shared pointer, this may happen if another
+    // thread has already decided to complete the request (e.g. via flushing),
+    // since that locks the metadata (in that case, this failing is fine,
+    // and completeRequest will simply do nothing).
+    HAL_LOGE("Failed to fill result metadata.");
+    completeRequest(request, res);
+    return true;
+  }
+
+  int32_t jpegOrientation = (getCameraId() == 1 ? 270 : 90); 
+  request->settings.update(ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+
+  {
+    int retry = 5;
+    while (retry > 0) {
+        res = device_->DequeueRequest(request);
+        if (device_->get_stream_status() == 0)
+        {
+            HAL_LOGE("get request when stream is offf, we will flush_lite");
+            flush_lite();
+            {
+                std::lock_guard<std::mutex> guard(request_queue_lock_);
+                //clear request_queue_ 
+                while(!request_queue_.empty())
+                    request_queue_.pop();
+            }
+            return false;
+        }
+        if ( res == -EAGAIN)
+            continue;
+        if (!res)
+        {
+            completeRequest(request, res);
+            return true;
+        }
+    }
+    completeRequest(request, res);
+    msleep(100);
+  }
+  return true;
+}
+
+bool V4L2Camera:: unitTest() {
+  HAL_LOG_ENTER();
+  arc::FormatConvert_UnitTest();
+  return false;
+}
+
+bool V4L2Camera::validateDataspacesAndRotations(
+    const camera3_stream_configuration_t* stream_config) {
+  HAL_LOG_ENTER();
+
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    if (stream_config->streams[i]->rotation != CAMERA3_STREAM_ROTATION_0) {
+      HAL_LOGE("Rotation %d for stream %d not supported",
+               stream_config->streams[i]->rotation,
+               i);
+      return false;
+    }
+    // Accept all dataspaces, as it will just be overwritten below anyways.
+  }
+  return true;
+}
+
+int V4L2Camera::setupStreams(camera3_stream_configuration_t* stream_config) {
+  HAL_LOG_ENTER();
+
+  // The framework should be enforcing this, but doesn't hurt to be safe.
+  int res = 0; 
+  if (device_->GetInFlightBufferCount() != 0) {
+    res = device_->StreamOff();
+    if (res) {
+        HAL_LOGE("Device failed to turn off stream for reconfiguration: %d.", res);
+        return -ENODEV;
+    }
+  } 
+
+  // TODO(b/29939583):  V4L2 doesn't actually support more than 1
+  // stream at a time. If not all streams are the same format
+  // and size, error. Note that this means the HAL is not spec-compliant.
+  // Technically, this error should be thrown during validation, but
+  // since it isn't a spec-valid error validation isn't set up to check it.
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    HAL_LOGE(
+        "(stream %d: stream_type %d format %d, width %u, height %u rotation %d max_buffers %d).",
+        i,
+        stream_config->streams[i]->stream_type,
+        stream_config->streams[i]->format,
+        stream_config->streams[i]->width,
+        stream_config->streams[i]->height,
+        stream_config->streams[i]->rotation,
+        stream_config->streams[i]->max_buffers);
+  }
+
+  // stream_config should have been validated; assume at least 1 streametadata->
+  camera3_stream_t* stream = nullptr;
+  int format = 0;
+  uint32_t width = 0;
+  uint32_t height = 0;
+  uint32_t idx = 0;
+
+  //we always use the max size output stream to config hardware
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    if (stream_config->streams[i]->stream_type == CAMERA3_STREAM_OUTPUT) {
+      if ((stream_config->streams[i]->width > width && stream_config->streams[i]->height > height)) {
+          stream = stream_config->streams[i];
+          width = stream->width;
+          height = stream->height;
+          format = stream->format;
+          idx = i;
+      }
+    }
+  }
+  if (stream == nullptr) {
+    HAL_LOGE("no output stream found. return");
+    return -EINVAL;
+  } else {
+    HAL_LOGE("Will configure hw with stream %d", idx);
+  }  
+
+  // Ensure the stream is off.
+  res = device_->StreamOff();
+  if (res) {
+    HAL_LOGE("Device failed to turn off stream for reconfiguration: %d.", res);
+    return -ENODEV;
+  }
+
+  StreamFormat stream_format(format, width, height);
+  uint32_t max_buffers = 0;
+  res = device_->SetFormat(stream_format, &max_buffers);
+  if (res) {
+    HAL_LOGE("Failed to set device to correct format for stream: %d.", res);
+    return -ENODEV;
+  }
+
+  // Sanity check.
+  if (max_buffers < 1) {
+    HAL_LOGE("Setting format resulted in an invalid maximum of %u buffers.",
+             max_buffers);
+    return -ENODEV;
+  }
+
+  // Set all the streams dataspaces, usages, and max buffers.
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    stream = stream_config->streams[i];
+
+    // Override HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED format.
+    if (stream->format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+      stream->format = HAL_PIXEL_FORMAT_RGBA_8888;
+    }
+
+    // Max buffers as reported by the device.
+    stream->max_buffers = max_buffers;
+
+    // Usage: currently using sw graphics.
+    switch (stream->stream_type) {
+      case CAMERA3_STREAM_INPUT:
+        stream->usage = GRALLOC_USAGE_SW_READ_OFTEN;
+        break;
+      case CAMERA3_STREAM_OUTPUT:
+        stream->usage = GRALLOC_USAGE_SW_WRITE_OFTEN;
+        break;
+      case CAMERA3_STREAM_BIDIRECTIONAL:
+        stream->usage =
+            GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN;
+        break;
+      default:
+        // nothing to do.
+        break;
+    }
+
+    // Doesn't matter what was requested, we always use dataspace V0_JFIF.
+    // Note: according to camera3.h, this isn't allowed, but the camera
+    // framework team claims it's underdocumented; the implementation lets the
+    // HAL overwrite it. If this is changed, change the validation above.
+    stream->data_space = HAL_DATASPACE_V0_JFIF;
+  }
+    // Make sure the stream is on (no effect if already on).
+    res = device_->StreamOn();
+    if (res) {
+      HAL_LOGE("Device failed to turn on stream, res=%d", res);
+      // Don't really want to send an error for only the request here,
+      // since this is a full device error.
+      // TODO: Should trigger full flush.
+      return -ENODEV;
+    }
+    res = initDevice();
+    if (res != 0) {
+        HAL_LOGE("Failed to init device res=%d!", res);
+        return res;
+    }
+
+  return 0;
+}
+
+bool V4L2Camera::isValidRequestSettings(
+    const android::CameraMetadata& settings) {
+  if (!metadata_->IsValidRequest(settings)) {
+    HAL_LOGE("Invalid request metadata->");
+    return false;
+  }
+  return true;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_camera.h b/hardware/ntimespace/camera/v4l2_camera.h
new file mode 100644
index 0000000000..f27841281f
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera.h
@@ -0,0 +1,120 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Loosely based on hardware/libhardware/modules/camera/ExampleCamera.h
+
+#ifndef V4L2_CAMERA_HAL_V4L2_CAMERA_H_
+#define V4L2_CAMERA_HAL_V4L2_CAMERA_H_
+
+#include <array>
+#include <condition_variable>
+#include <queue>
+#include <string>
+
+//#include <camera/CameraMetadata.h>
+#include <utils/StrongPointer.h>
+#include <utils/Thread.h>
+#include "camera.h"
+#include "common.h"
+#include "metadata/metadata.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+// V4L2Camera is a specific V4L2-supported camera device. The Camera object
+// contains all logic common between all cameras (e.g. front and back cameras),
+// while a specific camera device (e.g. V4L2Camera) holds all specific
+// metadata and logic about that device.
+class V4L2Camera : public default_camera_hal::Camera {
+ public:
+  // Use this method to create V4L2Camera objects. Functionally equivalent
+  // to "new V4L2Camera", except that it may return nullptr in case of failure.
+  static V4L2Camera* NewV4L2Camera(int id, const std::string path);
+  ~V4L2Camera();
+
+ private:
+  // Constructor private to allow failing on bad input.
+  // Use NewV4L2Camera instead.
+  V4L2Camera(int id,
+             std::shared_ptr<V4L2Wrapper> v4l2_wrapper,
+             std::unique_ptr<Metadata> metadata);
+
+  // default_camera_hal::Camera virtual methods.
+  // Connect to the device: open dev nodes, etc.
+  int connect() override;
+  // Disconnect from the device: close dev nodes, etc.
+  void disconnect() override;
+  // Initialize static camera characteristics for individual device.
+  int initStaticInfo(android::CameraMetadata* out) override;
+  // Initialize a template of the given type.
+  int initTemplate(int type, android::CameraMetadata* out) override;
+  // Initialize device info: resource cost and conflicting devices
+  // (/conflicting devices length).
+  void initDeviceInfo(camera_info_t* info) override;
+  // Extra initialization of device when opened.
+  int initDevice() override;
+  int StopQueue();
+  // Verify stream configuration dataspaces and rotation values
+  bool validateDataspacesAndRotations(
+      const camera3_stream_configuration_t* stream_config) override;
+  // Set up the streams, including seting usage & max_buffers
+  int setupStreams(camera3_stream_configuration_t* stream_config) override;
+  // Verify settings are valid for a capture or reprocessing.
+  bool isValidRequestSettings(const android::CameraMetadata& settings) override;
+  // Enqueue a request to receive data from the camera.
+  int enqueueRequest(
+      std::shared_ptr<default_camera_hal::CaptureRequest> request) override;
+  // Flush in flight buffers.
+  int flushBuffers() override;
+  int GetStreamStatus() override {return device_->get_stream_status();}
+
+  int UpdateVendorStaticInfo(android::CameraMetadata* metadata);
+  
+  // Async request processing helpers.
+  // Dequeue a request from the waiting queue.
+  // Blocks until a request is available.
+  std::shared_ptr<default_camera_hal::CaptureRequest> dequeueRequest();
+
+  // Thread functions. Return true to loop, false to exit.
+  // Pass buffers for enqueued requests to the device.
+  bool enqueueRequestBuffers();
+  // Retreive buffers from the device.
+  bool dequeueRequestBuffers();
+
+  bool unitTest();
+
+  // V4L2 helper.
+  std::shared_ptr<V4L2Wrapper> device_;
+  std::unique_ptr<V4L2Wrapper::Connection> connection_;
+  std::unique_ptr<Metadata> metadata_;
+  std::mutex request_queue_lock_;
+  std::queue<std::shared_ptr<default_camera_hal::CaptureRequest>>
+      request_queue_;
+  // Threads require holding an Android strong pointer.
+  android::sp<android::Thread> buffer_enqueuer_;
+  android::sp<android::Thread> buffer_dequeuer_;
+  std::condition_variable requests_available_;
+
+  android::sp<android::Thread> unit_tester_;
+
+  int32_t max_input_streams_;
+  std::array<int, 3> max_output_streams_;  // {raw, non-stalling, stalling}.
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2Camera);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_CAMERA_H_
diff --git a/hardware/ntimespace/camera/v4l2_camera_hal.cpp b/hardware/ntimespace/camera/v4l2_camera_hal.cpp
new file mode 100644
index 0000000000..f73282d2db
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera_hal.cpp
@@ -0,0 +1,345 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/CameraHAL.cpp
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2CameraHAL"
+
+#include "hardware/camera3.h"
+#include "v4l2_camera_hal.h"
+
+#include <dirent.h>
+#include <fcntl.h>
+#include <linux/videodev2.h>
+#include <sys/ioctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <algorithm>
+#include <cstdlib>
+#include <unordered_set>
+#include <android-base/parseint.h>
+#include "common.h"
+#include "v4l2_camera.h"
+#include "flash.h"
+#include "arc/cached_frame.h"
+#include <cutils/properties.h>
+
+/*
+ * This file serves as the entry point to the HAL. It is modified from the
+ * example default HAL available in hardware/libhardware/modules/camera.
+ * It contains the module structure and functions used by the framework
+ * to load and interface to this HAL, as well as the handles to the individual
+ * camera devices.
+ */
+
+namespace v4l2_camera_hal {
+
+// Default global camera hal.
+static V4L2CameraHAL gCameraHAL;
+int ion_fd = -1;
+bool using_hw;
+
+void open_ion() {
+  if (ion_fd < 0) {
+    ion_fd = open("/dev/ion", O_RDONLY | O_CLOEXEC);
+    if (ion_fd < 0) {
+      LOGF(ERROR) << "open /dev/ion failed!"; 
+      return;
+    }   
+  }
+}
+
+void close_ion() {
+  if (ion_fd > 0) {
+    close(ion_fd);
+    ion_fd = -1;
+  }
+}
+
+void check_convert_mode() {
+  using_hw = false;
+  char value[PROPERTY_VALUE_MAX];
+  if (property_get("camera.debug.convert_mode", value, "hw") && !strcmp("hw", value)) {
+    using_hw = true;
+  }
+}
+
+V4L2CameraHAL::V4L2CameraHAL() : mCameras(), mCallbacks(NULL) {
+  HAL_LOG_ENTER();
+
+  const char kDateTime[] = __DATE__ " " __TIME__ " PST";
+  HAL_LOGE("v4l2 camera hal built time %s", kDateTime);
+
+  // Adds all available V4L2 devices.
+  // List /dev nodes.
+  DIR* dir = opendir("/dev");
+  if (dir == NULL) {
+    HAL_LOGE("Failed to open /dev");
+    return;
+  }
+  // Find /dev/camera* nodes.
+  std::vector<std::string> nodes;
+  std::string desired = "/dev/camera";
+  std::string path = "";
+  for (int i = 0; i < MAX_NODE; i++)
+  {
+    path = desired + std::to_string(i);
+    if (access(path.c_str(), F_OK|R_OK|W_OK) == 0)
+    {
+        nodes.push_back(path);
+        HAL_LOGD("Found video node %s.", nodes.back().c_str());    
+    }
+  }
+
+  // Test each for V4L2 support and uniqueness.
+  std::unordered_set<std::string> buses;
+  std::string bus;
+  v4l2_capability cap;
+  int fd;
+  int id = 0;
+  for (const auto& node : nodes) {
+    HAL_LOGE("Try to open %s ", node.c_str());
+    // Open the node.
+    fd = TEMP_FAILURE_RETRY(open(node.c_str(), O_RDONLY));
+    if (fd < 0) {
+      HAL_LOGE("failed to open %s (%s).", node.c_str(), strerror(errno));
+      continue;
+    }
+    // Read V4L2 capabilities.
+    if (TEMP_FAILURE_RETRY(ioctl(fd, VIDIOC_QUERYCAP, &cap)) != 0) {
+      HAL_LOGE(
+          "VIDIOC_QUERYCAP on %s fail: %s.", node.c_str(), strerror(errno));
+    } else if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE)) {
+      HAL_LOGE("%s is not a V4L2 video capture device.", node.c_str());
+    } else {
+      // If the node is unique, add a camera for it.
+      bus = reinterpret_cast<char*>(cap.bus_info);
+      /*if (buses.insert(bus).second) */{
+        HAL_LOGD("Found unique bus at %s.", node.c_str());
+        std::unique_ptr<V4L2Camera> cam(V4L2Camera::NewV4L2Camera(id++, node));
+        if (cam) {
+          HAL_LOGD("Add camera %s with id %d.", node.c_str(), id - 1);
+          mCameras.push_back(std::move(cam));
+        } else {
+          HAL_LOGE("Failed to initialize camera at %s.", node.c_str());
+        }
+      }
+    }
+    close(fd);
+  }
+
+  open_ion();
+  check_convert_mode();
+  HAL_LOG_EXIT();
+}
+
+V4L2CameraHAL::~V4L2CameraHAL() {
+  HAL_LOG_ENTER();
+  close_ion();
+}
+
+int V4L2CameraHAL::getNumberOfCameras() {
+  HAL_LOGD("returns %zu", mCameras.size());
+  return mCameras.size();
+}
+
+int V4L2CameraHAL::getCameraInfo(int id, camera_info_t* info) {
+  HAL_LOG_ENTER();
+  if (id < 0 || static_cast<size_t>(id) >= mCameras.size()) {
+    return -EINVAL;
+  }
+  // TODO(b/29185945): Hotplugging: return -EINVAL if unplugged.
+  return mCameras[id]->getInfo(info);
+}
+
+int V4L2CameraHAL::setCallbacks(const camera_module_callbacks_t* callbacks) {
+  HAL_LOG_ENTER();
+  mCallbacks = callbacks;
+  return 0;
+}
+
+void V4L2CameraHAL::getVendorTagOps(vendor_tag_ops_t* /*ops*/) {
+  HAL_LOG_ENTER();
+  // No vendor ops for this HAL. From <hardware/camera_common.h>:
+  // "leave ops unchanged if no vendor tags are defined."
+}
+
+int V4L2CameraHAL::openLegacy(const hw_module_t* /*module*/,
+                              const char* id,
+                              uint32_t halVersion,
+                              hw_device_t** /*device*/) {
+  HAL_LOG_ENTER();
+
+  HAL_LOGI("openLegacy halVersion: %d cameraId = %s", halVersion, id);
+
+  // Not supported.
+  return -EINVAL;
+}
+
+int V4L2CameraHAL::setTorchMode(const char* camera_id, bool on) {
+  HAL_LOG_ENTER();
+
+#if SUPPORT_FLASH
+  int retVal(0);
+  long cameraIdLong(-1);
+  int cameraIdInt(-1);
+  char* endPointer = NULL;
+  errno = 0;
+  qcamera::CameraFlash& flash = qcamera::CameraFlash::getInstance();
+
+  cameraIdLong = strtol(camera_id, &endPointer, 10);
+
+  if ((errno == ERANGE) ||
+          (cameraIdLong < 0) ||
+          (cameraIdLong >= static_cast<long>(getNumberOfCameras())) ||
+          (endPointer == camera_id) ||
+          (*endPointer != '\0')) {
+      retVal = -EINVAL;
+  } else if (on) {
+      cameraIdInt = static_cast<int>(cameraIdLong);
+      retVal = flash.initFlash(cameraIdInt);
+
+      if (retVal == 0) {
+          retVal = flash.setFlashMode(cameraIdInt, on);
+          if ((retVal == 0) && (mCallbacks != NULL)) {
+              mCallbacks->torch_mode_status_change(mCallbacks,
+                      camera_id,
+                      TORCH_MODE_STATUS_AVAILABLE_ON);
+          } else if (retVal == -EALREADY) {
+              // Flash is already on, so treat this as a success.
+              retVal = 0;
+          }
+      }
+  } else {
+      cameraIdInt = static_cast<int>(cameraIdLong);
+      retVal = flash.setFlashMode(cameraIdInt, on);
+
+      if (retVal == 0) {
+          retVal = flash.deinitFlash(cameraIdInt);
+          if ((retVal == 0) && (mCallbacks != NULL)) {
+              mCallbacks->torch_mode_status_change(mCallbacks,
+                      camera_id,
+                      TORCH_MODE_STATUS_AVAILABLE_OFF);
+          }
+      } else if (retVal == -EALREADY) {
+          // Flash is already off, so treat this as a success.
+          retVal = 0;
+      }
+  }
+
+  return retVal;
+#else 
+  (void)camera_id;
+  (void)on;
+  return -ENOSYS;
+#endif  
+}
+
+int V4L2CameraHAL::openDevice(const hw_module_t* module,
+                              const char* name,
+                              hw_device_t** device) {
+  HAL_LOG_ENTER();
+
+  if (module != &HAL_MODULE_INFO_SYM.common) {
+    HAL_LOGE(
+        "Invalid module %p expected %p", module, &HAL_MODULE_INFO_SYM.common);
+    return -EINVAL;
+  }
+
+  int id;
+  if (!android::base::ParseInt(name, &id, 0, getNumberOfCameras() - 1)) {
+    return -EINVAL;
+  }
+
+#if SUPPORT_FLASH
+  int rc = qcamera::CameraFlash::getInstance().reserveFlashForCamera(id);
+  if (rc < 0) {
+      HAL_LOGE("Failed to reserve flash for camera id: %d", id);
+      //return -EINVAL;
+  }
+#endif
+
+  // TODO(b/29185945): Hotplugging: return -EINVAL if unplugged.
+  return mCameras[id]->openDevice(module, device);
+}
+
+/*
+ * The framework calls the following wrappers, which in turn
+ * call the corresponding methods of the global HAL object.
+ */
+
+static int get_number_of_cameras() {
+  return gCameraHAL.getNumberOfCameras();
+}
+
+static int get_camera_info(int id, struct camera_info* info) {
+  return gCameraHAL.getCameraInfo(id, info);
+}
+
+static int set_callbacks(const camera_module_callbacks_t* callbacks) {
+  return gCameraHAL.setCallbacks(callbacks);
+}
+
+static void get_vendor_tag_ops(vendor_tag_ops_t* ops) {
+  return gCameraHAL.getVendorTagOps(ops);
+}
+
+static int open_legacy(const hw_module_t* module,
+                       const char* id,
+                       uint32_t halVersion,
+                       hw_device_t** device) {
+  return gCameraHAL.openLegacy(module, id, halVersion, device);
+}
+
+static int set_torch_mode(const char* camera_id, bool enabled) {
+  return gCameraHAL.setTorchMode(camera_id, enabled);
+}
+
+static int open_dev(const hw_module_t* module,
+                    const char* name,
+                    hw_device_t** device) {
+  return gCameraHAL.openDevice(module, name, device);
+}
+
+}  // namespace v4l2_camera_hal
+
+static hw_module_methods_t v4l2_module_methods = {
+    .open = v4l2_camera_hal::open_dev};
+
+camera_module_t HAL_MODULE_INFO_SYM __attribute__((visibility("default"))) = {
+    .common =
+        {
+            .tag = HARDWARE_MODULE_TAG,
+            .module_api_version = CAMERA_MODULE_API_VERSION_2_4,
+            .hal_api_version = HARDWARE_HAL_API_VERSION,
+            .id = CAMERA_HARDWARE_MODULE_ID,
+            .name = "V4L2 Camera HAL v3",
+            .author = "The Android Open Source Project",
+            .methods = &v4l2_module_methods,
+            .dso = nullptr,
+            .reserved = {0},
+        },
+    .get_number_of_cameras = v4l2_camera_hal::get_number_of_cameras,
+    .get_camera_info = v4l2_camera_hal::get_camera_info,
+    .set_callbacks = v4l2_camera_hal::set_callbacks,
+    .get_vendor_tag_ops = v4l2_camera_hal::get_vendor_tag_ops,
+    .open_legacy = v4l2_camera_hal::open_legacy,
+    .set_torch_mode = v4l2_camera_hal::set_torch_mode,
+    .init = nullptr,
+//    .get_physical_camera_info = nullptr,
+    .reserved = {nullptr, nullptr}};
diff --git a/hardware/ntimespace/camera/v4l2_camera_hal.h b/hardware/ntimespace/camera/v4l2_camera_hal.h
new file mode 100644
index 0000000000..b99b627b7b
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera_hal.h
@@ -0,0 +1,74 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/CameraHAL.h
+
+#ifndef V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
+#define V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
+
+#include <vector>
+
+#include <hardware/camera_common.h>
+#include <hardware/hardware.h>
+
+#include "camera.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+/*
+ * V4L2CameraHAL contains all module state that isn't specific to an
+ * individual camera device. This class is based off of the sample
+ * default CameraHAL from /hardware/libhardware/modules/camera.
+ */
+class V4L2CameraHAL {
+ public:
+  V4L2CameraHAL();
+  ~V4L2CameraHAL();
+
+  // Camera Module Interface (see <hardware/camera_common.h>).
+  int getNumberOfCameras();
+  int getCameraInfo(int camera_id, camera_info_t* info);
+  int setCallbacks(const camera_module_callbacks_t* callbacks);
+  void getVendorTagOps(vendor_tag_ops_t* ops);
+  int openLegacy(const hw_module_t* module,
+                 const char* id,
+                 uint32_t halVersion,
+                 hw_device_t** device);
+  int setTorchMode(const char* camera_id, bool on);
+
+  // Hardware Module Interface (see <hardware/hardware.h>).
+  int openDevice(const hw_module_t* mod, const char* name, hw_device_t** dev);
+
+ private:
+  // Vector of cameras.
+  std::vector<std::unique_ptr<default_camera_hal::Camera>> mCameras;
+  // Callback handle.
+  const camera_module_callbacks_t* mCallbacks;
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2CameraHAL);
+};
+
+extern int ion_fd;
+extern bool using_hw;
+}  // namespace v4l2_camera_hal
+
+extern camera_module_t HAL_MODULE_INFO_SYM;
+
+
+#define MAX_NODE 2
+#define MM_CAMERA_MAX_NUM_SENSORS MAX_NODE
+
+#endif  // V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
diff --git a/hardware/ntimespace/camera/v4l2_metadata_factory.cpp b/hardware/ntimespace/camera/v4l2_metadata_factory.cpp
new file mode 100644
index 0000000000..6f3f49245e
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_metadata_factory.cpp
@@ -0,0 +1,601 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2MetadataFactory"
+
+#include "v4l2_metadata_factory.h"
+
+#include "metadata/camera_metadata.h"
+#include "common.h"
+#include "format_metadata_factory.h"
+#include "metadata/boottime_state_delegate.h"
+#include "metadata/control.h"
+#include "metadata/enum_converter.h"
+#include "metadata/partial_metadata_factory.h"
+#include "metadata/property.h"
+#include "metadata/scaling_converter.h"
+#include "flash.h"
+
+namespace v4l2_camera_hal {
+
+// According to spec, each unit of V4L2_CID_AUTO_EXPOSURE_BIAS is 0.001 EV.
+//const camera_metadata_rational_t kAeCompensationUnit = {1, 1000};
+// According to spec, each unit of V4L2_CID_EXPOSURE_ABSOLUTE is 100 us.
+const int64_t kV4L2ExposureTimeStepNs = 100000;
+// According to spec, each unit of V4L2_CID_ISO_SENSITIVITY is ISO/1000.
+const int32_t kV4L2SensitivityDenominator = 1000;
+// Generously allow up to 6MB (the largest size on the RPi Camera is about 5MB).
+const size_t kV4L2MaxJpegSize = 6000000;
+
+int GetV4L2Metadata(std::shared_ptr<V4L2Wrapper> device,
+                    std::unique_ptr<Metadata>* result) {
+  HAL_LOG_ENTER();
+
+  // Open a temporary connection to the device for all the V4L2 querying
+  // that will be happening (this could be done for each component individually,
+  // but doing it here prevents connecting and disconnecting for each one).
+  V4L2Wrapper::Connection temp_connection = V4L2Wrapper::Connection(device);
+  if (temp_connection.status()) {
+    HAL_LOGE("Failed to connect to device: %d.", temp_connection.status());
+    return temp_connection.status();
+  }
+
+  //return 0;
+  // TODO(b/30035628): Add states.
+
+  PartialMetadataSet components;
+
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES,
+      {ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST,
+       ANDROID_COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST}}));
+
+#if 0
+  // TODO(b/30510395): subcomponents of 3A.
+  // In general, default to ON/AUTO since they imply pretty much nothing,
+  // while OFF implies guarantees about not hindering performance.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 3>>(ANDROID_CONTROL_MAX_REGIONS,
+                                           {{/*AE*/ 0, /*AWB*/ 0, /*AF*/ 0}})));
+#endif
+#if 0
+  // TODO(b/30921166): V4L2_CID_AUTO_EXPOSURE_BIAS is an int menu, so
+  // this will be falling back to NoEffect until int menu support is added.
+  components.insert(V4L2ControlOrDefault<int32_t>(
+      ControlType::kSlider,
+      ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION,
+      ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+      device,
+      V4L2_CID_AUTO_EXPOSURE_BIAS,
+      // No scaling necessary, AE_COMPENSATION_STEP handles this.
+      std::make_shared<ScalingConverter<int32_t, int32_t>>(1, 1),
+      0,
+      {{OTHER_TEMPLATES, 0}}));
+#endif
+#if 0
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<camera_metadata_rational_t>(
+          ANDROID_CONTROL_AE_COMPENSATION_STEP, kAeCompensationUnit)));
+#endif
+#if 0
+  // TODO(b/31021522): Autofocus subcomponent.
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AF_MODE,
+                                   ANDROID_CONTROL_AF_AVAILABLE_MODES,
+                                   {ANDROID_CONTROL_AF_MODE_OFF}));
+#endif
+  // TODO(b/31021522): Should read autofocus state from
+  // V4L2_CID_AUTO_FOCUS_STATUS bitmask. The framework gets a little more
+  // complex than that does; there's a whole state-machine table in
+  // the docs (system/media/camera/docs/docs.html).
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AF_STATE,
+                                        ANDROID_CONTROL_AF_STATE_INACTIVE));
+  // TODO(b/31022735): Correctly implement AE & AF triggers that
+  // actually do something. These no effect triggers are even worse than most
+  // of the useless controls in this class, since technically they should
+  // revert back to IDLE eventually after START/CANCEL, but for now they won't
+  // unless IDLE is requested.
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AF_TRIGGER,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AF_TRIGGER_IDLE,
+                                    ANDROID_CONTROL_AF_TRIGGER_START,
+                                    ANDROID_CONTROL_AF_TRIGGER_CANCEL}));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER,
+      DO_NOT_REPORT_OPTIONS,
+      {ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_IDLE,
+       ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_START,
+       ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL}));
+#if 0
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AE_ANTIBANDING_MODE,
+      ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+      device,
+      V4L2_CID_POWER_LINE_FREQUENCY,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+          new EnumConverter({{V4L2_CID_POWER_LINE_FREQUENCY_DISABLED,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_50HZ,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_50HZ},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_60HZ,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_60HZ},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_AUTO,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO}})),
+      ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO,
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO}}));
+#endif
+  std::unique_ptr<PartialMetadataInterface> exposure_time =
+      V4L2Control<int64_t>(ControlType::kSlider,
+                           ANDROID_SENSOR_EXPOSURE_TIME,
+                           ANDROID_SENSOR_INFO_EXPOSURE_TIME_RANGE,
+                           device,
+                           V4L2_CID_EXPOSURE_ABSOLUTE,
+                           std::make_shared<ScalingConverter<int64_t, int32_t>>(
+                               kV4L2ExposureTimeStepNs, 1));
+  // TODO(b/31037072): Sensitivity has additional V4L2 controls
+  // (V4L2_CID_ISO_SENSITIVITY_AUTO), so this control currently has
+  // undefined behavior.
+  // TODO(b/30921166): V4L2_CID_ISO_SENSITIVITY is an int menu, so
+  // this will return nullptr until that is added.
+  std::unique_ptr<PartialMetadataInterface> sensitivity =
+      V4L2Control<int32_t>(ControlType::kSlider,
+                           ANDROID_SENSOR_SENSITIVITY,
+                           ANDROID_SENSOR_INFO_SENSITIVITY_RANGE,
+                           device,
+                           V4L2_CID_ISO_SENSITIVITY,
+                           std::make_shared<ScalingConverter<int32_t, int32_t>>(
+                               1, kV4L2SensitivityDenominator));
+  std::multimap<int32_t, uint8_t> ae_mode_mapping = {
+      {V4L2_EXPOSURE_AUTO, ANDROID_CONTROL_AE_MODE_ON}};
+  if (exposure_time && sensitivity) {
+    // TODO(b/30510395): as part of coordinated 3A component,
+    // if these aren't available don't advertise AE mode OFF, only AUTO.
+    components.insert(std::move(exposure_time));
+    components.insert(std::move(sensitivity));
+    ae_mode_mapping.emplace(V4L2_EXPOSURE_MANUAL, ANDROID_CONTROL_AE_MODE_OFF);
+  }
+#if 0
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AE_MODE,
+      ANDROID_CONTROL_AE_AVAILABLE_MODES,
+      device,
+      V4L2_CID_EXPOSURE_AUTO,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+          new EnumConverter(ae_mode_mapping)),
+      ANDROID_CONTROL_AE_MODE_ON,
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AE_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AE_MODE_ON}}));
+#endif
+  // Can't get AE status from V4L2.
+  // TODO(b/30510395): If AE mode is OFF, this should switch to INACTIVE.
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AE_STATE,
+                                        ANDROID_CONTROL_AE_STATE_CONVERGED));
+  // V4L2 offers multiple white balance interfaces. Try the advanced one before
+  // falling
+  // back to the simpler version.
+  // Modes from each API that don't match up:
+  // Android: WARM_FLUORESCENT, TWILIGHT.
+  // V4L2: FLUORESCENT_H, HORIZON, FLASH.
+  std::unique_ptr<PartialMetadataInterface> awb(V4L2Control<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AWB_MODE,
+      ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+      device,
+      V4L2_CID_AUTO_N_PRESET_WHITE_BALANCE,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_WHITE_BALANCE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+           {V4L2_WHITE_BALANCE_AUTO, ANDROID_CONTROL_AWB_MODE_AUTO},
+           {V4L2_WHITE_BALANCE_INCANDESCENT,
+            ANDROID_CONTROL_AWB_MODE_INCANDESCENT},
+           {V4L2_WHITE_BALANCE_FLUORESCENT,
+            ANDROID_CONTROL_AWB_MODE_FLUORESCENT},
+           {V4L2_WHITE_BALANCE_DAYLIGHT, ANDROID_CONTROL_AWB_MODE_DAYLIGHT},
+           {V4L2_WHITE_BALANCE_CLOUDY,
+            ANDROID_CONTROL_AWB_MODE_CLOUDY_DAYLIGHT},
+           {V4L2_WHITE_BALANCE_SHADE, ANDROID_CONTROL_AWB_MODE_SHADE}})),
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AWB_MODE_AUTO}}));
+  if (awb) {
+    components.insert(std::move(awb));
+  } else {
+    // Fall back to simpler AWB or even just an ignored control.
+    components.insert(V4L2ControlOrDefault<uint8_t>(
+        ControlType::kMenu,
+        ANDROID_CONTROL_AWB_MODE,
+        ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+        device,
+        V4L2_CID_AUTO_WHITE_BALANCE,
+        std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+            new EnumConverter({{0, ANDROID_CONTROL_AWB_MODE_OFF},
+                               {1, ANDROID_CONTROL_AWB_MODE_AUTO}})),
+        ANDROID_CONTROL_AWB_MODE_AUTO,
+        {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+         {OTHER_TEMPLATES, ANDROID_CONTROL_AWB_MODE_AUTO}}));
+  }
+  // TODO(b/31041577): Handle AWB state machine correctly.
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AWB_STATE,
+                                        ANDROID_CONTROL_AWB_STATE_CONVERGED));
+  // TODO(b/31022153): 3A locks.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_CONTROL_AE_LOCK_AVAILABLE,
+                            ANDROID_CONTROL_AE_LOCK_AVAILABLE_FALSE)));
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AE_LOCK,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AE_LOCK_OFF, ANDROID_CONTROL_AE_LOCK_ON}));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_CONTROL_AWB_LOCK_AVAILABLE,
+                            ANDROID_CONTROL_AWB_LOCK_AVAILABLE_TRUE)));
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AWB_LOCK,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AWB_LOCK_OFF}));
+  // TODO(b/30510395): subcomponents of scene modes
+  // (may itself be a subcomponent of 3A).
+  // Modes from each API that don't match up:
+  // Android: FACE_PRIORITY, ACTION, NIGHT_PORTRAIT, THEATRE, STEADYPHOTO,
+  // BARCODE, HIGH_SPEED_VIDEO.
+  // V4L2: BACKLIGHT, DAWN_DUSK, FALL_COLORS, TEXT.
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_SCENE_MODE,
+      ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+      device,
+      V4L2_CID_SCENE_MODE,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_SCENE_MODE_NONE, ANDROID_CONTROL_SCENE_MODE_DISABLED},
+           {V4L2_SCENE_MODE_BEACH_SNOW, ANDROID_CONTROL_SCENE_MODE_BEACH},
+           {V4L2_SCENE_MODE_BEACH_SNOW, ANDROID_CONTROL_SCENE_MODE_SNOW},
+           {V4L2_SCENE_MODE_CANDLE_LIGHT,
+            ANDROID_CONTROL_SCENE_MODE_CANDLELIGHT},
+           {V4L2_SCENE_MODE_FIREWORKS, ANDROID_CONTROL_SCENE_MODE_FIREWORKS},
+           {V4L2_SCENE_MODE_LANDSCAPE, ANDROID_CONTROL_SCENE_MODE_LANDSCAPE},
+           {V4L2_SCENE_MODE_NIGHT, ANDROID_CONTROL_SCENE_MODE_NIGHT},
+           {V4L2_SCENE_MODE_PARTY_INDOOR, ANDROID_CONTROL_SCENE_MODE_PARTY},
+           {V4L2_SCENE_MODE_SPORTS, ANDROID_CONTROL_SCENE_MODE_SPORTS},
+           {V4L2_SCENE_MODE_SUNSET, ANDROID_CONTROL_SCENE_MODE_SUNSET}})),
+      ANDROID_CONTROL_SCENE_MODE_DISABLED));
+#if 0
+  // TODO(b/31022612): Scene mode overrides.
+  // Modes from each API that don't match up:
+  // Android: POSTERIZE, WHITEBOARD, BLACKBOARD.
+  // V4L2: ANTIQUE, ART_FREEZE, EMBOSS, GRASS_GREEN, SKETCH, SKIN_WHITEN,
+  // SKY_BLUE, SILHOUETTE, VIVID, SET_CBCR.
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_EFFECT_MODE,
+      ANDROID_CONTROL_AVAILABLE_EFFECTS,
+      device,
+      V4L2_CID_COLORFX,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_COLORFX_NONE, ANDROID_CONTROL_EFFECT_MODE_OFF},
+           {V4L2_COLORFX_BW, ANDROID_CONTROL_EFFECT_MODE_MONO},
+           {V4L2_COLORFX_NEGATIVE, ANDROID_CONTROL_EFFECT_MODE_NEGATIVE},
+           {V4L2_COLORFX_SOLARIZATION, ANDROID_CONTROL_EFFECT_MODE_SOLARIZE},
+           {V4L2_COLORFX_SEPIA, ANDROID_CONTROL_EFFECT_MODE_SEPIA},
+           {V4L2_COLORFX_AQUA, ANDROID_CONTROL_EFFECT_MODE_AQUA}})),
+      ANDROID_CONTROL_EFFECT_MODE_OFF));
+#endif
+  // TODO(b/31021654): This should behave as a top level switch, not no effect.
+  // Should enforce being set to USE_SCENE_MODE when a scene mode is requested.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_MODE,
+      ANDROID_CONTROL_AVAILABLE_MODES,
+      {ANDROID_CONTROL_MODE_AUTO, ANDROID_CONTROL_MODE_USE_SCENE_MODE}));
+
+  // Not sure if V4L2 does or doesn't do this, but HAL documentation says
+  // all devices must support FAST, and FAST can be equivalent to OFF, so
+  // either way it's fine to list. And if FAST is included, HIGH_QUALITY
+  // is supposed to be included as well.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_EDGE_MODE,
+      ANDROID_EDGE_AVAILABLE_EDGE_MODES,
+      {ANDROID_EDGE_MODE_FAST, ANDROID_EDGE_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE, ANDROID_EDGE_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_EDGE_MODE_FAST}}));
+
+#if SUPPORT_FLASH
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_FLASH_INFO_AVAILABLE, ANDROID_FLASH_INFO_AVAILABLE_TRUE)));
+  components.insert(FixedState<uint8_t>(ANDROID_FLASH_STATE,
+                                        ANDROID_FLASH_STATE_UNAVAILABLE));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_FLASH_MODE, DO_NOT_REPORT_OPTIONS, {ANDROID_FLASH_MODE_OFF}));
+#else
+  // TODO(b/31023454): subcomponents of flash.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_FLASH_INFO_AVAILABLE, ANDROID_FLASH_INFO_AVAILABLE_FALSE)));
+  components.insert(FixedState<uint8_t>(ANDROID_FLASH_STATE,
+                                        ANDROID_FLASH_STATE_UNAVAILABLE));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_FLASH_MODE, DO_NOT_REPORT_OPTIONS, {ANDROID_FLASH_MODE_OFF}));
+#endif
+
+  // TODO(30510395): subcomponents of hotpixel.
+  // No known V4L2 hot pixel correction. But it might be happening,
+  // so we report FAST/HIGH_QUALITY.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_HOT_PIXEL_MODE,
+      ANDROID_HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES,
+      {ANDROID_HOT_PIXEL_MODE_FAST, ANDROID_HOT_PIXEL_MODE_HIGH_QUALITY}));
+  // ON only needs to be supported for RAW capable devices.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES,
+      {ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE_OFF}));
+
+  // TODO(30510395): subcomponents focus/lens.
+  // No way to actually get the aperture and focal length
+  // in V4L2, but they're required keys, so fake them.
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_APERTURE,
+                                 ANDROID_LENS_INFO_AVAILABLE_APERTURES,
+                                 {2.0}));  // RPi camera v2 is f/2.0.
+  // Always assume external-facing.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_LENS_FACING, ANDROID_LENS_FACING_EXTERNAL)));
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FOCAL_LENGTH,
+                                 ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
+                                 {3.04}));  // RPi camera v2 is 3.04mm.
+  // No known way to get filter densities from V4L2,
+  // report 0 to indicate this control is not supported.
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FILTER_DENSITY,
+                                 ANDROID_LENS_INFO_AVAILABLE_FILTER_DENSITIES,
+                                 {0.0}));
+  // V4L2 focal units do not correspond to a particular physical unit.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION,
+          ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION_UNCALIBRATED)));
+  // TODO(b/31022711): Focus distance component.
+  // Using a NoEffectMenuControl for now because for
+  // fixed-focus it meets expectations. Framework may allow
+  // setting any value and expect it to be clamped to 0, in which
+  // case this will have unexpected behavior (failing on non-0 settings).
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FOCUS_DISTANCE,
+                                 ANDROID_LENS_INFO_MINIMUM_FOCUS_DISTANCE,
+                                 {0}));
+  // Hypefocal distance doesn't mean much for a fixed-focus uncalibrated device.
+  components.insert(std::make_unique<Property<float>>(
+      ANDROID_LENS_INFO_HYPERFOCAL_DISTANCE, 0));
+
+  // No way to know when the lens is moving or not in V4L2.
+  components.insert(
+      FixedState<uint8_t>(ANDROID_LENS_STATE, ANDROID_LENS_STATE_STATIONARY));
+  // No known V4L2 lens shading. But it might be happening,
+  // so report FAST/HIGH_QUALITY.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_SHADING_MODE,
+      ANDROID_SHADING_AVAILABLE_MODES,
+      {ANDROID_SHADING_MODE_FAST, ANDROID_SHADING_MODE_HIGH_QUALITY}));
+  // ON only needs to be supported for RAW capable devices.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_LENS_SHADING_MAP_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES,
+      {ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF}));
+  // V4L2 doesn't differentiate between OPTICAL and VIDEO stabilization,
+  // so only report one (and report the other as OFF).
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+      ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+      device,
+      V4L2_CID_IMAGE_STABILIZATION,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{0, ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF},
+           {1, ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_ON}})),
+      ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+      ANDROID_LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION,
+      {ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF}));
+  // TODO(b/31017806): This should definitely have a different default depending
+  // on template.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_CAPTURE_INTENT,
+      DO_NOT_REPORT_OPTIONS,
+      {ANDROID_CONTROL_CAPTURE_INTENT_CUSTOM,
+       ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW,
+       ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE,
+       ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD,
+       ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT,
+       ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG,
+       ANDROID_CONTROL_CAPTURE_INTENT_MANUAL},
+      {{CAMERA3_TEMPLATE_PREVIEW, ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW},
+       {CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE},
+      // {CAMERA3_TEMPLATE_VIDEO_RECORD,
+      //  ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD},
+     //  {CAMERA3_TEMPLATE_VIDEO_SNAPSHOT,
+     //   ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT},
+     //  {CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+     //   ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG},
+     //  {CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_CAPTURE_INTENT_MANUAL},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_CAPTURE_INTENT_CUSTOM}}));
+
+  // Unable to control noise reduction in V4L2 devices,
+  // but FAST is allowed to be the same as OFF,
+  // and HIGH_QUALITY can be the same as FAST.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_NOISE_REDUCTION_MODE,
+      ANDROID_NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES,
+      {ANDROID_NOISE_REDUCTION_MODE_FAST,
+       ANDROID_NOISE_REDUCTION_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_NOISE_REDUCTION_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_NOISE_REDUCTION_MODE_FAST}}));
+
+  // TODO(30510395): subcomponents of formats/streams.
+  // For now, no thumbnails available (only [0,0], the "no thumbnail" size).
+  // TODO(b/29580107): Could end up with a mismatch between request & result,
+  // since V4L2 doesn't actually allow for thumbnail size control.
+  components.insert(NoEffectMenuControl<std::array<int32_t, 2>>(
+      ANDROID_JPEG_THUMBNAIL_SIZE,
+      ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+      {{{0, 0}}}));
+  // TODO(b/31022752): Get this from the device, not constant.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_JPEG_MAX_SIZE, kV4L2MaxJpegSize)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_JPEG_ORIENTATION, 0)));
+
+  // TODO(b/31021672): Other JPEG controls (GPS, quality, orientation).
+  // TODO(b/29939583): V4L2 can only support 1 stream at a time.
+  // For now, just reporting minimum allowable for LIMITED devices.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 3>>(
+          ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+          {{/* Raw */ 0, /* Non-stalling */ 2, /* Stalling */ 1}})));
+  // Reprocessing not supported.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, 0)));
+  // No way to know pipeline depth for V4L2, so fake with max allowable latency.
+  // Doesn't mean much without per-frame controls anyways.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_REQUEST_PIPELINE_MAX_DEPTH, 4)));
+  components.insert(FixedState<uint8_t>(ANDROID_REQUEST_PIPELINE_DEPTH, 4));
+  // "LIMITED devices are strongly encouraged to use a non-negative value.
+  // If UNKNOWN is used here then app developers do not have a way to know
+  // when sensor settings have been applied." - Unfortunately, V4L2 doesn't
+  // really help here either. Could even be that adjusting settings mid-stream
+  // blocks in V4L2, and should be avoided.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<int32_t>(
+          ANDROID_SYNC_MAX_LATENCY, ANDROID_SYNC_MAX_LATENCY_UNKNOWN)));
+  // Never know when controls are synced.
+  components.insert(FixedState<int64_t>(ANDROID_SYNC_FRAME_NUMBER,
+                                        ANDROID_SYNC_FRAME_NUMBER_UNKNOWN));
+
+  // TODO(b/31022480): subcomponents of cropping/sensors.
+  // Need ANDROID_SCALER_CROP_REGION control support.
+  // V4L2 VIDIOC_CROPCAP doesn't give a way to query this;
+  // it's driver dependent. For now, assume freeform, and
+  // some cameras may just behave badly.
+  // TODO(b/29579652): Figure out a way to determine this.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<float>(ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM, 1)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_SCALER_CROPPING_TYPE,
+                            ANDROID_SCALER_CROPPING_TYPE_FREEFORM)));
+  // Spoof pixel array size for now, eventually get from CROPCAP.
+  std::array<int32_t, 2> pixel_array_size = {{3280, 2464}};
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 2>>(ANDROID_SENSOR_INFO_PIXEL_ARRAY_SIZE,
+                                           pixel_array_size)));
+  // Active array size is {x-offset, y-offset, width, height}, relative to
+  // the pixel array size, with {0, 0} being the top left. Since there's no way
+  // to get this in V4L2, assume the full pixel array is the active array.
+  std::array<int32_t, 4> active_array_size = {
+      {0, 0, pixel_array_size[0], pixel_array_size[1]}};
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 4>>(
+          ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE, active_array_size)));
+  // This is really more freeform than a menu control, but since we're
+  // restricting it to not being used anyways this works for now.
+  components.insert(NoEffectMenuControl<std::array<int32_t, 4>>(
+      ANDROID_SCALER_CROP_REGION, DO_NOT_REPORT_OPTIONS, {active_array_size}));
+  // No way to get in V4L2, so faked. RPi camera v2 is 3.674 x 2.760 mm.
+  // Physical size is used in framework calculations (field of view,
+  // pixel pitch, etc.), so faking it may have unexpected results.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<float, 2>>(ANDROID_SENSOR_INFO_PHYSICAL_SIZE,
+                                         {{3.674, 2.760}})));
+  // HAL uses BOOTTIME timestamps.
+  // TODO(b/29457051): make sure timestamps are consistent throughout the HAL.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE,
+                            ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE_UNKNOWN)));
+  components.insert(std::make_unique<State<int64_t>>(
+      ANDROID_SENSOR_TIMESTAMP, std::make_unique<BoottimeStateDelegate>()));
+  // No way to actually get shutter skew from V4L2.
+  components.insert(
+      FixedState<int64_t>(ANDROID_SENSOR_ROLLING_SHUTTER_SKEW, 0));
+  // No way to actually get orientation from V4L2.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_SENSOR_ORIENTATION, 90)));
+  // TODO(b/31023611): Sensor frame duration. Range should
+  // be dependent on the stream configuration being used.
+  // No test patterns supported.
+  components.insert(
+      NoEffectMenuControl<int32_t>(ANDROID_SENSOR_TEST_PATTERN_MODE,
+                                   ANDROID_SENSOR_AVAILABLE_TEST_PATTERN_MODES,
+                                   {ANDROID_SENSOR_TEST_PATTERN_MODE_OFF}));
+
+  // TODO(b/30510395): subcomponents of face detection.
+  // Face detection not supported.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_FACE_DETECT_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES,
+      {ANDROID_STATISTICS_FACE_DETECT_MODE_OFF}));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_STATISTICS_INFO_MAX_FACE_COUNT, 0)));
+
+  // No way to get detected scene flicker from V4L2.
+  components.insert(FixedState<uint8_t>(ANDROID_STATISTICS_SCENE_FLICKER,
+                                        ANDROID_STATISTICS_SCENE_FLICKER_NONE));
+
+  // TOOD(b/31023265): V4L2_CID_FLASH_INDICATOR_INTENSITY could be queried
+  // to see if there's a transmit LED. Would need to translate HAL off/on
+  // enum to slider min/max value. For now, no LEDs available.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_LED_AVAILABLE_LEDS, {})));
+
+  /* Capabilities. */
+  // The V4L2Metadata pretends to at least meet the
+  // "LIMITED" and "BACKWARD_COMPATIBLE" functionality requirements.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL,
+                            ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::vector<uint8_t>>(
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES,
+          {ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE})));
+
+  // Request is unused, and can be any value,
+  // but that value needs to be propagated.
+  components.insert(NoEffectOptionlessControl<int32_t>(ANDROID_REQUEST_ID, 0));
+
+  // Metadata is returned in a single result; not multiple pieces.
+  components.insert(std::make_unique<Property<int32_t>>(
+      ANDROID_REQUEST_PARTIAL_RESULT_COUNT, 1));
+
+  int res =
+      AddFormatComponents(device, std::inserter(components, components.end()));
+  if (res) {
+    HAL_LOGE("Failed to initialize format components.");
+    return res;
+  }
+
+  *result = std::make_unique<Metadata>(std::move(components));
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_metadata_factory.h b/hardware/ntimespace/camera/v4l2_metadata_factory.h
new file mode 100644
index 0000000000..f25a370ff3
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_metadata_factory.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
+#define V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
+
+#include <memory>
+
+#include "metadata/metadata.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A static function to get a Metadata object populated with V4L2 or other
+// controls as appropriate.
+int GetV4L2Metadata(std::shared_ptr<V4L2Wrapper> device,
+                    std::unique_ptr<Metadata>* result);
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
new file mode 100644
index 0000000000..f794a6b708
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -0,0 +1,1136 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Wrapper"
+
+#include "v4l2_wrapper.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "arc/cached_frame.h"
+#include "android-base/properties.h"
+#include "debug.h"
+
+namespace v4l2_camera_hal {
+
+using arc::V4L2FrameBuffer;
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+using default_camera_hal::CaptureRequest;
+
+const int32_t kStandardSizes[][2] = {
+  {4096, 2160}, // 4KDCI (for USB camera)
+  {3840, 2160}, // 4KUHD (for USB camera)
+  {3280, 2464}, // 8MP
+  {2560, 1440}, // QHD
+  {1920, 1080}, // HD1080
+  {1640, 1232}, // 2MP
+  {1280,  720}, // HD
+  {1024,  768}, // XGA
+  { 960,  540}, // VGA
+  { 640,  480}, // VGA
+  { 640,  360}, // VGA
+  { 320,  240}, // QVGA
+  { 176,  144}  // QCIF
+};
+
+V4L2Wrapper* V4L2Wrapper::NewV4L2Wrapper(const std::string device_path, int camera_id) {
+  return new V4L2Wrapper(device_path, camera_id);
+}
+
+V4L2Wrapper::V4L2Wrapper(const std::string device_path, int camera_id)
+    : device_path_(std::move(device_path)), connection_count_(0) {
+      HAL_LOG_ENTER();
+      camera_id_ = camera_id;
+      camera_share_fd_ = -1;
+      last_index_ = -1;
+      last_dq_index = -1;
+      stream_status = 0;
+      dump_data_init();
+      get_gpu_pixel_alignment();
+    }
+
+V4L2Wrapper::~V4L2Wrapper() {}
+
+inline std::string V4L2Wrapper::FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+int V4L2Wrapper::Connect() {
+  HAL_LOG_ENTER();
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connected()) {
+    HAL_LOGV("Camera device %s is already connected.", device_path_.c_str());
+    ++connection_count_;
+    return 0;
+  }
+
+  if (camera_share_fd_ > 0)
+    close(camera_share_fd_);
+  camera_share_fd_ = -1;
+  last_index_ = -1;  
+  last_dq_index = 0;
+  // Open in nonblocking mode (DQBUF may return EAGAIN).
+  int fd = TEMP_FAILURE_RETRY(open(device_path_.c_str(), O_RDONLY | O_NONBLOCK));
+  if (fd < 0) {
+    HAL_LOGE("failed to open %s (%s)", device_path_.c_str(), strerror(errno));
+    return -ENODEV;
+  }
+  device_fd_.reset(fd);
+  ++connection_count_;
+
+  // Check if this connection has the extended control query capability.
+  v4l2_query_ext_ctrl query;
+  query.id = V4L2_CTRL_FLAG_NEXT_CTRL | V4L2_CTRL_FLAG_NEXT_COMPOUND;
+  extended_query_supported_ = (IoctlLocked(VIDIOC_QUERY_EXT_CTRL, &query) == 0);
+
+  //camera id 0: back, facing 0
+  //camera id 1: front, facing 1
+  //other id: facing 0
+  int facing = (camera_id_ == 1 ? 1 : 0);
+  struct v4l2_control ctrl;
+  memset(&ctrl, 0, sizeof(ctrl));
+  ctrl.id = CID_SET_FACING;
+  ctrl.value = facing;
+  ctrl.value = 1;
+  if (IoctlLocked(VIDIOC_S_CTRL, &ctrl) != 0)
+  {
+      HAL_LOGE("%s(%d) set facing info failed", __FUNCTION__, __LINE__);
+  }
+  HAL_LOGE("VIDIOC_S_CTRL CID_SET_FACING val = %d", ctrl.value);
+
+  if (IoctlLocked(VIDIOC_G_CTRL, &ctrl) != 0)
+  {
+      HAL_LOGE("%s(%d) get facing info failed", __FUNCTION__, __LINE__);
+  }
+  else
+  {
+      HAL_LOGE("VIDIOC_G_CTRL CID_SET_FACING val = %d", ctrl.value);
+  }
+
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at device_path_ may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so Connect() is never called on an unsupported camera)
+
+  supported_formats_ = GetSupportedFormats();
+  qualified_formats_ = StreamFormat::GetQualifiedFormats(supported_formats_);
+
+  HAL_LOG_EXIT();
+
+  return 0;
+}
+
+void V4L2Wrapper::Disconnect() {
+  HAL_LOG_ENTER();
+  HAL_LOGD("Disconnect...");
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connection_count_ == 0) {
+    // Not connected.
+    HAL_LOGE("Camera device %s is not connected, cannot disconnect.",
+             device_path_.c_str());
+    return;
+  }
+
+  --connection_count_;
+  if (connection_count_ > 0) {
+    HAL_LOGV("Disconnected from camera device %s. %d connections remain.",
+             device_path_.c_str(), connection_count_);
+    return;
+  }
+
+  device_fd_.reset(-1);  // Includes close().
+  format_.reset();
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+    buffers_.clear();
+  }
+
+  if (camera_share_fd_ > 0){
+    close(camera_share_fd_);
+    camera_share_fd_ = -1;
+  }
+}
+
+// Helper function. Should be used instead of ioctl throughout this class.
+template <typename T>
+int V4L2Wrapper::IoctlLocked(unsigned long request, T data) {
+  // Potentially called so many times logging entry is a bad idea.
+  std::lock_guard<std::mutex> lock(device_lock_);
+
+  HAL_LOG_ENTER();
+
+  if (!connected()) {
+    HAL_LOGE("Device %s not connected.", device_path_.c_str());
+    return -ENODEV;
+  }
+  return TEMP_FAILURE_RETRY(ioctl(device_fd_.get(), request, data));
+}
+
+int V4L2Wrapper::StreamOn() {
+  HAL_LOG_ENTER();
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before turning on stream.");
+    return -EINVAL;
+  }
+
+  int32_t buffer_numbers = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  if (IoctlLocked(VIDIOC_STREAMON, &buffer_numbers) < 0) {
+    HAL_LOGE("STREAMON fails (%d): %s", errno, strerror(errno));
+    return -ENODEV;
+  }
+
+  stream_status = 1;
+  HAL_LOGD("Stream turned on.");
+  return 0;
+}
+
+int V4L2Wrapper::StreamOff() {
+  HAL_LOG_ENTER();
+  stream_status = 0;
+  buffer_queue_notify_.notify_one();
+  if (!format_) {
+    // Can't have turned on the stream without format being set,
+    // so nothing to turn off here.
+    return 0;
+  }
+
+  int32_t type = format_->type();
+  int res = IoctlLocked(VIDIOC_STREAMOFF, &type);
+  // Calling STREAMOFF releases all queued buffers back to the user.
+  // No buffers in flight.
+  if (res < 0) {
+    HAL_LOGE("STREAMOFF fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    buffer.active = false;
+  }
+
+  last_index_ = -1;
+  last_dq_index = 0;
+  HAL_LOGI("Stream turned off.");
+  return 0;
+}
+
+int V4L2Wrapper::QueryControl(uint32_t control_id,
+                              v4l2_query_ext_ctrl* result) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("control_id: %d", control_id);
+
+  int res;
+  memset(result, 0, sizeof(*result));
+
+  if (extended_query_supported_) {
+    result->id = control_id;
+    res = IoctlLocked(VIDIOC_QUERY_EXT_CTRL, result);
+    // Assuming the operation was supported (not ENOTTY), no more to do.
+    if (errno != ENOTTY) {
+      if (res) {
+        HAL_LOGE("QUERY_EXT_CTRL fails: %s", strerror(errno));
+        return -ENODEV;
+      }
+      return 0;
+    }
+  }
+
+  // Extended control querying not supported, fall back to basic control query.
+  v4l2_queryctrl query;
+  query.id = control_id;
+  if (IoctlLocked(VIDIOC_QUERYCTRL, &query)) {
+    HAL_LOGE("QUERYCTRL fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Convert the basic result to the extended result.
+  result->id = query.id;
+  result->type = query.type;
+  memcpy(result->name, query.name, sizeof(query.name));
+  result->minimum = query.minimum;
+  if (query.type == V4L2_CTRL_TYPE_BITMASK) {
+    // According to the V4L2 documentation, when type is BITMASK,
+    // max and default should be interpreted as __u32. Practically,
+    // this means the conversion from 32 bit to 64 will pad with 0s not 1s.
+    result->maximum = static_cast<uint32_t>(query.maximum);
+    result->default_value = static_cast<uint32_t>(query.default_value);
+  } else {
+    result->maximum = query.maximum;
+    result->default_value = query.default_value;
+  }
+  result->step = static_cast<uint32_t>(query.step);
+  result->flags = query.flags;
+  result->elems = 1;
+  switch (result->type) {
+    case V4L2_CTRL_TYPE_INTEGER64:
+      result->elem_size = sizeof(int64_t);
+      break;
+    case V4L2_CTRL_TYPE_STRING:
+      result->elem_size = result->maximum + 1;
+      break;
+    default:
+      result->elem_size = sizeof(int32_t);
+      break;
+  }
+
+  return 0;
+}
+
+int V4L2Wrapper::GetControl(uint32_t control_id, int32_t* value) {
+  HAL_LOG_ENTER();
+  // For extended controls (any control class other than "user"),
+  // G_EXT_CTRL must be used instead of G_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_G_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("G_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  } else {
+    v4l2_control control{control_id, 0};
+    if (IoctlLocked(VIDIOC_G_CTRL, &control) < 0) {
+      HAL_LOGE("G_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::SetControl(uint32_t control_id,
+                            int32_t desired,
+                            int32_t* result) {
+  int32_t result_value = 0;
+
+  HAL_LOG_ENTER();
+  // TODO(b/29334616): When async, this may need to check if the stream
+  // is on, and if so, lock it off while setting format. Need to look
+  // into if V4L2 supports adjusting controls while the stream is on.
+
+  // For extended controls (any control class other than "user"),
+  // S_EXT_CTRL must be used instead of S_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    control.value = desired;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_S_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("S_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  } else {
+    v4l2_control control{control_id, desired};
+    if (IoctlLocked(VIDIOC_S_CTRL, &control) < 0) {
+      HAL_LOGE("S_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  }
+
+  // If the caller wants to know the result, pass it back.
+  if (result != nullptr) {
+    *result = result_value;
+  }
+  return 0;
+}
+
+const SupportedFormats V4L2Wrapper::GetSupportedFormats() {
+  HAL_LOG_ENTER();
+
+  SupportedFormats formats;
+  std::set<uint32_t> pixel_formats;
+
+  int res = GetFormats(&pixel_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return formats;
+  }
+
+  arc::SupportedFormat supported_format;
+  std::set<std::array<int32_t, 2>> frame_sizes;
+
+  for (auto pixel_format : pixel_formats) {
+    supported_format.fourcc = pixel_format;
+
+    frame_sizes.clear();
+    res = GetFormatFrameSizes(pixel_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get frame sizes for format: 0x%x", pixel_format);
+      continue;
+    }
+    for (auto frame_size : frame_sizes) {
+      supported_format.width = frame_size[0];
+      supported_format.height = frame_size[1];
+      formats.push_back(supported_format);
+    }
+  }
+  return formats;
+}
+
+int V4L2Wrapper::GetFormats(std::set<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+
+  v4l2_fmtdesc format_query;
+  memset(&format_query, 0, sizeof(format_query));
+  // TODO(b/30000211): multiplanar support.
+  format_query.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  while (IoctlLocked(VIDIOC_ENUM_FMT, &format_query) >= 0) {
+    HAL_LOGE("ENUM_FMT got at index %d with %s 0x%x [%d]", format_query.index, 
+              FormatToString(format_query.pixelformat).c_str(), 
+              format_query.pixelformat, format_query.pixelformat);
+    v4l2_formats->insert(format_query.pixelformat);
+    ++format_query.index;
+  }
+
+  if (errno != EINVAL) {
+    HAL_LOGE(
+        "ENUM_FMT fails at index %d: %s", format_query.index, strerror(errno));
+    return -ENODEV;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+  if (!connected()) {
+    HAL_LOGE(
+        "Device is not connected, qualified formats may not have been set.");
+    return -EINVAL;
+  }
+  v4l2_formats->clear();
+  std::set<uint32_t> unique_fourccs;
+  for (auto& format : qualified_formats_) {
+    unique_fourccs.insert(format.fourcc);
+  }
+  v4l2_formats->assign(unique_fourccs.begin(), unique_fourccs.end());
+  return 0;
+}
+
+int V4L2Wrapper::GetFormatFrameSizes(uint32_t v4l2_format,
+                                     std::set<std::array<int32_t, 2>>* sizes) {
+  v4l2_frmsizeenum size_query;
+
+  HAL_LOG_ENTER();
+  memset(&size_query, 0, sizeof(size_query));
+  size_query.pixel_format = v4l2_format;
+  if (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) < 0) {
+    HAL_LOGE("ENUM_FRAMESIZES failed at pixel_format 0x%x index 0: %s", v4l2_format, strerror(errno));
+    return -ENODEV;
+  }
+  if (size_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all sizes using VIDIOC_ENUM_FRAMESIZES.
+    // Assuming that a driver with discrete frame sizes has a reasonable number
+    // of them.
+    do {
+      sizes->insert({{{static_cast<int32_t>(size_query.discrete.width),
+                       static_cast<int32_t>(size_query.discrete.height)}}});
+      ++size_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMESIZES fails at index %d: %s",
+               size_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: based on the stepwise struct returned by the query.
+    // Fully listing all possible sizes, with large enough range/small enough
+    // step size, may produce far too many potential sizes. Instead, find the
+    // closest to a set of standard sizes.
+    for (const auto size : kStandardSizes) {
+      // Find the closest size, rounding up.
+      uint32_t desired_width = size[0];
+      uint32_t desired_height = size[1];
+      if (desired_width < size_query.stepwise.min_width ||
+          desired_height < size_query.stepwise.min_height) {
+        HAL_LOGE("Standard size %u x %u is too small for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      } else if (desired_width > size_query.stepwise.max_width ||
+                 desired_height > size_query.stepwise.max_height) {
+        HAL_LOGE("Standard size %u x %u is too big for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      }
+
+      // Round up.
+      uint32_t width_steps = (desired_width - size_query.stepwise.min_width +
+                              size_query.stepwise.step_width - 1) /
+                             size_query.stepwise.step_width;
+      uint32_t height_steps = (desired_height - size_query.stepwise.min_height +
+                               size_query.stepwise.step_height - 1) /
+                              size_query.stepwise.step_height;
+      sizes->insert(
+          {{{static_cast<int32_t>(size_query.stepwise.min_width +
+                                  width_steps * size_query.stepwise.step_width),
+             static_cast<int32_t>(size_query.stepwise.min_height +
+                                  height_steps *
+                                      size_query.stepwise.step_height)}}});
+    }
+  }
+  return 0;
+}
+
+// Converts a v4l2_fract with units of seconds to an int64_t with units of ns.
+inline int64_t FractToNs(const v4l2_fract& fract) {
+  return (1000000000LL * fract.numerator) / fract.denominator;
+}
+
+int V4L2Wrapper::GetFormatFrameDurationRange(
+    uint32_t v4l2_format,
+    const std::array<int32_t, 2>& size,
+    std::array<int64_t, 2>* duration_range) {
+  // Potentially called so many times logging entry is a bad idea.
+
+  v4l2_frmivalenum duration_query;
+  memset(&duration_query, 0, sizeof(duration_query));
+  duration_query.pixel_format = v4l2_format;
+  duration_query.width = size[0];
+  duration_query.height = size[1];
+  if (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) < 0) {
+    HAL_LOGE("ENUM_FRAMEINTERVALS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  int64_t min = std::numeric_limits<int64_t>::max();
+  int64_t max = std::numeric_limits<int64_t>::min();
+  if (duration_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all durations using VIDIOC_ENUM_FRAMEINTERVALS.
+    do {
+      min = std::min(min, FractToNs(duration_query.discrete));
+      max = std::max(max, FractToNs(duration_query.discrete));
+      ++duration_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMEINTERVALS fails at index %d: %s",
+               duration_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: simply convert the given min and max.
+    min = FractToNs(duration_query.stepwise.min);
+    max = FractToNs(duration_query.stepwise.max);
+  }
+  (*duration_range)[0] = min;
+  (*duration_range)[1] = max;
+  return 0;
+}
+
+int V4L2Wrapper::SetFormat(const StreamFormat& desired_format,
+                           uint32_t* result_max_buffers) {
+  HAL_LOG_ENTER();
+
+  if (format_ && desired_format == *format_) {
+    HAL_LOGV("Already in correct format, skipping format setting.");
+    *result_max_buffers = buffers_.size();
+    return 0;
+  }
+
+  if (format_) {
+    // If we had an old format, first request 0 buffers to inform the device
+    // we're no longer using any previously "allocated" buffers from the old
+    // format. This seems like it shouldn't be necessary for USERPTR memory,
+    // and/or should happen from turning the stream off, but the driver
+    // complained. May be a driver issue, or may be intended behavior.
+    int res = RequestBuffers(0);
+    if (res) {
+      return res;
+    }
+  }
+
+  // Select the matching format, or if not available, select a qualified format
+  // we can convert from.
+  SupportedFormat format;
+  if (!StreamFormat::FindBestFitFormat(supported_formats_, qualified_formats_,
+                                       desired_format.v4l2_pixel_format(),
+                                       desired_format.width(),
+                                       desired_format.height(), &format)) {
+    HAL_LOGE(
+        "Unable to find supported resolution in list, "
+        "width: %d, height: %d",
+        desired_format.width(), desired_format.height());
+    return -EINVAL;
+  }
+
+  HAL_LOGD("supported format size:%d,%d forcc:%x", format.width, format.height, format.fourcc);
+
+  // Set the camera to the new format.
+  v4l2_format new_format;
+  const StreamFormat resolved_format(format);
+  resolved_format.FillFormatRequest(&new_format);
+
+  // TODO(b/29334616): When async, this will need to check if the stream
+  // is on, and if so, lock it off while setting format.
+  if (IoctlLocked(VIDIOC_S_FMT, &new_format) < 0) {
+    HAL_LOGE("S_FMT failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  HAL_LOGD("S_FMT format size:%d,%d forcc:%x", 
+		  new_format.fmt.pix.width, 
+		  new_format.fmt.pix.height, 
+		  new_format.fmt.pix.pixelformat);
+  // Check that the driver actually set to the requested values.
+  if (resolved_format != new_format) {
+    HAL_LOGE("Device doesn't support desired stream configuration.");
+    return -EINVAL;
+  }
+
+  // Keep track of our new format.
+  format_.reset(new StreamFormat(new_format));
+
+  // Format changed, request new buffers.
+  buffer_numbers_ = android::base::GetIntProperty("camera.debug.buffers", DEFAULT_BUFFER_NUMBERS);
+  HAL_LOGI("Requesting buffers with number %d.", buffer_numbers_);
+  int res = RequestBuffers(buffer_numbers_);
+  if (res) {
+    HAL_LOGE("Requesting buffers for new format failed.");
+    return res;
+  }
+  *result_max_buffers = buffers_.size();
+  return 0;
+}
+
+int V4L2Wrapper::RequestBuffers(uint32_t num_requested) {
+  v4l2_requestbuffers req_buffers;
+
+  memset(&req_buffers, 0, sizeof(req_buffers));
+  req_buffers.type = format_->type();
+  req_buffers.memory = V4L2_MEMORY_MMAP;
+  req_buffers.count = num_requested;
+
+  int res = IoctlLocked(VIDIOC_REQBUFS, &req_buffers);
+  // Calling REQBUFS releases all queued buffers back to the user.
+  if (res < 0) {
+    HAL_LOGE("REQBUFS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // V4L2 will set req_buffers.count to a number of buffers it can handle.
+  if (num_requested > 0 && req_buffers.count < 1) {
+    HAL_LOGE("REQBUFS claims it can't handle any buffers.");
+    return -ENODEV;
+  }
+
+  HAL_LOGE("FW REQBUFS: %d kernel support: %d ", num_requested, req_buffers.count);
+
+  buffers_.resize(req_buffers.count);
+  last_index_ = -1; 
+  last_dq_index = 0;
+
+  return 0;
+}
+
+int V4L2Wrapper::get_camera_sharefd()
+{
+    if (camera_share_fd_ > 0) {
+      return camera_share_fd_;
+    }
+
+    int camera_share_fd = -1;
+    struct v4l2_control ctrl;
+    memset(&ctrl, 0, sizeof(ctrl));
+    ctrl.id = CID_GET_DMABUF_FD;
+    ctrl.value = 0;
+    if (IoctlLocked(VIDIOC_S_CTRL, &ctrl) != 0)
+    {
+        HAL_LOGE("CID_GET_DMABUF_FD: ioctl error\n");
+        camera_share_fd = -1;
+    }
+    else
+    {
+        if (IoctlLocked(VIDIOC_G_CTRL, &ctrl) != 0)
+        {
+            HAL_LOGE("VIDIOC_G_CTRL CID_GET_DMABUF_FD: ioctl error\n");
+            camera_share_fd = -1;
+        }
+        else
+        {
+            HAL_LOGI("CID_GET_DMABUF_FD fd=%d", ctrl.value);
+            camera_share_fd = ctrl.value;
+        }
+    }
+    camera_share_fd_ = camera_share_fd;
+
+    HAL_LOGD("dma buffer fd: %d", camera_share_fd_);
+    return camera_share_fd_;
+}
+
+uint64_t dq_time_end = 0;
+uint64_t q_time_start = 0;
+bool dq_success = false;
+
+void calulateTimespan() {
+  if (dq_success) {
+    uint64_t testDurationNs = q_time_start - dq_time_end;
+    HAL_LOGD("+++++++++++++++++++++++++++++Dequeue->Queue [+ %d ms]+++++++++++++++++++++++++++++", 
+      toMilliSeconds(testDurationNs));  
+
+    dq_success = false;
+  } 
+}
+
+int V4L2Wrapper::EnqueueRequest() {
+  HAL_LOG_ENTER();
+  HAL_LOGV("++++++++++++++++++++++++++++++++++++Try to QBUF++++++++++++++++++++++++++++++++++++"); 
+  int ret = 0;
+
+  uint64_t startTimeNs = timeNanos();
+  q_time_start = startTimeNs;
+  if (isDebug()) {
+    calulateTimespan();
+  }
+
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before enqueuing buffers.");
+    ret = -ENODEV;
+    goto Exit;
+  }
+
+  {
+    int index = -1;
+    size_t i = 1;
+    for(i = 1; i <= buffers_.size(); i++)
+    {
+      std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+      index = (last_index_ + i) % buffers_.size();
+      if (!buffers_[index].active) {
+        last_index_ = index;
+        ret = 0;
+        HAL_LOGV("enqueue buffer at index: %d.", last_index_);
+        break;
+      }
+      else {
+        ret = -EAGAIN;
+      }
+    }
+
+    if (stream_status == 0)
+    {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+    }
+
+    if (ret == -EAGAIN) {
+        HAL_LOGD("Cannot enqueue buffer: stream is already full. wait");
+        goto Exit;
+        //// wait!
+        /*
+        std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+        buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+        */
+        goto Exit;
+    }
+
+
+    {
+      // Set up a v4l2 buffer struct.
+      v4l2_buffer device_buffer;
+      memset(&device_buffer, 0, sizeof(device_buffer));
+      device_buffer.type = format_->type();
+      device_buffer.index = index;
+      device_buffer.memory = V4L2_MEMORY_MMAP;
+
+      // Use QUERYBUF to ensure our buffer/device is in good shape,
+      // and fill out remaining fields.
+      if (IoctlLocked(VIDIOC_QUERYBUF, &device_buffer) < 0) {
+        HAL_LOGE("QUERYBUF fails: %s", strerror(errno));
+        // Return buffer index.
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        buffers_[index].active = false;
+        ret = -ENODEV;
+        goto Exit;
+      }
+
+      //HAL_LOGE("device_buffer.length: %d device_buffer.m.offset: %d", device_buffer.length, device_buffer.m.offset);
+      if (stream_status == 0)
+      {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+      }
+
+        HAL_LOGI("VIDIOC_QUERYBUF[%d] length=%d offset=%d",device_buffer.index, device_buffer.length, device_buffer.m.offset);
+      {
+        // Setup our request context and fill in the user pointer field.
+        RequestContext* request_context;
+        {
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context = &buffers_[index];
+          request_context->camera_buffer->SetFd(get_camera_sharefd());
+          request_context->camera_buffer->SetDataSize(device_buffer.length);
+          request_context->camera_buffer->SetOffset(device_buffer.m.offset);
+          request_context->camera_buffer->Map();
+
+          request_context->camera_buffer->SetFourcc(format_->v4l2_pixel_format());
+          request_context->camera_buffer->SetWidth(format_->width());
+          request_context->camera_buffer->SetHeight(format_->height());
+          //request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart() + device_buffer.m.offset);
+          request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart());
+          request_context->request = NULL;
+        }
+
+        // Pass the buffer to the camera.
+        if (IoctlLocked(VIDIOC_QBUF, &device_buffer) < 0) {
+          HAL_LOGE("QBUF fails: %s", strerror(errno));
+          ret = -ENODEV;
+          goto Exit;
+        }
+
+        {
+          // Mark the buffer as in flight.
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context->active = true;
+        }
+      }
+    }
+  }
+
+Exit:
+  uint64_t testDurationNs = timeNanos() - startTimeNs;
+  if (!ret) {
+    if (isDebug()) {
+        HAL_LOGD("+++++++++++++++++++++++++++++QBUF index[%d] Done[+ %d ms]++++++++++++++++++++++++++++++++++",
+            last_index_,
+            toMilliSeconds(testDurationNs));
+    }
+  } else if (ret == -EAGAIN) {
+    std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+    buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF AGAIN[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+  else {
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF Fail[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+
+  if (stream_status == 0)
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+  }
+
+  return ret;
+}
+
+void V4L2Wrapper::CopyBlt(void * dest, const void * src, size_t width, size_t height) {
+    size_t stride = Align64(width);
+    for(size_t r = 0; r < height; r++) {
+      for(size_t c = 0; c < width; c++) {
+          for(size_t i = 0; i < 4; i++) {
+            *((unsigned char *)dest + 4 * (r * stride + c) + i) =  *((unsigned char *)src + 4 * (r * width + c) + i);
+          }
+      }
+    }
+    HAL_LOGV("width %zu stride %zu", width, stride);
+}
+
+int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("------------------------------------Try to DQBUF------------------------------------");
+  uint64_t startTimeNs = timeNanos();
+  uint64_t ioctlTimeNs = timeNanos();
+  uint64_t convertTimeNs = 0;
+  uint64_t memcpyTimeNs = 0;
+
+  int ret = 0;
+  int res = 0;
+
+  if (!format_) {
+    HAL_LOGV(
+        "Format not set, so stream can't be on, "
+        "so no buffers available for dequeueing");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  if (!request)
+  {
+    HAL_LOGE("DequeueRequest failed, request is null");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  {
+    v4l2_buffer buffer;
+    memset(&buffer, 0, sizeof(buffer));
+    buffer.type = format_->type();
+    buffer.memory = V4L2_MEMORY_MMAP;
+    static int frame_count = 0;
+
+    int retry = 5;
+    while (retry > 0)
+    {
+        res = IoctlLocked(VIDIOC_DQBUF, &buffer);
+        if (res) {
+            if (errno == EAGAIN) {
+                // Expected failure.
+                retry--;
+                if (retry > 0)
+                {
+                    usleep(5*1000);
+                    continue;
+                }
+                else
+                {
+                    frame_count++;
+                    HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    ret = -EAGAIN;
+                    //goto Exit;
+                }
+            } else {
+                // Unexpected failure.
+                HAL_LOGE("DQBUF fails: %s", strerror(errno));
+                usleep(10*1000);
+                ret = -EIO;
+                goto Exit;
+            }
+        }
+        else
+        {
+            break;
+        }
+    }
+    ioctlTimeNs = timeNanos();
+    if (ret == -EAGAIN)
+        buffer.index = last_dq_index;
+    if (stream_status == 0)
+    {
+        ret = -EIO;
+        goto Exit;
+    }
+    HAL_LOGD("VIDIOC_DQBUF got buffer index %d", buffer.index);
+
+    {
+      RequestContext* request_context = &buffers_[buffer.index];
+
+      request_context->request = request;
+      retry = 5;
+      while (!request_context->active && retry > 0)
+      {
+        buffer_queue_notify_.notify_one();
+        usleep(5*1000);
+        retry--;
+        if (retry == 0) {
+            ret = -EAGAIN;
+            goto Exit;
+        }
+      }
+      if (ret == -EAGAIN)
+      {
+        buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
+      }
+
+      last_dq_index = buffer.index;
+      dump_data_index = request_context->request->frame_number;
+      HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
+        (uint32_t)request_context->request->output_buffers.size());
+
+      // Perform the format conversion.
+      arc::CachedFrame cached_frame;
+      uint32_t output_buffer_size = request_context->request->output_buffers.size();      
+      for(uint32_t i = 0; i < output_buffer_size; i++) {
+          HAL_LOGV("-----------------------------------------------------------");
+          HAL_LOGD("Process buffer[%d]", i);
+          if (stream_status == 0)
+          {
+            ret = -EIO;
+            goto Exit;
+          }
+          // Lock the camera stream buffer for painting.
+          const camera3_stream_buffer_t* stream_buffer = &request_context->request->output_buffers[i];
+          uint32_t fourcc = StreamFormat::HalToV4L2PixelFormat(stream_buffer->stream->format);
+          HAL_LOGD("Driver format: %s 0x%x width: %d height: %d", 
+            FormatToString(request_context->camera_buffer->GetFourcc()).c_str(),
+            request_context->camera_buffer->GetFourcc(),
+            request_context->camera_buffer->GetWidth(),
+            request_context->camera_buffer->GetHeight());
+
+          HAL_LOGD("App format: %s 0x%x width: %d height: %d", 
+            FormatToString(fourcc).c_str(), 
+            fourcc,
+            stream_buffer->stream->width,
+            stream_buffer->stream->height);
+
+          dump_data(dump_data_index, (unsigned char *)request_context->camera_buffer->GetData(), 
+                    request_context->camera_buffer->GetWidth(), request_context->camera_buffer->GetHeight(), 
+                    request_context->camera_buffer->GetFourcc(), i, "pre-used");
+
+          // Note that the device buffer length is passed to the output frame. If the
+          // GrallocFrameBuffer does not have support for the transformation to
+          // |fourcc|, it will assume that the amount of data to lock is based on
+          // |buffer.length|, otherwise it will use the ImageProcessor::ConvertedSize.   
+          arc::GrallocFrameBuffer output_frame( *stream_buffer->buffer, stream_buffer->stream->width,
+                                                stream_buffer->stream->height, fourcc, buffer.length, 
+                                                stream_buffer->stream->usage);
+
+          HAL_LOGV("out buffer  fd: %d", 
+            ((buffer_handle_t)*stream_buffer->buffer)->data[0]);
+
+          res = output_frame.Map();
+          if (res) {
+            HAL_LOGE("Failed to map output frame.");
+            request_context->request.reset();
+            ret = -EINVAL;
+            goto Exit;
+          }
+
+          uint64_t time = timeNanos();
+          if (request_context->camera_buffer->GetFourcc() == fourcc &&
+            request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+            request_context->camera_buffer->GetHeight() == stream_buffer->stream->height) {
+            HAL_LOGV("No need to do conversion. Copy directly");
+            #if 1            
+            // If no format conversion needs to be applied, directly copy the data over.
+            memcpy(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetDataSize());
+            #else
+            CopyBlt(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetWidth(),
+                  request_context->camera_buffer->GetHeight());
+            #endif
+            memcpyTimeNs = timeNanos() - time;
+          } else {
+            HAL_LOGV("Need to perform the format conversion.");
+            bool can_convert_directly = (fourcc != V4L2_PIX_FMT_JPEG);
+            bool size_match = ( request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+                                request_context->camera_buffer->GetHeight() == stream_buffer->stream->height);
+            if (output_buffer_size == 1 && size_match && can_convert_directly){
+              arc::SimpleFrameBuffer in_frame(request_context->camera_buffer->GetData(), 
+                                              request_context->camera_buffer->GetFourcc(),
+                                              request_context->camera_buffer->GetWidth(), 
+                                              request_context->camera_buffer->GetHeight(),  
+                                              request_context->camera_buffer->GetFd(),
+                                              buffer.length);
+ 
+              cached_frame.ConvertDirectly(request_context->request->settings, in_frame, &output_frame);
+            } else {
+              if (!cached_frame.already_cached) {
+                cached_frame.SetSource(request_context->request->settings, request_context->camera_buffer.get(), 0);
+                dump_data(dump_data_index, (unsigned char *)cached_frame.yu12_frame_->GetData(), 
+                              cached_frame.yu12_frame_->GetWidth(), cached_frame.yu12_frame_->GetHeight(), 
+                              cached_frame.yu12_frame_->GetFourcc(), i, "mid");                
+              }
+              
+              cached_frame.Convert(request_context->request->settings, &output_frame, i);                                  
+            }
+
+          HAL_LOGV("copy data buffer  fd: %d", ((buffer_handle_t)output_frame.buffer_)->data[0]);
+
+          dump_data(dump_data_index, (unsigned char *)output_frame.GetData(), 
+                      output_frame.GetWidth(), output_frame.GetHeight(), fourcc, i, "post");
+          convertTimeNs = timeNanos() - time;
+          }  
+ 
+      }
+
+      //EAGAIN we will not QBUF
+      if (ret == -EAGAIN) {
+        ret = 0;
+        goto Exit;
+      }
+
+      {
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        request_context->request.reset();
+        // Mark the buffer as not in flight.
+        request_context->active = false;
+      }
+
+      buffer_queue_notify_.notify_one();
+    }
+  }
+
+Exit:
+  if (isDebug())
+  {
+    uint64_t testDurationNs = timeNanos() - startTimeNs;
+    if (!ret) {
+        dq_time_end = timeNanos();
+        dq_success = true;
+        //dump_data_index++;
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] index[%d] Done[+ %d ms] [ioctl:%d ms] [convert:%d ms] [memcpy:%d ms]------------------------------------",
+            dump_data_index, last_dq_index,
+            toMilliSeconds(testDurationNs), toMilliSeconds(ioctlTimeNs-startTimeNs), toMilliSeconds(convertTimeNs), toMilliSeconds(memcpyTimeNs));
+    } else {
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] Fail[+ %d ms]------------------------------------",
+            dump_data_index,
+            toMilliSeconds(testDurationNs));
+    }
+}
+  if (!ret) {
+    ShowPreviewFPS();
+  }
+
+  return ret;
+}
+
+int V4L2Wrapper::GetInFlightBufferCount() {
+  int count = 0;
+  std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    if (buffer.active) {
+      count++;
+    }
+  }
+  return count;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp_10 b/hardware/ntimespace/camera/v4l2_wrapper.cpp_10
new file mode 100644
index 0000000000..ec3a9a8f73
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp_10
@@ -0,0 +1,1089 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Wrapper"
+
+#include "v4l2_wrapper.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "arc/cached_frame.h"
+#include "android-base/properties.h"
+#include "debug.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+using arc::V4L2FrameBuffer;
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+using default_camera_hal::CaptureRequest;
+
+const int32_t kStandardSizes[][2] = {
+  {4096, 2160}, // 4KDCI (for USB camera)
+  {3840, 2160}, // 4KUHD (for USB camera)
+  {3280, 2464}, // 8MP
+  {2560, 1440}, // QHD
+  {1920, 1080}, // HD1080
+  {1640, 1232}, // 2MP
+  {1280,  720}, // HD
+  {1024,  768}, // XGA
+  { 960,  540}, // VGA
+  { 640,  480}, // VGA
+  { 640,  360}, // VGA
+  { 320,  240}, // QVGA
+  { 176,  144}  // QCIF
+};
+
+V4L2Wrapper* V4L2Wrapper::NewV4L2Wrapper(const std::string device_path, int camera_id) {
+  return new V4L2Wrapper(device_path, camera_id);
+}
+
+V4L2Wrapper::V4L2Wrapper(const std::string device_path, int camera_id)
+    : device_path_(std::move(device_path)), connection_count_(0) {
+      HAL_LOG_ENTER();
+      camera_id_ = camera_id;
+      camera_share_fd_ = -1;
+      last_index_ = -1;
+      last_dq_index = -1;
+      stream_status = 0;
+      dump_data_init();
+      get_gpu_pixel_alignment();
+    }
+
+V4L2Wrapper::~V4L2Wrapper() {}
+
+inline std::string V4L2Wrapper::FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+int V4L2Wrapper::Connect() {
+  HAL_LOG_ENTER();
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connected()) {
+    HAL_LOGV("Camera device %s is already connected.", device_path_.c_str());
+    ++connection_count_;
+    return 0;
+  }
+
+  if (camera_share_fd_ > 0)
+    close(camera_share_fd_);
+  camera_share_fd_ = -1;
+  last_index_ = -1;  
+  last_dq_index = 0;
+  // Open in nonblocking mode (DQBUF may return EAGAIN).
+  int fd = TEMP_FAILURE_RETRY(open(device_path_.c_str(), O_RDONLY | O_NONBLOCK));
+  if (fd < 0) {
+    HAL_LOGE("failed to open %s (%s)", device_path_.c_str(), strerror(errno));
+    return -ENODEV;
+  }
+  device_fd_.reset(fd);
+  ++connection_count_;
+
+  // Check if this connection has the extended control query capability.
+  v4l2_query_ext_ctrl query;
+  query.id = V4L2_CTRL_FLAG_NEXT_CTRL | V4L2_CTRL_FLAG_NEXT_COMPOUND;
+  extended_query_supported_ = (IoctlLocked(VIDIOC_QUERY_EXT_CTRL, &query) == 0);
+
+  //camera id 0: back, facing 0
+  //camera id 1: front, facing 1
+  //other id: facing 0
+  long facing = (camera_id_ == 1 ? 1 : 0);
+  if (IoctlLocked(RFVIDEO_SET_FACING, &facing) != 0)
+  {
+      HAL_LOGE("%s(%d) set facing info failed", __FUNCTION__, __LINE__);
+  }
+
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at device_path_ may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so Connect() is never called on an unsupported camera)
+
+  supported_formats_ = GetSupportedFormats();
+  qualified_formats_ = StreamFormat::GetQualifiedFormats(supported_formats_);
+
+  HAL_LOG_EXIT();
+
+  return 0;
+}
+
+void V4L2Wrapper::Disconnect() {
+  HAL_LOG_ENTER();
+  HAL_LOGD("DisConnect...");
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connection_count_ == 0) {
+    // Not connected.
+    HAL_LOGE("Camera device %s is not connected, cannot disconnect.",
+             device_path_.c_str());
+    return;
+  }
+
+  --connection_count_;
+  if (connection_count_ > 0) {
+    HAL_LOGV("Disconnected from camera device %s. %d connections remain.",
+             device_path_.c_str(), connection_count_);
+    return;
+  }
+
+  device_fd_.reset(-1);  // Includes close().
+  format_.reset();
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+    buffers_.clear();
+  }
+
+  if (camera_share_fd_ > 0){
+    close(camera_share_fd_);
+    camera_share_fd_ = -1;
+  }
+}
+
+// Helper function. Should be used instead of ioctl throughout this class.
+template <typename T>
+int V4L2Wrapper::IoctlLocked(unsigned long request, T data) {
+  // Potentially called so many times logging entry is a bad idea.
+  std::lock_guard<std::mutex> lock(device_lock_);
+
+  HAL_LOG_ENTER();
+
+  if (!connected()) {
+    HAL_LOGE("Device %s not connected.", device_path_.c_str());
+    return -ENODEV;
+  }
+  return TEMP_FAILURE_RETRY(ioctl(device_fd_.get(), request, data));
+}
+
+int V4L2Wrapper::StreamOn() {
+  HAL_LOG_ENTER();
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before turning on stream.");
+    return -EINVAL;
+  }
+
+  int32_t buffer_numbers = buffer_numbers_;
+  if (IoctlLocked(VIDIOC_STREAMON, &buffer_numbers) < 0) {
+    HAL_LOGE("STREAMON fails (%d): %s", errno, strerror(errno));
+    return -ENODEV;
+  }
+
+  stream_status = 1;
+  HAL_LOGD("Stream turned on.");
+  return 0;
+}
+
+int V4L2Wrapper::StreamOff() {
+  HAL_LOG_ENTER();
+  stream_status = 0;
+  buffer_queue_notify_.notify_one();
+  if (!format_) {
+    // Can't have turned on the stream without format being set,
+    // so nothing to turn off here.
+    return 0;
+  }
+
+  int32_t type = format_->type();
+  int res = IoctlLocked(VIDIOC_STREAMOFF, &type);
+  // Calling STREAMOFF releases all queued buffers back to the user.
+  // No buffers in flight.
+  if (res < 0) {
+    HAL_LOGE("STREAMOFF fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    buffer.active = false;
+  }
+
+  last_index_ = -1;
+  last_dq_index = 0;
+  HAL_LOGI("Stream turned off.");
+  return 0;
+}
+
+int V4L2Wrapper::QueryControl(uint32_t control_id,
+                              v4l2_query_ext_ctrl* result) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("control_id: %d", control_id);
+
+  int res;
+  memset(result, 0, sizeof(*result));
+
+  if (extended_query_supported_) {
+    result->id = control_id;
+    res = IoctlLocked(VIDIOC_QUERY_EXT_CTRL, result);
+    // Assuming the operation was supported (not ENOTTY), no more to do.
+    if (errno != ENOTTY) {
+      if (res) {
+        HAL_LOGE("QUERY_EXT_CTRL fails: %s", strerror(errno));
+        return -ENODEV;
+      }
+      return 0;
+    }
+  }
+
+  // Extended control querying not supported, fall back to basic control query.
+  v4l2_queryctrl query;
+  query.id = control_id;
+  if (IoctlLocked(VIDIOC_QUERYCTRL, &query)) {
+    HAL_LOGE("QUERYCTRL fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Convert the basic result to the extended result.
+  result->id = query.id;
+  result->type = query.type;
+  memcpy(result->name, query.name, sizeof(query.name));
+  result->minimum = query.minimum;
+  if (query.type == V4L2_CTRL_TYPE_BITMASK) {
+    // According to the V4L2 documentation, when type is BITMASK,
+    // max and default should be interpreted as __u32. Practically,
+    // this means the conversion from 32 bit to 64 will pad with 0s not 1s.
+    result->maximum = static_cast<uint32_t>(query.maximum);
+    result->default_value = static_cast<uint32_t>(query.default_value);
+  } else {
+    result->maximum = query.maximum;
+    result->default_value = query.default_value;
+  }
+  result->step = static_cast<uint32_t>(query.step);
+  result->flags = query.flags;
+  result->elems = 1;
+  switch (result->type) {
+    case V4L2_CTRL_TYPE_INTEGER64:
+      result->elem_size = sizeof(int64_t);
+      break;
+    case V4L2_CTRL_TYPE_STRING:
+      result->elem_size = result->maximum + 1;
+      break;
+    default:
+      result->elem_size = sizeof(int32_t);
+      break;
+  }
+
+  return 0;
+}
+
+int V4L2Wrapper::GetControl(uint32_t control_id, int32_t* value) {
+  HAL_LOG_ENTER();
+  // For extended controls (any control class other than "user"),
+  // G_EXT_CTRL must be used instead of G_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_G_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("G_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  } else {
+    v4l2_control control{control_id, 0};
+    if (IoctlLocked(VIDIOC_G_CTRL, &control) < 0) {
+      HAL_LOGE("G_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::SetControl(uint32_t control_id,
+                            int32_t desired,
+                            int32_t* result) {
+  int32_t result_value = 0;
+
+  HAL_LOG_ENTER();
+  // TODO(b/29334616): When async, this may need to check if the stream
+  // is on, and if so, lock it off while setting format. Need to look
+  // into if V4L2 supports adjusting controls while the stream is on.
+
+  // For extended controls (any control class other than "user"),
+  // S_EXT_CTRL must be used instead of S_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    control.value = desired;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_S_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("S_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  } else {
+    v4l2_control control{control_id, desired};
+    if (IoctlLocked(VIDIOC_S_CTRL, &control) < 0) {
+      HAL_LOGE("S_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  }
+
+  // If the caller wants to know the result, pass it back.
+  if (result != nullptr) {
+    *result = result_value;
+  }
+  return 0;
+}
+
+const SupportedFormats V4L2Wrapper::GetSupportedFormats() {
+  HAL_LOG_ENTER();
+
+  SupportedFormats formats;
+  std::set<uint32_t> pixel_formats;
+
+  int res = GetFormats(&pixel_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return formats;
+  }
+
+  arc::SupportedFormat supported_format;
+  std::set<std::array<int32_t, 2>> frame_sizes;
+
+  for (auto pixel_format : pixel_formats) {
+    supported_format.fourcc = pixel_format;
+
+    frame_sizes.clear();
+    res = GetFormatFrameSizes(pixel_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get frame sizes for format: 0x%x", pixel_format);
+      continue;
+    }
+    for (auto frame_size : frame_sizes) {
+      supported_format.width = frame_size[0];
+      supported_format.height = frame_size[1];
+      formats.push_back(supported_format);
+    }
+  }
+  return formats;
+}
+
+int V4L2Wrapper::GetFormats(std::set<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+
+  v4l2_fmtdesc format_query;
+  memset(&format_query, 0, sizeof(format_query));
+  // TODO(b/30000211): multiplanar support.
+  format_query.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  while (IoctlLocked(VIDIOC_ENUM_FMT, &format_query) >= 0) {
+    HAL_LOGE("ENUM_FMT got at index %d with %s 0x%x [%d]", format_query.index, 
+              FormatToString(format_query.pixelformat).c_str(), 
+              format_query.pixelformat, format_query.pixelformat);
+    v4l2_formats->insert(format_query.pixelformat);
+    ++format_query.index;
+  }
+
+  if (errno != EINVAL) {
+    HAL_LOGE(
+        "ENUM_FMT fails at index %d: %s", format_query.index, strerror(errno));
+    return -ENODEV;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+  if (!connected()) {
+    HAL_LOGE(
+        "Device is not connected, qualified formats may not have been set.");
+    return -EINVAL;
+  }
+  v4l2_formats->clear();
+  std::set<uint32_t> unique_fourccs;
+  for (auto& format : qualified_formats_) {
+    unique_fourccs.insert(format.fourcc);
+  }
+  v4l2_formats->assign(unique_fourccs.begin(), unique_fourccs.end());
+  return 0;
+}
+
+int V4L2Wrapper::GetFormatFrameSizes(uint32_t v4l2_format,
+                                     std::set<std::array<int32_t, 2>>* sizes) {
+  v4l2_frmsizeenum size_query;
+
+  HAL_LOG_ENTER();
+  memset(&size_query, 0, sizeof(size_query));
+  size_query.pixel_format = v4l2_format;
+  if (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) < 0) {
+    HAL_LOGE("ENUM_FRAMESIZES failed at pixel_format 0x%x index 0: %s", v4l2_format, strerror(errno));
+    return -ENODEV;
+  }
+  if (size_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all sizes using VIDIOC_ENUM_FRAMESIZES.
+    // Assuming that a driver with discrete frame sizes has a reasonable number
+    // of them.
+    do {
+      sizes->insert({{{static_cast<int32_t>(size_query.discrete.width),
+                       static_cast<int32_t>(size_query.discrete.height)}}});
+      ++size_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMESIZES fails at index %d: %s",
+               size_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: based on the stepwise struct returned by the query.
+    // Fully listing all possible sizes, with large enough range/small enough
+    // step size, may produce far too many potential sizes. Instead, find the
+    // closest to a set of standard sizes.
+    for (const auto size : kStandardSizes) {
+      // Find the closest size, rounding up.
+      uint32_t desired_width = size[0];
+      uint32_t desired_height = size[1];
+      if (desired_width < size_query.stepwise.min_width ||
+          desired_height < size_query.stepwise.min_height) {
+        HAL_LOGE("Standard size %u x %u is too small for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      } else if (desired_width > size_query.stepwise.max_width ||
+                 desired_height > size_query.stepwise.max_height) {
+        HAL_LOGE("Standard size %u x %u is too big for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      }
+
+      // Round up.
+      uint32_t width_steps = (desired_width - size_query.stepwise.min_width +
+                              size_query.stepwise.step_width - 1) /
+                             size_query.stepwise.step_width;
+      uint32_t height_steps = (desired_height - size_query.stepwise.min_height +
+                               size_query.stepwise.step_height - 1) /
+                              size_query.stepwise.step_height;
+      sizes->insert(
+          {{{static_cast<int32_t>(size_query.stepwise.min_width +
+                                  width_steps * size_query.stepwise.step_width),
+             static_cast<int32_t>(size_query.stepwise.min_height +
+                                  height_steps *
+                                      size_query.stepwise.step_height)}}});
+    }
+  }
+  return 0;
+}
+
+// Converts a v4l2_fract with units of seconds to an int64_t with units of ns.
+inline int64_t FractToNs(const v4l2_fract& fract) {
+  return (1000000000LL * fract.numerator) / fract.denominator;
+}
+
+int V4L2Wrapper::GetFormatFrameDurationRange(
+    uint32_t v4l2_format,
+    const std::array<int32_t, 2>& size,
+    std::array<int64_t, 2>* duration_range) {
+  // Potentially called so many times logging entry is a bad idea.
+
+  v4l2_frmivalenum duration_query;
+  memset(&duration_query, 0, sizeof(duration_query));
+  duration_query.pixel_format = v4l2_format;
+  duration_query.width = size[0];
+  duration_query.height = size[1];
+  if (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) < 0) {
+    HAL_LOGE("ENUM_FRAMEINTERVALS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  int64_t min = std::numeric_limits<int64_t>::max();
+  int64_t max = std::numeric_limits<int64_t>::min();
+  if (duration_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all durations using VIDIOC_ENUM_FRAMEINTERVALS.
+    do {
+      min = std::min(min, FractToNs(duration_query.discrete));
+      max = std::max(max, FractToNs(duration_query.discrete));
+      ++duration_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMEINTERVALS fails at index %d: %s",
+               duration_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: simply convert the given min and max.
+    min = FractToNs(duration_query.stepwise.min);
+    max = FractToNs(duration_query.stepwise.max);
+  }
+  (*duration_range)[0] = min;
+  (*duration_range)[1] = max;
+  return 0;
+}
+
+int V4L2Wrapper::SetFormat(const StreamFormat& desired_format,
+                           uint32_t* result_max_buffers) {
+  HAL_LOG_ENTER();
+
+  if (format_ && desired_format == *format_) {
+    HAL_LOGV("Already in correct format, skipping format setting.");
+    *result_max_buffers = buffers_.size();
+    return 0;
+  }
+
+  if (format_) {
+    // If we had an old format, first request 0 buffers to inform the device
+    // we're no longer using any previously "allocated" buffers from the old
+    // format. This seems like it shouldn't be necessary for USERPTR memory,
+    // and/or should happen from turning the stream off, but the driver
+    // complained. May be a driver issue, or may be intended behavior.
+    int res = RequestBuffers(0);
+    if (res) {
+      return res;
+    }
+  }
+
+  // Select the matching format, or if not available, select a qualified format
+  // we can convert from.
+  SupportedFormat format;
+  if (!StreamFormat::FindBestFitFormat(supported_formats_, qualified_formats_,
+                                       desired_format.v4l2_pixel_format(),
+                                       desired_format.width(),
+                                       desired_format.height(), &format)) {
+    HAL_LOGE(
+        "Unable to find supported resolution in list, "
+        "width: %d, height: %d",
+        desired_format.width(), desired_format.height());
+    return -EINVAL;
+  }
+
+  // Set the camera to the new format.
+  v4l2_format new_format;
+  const StreamFormat resolved_format(format);
+  resolved_format.FillFormatRequest(&new_format);
+
+  // TODO(b/29334616): When async, this will need to check if the stream
+  // is on, and if so, lock it off while setting format.
+  if (IoctlLocked(VIDIOC_S_FMT, &new_format) < 0) {
+    HAL_LOGE("S_FMT failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Check that the driver actually set to the requested values.
+  if (resolved_format != new_format) {
+    HAL_LOGE("Device doesn't support desired stream configuration.");
+    return -EINVAL;
+  }
+
+  // Keep track of our new format.
+  format_.reset(new StreamFormat(new_format));
+
+  // Format changed, request new buffers.
+  buffer_numbers_ = android::base::GetIntProperty("camera.debug.buffers", DEFAULT_BUFFER_NUMBERS);
+  HAL_LOGI("Requesting buffers with number %d.", buffer_numbers_);
+  int res = RequestBuffers(buffer_numbers_);
+  if (res) {
+    HAL_LOGE("Requesting buffers for new format failed.");
+    return res;
+  }
+  *result_max_buffers = buffers_.size();
+  return 0;
+}
+
+int V4L2Wrapper::RequestBuffers(uint32_t num_requested) {
+  v4l2_requestbuffers req_buffers;
+
+  memset(&req_buffers, 0, sizeof(req_buffers));
+  req_buffers.type = format_->type();
+  req_buffers.memory = V4L2_MEMORY_MMAP;
+  req_buffers.count = num_requested;
+
+  int res = IoctlLocked(VIDIOC_REQBUFS, &req_buffers);
+  // Calling REQBUFS releases all queued buffers back to the user.
+  if (res < 0) {
+    HAL_LOGE("REQBUFS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // V4L2 will set req_buffers.count to a number of buffers it can handle.
+  if (num_requested > 0 && req_buffers.count < 1) {
+    HAL_LOGE("REQBUFS claims it can't handle any buffers.");
+    return -ENODEV;
+  }
+
+  HAL_LOGE("FW REQBUFS: %d kernel support: %d ", num_requested, req_buffers.count);
+
+  buffers_.resize(req_buffers.count);
+  last_index_ = -1; 
+  last_dq_index = 0;
+
+  return 0;
+}
+
+int V4L2Wrapper::get_camera_sharefd(int nCameraFd)
+{
+    if (camera_share_fd_ > 0) {
+      return camera_share_fd_;
+    }
+
+    int camera_share_fd = -1;
+    if (ioctl(nCameraFd, RFVIDEO_GET_DMABUF_FD, &camera_share_fd) != 0) {
+        HAL_LOGE("RFVIDEO_GET_DMABUF_FD: ioctl error\n");
+        camera_share_fd = -1;
+    }
+    camera_share_fd_ = camera_share_fd;
+
+    HAL_LOGD("dma buffer fd: %d", camera_share_fd_);
+    return camera_share_fd_;
+}
+
+uint64_t dq_time_end = 0;
+uint64_t q_time_start = 0;
+bool dq_success = false;
+
+void calulateTimespan() {
+  if (dq_success) {
+    uint64_t testDurationNs = q_time_start - dq_time_end;
+    HAL_LOGD("+++++++++++++++++++++++++++++Dequeue->Queue [+ %d ms]+++++++++++++++++++++++++++++", 
+      toMilliSeconds(testDurationNs));  
+
+    dq_success = false;
+  } 
+}
+
+int V4L2Wrapper::EnqueueRequest() {
+  HAL_LOG_ENTER();
+  HAL_LOGV("++++++++++++++++++++++++++++++++++++Try to QBUF++++++++++++++++++++++++++++++++++++"); 
+  int ret = 0;
+
+  uint64_t startTimeNs = timeNanos();
+  q_time_start = startTimeNs;
+  if (isDebug()) {
+    calulateTimespan();
+  }
+
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before enqueuing buffers.");
+    ret = -ENODEV;
+    goto Exit;
+  }
+
+  {
+    int index = -1;
+    size_t i = 1;
+    for(i = 1; i <= buffers_.size(); i++)
+    {
+      std::lock_guard<std::mutex> guard(buffer_queue_lock_);  
+        index = (last_index_ + i) % buffers_.size();
+        if (!buffers_[index].active) {
+          last_index_ = index;
+          ret = 0;
+          HAL_LOGV("enqueue buffer at index: %d.", last_index_);
+          break;
+        }
+        else {
+          ret = -EAGAIN;
+        }
+    }
+
+    if (stream_status == 0)
+    {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+    }
+
+    if (ret == -EAGAIN) {
+        HAL_LOGD("Cannot enqueue buffer: stream is already full. wait");
+        goto Exit;
+        //// wait!
+        /*
+        std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+        buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+        */
+        goto Exit;
+    }
+
+    {
+      // Set up a v4l2 buffer struct.
+      v4l2_buffer device_buffer;
+      memset(&device_buffer, 0, sizeof(device_buffer));
+      device_buffer.type = format_->type();
+      device_buffer.index = index;
+      device_buffer.memory = V4L2_MEMORY_MMAP;
+
+      // Use QUERYBUF to ensure our buffer/device is in good shape,
+      // and fill out remaining fields.
+      if (IoctlLocked(VIDIOC_QUERYBUF, &device_buffer) < 0) {
+        HAL_LOGE("QUERYBUF fails: %s", strerror(errno));
+        // Return buffer index.
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        buffers_[index].active = false;
+        ret = -ENODEV;
+        goto Exit;
+      }
+
+      //HAL_LOGE("device_buffer.length: %d device_buffer.m.offset: %d", device_buffer.length, device_buffer.m.offset);
+      if (stream_status == 0)
+      {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+      }
+
+      {
+        // Setup our request context and fill in the user pointer field.
+        RequestContext* request_context;
+        {
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context = &buffers_[index];
+          request_context->camera_buffer->SetFd(get_camera_sharefd(device_fd_));
+          request_context->camera_buffer->Map();
+
+          request_context->camera_buffer->SetDataSize(device_buffer.length);
+          request_context->camera_buffer->SetFourcc(format_->v4l2_pixel_format());
+          request_context->camera_buffer->SetWidth(format_->width());
+          request_context->camera_buffer->SetHeight(format_->height());
+          request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart() + device_buffer.m.offset);
+          request_context->request = NULL;
+        }
+
+        // Pass the buffer to the camera.
+        if (IoctlLocked(VIDIOC_QBUF, &device_buffer) < 0) {
+          HAL_LOGE("QBUF fails: %s", strerror(errno));
+          ret = -ENODEV;
+          goto Exit;
+        }
+
+        {
+          // Mark the buffer as in flight.
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context->active = true;
+        }
+      }
+    }
+  }
+
+Exit:
+  uint64_t testDurationNs = timeNanos() - startTimeNs;
+  if (!ret) {
+    if (isDebug()) {
+        HAL_LOGD("+++++++++++++++++++++++++++++QBUF index[%d] Done[+ %d ms]++++++++++++++++++++++++++++++++++",
+            last_index_,
+            toMilliSeconds(testDurationNs));
+    }
+  } else if (ret == -EAGAIN) {
+    std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+    buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF AGAIN[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+  else {
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF Fail[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+
+  if (stream_status == 0)
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+  }
+
+  return ret;
+}
+
+void V4L2Wrapper::CopyBlt(void * dest, const void * src, size_t width, size_t height) {
+    size_t stride = Align64(width);
+    for(size_t r = 0; r < height; r++) {
+      for(size_t c = 0; c < width; c++) {
+          for(size_t i = 0; i < 4; i++) {
+            *((unsigned char *)dest + 4 * (r * stride + c) + i) =  *((unsigned char *)src + 4 * (r * width + c) + i);
+          }
+      }
+    }
+    HAL_LOGV("width %zu stride %zu", width, stride);
+}
+
+int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("------------------------------------Try to DQBUF------------------------------------");
+  uint64_t startTimeNs = timeNanos();
+  uint64_t ioctlTimeNs = timeNanos();
+  uint64_t convertTimeNs = 0;
+  uint64_t memcpyTimeNs = 0;
+
+  int ret = 0;
+  int res = 0;
+
+  if (!format_) {
+    HAL_LOGV(
+        "Format not set, so stream can't be on, "
+        "so no buffers available for dequeueing");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  if (!request)
+  {
+    HAL_LOGE("DequeueRequest failed, request is null");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  {
+    v4l2_buffer buffer;
+    memset(&buffer, 0, sizeof(buffer));
+    buffer.type = format_->type();
+    buffer.memory = V4L2_MEMORY_MMAP;
+    static int frame_count = 0;
+
+    int retry = 5;
+    while (retry > 0)
+    {
+        res = IoctlLocked(VIDIOC_DQBUF, &buffer);
+        if (res) {
+            if (errno == EAGAIN) {
+                // Expected failure.
+                retry--;
+                if (retry > 0)
+                {
+                    usleep(5*1000);
+                    continue;
+                }
+                else
+                {
+                    frame_count++;
+                    HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    ret = -EAGAIN;
+                    //goto Exit;
+                }
+            } else {
+                // Unexpected failure.
+                HAL_LOGE("DQBUF fails: %s", strerror(errno));
+                usleep(10*1000);
+                ret = -EIO;
+                goto Exit;
+            }
+        }
+        else
+        {
+            break;
+        }
+    }
+    ioctlTimeNs = timeNanos();
+    if (ret == -EAGAIN)
+        buffer.index = last_dq_index;
+    if (stream_status == 0)
+    {
+        ret = -EIO;
+        goto Exit;
+    }
+    HAL_LOGD("VIDIOC_DQBUF got buffer index %d", buffer.index);
+
+    {
+      RequestContext* request_context = &buffers_[buffer.index];
+
+      request_context->request = request;
+      retry = 5;
+      while (!request_context->active && retry > 0)
+      {
+        buffer_queue_notify_.notify_one();
+        usleep(5*1000);
+        retry--;
+        if (retry == 0){
+            ret = -EAGAIN;
+            goto Exit;
+        }
+      }
+      if (ret == -EAGAIN)
+      {
+        buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
+      }
+
+      last_dq_index = buffer.index;
+      dump_data_index = request_context->request->frame_number;
+      HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
+        (uint32_t)request_context->request->output_buffers.size());
+
+      // Perform the format conversion.
+      arc::CachedFrame cached_frame;
+      uint32_t output_buffer_size = request_context->request->output_buffers.size();      
+      for(uint32_t i = 0; i < output_buffer_size; i++) {
+          HAL_LOGV("-----------------------------------------------------------");
+          HAL_LOGD("Process buffer[%d]", i);
+          if (stream_status == 0)
+          {
+            ret = -EIO;
+            goto Exit;
+          }
+          // Lock the camera stream buffer for painting.
+          const camera3_stream_buffer_t* stream_buffer = &request_context->request->output_buffers[i];
+          uint32_t fourcc = StreamFormat::HalToV4L2PixelFormat(stream_buffer->stream->format);
+          HAL_LOGD("Driver format: %s 0x%x width: %d height: %d", 
+            FormatToString(request_context->camera_buffer->GetFourcc()).c_str(),
+            request_context->camera_buffer->GetFourcc(),
+            request_context->camera_buffer->GetWidth(),
+            request_context->camera_buffer->GetHeight());
+
+          HAL_LOGD("App format: %s 0x%x width: %d height: %d", 
+            FormatToString(fourcc).c_str(), 
+            fourcc,
+            stream_buffer->stream->width,
+            stream_buffer->stream->height);
+
+          dump_data(dump_data_index, (unsigned char *)request_context->camera_buffer->GetData(), 
+                    request_context->camera_buffer->GetWidth(), request_context->camera_buffer->GetHeight(), 
+                    request_context->camera_buffer->GetFourcc(), i, "pre-used");
+
+          // Note that the device buffer length is passed to the output frame. If the
+          // GrallocFrameBuffer does not have support for the transformation to
+          // |fourcc|, it will assume that the amount of data to lock is based on
+          // |buffer.length|, otherwise it will use the ImageProcessor::ConvertedSize.   
+          arc::GrallocFrameBuffer output_frame( *stream_buffer->buffer, stream_buffer->stream->width,
+                                                stream_buffer->stream->height, fourcc, buffer.length, 
+                                                stream_buffer->stream->usage);
+
+          res = output_frame.Map();
+          if (res) {
+            HAL_LOGE("Failed to map output frame.");
+            request_context->request.reset();
+            ret = -EINVAL;
+            goto Exit;
+          }
+
+          uint64_t time = timeNanos();
+          if (request_context->camera_buffer->GetFourcc() == fourcc &&
+            request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+            request_context->camera_buffer->GetHeight() == stream_buffer->stream->height) {
+            HAL_LOGV("No need to do conversion. Copy directly");
+            #if 1            
+            // If no format conversion needs to be applied, directly copy the data over.
+            memcpy(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetDataSize());
+            #else
+            CopyBlt(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetWidth(),
+                  request_context->camera_buffer->GetHeight());
+            #endif
+            memcpyTimeNs = timeNanos() - time;
+          } else {
+            HAL_LOGV("Need to perform the format conversion.");
+            bool can_convert_directly = (fourcc != V4L2_PIX_FMT_JPEG);
+            bool size_match = ( request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+                                request_context->camera_buffer->GetHeight() == stream_buffer->stream->height);
+            if (output_buffer_size == 1 && size_match && can_convert_directly){
+              arc::SimpleFrameBuffer in_frame(request_context->camera_buffer->GetData(), 
+                                              request_context->camera_buffer->GetFourcc(),
+                                              request_context->camera_buffer->GetWidth(), 
+                                              request_context->camera_buffer->GetHeight(),  
+                                              request_context->camera_buffer->GetFd(),
+                                              buffer.length);
+ 
+              cached_frame.ConvertDirectly(request_context->request->settings, in_frame, &output_frame);
+            } else {
+              if (!cached_frame.already_cached) {
+                cached_frame.SetSource(request_context->request->settings, request_context->camera_buffer.get(), 0);
+                dump_data(dump_data_index, (unsigned char *)cached_frame.yu12_frame_->GetData(), 
+                              cached_frame.yu12_frame_->GetWidth(), cached_frame.yu12_frame_->GetHeight(), 
+                              cached_frame.yu12_frame_->GetFourcc(), i, "mid");                
+              }
+              
+              cached_frame.Convert(request_context->request->settings, &output_frame, i);                                  
+            }
+
+            dump_data(dump_data_index, (unsigned char *)output_frame.GetData(), 
+                      output_frame.GetWidth(), output_frame.GetHeight(), fourcc, i, "post");                
+            convertTimeNs = timeNanos() - time;
+          }  
+ 
+      }
+
+      //EAGAIN we will not QBUF
+      if (ret == -EAGAIN) {
+        ret = 0;
+        goto Exit;
+      }
+
+      {
+        std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+        request_context->request.reset();
+        // Mark the buffer as not in flight.
+        request_context->active = false;
+      }
+
+      buffer_queue_notify_.notify_one();
+    }
+  }
+
+Exit:
+  if (isDebug())
+  {
+    uint64_t testDurationNs = timeNanos() - startTimeNs;
+    if (!ret) {
+        dq_time_end = timeNanos();
+        dq_success = true;
+        //dump_data_index++;
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] index[%d] Done[+ %d ms] [ioctl:%d ms] [convert:%d ms] [memcpy:%d ms]------------------------------------",
+            dump_data_index, last_dq_index,
+            toMilliSeconds(testDurationNs), toMilliSeconds(ioctlTimeNs-startTimeNs), toMilliSeconds(convertTimeNs), toMilliSeconds(memcpyTimeNs));
+    } else {
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] Fail[+ %d ms]------------------------------------",
+            dump_data_index,
+            toMilliSeconds(testDurationNs));
+    }
+}
+  if (!ret) {
+    ShowPreviewFPS();
+  }
+
+  return ret;
+}
+
+int V4L2Wrapper::GetInFlightBufferCount() {
+  int count = 0;
+  std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    if (buffer.active) {
+      count++;
+    }
+  }
+  return count;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.h b/hardware/ntimespace/camera/v4l2_wrapper.h
new file mode 100644
index 0000000000..a500ef81fc
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.h
@@ -0,0 +1,187 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
+#define V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
+
+#include <array>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <string>
+#include <vector>
+
+#include <android-base/unique_fd.h>
+#include "arc/common_types.h"
+#include "arc/frame_buffer.h"
+#include "capture_request.h"
+#include "common.h"
+#include "stream_format.h"
+
+namespace v4l2_camera_hal {
+
+#define DEFAULT_BUFFER_NUMBERS 2
+
+class V4L2Wrapper {
+ public:
+  // Use this method to create V4L2Wrapper objects. Functionally equivalent
+  // to "new V4L2Wrapper", except that it may return nullptr in case of failure.
+  static V4L2Wrapper* NewV4L2Wrapper(const std::string device_path, int camera_id);
+  virtual ~V4L2Wrapper();
+
+  // Helper class to ensure all opened connections are closed.
+  class Connection {
+   public:
+    Connection(std::shared_ptr<V4L2Wrapper> device)
+        : device_(std::move(device)), connect_result_(device_->Connect()) {}
+    ~Connection() {
+      if (connect_result_ == 0) {
+        device_->Disconnect();
+      }
+    }
+    // Check whether the connection succeeded or not.
+    inline int status() const { return connect_result_; }
+
+   private:
+    std::shared_ptr<V4L2Wrapper> device_;
+    const int connect_result_;
+  };
+
+  // Turn the stream on or off.
+  virtual int StreamOn();
+  virtual int StreamOff();
+  // Manage controls.
+  virtual int QueryControl(uint32_t control_id, v4l2_query_ext_ctrl* result);
+  virtual int GetControl(uint32_t control_id, int32_t* value);
+  virtual int SetControl(uint32_t control_id,
+                         int32_t desired,
+                         int32_t* result = nullptr);
+  // Manage format.
+  virtual int GetFormats(std::set<uint32_t>* v4l2_formats);
+  virtual int GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats);
+  virtual int GetFormatFrameSizes(uint32_t v4l2_format,
+                                  std::set<std::array<int32_t, 2>>* sizes);
+
+  // Durations are returned in ns.
+  virtual int GetFormatFrameDurationRange(
+      uint32_t v4l2_format,
+      const std::array<int32_t, 2>& size,
+      std::array<int64_t, 2>* duration_range);
+  virtual int SetFormat(const StreamFormat& desired_format,
+                        uint32_t* result_max_buffers);
+  // Manage buffers.
+  virtual int EnqueueRequest();
+  virtual int DequeueRequest(
+      std::shared_ptr<default_camera_hal::CaptureRequest> request);
+  virtual int GetInFlightBufferCount();
+
+  int get_fd() {return device_fd_;}
+  int get_camera_sharefd();
+  int get_stream_status() {return stream_status;}
+
+  inline std::string FormatToString(int32_t format);
+  void CopyBlt(void * dest, const void * src, size_t width, size_t height);
+  
+ private:
+  // Constructor is private to allow failing on bad input.
+  // Use NewV4L2Wrapper instead.
+  V4L2Wrapper(const std::string device_path, int camera_id);
+
+  // Connect or disconnect to the device. Access by creating/destroying
+  // a V4L2Wrapper::Connection object.
+  int Connect();
+  void Disconnect();
+  // Perform an ioctl call in a thread-safe fashion.
+  template <typename T>
+  int IoctlLocked(unsigned long request, T data);
+  // Request/release userspace buffer mode via VIDIOC_REQBUFS.
+  int RequestBuffers(uint32_t num_buffers);
+
+  inline bool connected() { return device_fd_.get() >= 0; }
+
+  // Format management.
+  const arc::SupportedFormats GetSupportedFormats();
+
+  // The camera device path. For example, /dev/video0.
+  const std::string device_path_;
+  int camera_id_;
+  // The opened device fd.
+  android::base::unique_fd device_fd_;
+
+  //dma buffer fd
+  int camera_share_fd_;
+  int ion_fd_;
+  
+  // The underlying gralloc module.
+  // std::unique_ptr<V4L2Gralloc> gralloc_;
+  // Whether or not the device supports the extended control query.
+  bool extended_query_supported_;
+  // The format this device is set up for.
+  std::unique_ptr<StreamFormat> format_;
+  // Lock protecting use of the buffer tracker.
+  std::mutex buffer_queue_lock_;
+  std::condition_variable buffer_queue_notify_;
+
+  // Lock protecting use of the device.
+  std::mutex device_lock_;
+  // Lock protecting connecting/disconnecting the device.
+  std::mutex connection_lock_;
+  // Reference count connections.
+  int connection_count_;
+  // Supported formats.
+  arc::SupportedFormats supported_formats_;
+  // Qualified formats.
+  arc::SupportedFormats qualified_formats_;
+
+  class RequestContext {
+   public:
+    RequestContext()
+        : active(false),
+          camera_buffer(std::make_shared<arc::V4L2FrameBuffer>()){};
+    ~RequestContext(){};
+    // Indicates whether this request context is in use.
+    bool active;
+    // Buffer handles of the context.
+    std::shared_ptr<arc::V4L2FrameBuffer> camera_buffer;
+    std::shared_ptr<default_camera_hal::CaptureRequest> request;
+  };
+
+  // Map of in flight requests.
+  // |buffers_.size()| will always be the maximum number of buffers this device
+  // can handle in its current format.
+  std::vector<RequestContext> buffers_;
+  int last_index_;
+  int last_dq_index;
+  int stream_status;
+  int buffer_numbers_ = DEFAULT_BUFFER_NUMBERS;
+
+  friend class Connection;
+  friend class V4L2WrapperMock;
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2Wrapper);
+};
+
+#define V4L2LOOPBACK_CID_BASE (V4L2_CID_USER_BASE | 0xf000)
+#define CID_KEEP_FORMAT (V4L2LOOPBACK_CID_BASE + 0)
+#define CID_SUSTAIN_FRAMERATE (V4L2LOOPBACK_CID_BASE + 1)
+#define CID_TIMEOUT (V4L2LOOPBACK_CID_BASE + 2)
+#define CID_TIMEOUT_IMAGE_IO (V4L2LOOPBACK_CID_BASE + 3)
+#define CID_SET_FACING  (V4L2LOOPBACK_CID_BASE + 4)
+#define CID_GET_DMABUF_FD (V4L2LOOPBACK_CID_BASE + 5)
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
diff --git a/hardware/ntimespace/camera/v4l2_wrapper_mock.h b/hardware/ntimespace/camera/v4l2_wrapper_mock.h
new file mode 100644
index 0000000000..1e4d3ad5fa
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper_mock.h
@@ -0,0 +1,56 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for wrapper class used to communicate with V4L2 devices.
+
+#ifndef V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
+#define V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
+
+#include "v4l2_wrapper.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+class V4L2WrapperMock : public V4L2Wrapper {
+ public:
+  V4L2WrapperMock() : V4L2Wrapper(""){};
+  MOCK_METHOD0(StreamOn, int());
+  MOCK_METHOD0(StreamOff, int());
+  MOCK_METHOD2(QueryControl,
+               int(uint32_t control_id, v4l2_query_ext_ctrl* result));
+  MOCK_METHOD2(GetControl, int(uint32_t control_id, int32_t* value));
+  MOCK_METHOD3(SetControl,
+               int(uint32_t control_id, int32_t desired, int32_t* result));
+  MOCK_METHOD1(GetFormats, int(std::set<uint32_t>*));
+  MOCK_METHOD1(GetQualifiedFormats, int(std::vector<uint32_t>*));
+  MOCK_METHOD2(GetFormatFrameSizes,
+               int(uint32_t, std::set<std::array<int32_t, 2>>*));
+  MOCK_METHOD3(GetFormatFrameDurationRange,
+               int(uint32_t,
+                   const std::array<int32_t, 2>&,
+                   std::array<int64_t, 2>*));
+  MOCK_METHOD2(SetFormat, int(const StreamFormat& desired_format,
+                              uint32_t* result_max_buffers));
+  MOCK_METHOD2(EnqueueBuffer,
+               int(const camera3_stream_buffer_t* camera_buffer,
+                   uint32_t* enqueued_index));
+  MOCK_METHOD1(DequeueBuffer, int(uint32_t* dequeued_index));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
diff --git a/hardware/rockchip/camera/Android.mk b/hardware/rockchip/camera/Android.mk.1
similarity index 100%
rename from hardware/rockchip/camera/Android.mk
rename to hardware/rockchip/camera/Android.mk.1
-- 
2.25.1

From 99460ea282877be9842750a62636eb1124c978b2 Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Thu, 27 Jun 2024 20:22:45 +0800
Subject: [PATCH] =?UTF-8?q?=E6=8F=90=E4=BA=A4=E6=91=84=E5=83=8F=E5=A4=B4AO?=
 =?UTF-8?q?SP=E4=BB=A3=E7=A0=81?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 device/rockchip/rk3588/rk3588_docker/manifest.xml | 9 +++++++++
 1 file changed, 9 insertions(+)

diff --git a/device/rockchip/rk3588/rk3588_docker/manifest.xml b/device/rockchip/rk3588/rk3588_docker/manifest.xml
index c540005b47..4d36816ea2 100644
--- a/device/rockchip/rk3588/rk3588_docker/manifest.xml
+++ b/device/rockchip/rk3588/rk3588_docker/manifest.xml
@@ -164,6 +164,15 @@
             <instance>default</instance>
         </interface>
     </hal>
+    <hal format="hidl">
+        <name>android.hardware.camera.provider</name>
+        <transport>hwbinder</transport>
+        <version>2.4</version>
+        <interface>
+            <name>ICameraProvider</name>
+            <instance>legacy/0</instance>
+        </interface>
+    </hal>
     <hal format="hidl">
         <name>android.hardware.radio</name>
         <transport>hwbinder</transport>
-- 
2.25.1

From f95ef3c5acfc86a8fc2fcbc668b3f06b8c28b202 Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Thu, 27 Jun 2024 16:11:28 +0800
Subject: [PATCH] =?UTF-8?q?=E6=8F=90=E4=BA=A4=E6=91=84=E5=83=8F=E5=A4=B4AO?=
 =?UTF-8?q?SP=E4=BB=A3=E7=A0=81?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 .../av/services/camera/libcameraservice/CameraService.cpp     | 4 ++++
 hardware/rockchip/camera/{Android.mk => Android.mk.1}         | 0
 2 files changed, 4 insertions(+)
 rename hardware/rockchip/camera/{Android.mk => Android.mk.1} (100%)

diff --git a/frameworks/av/services/camera/libcameraservice/CameraService.cpp b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
index ccc4caf5aa..6116c61936 100755
--- a/frameworks/av/services/camera/libcameraservice/CameraService.cpp
+++ b/frameworks/av/services/camera/libcameraservice/CameraService.cpp
@@ -1943,6 +1943,10 @@ Status CameraService::supportsCameraApi(const String16& cameraId, int apiVersion
     }
 
     int deviceVersion = getDeviceVersion(id);
+    while(deviceVersion == -1){
+        usleep(100000);
+        deviceVersion = getDeviceVersion(id);
+    }
     switch (deviceVersion) {
         case CAMERA_DEVICE_API_VERSION_1_0:
         case CAMERA_DEVICE_API_VERSION_3_0:
diff --git a/hardware/rockchip/camera/Android.mk b/hardware/rockchip/camera/Android.mk.1
similarity index 100%
rename from hardware/rockchip/camera/Android.mk
rename to hardware/rockchip/camera/Android.mk.1
-- 
2.25.1

From 01dd00f06d393dbec06ef4ec4634b5432a0de154 Mon Sep 17 00:00:00 2001
From: kongxiangqiao <kongxiangqiao@ntimespace.com>
Date: Thu, 27 Jun 2024 15:06:55 +0800
Subject: [PATCH] =?UTF-8?q?=E6=8F=90=E4=BA=A4=E6=91=84=E5=83=8F=E5=A4=B4AO?=
 =?UTF-8?q?SP=E4=BB=A3=E7=A0=81?=
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

---
 device/rockchip/common/device.mk              |    1 +
 .../rk3588/rk3588_docker/rk3588_docker.mk     |    7 +
 device/rockchip/space-common/device.mk        |    5 +
 hardware/ntimespace/camera/Android.mk         |  178 +++
 hardware/ntimespace/camera/Android.mk-1       |  227 ++++
 hardware/ntimespace/camera/README.md          |  156 +++
 .../ntimespace/camera/arc/cached_frame.cpp    |  424 ++++++
 hardware/ntimespace/camera/arc/cached_frame.h |   97 ++
 hardware/ntimespace/camera/arc/common.h       |   37 +
 hardware/ntimespace/camera/arc/common_types.h |   55 +
 hardware/ntimespace/camera/arc/exif_utils.cpp |  512 ++++++++
 hardware/ntimespace/camera/arc/exif_utils.h   |  178 +++
 .../camera/arc/format_convert_test.cpp        |  248 ++++
 .../camera/arc/format_convert_test.h          |   23 +
 .../ntimespace/camera/arc/frame_buffer.cpp    |  379 ++++++
 hardware/ntimespace/camera/arc/frame_buffer.h |  268 ++++
 .../ntimespace/camera/arc/image_processor.cpp |  663 ++++++++++
 .../ntimespace/camera/arc/image_processor.h   |   47 +
 .../ntimespace/camera/arc/jpeg_compressor.cpp |  188 +++
 .../ntimespace/camera/arc/jpeg_compressor.h   |   73 ++
 hardware/ntimespace/camera/camera.cpp         |  643 ++++++++++
 hardware/ntimespace/camera/camera.h           |  151 +++
 hardware/ntimespace/camera/camera_init.rc     |    5 +
 hardware/ntimespace/camera/camera_init.sh     |   13 +
 .../ntimespace/camera/capture_request.cpp     |   54 +
 hardware/ntimespace/camera/capture_request.h  |   44 +
 hardware/ntimespace/camera/common.h           |   65 +
 hardware/ntimespace/camera/debug.cpp          |  316 +++++
 hardware/ntimespace/camera/debug.h            |   58 +
 hardware/ntimespace/camera/flash.cpp          |  340 +++++
 hardware/ntimespace/camera/flash.h            |   70 +
 .../camera/format_metadata_factory.cpp        |  271 ++++
 .../camera/format_metadata_factory.h          |   36 +
 .../camera/format_metadata_factory_test.cpp   |  198 +++
 hardware/ntimespace/camera/function_thread.h  |   41 +
 .../camera/gralloc/gralloc3_impl.cpp          |  317 +++++
 .../ntimespace/camera/gralloc/gralloc3_impl.h |   84 ++
 .../ntimespace/camera/gralloc/hal_public.h    |  215 ++++
 .../ntimespace/camera/gralloc/img_gralloc.h   |  107 ++
 .../ntimespace/camera/gralloc/img_gralloc1.h  |  305 +++++
 .../gralloc/img_gralloc_common_public.h       |  370 ++++++
 .../ntimespace/camera/gralloc/psb_gralloc.cpp |  242 ++++
 .../ntimespace/camera/gralloc/psb_gralloc.h   |   60 +
 .../camera/gralloc/psb_gralloc3.cpp           |  151 +++
 .../ntimespace/camera/gralloc/psb_gralloc3.h  |   55 +
 .../ntimespace/camera/hardware/hw_converter.h |   94 ++
 .../camera/hardware/qc_hw_converter.cpp       |  252 ++++
 .../camera/hardware/rk_hw_converter.cpp       |  159 +++
 .../ntimespace/camera/metadata/array_vector.h |   52 +
 .../metadata/boottime_state_delegate.cpp      |   47 +
 .../camera/metadata/boottime_state_delegate.h |   38 +
 .../camera/metadata/camera_metadata.cpp       |  565 ++++++++
 .../camera/metadata/camera_metadata.h         |  234 ++++
 hardware/ntimespace/camera/metadata/control.h |  221 ++++
 .../metadata/control_delegate_interface.h     |   41 +
 .../control_delegate_interface_mock.h         |   38 +
 .../metadata/control_options_interface.h      |   44 +
 .../metadata/control_options_interface_mock.h |   39 +
 .../camera/metadata/control_test.cpp          |  458 +++++++
 .../camera/metadata/converter_interface.h     |   35 +
 .../metadata/converter_interface_mock.h       |   38 +
 .../camera/metadata/default_option_delegate.h |   60 +
 .../metadata/default_option_delegate_mock.h   |   37 +
 .../metadata/default_option_delegate_test.cpp |   62 +
 .../camera/metadata/enum_converter.cpp        |   81 ++
 .../camera/metadata/enum_converter.h          |   43 +
 .../camera/metadata/enum_converter_test.cpp   |   99 ++
 .../metadata/ignored_control_delegate.h       |   43 +
 .../ignored_control_delegate_test.cpp         |   44 +
 .../camera/metadata/map_converter.h           |  139 ++
 .../camera/metadata/map_converter_test.cpp    |  110 ++
 .../camera/metadata/menu_control_options.h    |   77 ++
 .../metadata/menu_control_options_test.cpp    |  108 ++
 .../ntimespace/camera/metadata/metadata.cpp   |  232 ++++
 .../ntimespace/camera/metadata/metadata.h     |   50 +
 .../camera/metadata/metadata_common.h         |  323 +++++
 .../camera/metadata/metadata_reader.cpp       |  297 +++++
 .../camera/metadata/metadata_reader.h         |   76 ++
 .../camera/metadata/metadata_reader_mock.h    |   46 +
 .../camera/metadata/metadata_reader_test.cpp  |  368 ++++++
 .../camera/metadata/metadata_test.cpp         |  322 +++++
 .../metadata/no_effect_control_delegate.h     |   46 +
 .../no_effect_control_delegate_test.cpp       |   43 +
 .../metadata/partial_metadata_factory.h       |  335 +++++
 .../partial_metadata_factory_test.cpp         |  456 +++++++
 .../metadata/partial_metadata_interface.h     |   64 +
 .../partial_metadata_interface_mock.h         |   45 +
 .../ntimespace/camera/metadata/property.h     |   69 +
 .../camera/metadata/property_test.cpp         |  156 +++
 .../camera/metadata/ranged_converter.h        |  103 ++
 .../camera/metadata/ranged_converter_test.cpp |   86 ++
 .../camera/metadata/scaling_converter.h       |   75 ++
 .../camera/metadata/slider_control_options.h  |   80 ++
 .../metadata/slider_control_options_test.cpp  |  128 ++
 hardware/ntimespace/camera/metadata/state.h   |   96 ++
 .../metadata/state_delegate_interface.h       |   34 +
 .../metadata/state_delegate_interface_mock.h  |   37 +
 .../ntimespace/camera/metadata/state_test.cpp |  117 ++
 .../camera/metadata/tagged_control_delegate.h |   50 +
 .../metadata/tagged_control_delegate_test.cpp |   90 ++
 .../camera/metadata/tagged_control_options.h  |   61 +
 .../metadata/tagged_control_options_test.cpp  |  102 ++
 .../ntimespace/camera/metadata/test_common.h  |   96 ++
 hardware/ntimespace/camera/metadata/types.h   |   82 ++
 .../camera/metadata/v4l2_control_delegate.h   |   66 +
 .../metadata/v4l2_control_delegate_test.cpp   |  109 ++
 .../ntimespace/camera/request_tracker.cpp     |  159 +++
 hardware/ntimespace/camera/request_tracker.h  |   80 ++
 .../camera/request_tracker_test.cpp           |  259 ++++
 .../ntimespace/camera/static_properties.cpp   |  503 ++++++++
 .../ntimespace/camera/static_properties.h     |  120 ++
 .../camera/static_properties_test.cpp         |  674 ++++++++++
 hardware/ntimespace/camera/stream_format.cpp  |  242 ++++
 hardware/ntimespace/camera/stream_format.h    |   83 ++
 hardware/ntimespace/camera/v4l2_camera.cpp    |  912 +++++++++++++
 hardware/ntimespace/camera/v4l2_camera.h      |  120 ++
 .../ntimespace/camera/v4l2_camera_hal.cpp     |  345 +++++
 hardware/ntimespace/camera/v4l2_camera_hal.h  |   74 ++
 .../camera/v4l2_metadata_factory.cpp          |  601 +++++++++
 .../ntimespace/camera/v4l2_metadata_factory.h |   34 +
 hardware/ntimespace/camera/v4l2_wrapper.cpp   | 1136 +++++++++++++++++
 .../ntimespace/camera/v4l2_wrapper.cpp_10     | 1089 ++++++++++++++++
 hardware/ntimespace/camera/v4l2_wrapper.h     |  187 +++
 .../ntimespace/camera/v4l2_wrapper_mock.h     |   56 +
 124 files changed, 22249 insertions(+)
 create mode 100644 hardware/ntimespace/camera/Android.mk
 create mode 100644 hardware/ntimespace/camera/Android.mk-1
 create mode 100644 hardware/ntimespace/camera/README.md
 create mode 100644 hardware/ntimespace/camera/arc/cached_frame.cpp
 create mode 100644 hardware/ntimespace/camera/arc/cached_frame.h
 create mode 100644 hardware/ntimespace/camera/arc/common.h
 create mode 100644 hardware/ntimespace/camera/arc/common_types.h
 create mode 100644 hardware/ntimespace/camera/arc/exif_utils.cpp
 create mode 100644 hardware/ntimespace/camera/arc/exif_utils.h
 create mode 100644 hardware/ntimespace/camera/arc/format_convert_test.cpp
 create mode 100644 hardware/ntimespace/camera/arc/format_convert_test.h
 create mode 100644 hardware/ntimespace/camera/arc/frame_buffer.cpp
 create mode 100644 hardware/ntimespace/camera/arc/frame_buffer.h
 create mode 100644 hardware/ntimespace/camera/arc/image_processor.cpp
 create mode 100644 hardware/ntimespace/camera/arc/image_processor.h
 create mode 100644 hardware/ntimespace/camera/arc/jpeg_compressor.cpp
 create mode 100644 hardware/ntimespace/camera/arc/jpeg_compressor.h
 create mode 100644 hardware/ntimespace/camera/camera.cpp
 create mode 100644 hardware/ntimespace/camera/camera.h
 create mode 100755 hardware/ntimespace/camera/camera_init.rc
 create mode 100755 hardware/ntimespace/camera/camera_init.sh
 create mode 100644 hardware/ntimespace/camera/capture_request.cpp
 create mode 100644 hardware/ntimespace/camera/capture_request.h
 create mode 100644 hardware/ntimespace/camera/common.h
 create mode 100644 hardware/ntimespace/camera/debug.cpp
 create mode 100644 hardware/ntimespace/camera/debug.h
 create mode 100644 hardware/ntimespace/camera/flash.cpp
 create mode 100644 hardware/ntimespace/camera/flash.h
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory.cpp
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/format_metadata_factory_test.cpp
 create mode 100644 hardware/ntimespace/camera/function_thread.h
 create mode 100644 hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/gralloc3_impl.h
 create mode 100644 hardware/ntimespace/camera/gralloc/hal_public.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc1.h
 create mode 100644 hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc.h
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
 create mode 100644 hardware/ntimespace/camera/gralloc/psb_gralloc3.h
 create mode 100644 hardware/ntimespace/camera/hardware/hw_converter.h
 create mode 100644 hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
 create mode 100644 hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/array_vector.h
 create mode 100644 hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/boottime_state_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/camera_metadata.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/camera_metadata.h
 create mode 100644 hardware/ntimespace/camera/metadata/control.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_delegate_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_options_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_options_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/control_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/converter_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/converter_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/enum_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/ignored_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/map_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/map_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/menu_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_common.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/metadata_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/property.h
 create mode 100644 hardware/ntimespace/camera/metadata/property_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/ranged_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/scaling_converter.h
 create mode 100644 hardware/ntimespace/camera/metadata/slider_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/state.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_delegate_interface.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
 create mode 100644 hardware/ntimespace/camera/metadata/state_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_options.h
 create mode 100644 hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
 create mode 100644 hardware/ntimespace/camera/metadata/test_common.h
 create mode 100644 hardware/ntimespace/camera/metadata/types.h
 create mode 100644 hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
 create mode 100644 hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
 create mode 100644 hardware/ntimespace/camera/request_tracker.cpp
 create mode 100644 hardware/ntimespace/camera/request_tracker.h
 create mode 100644 hardware/ntimespace/camera/request_tracker_test.cpp
 create mode 100644 hardware/ntimespace/camera/static_properties.cpp
 create mode 100644 hardware/ntimespace/camera/static_properties.h
 create mode 100644 hardware/ntimespace/camera/static_properties_test.cpp
 create mode 100644 hardware/ntimespace/camera/stream_format.cpp
 create mode 100644 hardware/ntimespace/camera/stream_format.h
 create mode 100644 hardware/ntimespace/camera/v4l2_camera.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_camera.h
 create mode 100644 hardware/ntimespace/camera/v4l2_camera_hal.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_camera_hal.h
 create mode 100644 hardware/ntimespace/camera/v4l2_metadata_factory.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_metadata_factory.h
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.cpp
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.cpp_10
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper.h
 create mode 100644 hardware/ntimespace/camera/v4l2_wrapper_mock.h

diff --git a/device/rockchip/common/device.mk b/device/rockchip/common/device.mk
index 5e3333407e..19689955d8 100644
--- a/device/rockchip/common/device.mk
+++ b/device/rockchip/common/device.mk
@@ -352,6 +352,7 @@ PRODUCT_COPY_FILES += \
 PRODUCT_PACKAGES += \
     camera.$(TARGET_BOARD_HARDWARE) \
     Camera
+    #camera.$(TARGET_BOARD_HARDWARE) \
 
 # Camera HAL
 PRODUCT_PACKAGES += \
diff --git a/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk b/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
index 3ab0420429..383a466a11 100755
--- a/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
+++ b/device/rockchip/rk3588/rk3588_docker/rk3588_docker.mk
@@ -61,6 +61,13 @@ PRODUCT_PACKAGES += \
 	binder_alloc \
 	ipconfigstore \
 
+PRODUCT_PACKAGES += \
+        camera.$(TARGET_BOARD_HARDWARE) \
+        camera.device@1.0-impl \
+        camera.device@3.2-impl \
+        android.hardware.camera.provider@2.4-impl \
+        android.hardware.camera.provider@2.4-service
+
 PRODUCT_COPY_FILES += \
 	$(LOCAL_PATH)/init.redroid.rc:$(TARGET_COPY_OUT_VENDOR)/etc/init/init.redroid.rc \
 	$(LOCAL_PATH)/chmod.sh:$(TARGET_COPY_OUT_VENDOR)/bin/chmod.sh \
diff --git a/device/rockchip/space-common/device.mk b/device/rockchip/space-common/device.mk
index 2fadf9f128..61304c53a2 100644
--- a/device/rockchip/space-common/device.mk
+++ b/device/rockchip/space-common/device.mk
@@ -81,6 +81,11 @@ PRODUCT_COPY_FILES += \
         vendor/ntimespace/scripts/s9.boot.rc:system/etc/init/s9.boot.rc \
         vendor/ntimespace/scripts/script.sh:system/bin/script.sh
 
+# camera
+PRODUCT_COPY_FILES += \
+        hardware/ntimespace/camera/camera_init.sh:system/bin/camera_init.sh \
+        hardware/ntimespace/camera/camera_init.rc:system/etc/init/camera_init.rc 
+
 # logcatd
 PRODUCT_PACKAGES += logcatd logpersist.start
 PRODUCT_PROPERTY_OVERRIDES += logd.logpersistd=logcatd 
diff --git a/hardware/ntimespace/camera/Android.mk b/hardware/ntimespace/camera/Android.mk
new file mode 100644
index 0000000000..c7b383dad8
--- /dev/null
+++ b/hardware/ntimespace/camera/Android.mk
@@ -0,0 +1,178 @@
+#
+# Copyright 2016 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+LOCAL_PATH:= $(call my-dir)
+include $(CLEAR_VARS)
+
+TARGET_HAS_RGA := true
+
+# Prevent the HAL from building on devices not specifically
+# requesting to use it.
+v4l2_shared_libs := \
+  libbase \
+  libchrome \
+  libcamera_metadata \
+  libcutils \
+  libexif \
+  libhardware \
+  liblog \
+  libsync \
+  libutils \
+  libion \
+  libhidlbase \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0 \
+  android.hardware.graphics.allocator@2.0	
+
+  #libgralloctypes \
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  librga 
+endif
+
+v4l2_static_libs := \
+  libyuv \
+  libjpeg 
+
+v4l2_cflags := -fno-short-enums -Wall -Wextra -Werror -fvisibility=hidden -DHAVE_JPEG -Wno-date-time -g
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_cflags += -DHAS_RGA
+endif
+
+v4l2_c_includes := $(call include-path-for, camera) \
+    external/libyuv/files/include \
+    frameworks/native/libs/ui/include \
+    hardware/libhardware/include/ \
+    system/core/libcutils/include \
+    hardware/libhardware/modules/gralloc \
+    system/core/libsystem/include \
+    system/memory/libion/original-kernel-headers \
+    system/core/liblog/include \
+    frameworks/native/include \
+    system/core/libsync \
+    system/core/libsync/include\
+    external/libdrm/include/drm \
+    system/libhidl/base/include \
+    system/libfmq/base \
+    hardware/rockchip/libgralloc \
+    frameworks/native/libs/gralloc/types/include \
+    frameworks/native/libs/nativewindow/include \
+    frameworks/native/libs/nativebase/include \
+    frameworks/native/libs/arect/include    
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/rockchip/librga/include/
+endif
+
+  
+v4l2_src_files := \
+  arc/cached_frame.cpp \
+  arc/exif_utils.cpp \
+  arc/frame_buffer.cpp \
+  arc/image_processor.cpp \
+  arc/jpeg_compressor.cpp \
+  arc/format_convert_test.cpp \
+  camera.cpp \
+  capture_request.cpp \
+  format_metadata_factory.cpp \
+  metadata/boottime_state_delegate.cpp \
+  metadata/enum_converter.cpp \
+  metadata/metadata.cpp \
+  metadata/metadata_reader.cpp \
+  metadata/camera_metadata.cpp \
+  request_tracker.cpp \
+  static_properties.cpp \
+  stream_format.cpp \
+  v4l2_camera.cpp \
+  v4l2_camera_hal.cpp \
+  v4l2_metadata_factory.cpp \
+  v4l2_wrapper.cpp \
+  gralloc/psb_gralloc3.cpp \
+  gralloc/gralloc3_impl.cpp \
+  debug.cpp \
+  flash.cpp
+
+
+ifeq ($(TARGET_HAS_RGA),true)
+  v4l2_src_files += hardware/rk_hw_converter.cpp
+endif
+
+
+#v4l2_test_files := \
+#  format_metadata_factory_test.cpp \
+#  metadata/control_test.cpp \
+#  metadata/default_option_delegate_test.cpp \
+#  metadata/enum_converter_test.cpp \
+#  metadata/ignored_control_delegate_test.cpp \
+#  metadata/map_converter_test.cpp \
+#  metadata/menu_control_options_test.cpp \
+#  metadata/metadata_reader_test.cpp \
+#  metadata/metadata_test.cpp \
+#  metadata/no_effect_control_delegate_test.cpp \
+#  metadata/partial_metadata_factory_test.cpp \
+#  metadata/property_test.cpp \
+#  metadata/ranged_converter_test.cpp \
+#  metadata/slider_control_options_test.cpp \
+#  metadata/state_test.cpp \
+#  metadata/tagged_control_delegate_test.cpp \
+#  metadata/tagged_control_options_test.cpp \
+#  metadata/v4l2_control_delegate_test.cpp \
+#  request_tracker_test.cpp \
+#  static_properties_test.cpp 
+
+# V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.rk3588luckion
+LOCAL_MODULE := camera.$(TARGET_BOARD_HARDWARE)
+LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+LOCAL_MODULE_RELATIVE_PATH := hw
+LOCAL_CFLAGS += $(v4l2_cflags) -DLOG_NDEBUG=0
+LOCAL_SHARED_LIBRARIES += $(v4l2_shared_libs)
+#LOCAL_HEADER_LIBRARIES := libgtest_prod_headers
+LOCAL_STATIC_LIBRARIES := $(v4l2_static_libs)
+
+LOCAL_VENDOR_MODULE := true
+
+LOCAL_C_INCLUDES += $(v4l2_c_includes)
+LOCAL_SRC_FILES := $(v4l2_src_files)
+
+include $(BUILD_SHARED_LIBRARY)
+
+# Unit tests for V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.v4l2_test
+#LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+#LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+
+#LOCAL_CFLAGS += $(v4l2_cflags)
+#LOCAL_SHARED_LIBRARIES := $(v4l2_shared_libs)
+#LOCAL_STATIC_LIBRARIES := \
+#  libgmock \
+#  $(v4l2_static_libs) \
+
+#LOCAL_C_INCLUDES += $(v4l2_c_includes)
+#LOCAL_SRC_FILES := \
+#  $(v4l2_src_files) \
+#  $(v4l2_test_files) \
+
+#include $(BUILD_NATIVE_TEST)
diff --git a/hardware/ntimespace/camera/Android.mk-1 b/hardware/ntimespace/camera/Android.mk-1
new file mode 100644
index 0000000000..8912d4b8a1
--- /dev/null
+++ b/hardware/ntimespace/camera/Android.mk-1
@@ -0,0 +1,227 @@
+#
+# Copyright 2016 The Android Open Source Project
+#
+# Licensed under the Apache License, Version 2.0 (the "License");
+# you may not use this file except in compliance with the License.
+# You may obtain a copy of the License at
+#
+#      http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an "AS IS" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+LOCAL_PATH:= $(call my-dir)
+include $(CLEAR_VARS)
+
+ifeq ($(PRODUCT_HARDWARE),rk30board)
+TARGET_HAS_C2D2 := false
+TARGET_HAS_RGA := true
+else
+TARGET_HAS_C2D2 := true
+TARGET_HAS_RGA := false
+endif
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+$(warning "TARGET_BOARD_PLATFORM [$(TARGET_BOARD_PLATFORM)]")
+$(warning "just be careful!the camera hal may be need develop for this device...")
+TARGET_HAS_C2D2 := false
+TARGET_HAS_RGA := false
+endif
+
+# Prevent the HAL from building on devices not specifically
+# requesting to use it.
+v4l2_shared_libs := \
+  libbase \
+  libchrome \
+  libcamera_metadata \
+  libcutils \
+  libexif \
+  libhardware \
+  liblog \
+  libsync \
+  libutils \
+  libion \
+  libhidlbase 
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0
+endif 
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+v4l2_shared_libs += \
+  android.hardware.graphics.mapper@2.0 \
+  android.hardware.graphics.mapper@3.0
+endif
+
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_shared_libs += \
+  libc2dcolorconvert 
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_shared_libs += \
+  librga 
+endif
+
+v4l2_static_libs := \
+  libyuv \
+  libjpeg
+
+v4l2_cflags := -fno-short-enums  -Wextra -Wmacro-redefined -fvisibility=hidden -DHAVE_JPEG -Wno-date-time -g
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_cflags += -DHAS_C2D2
+endif
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_cflags += -DHAS_RGA
+endif
+
+v4l2_c_includes := $(call include-path-for, camera) \
+    external/libyuv/files/include \
+    frameworks/native/libs/ui/include \
+    hardware/libhardware/modules/gralloc
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += \
+    hardware/libhardware/include/ \
+    system/core/libcutils/include \
+    system/core/libsystem/include \
+    system/memory/libion/original-kernel-headers \
+    system/core/liblog/include \
+    frameworks/native/include \
+    system/core/libsync \
+    system/core/libsync/include\
+    external/libdrm/include/drm \
+    system/libhidl/base/include \
+    system/libfmq/base \
+    hardware/rockchip/libgralloc \
+    frameworks/native/libs/gralloc/types/include \
+    frameworks/native/libs/nativewindow/include \
+    frameworks/native/libs/nativebase/include \
+    frameworks/native/libs/arect/include  
+endif
+
+ifeq ($(TARGET_HAS_C2D2),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/mci/qcom-media/$(TARGET_BOARD_PLATFORM)/libc2dcolorconvert \
+    $(TARGET_OUT_HEADERS)/adreno \
+    $(MCI_KERNEL_PREFIX)/usr/include \
+    $(TOP)/vendor/mci/qcom-opensource/display/gralloc
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+v4l2_c_includes += $(call include-path-for, camera) \
+    hardware/rockchip/librga/include
+endif
+
+  
+v4l2_src_files := \
+  arc/cached_frame.cpp \
+  arc/exif_utils.cpp \
+  arc/frame_buffer.cpp \
+  arc/image_processor.cpp \
+  arc/jpeg_compressor.cpp \
+  arc/format_convert_test.cpp \
+  camera.cpp \
+  capture_request.cpp \
+  format_metadata_factory.cpp \
+  metadata/boottime_state_delegate.cpp \
+  metadata/enum_converter.cpp \
+  metadata/metadata.cpp \
+  metadata/metadata_reader.cpp \
+  metadata/camera_metadata.cpp \
+  request_tracker.cpp \
+  static_properties.cpp \
+  stream_format.cpp \
+  v4l2_camera.cpp \
+  v4l2_camera_hal.cpp \
+  v4l2_metadata_factory.cpp \
+  v4l2_wrapper.cpp \
+  debug.cpp \
+  flash.cpp 
+
+ifeq ($(TARGET_HAS_C2D2),true)
+  v4l2_src_files += hardware/qc_hw_converter.cpp \
+    gralloc/psb_gralloc.cpp
+endif
+
+ifeq ($(TARGET_HAS_RGA),true)
+  v4l2_src_files += hardware/rk_hw_converter.cpp \
+    gralloc/psb_gralloc3.cpp \
+    gralloc/gralloc3_impl.cpp
+endif
+
+ifneq ($(filter cutefish_h1 cutefish_a2,$(TARGET_BOARD_PLATFORM)),)
+    v4l2_src_files += gralloc/psb_gralloc3.cpp \
+        gralloc/gralloc3_impl.cpp
+endif
+
+
+#v4l2_test_files := \
+#  format_metadata_factory_test.cpp \
+#  metadata/control_test.cpp \
+#  metadata/default_option_delegate_test.cpp \
+#  metadata/enum_converter_test.cpp \
+#  metadata/ignored_control_delegate_test.cpp \
+#  metadata/map_converter_test.cpp \
+#  metadata/menu_control_options_test.cpp \
+#  metadata/metadata_reader_test.cpp \
+#  metadata/metadata_test.cpp \
+#  metadata/no_effect_control_delegate_test.cpp \
+#  metadata/partial_metadata_factory_test.cpp \
+#  metadata/property_test.cpp \
+#  metadata/ranged_converter_test.cpp \
+#  metadata/slider_control_options_test.cpp \
+#  metadata/state_test.cpp \
+#  metadata/tagged_control_delegate_test.cpp \
+#  metadata/tagged_control_options_test.cpp \
+#  metadata/v4l2_control_delegate_test.cpp \
+#  request_tracker_test.cpp \
+#  static_properties_test.cpp 
+
+# V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+LOCAL_MODULE := camera.$(PRODUCT_HARDWARE)
+LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+LOCAL_MODULE_RELATIVE_PATH := hw
+LOCAL_CFLAGS += $(v4l2_cflags) 
+#-DLOG_NDEBUG=0
+LOCAL_SHARED_LIBRARIES += $(v4l2_shared_libs)
+#LOCAL_HEADER_LIBRARIES := libgtest_prod_headers
+LOCAL_STATIC_LIBRARIES := $(v4l2_static_libs)
+
+LOCAL_VENDOR_MODULE := true
+
+LOCAL_C_INCLUDES += $(v4l2_c_includes)
+LOCAL_SRC_FILES := $(v4l2_src_files)
+
+include $(BUILD_SHARED_LIBRARY)
+
+# Unit tests for V4L2 Camera HAL.
+# ==============================================================================
+#include $(CLEAR_VARS)
+#LOCAL_MODULE := camera.v4l2_test
+#LOCAL_LICENSE_KINDS := SPDX-license-identifier-Apache-2.0 SPDX-license-identifier-BSD
+#LOCAL_LICENSE_CONDITIONS := notice
+#LOCAL_NOTICE_FILE := $(LOCAL_PATH)/../../../NOTICE
+
+#LOCAL_CFLAGS += $(v4l2_cflags)
+#LOCAL_SHARED_LIBRARIES := $(v4l2_shared_libs)
+#LOCAL_STATIC_LIBRARIES := \
+#  libgmock \
+#  $(v4l2_static_libs) \
+
+#LOCAL_C_INCLUDES += $(v4l2_c_includes)
+#LOCAL_SRC_FILES := \
+#  $(v4l2_src_files) \
+#  $(v4l2_test_files) \
+
+#include $(BUILD_NATIVE_TEST)
diff --git a/hardware/ntimespace/camera/README.md b/hardware/ntimespace/camera/README.md
new file mode 100644
index 0000000000..8c682e9968
--- /dev/null
+++ b/hardware/ntimespace/camera/README.md
@@ -0,0 +1,156 @@
+# V4L2 Camera HALv3
+
+The camera.v4l2 library implements a Camera HALv3 using the
+Video For Linux 2 (V4L2) interface. This allows it to theoretically
+work with a wide variety of devices, though the limitations of V4L2
+introduce some [caveats](#V4L2-Deficiencies), causing this HAL to
+not be fully spec-compliant.
+
+## Current status
+
+People are free to use that library if that works for their purpose,
+but it's not maintained by Android Camera team. There is another V4L2
+camera HAL implementation which is maintained by Android Camera team
+starting in Android P. See more information
+[here](https://source.android.com/devices/camera/external-usb-cameras).
+
+## Building a Device with the HAL
+
+To ensure the HAL is built for a device, include the following in your
+`<device>.mk`:
+
+```
+USE_CAMERA_V4L2_HAL := true
+PRODUCT_PACKAGES += camera.v4l2
+PRODUCT_PROPERTY_OVERRIDES += ro.hardware.camera=v4l2
+```
+
+The first line ensures the V4L2 HAL module is visible to the build system.
+This prevents checkbuilds on devices that don't have the necessary support
+from failing. The product packages tells the build system to include the V4L2
+HALv3 library in the system image. The final line tells the hardware manager
+to load the V4L2 HAL instead of a default Camera HAL.
+
+## Requirements for Using the HAL
+
+Devices and cameras wishing to use this HAL must meet
+the following requirements:
+
+* The camera must support BGR32, YUV420, and JPEG formats.
+* The gralloc and other graphics modules used by the device must use
+`HAL_PIXEL_FORMAT_RGBA_8888` as the `HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED`
+
+## Understanding the HAL Code
+
+There are three large pieces to the V4L2 Camera HAL: the general HALv3
+Camera & HAL code, the specific implementation using V4L2,
+and the Metadata system.
+
+For context, you may also wish to read some of the documentation in
+libhardware/include/camera3.h about how the framework interacts with the HAL.
+
+### Camera & HAL Interface
+
+The camera and HAL interfaces are implemented by the Camera and
+V4L2CameraHAL classes.
+
+The V4L2CameraHAL class deals primarily with initialization of the system.
+On creation, it searches /dev/video* nodes for ones with the necessary
+capabilities. These are then all presented to the framework as available
+for use. Further operations are passed to the individual Cameras as appropriate.
+
+The Camera class implements the general logic for handling the camera -
+opening and closing, configuring streams, preparing and tracking requests, etc.
+While it handles the logistics surrounding the camera, actual image
+capture and settings logic are implemented by calling down into the
+[V4L2 Camera](#V4L2-Camera). The Camera (using helper classes) enforces
+restrictions given in the [Metadata](#Metadata) initialized by the V4L2Camera,
+such as limits on the number of in-flight requests per stream.
+Notably, this means you should be able to replace the V4L2 implementation
+with something else, and as long as you fill in the metadata correctly the
+Camera class should "just work".
+
+### V4L2 Specific Implementation
+
+The V4L2Camera class is the implementation of all the capture functionality.
+It includes some methods for the Camera class to verify the setup, but the
+bulk of the class is the request queue. The Camera class submits CaptureRequests
+as they come in and are verified. The V4L2Camera runs these through a three
+stage asynchronous pipeline:
+
+* Acceptance: the V4L2Camera accepts the request, and puts it into waiting to be
+picked up by the enqueuer.
+* Enqueuing: the V4L2Camera reads the request settings, applies them to the
+device, takes a snapshot of the settings, and hands the buffer over to the
+V4L2 driver.
+* Dequeueing: A completed frame is reclaimed from the driver, and sent
+back to the Camera class for final processing (validation, filling in the
+result object, and sending the data back to the framework).
+
+Much of this work is aided by the V4L2Wrapper helper class,
+which provides simpler inputs and outputs around the V4L2 ioctls
+based on their known use by the HAL; filling in common values automatically
+and extracting the information useful to the HAL from the results.
+This wrapper is also used to expose V4L2 controls to their corresponding
+Metadata components.
+
+### Metadata
+
+The Metadata subsystem attempts to organize and simplify handling of
+camera metadata (system/media/camera/docs/docs.html). At the top level
+is the Metadata class and the PartialMetadataInterface. The Metadata
+class provides high level interaction with the individual components -
+filling the static metadata, validating, getting, and setting settings,
+etc. The Metadata class passes all of these things on to the component
+PartialMetadataInterfaces, each of which filter for their specific
+metadata components and perform the requested task.
+
+Some generalized metadata classes are provided to simplify common logic
+for this filtering and application. At a high level, there are three
+types:
+
+* Properties: a static value.
+* Controls: dynamically adjustable values, and optionally an
+associated static property indicating what allowable values are.
+* States: a dynamic read-only value.
+
+The Metadata system uses further interfaces and subclasses to distinguish
+the variety of different functionalities necessary for different metadata
+tags.
+
+#### Metadata Factory
+
+This V4L2 Camera HAL implementation utilizes a metadata factory method.
+This method initializes all the 100+ required metadata components for
+basic HAL spec compliance. Most do nothing/report fixed values,
+but a few are hooked up to the V4L2 driver.
+
+This HAL was initially designed for use with the Raspberry Pi camera module
+v2.1, so the fixed defaults are usually assigned based on that camera.
+
+## V4L2 Deficiencies
+
+* One stream at a time is supported. Notably, this means you must re-configure
+the stream between preview and capture if they're not the same format.
+This makes this HAL not backwards compatible with the Android Camera (v1) API
+as many of its methods attempt to do just that; Camera2 must be used instead.
+* A variety of metadata properties can't be filled in from V4L2,
+such as physical properties of the camera. Thus this HAL will never be capable
+of providing perfectly accurate information for all cameras it can theoretically
+support.
+* Android requires HALs support YUV420, JPEG, and a format of the graphics
+stack's choice ("implementation defined"). Very few cameras actually support
+all of these formats (so far the Raspberry Pi cameras are the only known ones),
+so some form of format conversion built in to the HAL would be a useful feature
+to expand the reach/usefulness of this HAL.
+* V4L2 doesn't make promises about how fast settings will apply, and there's no
+good way to determine what settings were in effect for a given frame. Thus,
+the settings passed into requests and out with results are applied/read as
+a best effort and may be incorrect.
+* Many features V4L2 is capable of are not hooked up to the HAL, so the HAL
+is underfeatured compared to the ideal/what is possible.
+
+## Other Known Issues
+
+* A variety of features are unimplemented: High speed capture,
+flash torch mode, hotplugging/unplugging.
diff --git a/hardware/ntimespace/camera/arc/cached_frame.cpp b/hardware/ntimespace/camera/arc/cached_frame.cpp
new file mode 100644
index 0000000000..a4f7377950
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/cached_frame.cpp
@@ -0,0 +1,424 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+#include "v4l2_camera_hal.h"
+#include "arc/cached_frame.h"
+#include <cerrno>
+#include <libyuv.h>
+#include "arc/common.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+
+
+namespace arc {
+
+using android::CameraMetadata;
+
+CachedFrame::CachedFrame()
+    : source_frame_(nullptr),
+      cropped_buffer_capacity_(0),
+      yu12_frame_(new IonFrameBuffer()),
+      scaled_frame_(new IonFrameBuffer()),
+      cropped_frame_(new IonFrameBuffer()){
+  already_cached = false;
+}
+
+CachedFrame::~CachedFrame() { UnsetSource(); }
+
+int CachedFrame::SetSource(const CameraMetadata& metadata, const FrameBuffer* frame, int rotate_degree) {
+  VLOGF_ENTER();
+
+  (void)rotate_degree;
+
+  source_frame_ = frame;
+  int res = ConvertToYU12(metadata);
+  if (res != 0) {
+    LOGF(ERROR) << "ConvertToYU12() fail: " << res;    
+    return res;
+  }
+
+  return res;
+}
+
+void CachedFrame::UnsetSource() { 
+  source_frame_ = nullptr; 
+}
+
+uint8_t* CachedFrame::GetSourceBuffer() const {
+  return source_frame_->GetData();
+}
+
+size_t CachedFrame::GetSourceDataSize() const {
+  return source_frame_->GetDataSize();
+}
+
+uint32_t CachedFrame::GetSourceFourCC() const {
+  return source_frame_->GetFourcc();
+}
+
+uint8_t* CachedFrame::GetCachedBuffer() const { 
+  return yu12_frame_->GetData(); 
+}
+
+uint32_t CachedFrame::GetCachedFourCC() const {
+  return yu12_frame_->GetFourcc();
+}
+
+uint32_t CachedFrame::GetWidth() const { 
+  return yu12_frame_->GetWidth(); 
+}
+
+uint32_t CachedFrame::GetHeight() const { 
+  return yu12_frame_->GetHeight(); 
+}
+
+size_t CachedFrame::GetConvertedSize(int fourcc) const {
+  return ImageProcessor::GetConvertedSize(fourcc, yu12_frame_->GetWidth(), yu12_frame_->GetHeight());
+}
+
+int CachedFrame::DoConvert(const CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  int ret = -1;
+#if defined(HAS_C2D2) || defined(HAS_RGA)
+  if (v4l2_camera_hal::using_hw) {
+    ret = hw_conv::convert_format(metadata, in_frame, out_frame);
+  }
+#endif
+
+  if (ret < 0) {
+    ret = ImageProcessor::ConvertFormat(metadata, in_frame, out_frame);    
+  }
+
+  return 0;
+}
+
+int CachedFrame::Convert(const CameraMetadata& metadata, FrameBuffer* out_frame, int buf_id) {
+  VLOGF_ENTER();
+
+  FrameBuffer* source_frame = yu12_frame_.get();
+  if (GetWidth() != out_frame->GetWidth() ||
+    GetHeight() != out_frame->GetHeight()) {
+    LOGF(INFO) << "In/Out mis-match. Need to do scale"; 
+
+    size_t cache_size = ImageProcessor::GetConvertedSize(
+        yu12_frame_->GetFourcc(), out_frame->GetWidth(),
+        out_frame->GetHeight());
+    if (cache_size == 0) {
+      LOGF(ERROR) << "cache_size error";
+      return -EINVAL;
+    } 
+
+    scaled_frame_->SetFourcc(V4L2_PIX_FMT_YUV420);
+    scaled_frame_->SetWidth(out_frame->GetWidth());
+    scaled_frame_->SetHeight(out_frame->GetHeight());
+    scaled_frame_->SetDataSize(cache_size);
+
+    if (cache_size > scaled_frame_->GetBufferSize()) {
+      LOGF(ERROR) << "cache_size > buffer_size, overflow error";
+      //scaled_frame_.reset(new IonFrameBuffer(cache_size));
+      return -EINVAL;
+    }
+
+    #if 0
+      ImageProcessor::Scale(*yu12_frame_.get(), scaled_frame_.get(), buf_id);
+    #else
+      float target_aspect = static_cast<float>(out_frame->GetWidth()) / static_cast<float>(out_frame->GetHeight());
+      int res = CropRotateScaleEx(*source_frame, scaled_frame_.get(), 0, target_aspect, buf_id);
+      if (res < 0)
+        return res;
+    #endif
+
+    source_frame = scaled_frame_.get();
+  }
+
+  return DoConvert(metadata, *source_frame, out_frame);
+}
+
+int CachedFrame::ConvertDirectly(const android::CameraMetadata& metadata, 
+                                 FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  VLOGF_ENTER();
+
+  if (in_frame.GetWidth() != out_frame->GetWidth() || in_frame.GetHeight() != out_frame->GetHeight()) {
+        LOGF(INFO) << "Wrong path. Size mis-match. Need to do scale";
+        return -EINVAL;
+  }
+
+  return DoConvert(metadata, in_frame, out_frame);
+}
+
+int CachedFrame::ConvertToYU12(const CameraMetadata& metadata) {
+  VLOGF_ENTER();
+  size_t cache_size = ImageProcessor::GetConvertedSize(
+      V4L2_PIX_FMT_YUV420, source_frame_->GetWidth(),
+      source_frame_->GetHeight());
+  if (cache_size == 0) {
+    LOGF(ERROR) << "cache_size error";
+    return -EINVAL;
+  }
+
+  yu12_frame_->SetFourcc(V4L2_PIX_FMT_YUV420);
+  yu12_frame_->SetWidth(source_frame_->GetWidth());
+  yu12_frame_->SetHeight(source_frame_->GetHeight());
+  yu12_frame_->SetDataSize(cache_size);  
+
+  int res = DoConvert(metadata, *source_frame_, yu12_frame_.get());
+  if (res) {
+    LOGF(ERROR) << "Convert from " << FormatToString(source_frame_->GetFourcc())
+                << " to YU12 fails.";
+    return res;
+  }
+  return 0;
+}
+
+int CachedFrame::CropRotateScale(int rotate_degree) {
+  // TODO(henryhsu): Move libyuv part to ImageProcessor.
+  if (yu12_frame_->GetHeight() % 2 != 0 || yu12_frame_->GetWidth() % 2 != 0) {
+    LOGF(ERROR) << "yu12_frame_ has odd dimension: " << yu12_frame_->GetWidth()
+                << "x" << yu12_frame_->GetHeight();
+    return -EINVAL;
+  }
+
+  if (yu12_frame_->GetHeight() > yu12_frame_->GetWidth()) {
+    LOGF(ERROR) << "yu12_frame_ is tall frame already: "
+                << yu12_frame_->GetWidth() << "x" << yu12_frame_->GetHeight();
+    return -EINVAL;
+  }
+
+  // Step 1: Crop and rotate
+  //
+  //   Original frame                  Cropped frame              Rotated frame
+  // --------------------               --------
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |                 |             |
+  // |     |      |     |   =======>>   |      |     =======>>   |             |
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |
+  // --------------------               --------
+  //
+  int cropped_width = yu12_frame_->GetHeight() * yu12_frame_->GetHeight() /
+                      yu12_frame_->GetWidth();
+  if (cropped_width % 2 == 1) {
+    // Make cropped_width to the closest even number.
+    cropped_width++;
+  }
+  int cropped_height = yu12_frame_->GetHeight();
+  int margin = (yu12_frame_->GetWidth() - cropped_width) / 2;
+
+  int rotated_height = cropped_width;
+  int rotated_width = cropped_height;
+
+  int rotated_y_stride = rotated_width;
+  int rotated_uv_stride = rotated_width / 2;
+  size_t rotated_size =
+      rotated_y_stride * rotated_height + rotated_uv_stride * rotated_height;
+  if (rotated_size > cropped_buffer_capacity_) {
+    cropped_buffer_.reset(new uint8_t[rotated_size]);
+    cropped_buffer_capacity_ = rotated_size;
+  }
+  uint8_t* rotated_y_plane = cropped_buffer_.get();
+  uint8_t* rotated_u_plane =
+      rotated_y_plane + rotated_y_stride * rotated_height;
+  uint8_t* rotated_v_plane =
+      rotated_u_plane + rotated_uv_stride * rotated_height / 2;
+  libyuv::RotationMode rotation_mode = libyuv::RotationMode::kRotate90;
+  switch (rotate_degree) {
+    case 90:
+      rotation_mode = libyuv::RotationMode::kRotate90;
+      break;
+    case 270:
+      rotation_mode = libyuv::RotationMode::kRotate270;
+      break;
+    default:
+      LOGF(ERROR) << "Invalid rotation degree: " << rotate_degree;
+      return -EINVAL;
+  }
+  // This libyuv method first crops the frame and then rotates it 90 degrees
+  // clockwise.
+  int res = libyuv::ConvertToI420(
+      yu12_frame_->GetData(), yu12_frame_->GetDataSize(), rotated_y_plane,
+      rotated_y_stride, rotated_u_plane, rotated_uv_stride, rotated_v_plane,
+      rotated_uv_stride, margin, 0, yu12_frame_->GetWidth(),
+      yu12_frame_->GetHeight(), cropped_width, cropped_height, rotation_mode,
+      libyuv::FourCC::FOURCC_I420);
+
+  if (res) {
+    LOGF(ERROR) << "ConvertToI420 failed: " << res;
+    return res;
+  }
+
+  // Step 2: Scale
+  //
+  //                               Final frame
+  //  Rotated frame            ---------------------
+  // --------------            |                   |
+  // |            |  =====>>   |                   |
+  // |            |            |                   |
+  // --------------            |                   |
+  //                           |                   |
+  //                           ---------------------
+  //
+  //
+  res = libyuv::I420Scale(
+      rotated_y_plane, rotated_y_stride, rotated_u_plane, rotated_uv_stride,
+      rotated_v_plane, rotated_uv_stride, rotated_width, rotated_height,
+      yu12_frame_->GetData(), yu12_frame_->GetWidth(),
+      yu12_frame_->GetData() +
+          yu12_frame_->GetWidth() * yu12_frame_->GetHeight(),
+      yu12_frame_->GetWidth() / 2,
+      yu12_frame_->GetData() +
+          yu12_frame_->GetWidth() * yu12_frame_->GetHeight() * 5 / 4,
+      yu12_frame_->GetWidth() / 2, yu12_frame_->GetWidth(),
+      yu12_frame_->GetHeight(), libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, res) << "I420Scale failed: " << res;
+  return res;
+}
+
+int CachedFrame::CropRotateScaleEx(FrameBuffer& in_frame, FrameBuffer* out_frame, int rotate_degree, float target_aspect, int buf_id) {
+  (void)rotate_degree;
+
+  dump_data(dump_data_index, (unsigned char *)in_frame.GetData(), 
+                          in_frame.GetWidth(), 
+                          in_frame.GetHeight(), 
+                          in_frame.GetFourcc(),
+                          buf_id, "crs_pre");
+
+  if (in_frame.GetHeight() % 2 != 0 || in_frame.GetWidth() % 2 != 0) {
+    LOGF(ERROR) << "in_frame has odd dimension: " << in_frame.GetWidth()
+                << "x" << in_frame.GetHeight();
+    return -EINVAL;
+  }
+
+  if (in_frame.GetHeight() > in_frame.GetWidth()) {
+    LOGF(ERROR) << "in_frame is tall frame already: "
+                << in_frame.GetWidth() << "x" << in_frame.GetHeight();
+    return -EINVAL;
+  }
+
+  int scale_in_width = 0;
+  int scale_in_height = 0;
+  int scale_in_y_stride = 0;
+  int scale_in_uv_stride = 0;
+  uint8_t* scale_in_y_plane = nullptr;
+  uint8_t* scale_in_u_plane = nullptr;
+  uint8_t* scale_in_v_plane = nullptr;
+
+  int cropped_width = 0;
+  int cropped_height = 0;
+  int cropped_y_stride = 0;
+  int cropped_uv_stride = 0;
+  uint8_t* cropped_y_plane = nullptr;
+  uint8_t* cropped_u_plane = nullptr;
+  uint8_t* cropped_v_plane = nullptr;
+
+  float in_aspect = static_cast<float>(in_frame.GetWidth()) / static_cast<float>(in_frame.GetHeight());
+  LOGF(ERROR) << "in_aspect: " << in_aspect << " target_aspect: " << target_aspect;
+
+  if (in_aspect != target_aspect) {
+  // Step 1: Crop and rotate
+  //
+  //   Original frame                  Cropped frame              Rotated frame
+  // --------------------               --------
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |                 |             |
+  // |     |      |     |   =======>>   |      |     =======>>   |             |
+  // |     |      |     |               |      |                 ---------------
+  // |     |      |     |               |      |
+  // --------------------               --------
+  //
+  cropped_width = target_aspect * in_frame.GetHeight();
+  if (cropped_width % 2 == 1) {
+    // Make cropped_width to the closest even number.
+    cropped_width++;
+  }
+  cropped_height = in_frame.GetHeight();
+  int margin = (in_frame.GetWidth() - cropped_width) / 2;
+
+  LOGF(ERROR) << "cropped size: " << cropped_width << " x " << cropped_height;
+
+  size_t cache_size = ImageProcessor::GetConvertedSize(
+      in_frame.GetFourcc(), cropped_width, cropped_height);
+  if (cache_size == 0) {
+    LOGF(ERROR) << "cache_size error";
+    return -EINVAL;
+  } 
+
+  cropped_frame_->SetWidth(cropped_width);
+  cropped_frame_->SetHeight(cropped_height);
+  cropped_frame_->SetDataSize(cache_size);
+
+  if (cache_size > cropped_frame_->GetBufferSize()) {
+    LOGF(ERROR) << "cache_size > buffer_size, overflow error";
+    return -EINVAL;
+  }
+
+  cropped_y_stride = cropped_width;
+  cropped_uv_stride = cropped_width / 2;
+  cropped_y_plane = cropped_frame_->GetData();
+  cropped_u_plane = cropped_y_plane + cropped_y_stride * cropped_height;
+  cropped_v_plane = cropped_u_plane + cropped_uv_stride * cropped_height / 2;
+
+  // This libyuv method first crops the frame and then rotates it clockwise.
+  int res = libyuv::ConvertToI420(
+      in_frame.GetData(), in_frame.GetDataSize(), cropped_y_plane,
+      cropped_y_stride, cropped_u_plane, cropped_uv_stride, cropped_v_plane,
+      cropped_uv_stride, margin, 0, in_frame.GetWidth(),
+      in_frame.GetHeight(), cropped_width, cropped_height, libyuv::RotationMode::kRotate0,
+      libyuv::FourCC::FOURCC_I420);
+
+  if (res) {
+    LOGF(ERROR) << "ConvertToI420 failed: " << res;
+    return res;
+  } 
+  }
+
+  // Step 2: Scale
+  //
+  //                               Final frame
+  //  Rotated frame            ---------------------
+  // --------------            |                   |
+  // |            |  =====>>   |                   |
+  // |            |            |                   |
+  // --------------            |                   |
+  //                           |                   |
+  //                           ---------------------
+  //
+  //
+  if (in_aspect != target_aspect) {
+    scale_in_width = cropped_width;
+    scale_in_height = cropped_height;
+    scale_in_y_stride = cropped_y_stride;
+    scale_in_uv_stride = cropped_uv_stride;
+    scale_in_y_plane = cropped_y_plane;
+    scale_in_u_plane = cropped_u_plane;
+    scale_in_v_plane = cropped_v_plane;     
+  } else {
+    scale_in_width = in_frame.GetWidth();
+    scale_in_height = in_frame.GetHeight();
+    scale_in_y_stride = in_frame.GetWidth();
+    scale_in_uv_stride = in_frame.GetWidth() / 2;
+    scale_in_y_plane = in_frame.GetData();
+    scale_in_u_plane = scale_in_y_plane + in_frame.GetWidth() * in_frame.GetHeight();
+    scale_in_v_plane = scale_in_u_plane + scale_in_uv_stride * in_frame.GetHeight() / 2;    
+  }
+
+  int res = libyuv::I420Scale(
+      scale_in_y_plane, scale_in_y_stride, scale_in_u_plane, scale_in_uv_stride,
+      scale_in_v_plane, scale_in_uv_stride, scale_in_width, scale_in_height,
+      out_frame->GetData(), out_frame->GetWidth(),
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+      out_frame->GetWidth() / 2,
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+      out_frame->GetWidth() / 2, out_frame->GetWidth(),
+      out_frame->GetHeight(), libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, res) << "I420Scale failed: " << res;
+  
+  dump_data(dump_data_index, (unsigned char *)out_frame->GetData(), 
+                        out_frame->GetWidth(), 
+                        out_frame->GetHeight(), 
+                        out_frame->GetFourcc(),
+                        buf_id, "scale_post");
+
+  return res;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/cached_frame.h b/hardware/ntimespace/camera/arc/cached_frame.h
new file mode 100644
index 0000000000..75c330e98c
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/cached_frame.h
@@ -0,0 +1,97 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_CACHED_FRAME_H_
+#define HAL_USB_CACHED_FRAME_H_
+
+#include <memory>
+#include "metadata/camera_metadata.h"
+#include "arc/image_processor.h"
+#include "hardware/hw_converter.h"
+
+namespace arc {
+
+using android::CameraMetadata;
+
+
+// CachedFrame contains a source FrameBuffer and a cached, converted
+// FrameBuffer. The incoming frames would be converted to YU12, the default
+// format of libyuv, to allow convenient processing.
+class CachedFrame {
+ public:
+  CachedFrame();
+  ~CachedFrame();
+
+  // SetSource() doesn't take ownership of |frame|. The caller can only release
+  // |frame| after calling UnsetSource(). SetSource() immediately converts
+  // incoming frame into YU12. Return non-zero values if it encounters errors.
+  // If |rotate_degree| is 90 or 270, |frame| will be cropped, rotated by the
+  // specified amount and scaled.
+  // If |rotate_degree| is -1, |frame| will not be cropped, rotated, and scaled.
+  // This function will return an error if |rotate_degree| is not -1, 90, or
+  // 270.
+  int SetSource(const CameraMetadata& metadata, const FrameBuffer* frame, int rotate_degree);
+  void UnsetSource();
+
+  uint8_t* GetSourceBuffer() const;
+  size_t GetSourceDataSize() const;
+  uint32_t GetSourceFourCC() const;
+  uint8_t* GetCachedBuffer() const;
+  uint32_t GetCachedFourCC() const;
+
+  uint32_t GetWidth() const;
+  uint32_t GetHeight() const;
+
+  // Calculate the output buffer size when converting to the specified pixel
+  // format. |fourcc| is defined as V4L2_PIX_FMT_* in linux/videodev2.h. Return
+  // 0 on error.
+  size_t GetConvertedSize(int fourcc) const;
+
+  // Caller should fill everything except |data_size| and |fd| of |out_frame|.
+  // The function will do format conversion and scale to fit |out_frame|
+  // requirement.
+  // If |video_hack| is true, it outputs YU12 when |hal_pixel_format| is YV12
+  // (swapping U/V planes). Caller should fill |fourcc|, |data|, and
+  // Return non-zero error code on failure; return 0 on success.
+  int Convert(const android::CameraMetadata& metadata, FrameBuffer* out_frame,
+              int buf_id);
+  int ConvertDirectly(const android::CameraMetadata& metadata, FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+  int DoConvert(const android::CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+ private:
+  int ConvertToYU12(const CameraMetadata& metadata);
+  // When we have a landscape mounted camera and the current camera activity is
+  // portrait, the frames shown in the activity would be stretched. Therefore,
+  // we want to simulate a native portrait camera. That's why we want to crop,
+  // rotate |rotate_degree| clockwise and scale the frame. HAL would not change
+  // CameraInfo.orientation. Instead, framework would fake the
+  // CameraInfo.orientation. Framework would then tell HAL how much the frame
+  // needs to rotate clockwise by |rotate_degree|.
+  int CropRotateScale(int rotate_degree);
+  int CropRotateScaleEx(FrameBuffer& in_frame, FrameBuffer* out_frame, int rotate_degree, float target_aspect, int buf_id);
+
+  const FrameBuffer* source_frame_;
+
+  // Temporary buffer for cropped and rotated results.
+  std::unique_ptr<uint8_t[]> cropped_buffer_;
+  size_t cropped_buffer_capacity_;
+
+
+public:
+  // Cache YU12 decoded results.
+  //std::unique_ptr<AllocatedFrameBuffer> yu12_frame_;
+  std::unique_ptr<IonFrameBuffer> yu12_frame_;
+
+  // Temporary buffer for scaled results.
+  //std::unique_ptr<AllocatedFrameBuffer> scaled_frame_;
+  std::unique_ptr<IonFrameBuffer> scaled_frame_;
+  std::unique_ptr<IonFrameBuffer> cropped_frame_;
+  bool already_cached;  
+};
+
+}  // namespace arc
+
+#endif  // HAL_USB_CACHED_FRAME_H_
diff --git a/hardware/ntimespace/camera/arc/common.h b/hardware/ntimespace/camera/arc/common.h
new file mode 100644
index 0000000000..0ad5ad4579
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/common.h
@@ -0,0 +1,37 @@
+/* Copyright 2016 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_COMMON_H_
+#define INCLUDE_ARC_COMMON_H_
+
+#include <string>
+
+#include <base/logging.h>
+
+#define MSG_TAG "[v4l2_camera]"
+
+#define LOGF(level) LOG(level)
+#define LOGFID(level, id) LOG(level) << MSG_TAG << __FUNCTION__ << "(): id: " << id << ": "
+#define LOGF_IF(level, res) LOG_IF(level, res) << MSG_TAG << __FUNCTION__ << "(): "
+
+#define VLOGF(level) VLOG(level) << MSG_TAG << __FUNCTION__ << "(): "
+#define VLOGFID(level, id) \
+  VLOG(level) << MSG_TAG << __FUNCTION__ << "(): id: " << id << ": "
+
+#if 1
+#define VLOGF_ENTER() VLOGF(1) << "enter"
+#define VLOGF_EXIT() VLOGF(1) << "exit"
+#else
+#define VLOGF_ENTER()  LOGF(INFO) << MSG_TAG << __FUNCTION__ << " enter"
+#define VLOGF_EXIT()  LOGF(INFO) << MSG_TAG << __FUNCTION__ << " exit"
+#endif
+
+
+
+inline std::string FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+#endif  // INCLUDE_ARC_COMMON_H_
diff --git a/hardware/ntimespace/camera/arc/common_types.h b/hardware/ntimespace/camera/arc/common_types.h
new file mode 100644
index 0000000000..8f62ad6e0d
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/common_types.h
@@ -0,0 +1,55 @@
+/*
+ * Copyright 2016 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_COMMON_TYPES_H_
+#define HAL_USB_COMMON_TYPES_H_
+
+#include <string>
+#include <vector>
+
+namespace arc {
+
+struct DeviceInfo {
+  // ex: /dev/video0
+  std::string device_path;
+  // USB vender id
+  std::string usb_vid;
+  // USB product id
+  std::string usb_pid;
+  // Some cameras need to wait several frames to output correct images.
+  uint32_t frames_to_skip_after_streamon;
+
+  // Member definitions can be found in https://developer.android.com/
+  // reference/android/hardware/camera2/CameraCharacteristics.html
+  uint32_t lens_facing;
+  int32_t sensor_orientation;
+  float horizontal_view_angle_16_9;
+  float horizontal_view_angle_4_3;
+  std::vector<float> lens_info_available_focal_lengths;
+  float lens_info_minimum_focus_distance;
+  float lens_info_optimal_focus_distance;
+  float vertical_view_angle_16_9;
+  float vertical_view_angle_4_3;
+};
+
+typedef std::vector<DeviceInfo> DeviceInfos;
+
+struct SupportedFormat {
+  uint32_t width;
+  uint32_t height;
+  uint32_t fourcc;
+  // All the supported frame rates in fps with given width, height, and
+  // pixelformat. This is not sorted. For example, suppose width, height, and
+  // fourcc are 640x480 YUYV. If frameRates are 15.0 and 30.0, the camera
+  // supports outputting 640X480 YUYV in 15fps or 30fps.
+  std::vector<float> frameRates;
+};
+
+typedef std::vector<SupportedFormat> SupportedFormats;
+
+}  // namespace arc
+
+#endif  // HAL_USB_COMMON_TYPES_H_
diff --git a/hardware/ntimespace/camera/arc/exif_utils.cpp b/hardware/ntimespace/camera/arc/exif_utils.cpp
new file mode 100644
index 0000000000..512fdb9eae
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/exif_utils.cpp
@@ -0,0 +1,512 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/exif_utils.h"
+
+#include <cstdlib>
+#include <ctime>
+
+#include <libyuv.h>
+#include "arc/common.h"
+
+namespace std {
+
+template <>
+struct default_delete<ExifEntry> {
+  inline void operator()(ExifEntry* entry) const { exif_entry_unref(entry); }
+};
+
+}  // namespace std
+
+namespace arc {
+
+// This comes from the Exif Version 2.3 standard table 9.
+const uint8_t gExifAsciiPrefix[] = {0x41, 0x53, 0x43, 0x49,
+                                    0x49, 0x0,  0x0,  0x0};
+
+static void SetLatitudeOrLongitudeData(unsigned char* data, double num) {
+  // Take the integer part of |num|.
+  ExifLong degrees = static_cast<ExifLong>(num);
+  ExifLong minutes = static_cast<ExifLong>(60 * (num - degrees));
+  ExifLong microseconds =
+      static_cast<ExifLong>(3600000000u * (num - degrees - minutes / 60.0));
+  exif_set_rational(data, EXIF_BYTE_ORDER_INTEL, {degrees, 1});
+  exif_set_rational(data + sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {minutes, 1});
+  exif_set_rational(data + 2 * sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {microseconds, 1000000});
+}
+
+ExifUtils::ExifUtils()
+    : yu12_buffer_(nullptr),
+      yu12_width_(0),
+      yu12_height_(0),
+      thumbnail_width_(0),
+      thumbnail_height_(0),
+      exif_data_(nullptr),
+      app1_buffer_(nullptr),
+      app1_length_(0) {}
+
+ExifUtils::~ExifUtils() { Reset(); }
+
+bool ExifUtils::Initialize(const uint8_t* buffer, uint16_t width,
+                           uint16_t height, int quality) {
+  Reset();
+
+  if (width % 2 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "invalid image size " << width << "x" << height;
+    return false;
+  }
+  if (quality < 1 || quality > 100) {
+    LOGF(ERROR) << "invalid jpeg quality " << quality;
+    return false;
+  }
+  thumbnail_jpeg_quality_ = quality;
+  yu12_buffer_ = buffer;
+  yu12_width_ = width;
+  yu12_height_ = height;
+
+  exif_data_ = exif_data_new();
+  if (exif_data_ == nullptr) {
+    LOGF(ERROR) << "allocate memory for exif_data_ failed";
+    return false;
+  }
+  // Set the image options.
+  exif_data_set_option(exif_data_, EXIF_DATA_OPTION_FOLLOW_SPECIFICATION);
+  exif_data_set_data_type(exif_data_, EXIF_DATA_TYPE_COMPRESSED);
+  exif_data_set_byte_order(exif_data_, EXIF_BYTE_ORDER_INTEL);
+
+  // Set image width and length.
+  SetImageWidth(width);
+  SetImageLength(height);
+
+  return true;
+}
+
+bool ExifUtils::SetMaker(const std::string& maker) {
+  size_t entrySize = maker.length() + 1;
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_0, EXIF_TAG_MAKE, EXIF_FORMAT_ASCII, entrySize, entrySize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Make exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, maker.c_str(), entrySize);
+  return true;
+}
+
+bool ExifUtils::SetModel(const std::string& model) {
+  size_t entrySize = model.length() + 1;
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_0, EXIF_TAG_MODEL, EXIF_FORMAT_ASCII, entrySize, entrySize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Model exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, model.c_str(), entrySize);
+  return true;
+}
+
+bool ExifUtils::SetDateTime(const struct tm& t) {
+  // The length is 20 bytes including NULL for termination in Exif standard.
+  char str[20];
+  int result = snprintf(str, sizeof(str), "%04i:%02i:%02i %02i:%02i:%02i",
+                        t.tm_year + 1900, t.tm_mon + 1, t.tm_mday, t.tm_hour,
+                        t.tm_min, t.tm_sec);
+  if (result != sizeof(str) - 1) {
+    LOGF(WARNING) << "Input time is invalid";
+    return false;
+  }
+  std::unique_ptr<ExifEntry> entry =
+      AddVariableLengthEntry(EXIF_IFD_0, EXIF_TAG_DATE_TIME, EXIF_FORMAT_ASCII,
+                             sizeof(str), sizeof(str));
+  if (!entry) {
+    LOGF(ERROR) << "Adding DateTime exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, str, sizeof(str));
+  return true;
+}
+
+bool ExifUtils::SetFocalLength(uint32_t numerator, uint32_t denominator) {
+  std::unique_ptr<ExifEntry> entry =
+      AddEntry(EXIF_IFD_EXIF, EXIF_TAG_FOCAL_LENGTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding FocalLength exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {numerator, denominator});
+  return true;
+}
+
+bool ExifUtils::SetGpsLatitude(double latitude) {
+  const ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_LATITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_ASCII, 2, 2);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSLatitudeRef exif entry failed";
+    return false;
+  }
+  if (latitude >= 0) {
+    memcpy(refEntry->data, "N", sizeof("N"));
+  } else {
+    memcpy(refEntry->data, "S", sizeof("S"));
+    latitude *= -1;
+  }
+
+  const ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_LATITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 3, 3 * sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSLatitude exif entry failed";
+    return false;
+  }
+  SetLatitudeOrLongitudeData(entry->data, latitude);
+
+  return true;
+}
+
+bool ExifUtils::SetGpsLongitude(double longitude) {
+  ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_LONGITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_ASCII, 2, 2);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSLongitudeRef exif entry failed";
+    return false;
+  }
+  if (longitude >= 0) {
+    memcpy(refEntry->data, "E", sizeof("E"));
+  } else {
+    memcpy(refEntry->data, "W", sizeof("W"));
+    longitude *= -1;
+  }
+
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_LONGITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 3, 3 * sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSLongitude exif entry failed";
+    return false;
+  }
+  SetLatitudeOrLongitudeData(entry->data, longitude);
+
+  return true;
+}
+
+bool ExifUtils::SetGpsAltitude(double altitude) {
+  ExifTag refTag = static_cast<ExifTag>(EXIF_TAG_GPS_ALTITUDE_REF);
+  std::unique_ptr<ExifEntry> refEntry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, refTag, EXIF_FORMAT_BYTE, 1, 1);
+  if (!refEntry) {
+    LOGF(ERROR) << "Adding GPSAltitudeRef exif entry failed";
+    return false;
+  }
+  if (altitude >= 0) {
+    *refEntry->data = 0;
+  } else {
+    *refEntry->data = 1;
+    altitude *= -1;
+  }
+
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_ALTITUDE);
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_RATIONAL, 1, sizeof(ExifRational));
+  if (!entry) {
+    exif_content_remove_entry(exif_data_->ifd[EXIF_IFD_GPS], refEntry.get());
+    LOGF(ERROR) << "Adding GPSAltitude exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(altitude * 1000), 1000});
+
+  return true;
+}
+
+bool ExifUtils::SetGpsTimestamp(const struct tm& t) {
+  const ExifTag dateTag = static_cast<ExifTag>(EXIF_TAG_GPS_DATE_STAMP);
+  const size_t kGpsDateStampSize = 11;
+  std::unique_ptr<ExifEntry> entry =
+      AddVariableLengthEntry(EXIF_IFD_GPS, dateTag, EXIF_FORMAT_ASCII,
+                             kGpsDateStampSize, kGpsDateStampSize);
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSDateStamp exif entry failed";
+    return false;
+  }
+  int result =
+      snprintf(reinterpret_cast<char*>(entry->data), kGpsDateStampSize,
+               "%04i:%02i:%02i", t.tm_year + 1900, t.tm_mon + 1, t.tm_mday);
+  if (result != kGpsDateStampSize - 1) {
+    LOGF(WARNING) << "Input time is invalid";
+    return false;
+  }
+
+  const ExifTag timeTag = static_cast<ExifTag>(EXIF_TAG_GPS_TIME_STAMP);
+  entry = AddVariableLengthEntry(EXIF_IFD_GPS, timeTag, EXIF_FORMAT_RATIONAL, 3,
+                                 3 * sizeof(ExifRational));
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSTimeStamp exif entry failed";
+    return false;
+  }
+  exif_set_rational(entry->data, EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_hour), 1});
+  exif_set_rational(entry->data + sizeof(ExifRational), EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_min), 1});
+  exif_set_rational(entry->data + 2 * sizeof(ExifRational),
+                    EXIF_BYTE_ORDER_INTEL,
+                    {static_cast<ExifLong>(t.tm_sec), 1});
+
+  return true;
+}
+
+bool ExifUtils::SetGpsProcessingMethod(const std::string& method) {
+  ExifTag tag = static_cast<ExifTag>(EXIF_TAG_GPS_PROCESSING_METHOD);
+  size_t size = sizeof(gExifAsciiPrefix) + method.length();
+  std::unique_ptr<ExifEntry> entry = AddVariableLengthEntry(
+      EXIF_IFD_GPS, tag, EXIF_FORMAT_UNDEFINED, size, size);
+  if (!entry) {
+    LOGF(ERROR) << "Adding GPSProcessingMethod exif entry failed";
+    return false;
+  }
+  memcpy(entry->data, gExifAsciiPrefix, sizeof(gExifAsciiPrefix));
+  // Since the exif format is undefined, NULL termination is not necessary.
+  memcpy(entry->data + sizeof(gExifAsciiPrefix), method.c_str(),
+         method.length());
+
+  return true;
+}
+
+bool ExifUtils::SetThumbnailSize(uint16_t width, uint16_t height) {
+  if (width % 2 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "Invalid thumbnail size " << width << "x" << height;
+    return false;
+  }
+  thumbnail_width_ = width;
+  thumbnail_height_ = height;
+  return true;
+}
+
+bool ExifUtils::SetOrientation(uint16_t orientation) {
+  std::unique_ptr<ExifEntry> entry = AddEntry(EXIF_IFD_0, EXIF_TAG_ORIENTATION);
+  if (!entry) {
+    LOGF(ERROR) << "Adding Orientation exif entry failed";
+    return false;
+  }
+  /*
+   * Orientation value:
+   *  1      2      3      4      5          6          7          8
+   *
+   *  888888 888888     88 88     8888888888 88                 88 8888888888
+   *  88         88     88 88     88  88     88  88         88  88     88  88
+   *  8888     8888   8888 8888   88         8888888888 8888888888         88
+   *  88         88     88 88
+   *  88         88 888888 888888
+   */
+  int value = 1;
+  switch (orientation) {
+    case 90:
+      value = 6;
+      break;
+    case 180:
+      value = 3;
+      break;
+    case 270:
+      value = 8;
+      break;
+    default:
+      break;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, value);
+  return true;
+}
+
+bool ExifUtils::GenerateApp1() {
+  DestroyApp1();
+  if (thumbnail_width_ > 0 && thumbnail_height_ > 0) {
+    if (!GenerateThumbnail()) {
+      LOGF(ERROR) << "Generate thumbnail image failed";
+      return false;
+    }
+    exif_data_->data = const_cast<uint8_t*>(
+        static_cast<const uint8_t*>(compressor_.GetCompressedImagePtr()));
+    exif_data_->size = compressor_.GetCompressedImageSize();
+  }
+  // Save the result into |app1_buffer_|.
+  exif_data_save_data(exif_data_, &app1_buffer_, &app1_length_);
+  if (!app1_length_) {
+    LOGF(ERROR) << "Allocate memory for app1_buffer_ failed";
+    return false;
+  }
+  /*
+   * The JPEG segment size is 16 bits in spec. The size of APP1 segment should
+   * be smaller than 65533 because there are two bytes for segment size field.
+   */
+  if (app1_length_ > 65533) {
+    DestroyApp1();
+    LOGF(ERROR) << "The size of APP1 segment is too large";
+    return false;
+  }
+  return true;
+}
+
+const uint8_t* ExifUtils::GetApp1Buffer() { return app1_buffer_; }
+
+unsigned int ExifUtils::GetApp1Length() { return app1_length_; }
+
+void ExifUtils::Reset() {
+  yu12_buffer_ = nullptr;
+  yu12_width_ = 0;
+  yu12_height_ = 0;
+  thumbnail_width_ = 0;
+  thumbnail_height_ = 0;
+  DestroyApp1();
+  if (exif_data_) {
+    /*
+     * Since we decided to ignore the original APP1, we are sure that there is
+     * no thumbnail allocated by libexif. |exif_data_->data| is actually
+     * allocated by JpegCompressor. Sets |exif_data_->data| to nullptr to
+     * prevent exif_data_unref() destroy it incorrectly.
+     */
+    exif_data_->data = nullptr;
+    exif_data_->size = 0;
+    exif_data_unref(exif_data_);
+    exif_data_ = nullptr;
+  }
+}
+
+std::unique_ptr<ExifEntry> ExifUtils::AddVariableLengthEntry(
+    ExifIfd ifd, ExifTag tag, ExifFormat format, uint64_t components,
+    unsigned int size) {
+  // Remove old entry if exists.
+  exif_content_remove_entry(exif_data_->ifd[ifd],
+                            exif_content_get_entry(exif_data_->ifd[ifd], tag));
+  ExifMem* mem = exif_mem_new_default();
+  if (!mem) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    return nullptr;
+  }
+  std::unique_ptr<ExifEntry> entry(exif_entry_new_mem(mem));
+  if (!entry) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    exif_mem_unref(mem);
+    return nullptr;
+  }
+  void* tmpBuffer = exif_mem_alloc(mem, size);
+  if (!tmpBuffer) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    exif_mem_unref(mem);
+    return nullptr;
+  }
+
+  entry->data = static_cast<unsigned char*>(tmpBuffer);
+  entry->tag = tag;
+  entry->format = format;
+  entry->components = components;
+  entry->size = size;
+
+  exif_content_add_entry(exif_data_->ifd[ifd], entry.get());
+  exif_mem_unref(mem);
+
+  return entry;
+}
+
+std::unique_ptr<ExifEntry> ExifUtils::AddEntry(ExifIfd ifd, ExifTag tag) {
+  std::unique_ptr<ExifEntry> entry(
+      exif_content_get_entry(exif_data_->ifd[ifd], tag));
+  if (entry) {
+    // exif_content_get_entry() won't ref the entry, so we ref here.
+    exif_entry_ref(entry.get());
+    return entry;
+  }
+  entry.reset(exif_entry_new());
+  if (!entry) {
+    LOGF(ERROR) << "Allocate memory for exif entry failed";
+    return nullptr;
+  }
+  entry->tag = tag;
+  exif_content_add_entry(exif_data_->ifd[ifd], entry.get());
+  exif_entry_initialize(entry.get(), tag);
+  return entry;
+}
+
+bool ExifUtils::SetImageWidth(uint16_t width) {
+  std::unique_ptr<ExifEntry> entry = AddEntry(EXIF_IFD_0, EXIF_TAG_IMAGE_WIDTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding ImageWidth exif entry failed";
+    return false;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, width);
+  return true;
+}
+
+bool ExifUtils::SetImageLength(uint16_t length) {
+  std::unique_ptr<ExifEntry> entry =
+      AddEntry(EXIF_IFD_0, EXIF_TAG_IMAGE_LENGTH);
+  if (!entry) {
+    LOGF(ERROR) << "Adding ImageLength exif entry failed";
+    return false;
+  }
+  exif_set_short(entry->data, EXIF_BYTE_ORDER_INTEL, length);
+  return true;
+}
+
+bool ExifUtils::GenerateThumbnail() {
+  // Resize yuv image to |thumbnail_width_| x |thumbnail_height_|.
+  std::vector<uint8_t> scaled_buffer;
+  if (!GenerateYuvThumbnail(&scaled_buffer)) {
+    LOGF(ERROR) << "Generate YUV thumbnail failed";
+    return false;
+  }
+
+  // Compress thumbnail to JPEG.
+  if (!compressor_.CompressImage(scaled_buffer.data(), thumbnail_width_,
+                                 thumbnail_height_, thumbnail_jpeg_quality_,
+                                 NULL, 0)) {
+    LOGF(ERROR) << "Compress thumbnail failed";
+    return false;
+  }
+  return true;
+}
+
+bool ExifUtils::GenerateYuvThumbnail(std::vector<uint8_t>* scaled_buffer) {
+  size_t y_plane_size = yu12_width_ * yu12_height_;
+  const uint8_t* y_plane = yu12_buffer_;
+  const uint8_t* u_plane = y_plane + y_plane_size;
+  const uint8_t* v_plane = u_plane + y_plane_size / 4;
+
+  size_t scaled_y_plane_size = thumbnail_width_ * thumbnail_height_;
+  scaled_buffer->resize(scaled_y_plane_size * 3 / 2);
+  uint8_t* scaled_y_plane = scaled_buffer->data();
+  uint8_t* scaled_u_plane = scaled_y_plane + scaled_y_plane_size;
+  uint8_t* scaled_v_plane = scaled_u_plane + scaled_y_plane_size / 4;
+
+  int result = libyuv::I420Scale(
+      y_plane, yu12_width_, u_plane, yu12_width_ / 2, v_plane, yu12_width_ / 2,
+      yu12_width_, yu12_height_, scaled_y_plane, thumbnail_width_,
+      scaled_u_plane, thumbnail_width_ / 2, scaled_v_plane,
+      thumbnail_width_ / 2, thumbnail_width_, thumbnail_height_,
+      libyuv::kFilterNone);
+  if (result != 0) {
+    LOGF(ERROR) << "Scale I420 image failed";
+    return false;
+  }
+  return true;
+}
+
+void ExifUtils::DestroyApp1() {
+  /*
+   * Since there is no API to access ExifMem in ExifData->priv, we use free
+   * here, which is the default free function in libexif. See
+   * exif_data_dump_data() for detail.
+   */
+  free(app1_buffer_);
+  app1_buffer_ = nullptr;
+  app1_length_ = 0;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/exif_utils.h b/hardware/ntimespace/camera/arc/exif_utils.h
new file mode 100644
index 0000000000..956ee1d2a0
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/exif_utils.h
@@ -0,0 +1,178 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_EXIF_UTILS_H_
+#define INCLUDE_ARC_EXIF_UTILS_H_
+
+#include <cstddef>
+#include <memory>
+#include <string>
+#include <utility>
+#include <vector>
+
+extern "C" {
+#include <libexif/exif-data.h>
+}
+
+#include "arc/jpeg_compressor.h"
+
+namespace arc {
+
+// ExifUtils can generate APP1 segment with tags which caller set. ExifUtils can
+// also add a thumbnail in the APP1 segment if thumbnail size is specified.
+// ExifUtils can be reused with different images by calling initialize().
+//
+// Example of using this class :
+//  ExifUtils utils;
+//  utils.initialize(inputYU12Buffer, inputWidth, inputHeight,
+//                   outputJpegQuality);
+//  ...
+//  // Call ExifUtils functions to set Exif tags.
+//  ...
+//  utils.generateApp1();
+//  unsigned int app1Length = utils.getApp1Length();
+//  uint8_t* app1Buffer = new uint8_t[app1Length];
+//  memcpy(app1Buffer, utils.getApp1Buffer(), app1Length);
+class ExifUtils {
+ public:
+  ExifUtils();
+  ~ExifUtils();
+
+  // Sets input YU12 image |buffer| with |width| x |height|. |quality| is the
+  // compressed JPEG image quality. The caller should not release |buffer| until
+  // generateApp1() or the destructor is called. initialize() can be called
+  // multiple times. The setting of Exif tags will be cleared.
+  bool Initialize(const uint8_t* buffer, uint16_t width, uint16_t height,
+                  int quality);
+
+  // Sets the manufacturer of camera.
+  // Returns false if memory allocation fails.
+  bool SetMaker(const std::string& maker);
+
+  // Sets the model number of camera.
+  // Returns false if memory allocation fails.
+  bool SetModel(const std::string& model);
+
+  // Sets the date and time of image last modified. It takes local time. The
+  // name of the tag is DateTime in IFD0.
+  // Returns false if memory allocation fails.
+  bool SetDateTime(const struct tm& t);
+
+  // Sets the focal length of lens used to take the image in millimeters.
+  // Returns false if memory allocation fails.
+  bool SetFocalLength(uint32_t numerator, uint32_t denominator);
+
+  // Sets the latitude with degrees minutes seconds format.
+  // Returns false if memory allocation fails.
+  bool SetGpsLatitude(double latitude);
+
+  // Sets the longitude with degrees minutes seconds format.
+  // Returns false if memory allocation fails.
+  bool SetGpsLongitude(double longitude);
+
+  // Sets the altitude in meters.
+  // Returns false if memory allocation fails.
+  bool SetGpsAltitude(double altitude);
+
+  // Sets GPS date stamp and time stamp (atomic clock). It takes UTC time.
+  // Returns false if memory allocation fails.
+  bool SetGpsTimestamp(const struct tm& t);
+
+  // Sets GPS processing method.
+  // Returns false if memory allocation fails.
+  bool SetGpsProcessingMethod(const std::string& method);
+
+  // Since the size of APP1 segment is limited, it is recommended the
+  // resolution of thumbnail is equal to or smaller than 640x480. If the
+  // thumbnail is too big, generateApp1() will return false.
+  // Returns false if |width| or |height| is not even.
+  bool SetThumbnailSize(uint16_t width, uint16_t height);
+
+  // Sets image orientation.
+  // Returns false if memory allocation fails.
+  bool SetOrientation(uint16_t orientation);
+
+  // Generates APP1 segment.
+  // Returns false if generating APP1 segment fails.
+  bool GenerateApp1();
+
+  // Gets buffer of APP1 segment. This method must be called only after calling
+  // generateAPP1().
+  const uint8_t* GetApp1Buffer();
+
+  // Gets length of APP1 segment. This method must be called only after calling
+  // generateAPP1().
+  unsigned int GetApp1Length();
+
+ private:
+  // Resets the pointers and memories.
+  void Reset();
+
+  // Adds a variable length tag to |exif_data_|. It will remove the original one
+  // if the tag exists.
+  // Returns the entry of the tag. The reference count of returned ExifEntry is
+  // two.
+  std::unique_ptr<ExifEntry> AddVariableLengthEntry(ExifIfd ifd, ExifTag tag,
+                                                    ExifFormat format,
+                                                    uint64_t components,
+                                                    unsigned int size);
+
+  // Adds a entry of |tag| in |exif_data_|. It won't remove the original one if
+  // the tag exists.
+  // Returns the entry of the tag. It adds one reference count to returned
+  // ExifEntry.
+  std::unique_ptr<ExifEntry> AddEntry(ExifIfd ifd, ExifTag tag);
+
+  // Sets the width (number of columes) of main image.
+  // Returns false if memory allocation fails.
+  bool SetImageWidth(uint16_t width);
+
+  // Sets the length (number of rows) of main image.
+  // Returns false if memory allocation fails.
+  bool SetImageLength(uint16_t length);
+
+  // Generates a thumbnail. Calls compressor_.getCompressedImagePtr() to get the
+  // result image.
+  // Returns false if failed.
+  bool GenerateThumbnail();
+
+  // Resizes the thumbnail yuv image to |thumbnail_width_| x |thumbnail_height_|
+  // and stores in |scaled_buffer|.
+  // Returns false if scale image failed.
+  bool GenerateYuvThumbnail(std::vector<uint8_t>* scaled_buffer);
+
+  // Destroys the buffer of APP1 segment if exists.
+  void DestroyApp1();
+
+  // The buffer pointer of yuv image (YU12). Not owned by this class.
+  const uint8_t* yu12_buffer_;
+  // The size of yuv image.
+  uint16_t yu12_width_;
+  uint16_t yu12_height_;
+
+  // The size of thumbnail.
+  uint16_t thumbnail_width_;
+  uint16_t thumbnail_height_;
+
+  // The Exif data (APP1). Owned by this class.
+  ExifData* exif_data_;
+  // The raw data of APP1 segment. It's allocated by ExifMem in |exif_data_| but
+  // owned by this class.
+  uint8_t* app1_buffer_;
+  // The length of |app1_buffer_|.
+  unsigned int app1_length_;
+  // The quality of compressed thumbnail image. The size of EXIF thumbnail has
+  // to be smaller than 64KB. If quality is 100, the size may be bigger than
+  // 64KB.
+  int thumbnail_jpeg_quality_;
+
+  // The YU12 to Jpeg compressor.
+  JpegCompressor compressor_;
+};
+
+}  // namespace arc
+
+#endif  // INCLUDE_ARC_EXIF_UTILS_H_
diff --git a/hardware/ntimespace/camera/arc/format_convert_test.cpp b/hardware/ntimespace/camera/arc/format_convert_test.cpp
new file mode 100644
index 0000000000..f4a8b2ee8f
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/format_convert_test.cpp
@@ -0,0 +1,248 @@
+#include "arc/image_processor.h"
+#include <cerrno>
+#include <ctime>
+#include <string>
+#include <libyuv.h>
+#include "arc/common.h"
+#include "arc/exif_utils.h"
+#include "arc/jpeg_compressor.h"
+#include "debug.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+#include "hardware/hw_converter.h"
+#include "frame_buffer.h"
+#include "arc/format_convert_test.h"
+
+
+using android::CameraMetadata;
+
+namespace arc {
+
+void fill_data(unsigned char * rgbdata, int w, int sr, int sc, int er, int ec, unsigned char color_r, 
+               unsigned char color_g, unsigned char color_b, unsigned char color_a)
+{
+  int rr, cc;
+
+  for (rr = sr; rr < er; rr++)
+  {
+    for (cc = sc; cc < ec; cc++)
+    {
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc)) = color_r; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 1) = color_g; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 2) = color_b; 
+      *((unsigned char *)rgbdata + 4 * (w * rr + cc) + 3) = color_a; 
+    }
+  }
+}
+
+void fill_rgb_matrix(unsigned char * rgbdata, int camera_width, int camera_height)
+{
+  int dw = camera_width/3;
+  int dh = camera_height/3;
+  unsigned char color[][4] = { //r/g/b/r
+    {0xFF, 0, 0, 0}, 
+    {0, 0xFF, 0xFF, 0}, //cygon
+    {0xFF, 0xFF, 0xFF, 0xFF}, //white
+    {0, 0xFF, 0xFF, 0},
+    {0, 0xFF, 0, 0}, //green
+    {0, 0xFF, 0xFF, 0},
+    {0, 0, 0, 0}, //black
+    {0, 0xFF, 0xFF, 0},
+    {0, 0, 0xFF, 0}, //blue
+  };
+
+  int idx = 0;
+  for (int r = 0; r < 3; r++)
+  {
+    for (int c = 0; c < 3; c++) 
+    {
+      fill_data(rgbdata, camera_width, /*camera_height,*/ r * dh, c * dw, (r + 1)* dh, (c + 1) * dw, 
+                color[idx][0], color[idx][1], color[idx][2], color[idx][3]);
+      idx++;
+    }					
+  }
+}
+
+void ConvertFormat(const FrameBuffer& in_frame, FrameBuffer* out_frame) 
+{
+  ImageProcessor::ConvertFormat(CameraMetadata(), in_frame, out_frame);
+}
+
+void ConvertFormat_HW(const FrameBuffer& in_frame, FrameBuffer* out_frame) 
+{
+  (void)in_frame;
+  (void)out_frame;
+  hw_conv::convert_format(CameraMetadata(), in_frame, out_frame);
+}
+
+void SW_Convert(int in_formatcc, int out_formatcc, int width, int height)
+{
+  dump_data_index++;
+
+  UnitTestFrameBuffer rgb_frame(V4L2_PIX_FMT_RGB32, width, height);
+  UnitTestFrameBuffer yu12_frame(V4L2_PIX_FMT_YUV420, width, height);
+  UnitTestFrameBuffer out_frame(out_formatcc, width, height);
+  
+  arc::fill_rgb_matrix(rgb_frame.GetData(), width, height);
+
+  {
+    UnitTestFrameBuffer in_frame(in_formatcc, width, height);
+
+    ConvertFormat(rgb_frame, &in_frame);
+    dump_data(dump_data_index, in_frame.GetData(), in_frame.GetWidth(), in_frame.GetHeight(), 
+              in_frame.GetFourcc(), 0, "in");
+
+    ConvertFormat(in_frame, &yu12_frame);
+    dump_data(dump_data_index, yu12_frame.GetData(), yu12_frame.GetWidth(), yu12_frame.GetHeight(), 
+              yu12_frame.GetFourcc(), 0, "yu12");
+
+    ConvertFormat(yu12_frame, &out_frame);
+    dump_data(dump_data_index, out_frame.GetData(), out_frame.GetWidth(), out_frame.GetHeight(), 
+              out_frame.GetFourcc(), 0, "post"); 
+  }
+}
+
+void FormatConvert_UnitTest_SW()
+{
+  bool unit_test = android::base::GetBoolProperty("camera.debug.unit_test", true);
+  if (!unit_test)
+    return;
+
+  android::base::SetProperty("camera.debug.dump", "true");
+
+  LOGF(INFO) << "FormatConvertUnitTest start.";
+  dump_data_init();
+
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_RGB32, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_YUV420, 640, 480); 
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_NV12, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_NV21, 640, 480);
+  SW_Convert(V4L2_PIX_FMT_RGB32, V4L2_PIX_FMT_YVU420, 640, 480);
+
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_NV12,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_NV21,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_RGB32,  640, 480);  
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_YUV420,  640, 480);  
+  SW_Convert(V4L2_PIX_FMT_YUV420, V4L2_PIX_FMT_YVU420,  640, 480);    
+
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_NV12,  640, 480); 
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_RGB32,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_NV21,  640, 480); 
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_YUV420,  640, 480);
+  SW_Convert(V4L2_PIX_FMT_NV12,  V4L2_PIX_FMT_YVU420,  640, 480);
+
+  unit_test = false;
+  android::base::SetProperty("camera.debug.unit_test", "false");
+  android::base::SetProperty("camera.debug.dump", "false");
+
+  LOGF(INFO) << "FormatConvertUnitTest end.";	
+}
+
+void HW_Convert(int in_formatcc, int out_formatcc, int in_width, int in_height, int out_width, int out_height)
+{
+  dump_data_index++;
+
+  IonFrameBuffer rgb_frame(V4L2_PIX_FMT_RGB32, in_width, in_height);
+  IonFrameBuffer out_frame(out_formatcc, out_width, out_height);
+  IonFrameBuffer in_frame(in_formatcc, in_width, in_height);
+
+  arc::fill_rgb_matrix(rgb_frame.GetData(), in_width, in_height);
+
+  ConvertFormat(rgb_frame, &in_frame);
+  dump_data(dump_data_index, in_frame.GetData(), in_frame.GetWidth(), in_frame.GetHeight(), 
+            in_frame.GetFourcc(), 0, "in");
+
+  ConvertFormat_HW(in_frame, &out_frame);
+  dump_data(dump_data_index, out_frame.GetData(), out_frame.GetWidth(), out_frame.GetHeight(), 
+            out_frame.GetFourcc(), 0, "post"); 
+}
+
+void Test_Template(int in_fortmat) 
+{
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_NV12,  640, 480, 320, 240);
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_RGB32,  640, 480, 320, 240);  
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_YUV420,  640, 480, 320, 240);  
+  HW_Convert(in_fortmat, V4L2_PIX_FMT_YVU420,  640, 480, 320, 240);    
+}
+
+void FormatConvert_UnitTest_HW()
+{
+  bool unit_test = android::base::GetBoolProperty("camera.debug.unit_test", false);
+  if (!unit_test)
+    return;
+
+  android::base::SetProperty("camera.debug.dump", "true");
+
+  LOGF(INFO) << __FUNCTION__ << " start";
+  dump_data_init();
+
+  Test_Template(V4L2_PIX_FMT_RGB32);
+  Test_Template(V4L2_PIX_FMT_YUV420);
+  Test_Template(V4L2_PIX_FMT_NV12);
+  Test_Template(V4L2_PIX_FMT_YVU420);
+
+  android::base::SetProperty("camera.debug.unit_test", "false");
+  android::base::SetProperty("camera.debug.dump", "false");
+  LOGF(INFO) << __FUNCTION__ << " end";	
+}
+
+void FormatConvert_PerfTest(){
+  int in_width = 720;
+  int in_height = 1080;
+  int in_formatcc = V4L2_PIX_FMT_RGB32;
+  int out_formatcc = V4L2_PIX_FMT_YUV420;
+  int loop = 1000;
+
+  IonFrameBuffer out_frame(out_formatcc, in_width, in_height);
+  IonFrameBuffer in_frame(in_formatcc, in_width, in_height);
+
+  arc::fill_rgb_matrix(in_frame.GetData(), in_width, in_height);
+
+  uint64_t perf_time_start;
+  uint64_t perf_time_end;
+  uint64_t testDurationNs;
+  CPU_OCCUPY cpu_stat_start;
+  CPU_OCCUPY cpu_stat_end;  
+  int usage = 0;  
+
+  perf_time_start = timeNanos();
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start); 
+  for (int i = 0; i < loop; i++)
+    ConvertFormat(in_frame, &out_frame);
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_end);
+  perf_time_end = timeNanos();
+  testDurationNs = perf_time_end - perf_time_start;
+  usage = cal_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start,(CPU_OCCUPY *)&cpu_stat_end);
+  HAL_LOGD("SW convert perf - time: %d  cpu: %d%%", toMilliSeconds(testDurationNs), usage);     
+
+  sleep(3);
+
+  perf_time_start = timeNanos();
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start);   
+  for (int i = 0; i < loop; i++)
+    ConvertFormat_HW(in_frame, &out_frame);
+  get_cpuoccupy((CPU_OCCUPY *)&cpu_stat_end);    
+  perf_time_end = timeNanos();
+  testDurationNs = perf_time_end - perf_time_start;
+  usage = cal_cpuoccupy((CPU_OCCUPY *)&cpu_stat_start,(CPU_OCCUPY *)&cpu_stat_end);
+  HAL_LOGD("HW convert perf - time: %d  cpu: %d%%", toMilliSeconds(testDurationNs), usage);     
+}
+
+void FormatConvert_UnitTest(){
+  #if 0
+  if (android::base::GetBoolProperty("camera.debug.unit_test", false)) {
+    char value[PROPERTY_VALUE_MAX];
+    if (property_get("camera.debug.convert_mode", value, "hw")) {
+      if (!strcmp("hw", value)) {
+        FormatConvert_UnitTest_HW();
+      } else if (!strcmp("libyuv", value)) {
+      FormatConvert_UnitTest_SW();
+      } else if (!strcmp("perf", value)) {
+        FormatConvert_PerfTest();
+      }
+    }
+  }
+#endif
+}
+
+}
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/arc/format_convert_test.h b/hardware/ntimespace/camera/arc/format_convert_test.h
new file mode 100644
index 0000000000..52f0c78368
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/format_convert_test.h
@@ -0,0 +1,23 @@
+#ifndef __FORMAT_CONVERT_HEADER__
+#define __FORMAT_CONVERT_HEADER__
+
+#include "metadata/camera_metadata.h"
+// FourCC pixel formats (defined as V4L2_PIX_FMT_*).
+#include <linux/videodev2.h>
+// Declarations of HAL_PIXEL_FORMAT_XXX.
+#include <system/graphics.h>
+
+#include "frame_buffer.h"
+
+namespace arc {
+
+void fill_rgb_matrix(unsigned char * rgbdata, int camera_width, int camera_height);
+
+void FormatConvert_UnitTest_SW();
+void FormatConvert_UnitTest_HW();
+void FormatConvert_UnitTest();
+
+}  // namespace arc
+
+
+#endif
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/arc/frame_buffer.cpp b/hardware/ntimespace/camera/arc/frame_buffer.cpp
new file mode 100644
index 0000000000..86e1bc0ea0
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/frame_buffer.cpp
@@ -0,0 +1,379 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "v4l2_camera_hal.h"
+#include "arc/frame_buffer.h"
+#include <utility>
+#include <sys/mman.h>
+#include "arc/common.h"
+#include "arc/image_processor.h"
+#include "gralloc/psb_gralloc3.h"
+#include "stream_format.h"
+#include "debug.h"
+#include <sys/types.h>
+#include <linux/ion.h>
+//#include "linux/msm_ion.h"
+#include <ion/ion.h>
+#include <linux/dma-buf.h>
+
+
+namespace arc {
+
+FrameBuffer::FrameBuffer()
+    : data_(nullptr),
+      data_size_(0),
+      buffer_size_(0),
+      width_(0),
+      height_(0),
+      fourcc_(0),
+      fd_(-1) {
+}
+
+FrameBuffer::~FrameBuffer() {
+}
+
+int FrameBuffer::SetDataSize(size_t data_size) {
+  //LOGF(INFO) << "size "<< data_size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (data_size > buffer_size_) {
+    LOGF(ERROR) << "Buffer overflow: Buffer only has " << buffer_size_
+                << ", but data needs " << data_size;
+    return -EINVAL;
+  }
+  data_size_ = data_size;
+  return 0;
+}
+
+AllocatedFrameBuffer::AllocatedFrameBuffer(int buffer_size) {
+  buffer_.reset(new uint8_t[buffer_size]);
+  buffer_size_ = buffer_size;
+  data_ = buffer_.get();
+}
+
+AllocatedFrameBuffer::AllocatedFrameBuffer(uint8_t* buffer, int buffer_size) {
+  buffer_.reset(buffer);
+  buffer_size_ = buffer_size;
+  data_ = buffer_.get();
+}
+
+AllocatedFrameBuffer::~AllocatedFrameBuffer() {
+  fd_ = -1;
+}
+
+int AllocatedFrameBuffer::SetDataSize(size_t size) {
+  //LOGF(INFO) << "size "<< size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (size > buffer_size_) {
+    buffer_.reset(new uint8_t[size]);
+    buffer_size_ = size;
+    data_ = buffer_.get();
+  }
+  data_size_ = size;
+  return 0;
+}
+
+void AllocatedFrameBuffer::Reset() { memset(data_, 0, buffer_size_); }
+
+#define CAMERAMEMSIZE (1024*1024*24)
+V4L2FrameBuffer::V4L2FrameBuffer() {
+  fd_ = -1;
+  buffer_size_ = CAMERAMEMSIZE;
+  width_ = 0;
+  height_ = 0;
+  fourcc_ = 0;
+  data_ = nullptr;
+  offset_ = 0;
+}
+
+V4L2FrameBuffer::~V4L2FrameBuffer() {
+  if (Unmap()) {
+    LOGF(ERROR) << "Unmap failed";
+  }
+}
+
+void V4L2FrameBuffer::SetData(uint8_t* data) {
+  data_ = data;
+}
+
+int V4L2FrameBuffer::SetDataSize(size_t size) {
+  LOGF(INFO) << "size "<< size << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (size > buffer_size_) {
+    LOGF(ERROR) << "SetDataSize failed";
+    return -EINVAL;
+  }
+
+  data_size_ = size;
+  return 0;
+}
+
+void V4L2FrameBuffer::Reset() { memset(data_, 0, data_size_);}
+
+bool V4L2FrameBuffer::is_mapped_ = false;
+uint8_t* V4L2FrameBuffer::map_start_ = nullptr;
+
+int V4L2FrameBuffer::Map() {
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    return 0;
+  }
+
+  void* addr = mmap(NULL, data_size_, PROT_READ, MAP_SHARED, fd_, offset_);
+  if (addr == MAP_FAILED) {
+    HAL_LOGE("mmap() size %zu map_start_ offset %d fd %d failed: %s", data_size_, offset_, fd_, strerror(errno));
+    return -EINVAL;
+  }
+
+  map_start_ = static_cast<uint8_t*>(addr);
+  is_mapped_ = true;
+  HAL_LOGV("%s: map_start_ %p data_size_ %zd  ", __func__, map_start_, data_size_);    
+  return 0;
+}
+
+int V4L2FrameBuffer::Unmap() {
+  base::AutoLock l(lock_);
+  HAL_LOGV("%s: map_start_ %p data_size_ %zd  ", __func__, map_start_, data_size_);    
+  if (is_mapped_ && munmap(static_cast<void*>(map_start_), data_size_)) {
+    LOGF(ERROR) << "mummap() map_start_ failed: " << strerror(errno);
+    return -EINVAL;
+  }
+  HAL_LOGV("V4L2FrameBuffer::Unmap: map_start_ Try to Unmap success2");  
+  is_mapped_ = false; 
+ 
+  return 0;
+}
+ 
+GrallocFrameBuffer::GrallocFrameBuffer(buffer_handle_t buffer, uint32_t width,
+                                       uint32_t height, uint32_t fourcc,
+                                       uint32_t device_buffer_length,
+                                       uint32_t stream_usage)
+    : buffer_(buffer),
+      is_mapped_(false),
+      device_buffer_length_(device_buffer_length),
+      stream_usage_(stream_usage) {
+  width_ = width;
+  height_ = height;
+  fourcc_ = fourcc;
+  buffer_size_ = device_buffer_length;
+
+  fd_ = v4l2_camera_hal::ion_fd;
+  //LOGF(ERROR) << __FUNCTION__ << " fd_: " << fd_; 
+  /*
+  LOGF(INFO) << "buffer: " << buffer << " fourcc: " << fourcc << " width: " << width << " height: " << height
+              << " device_buffer_length: " << device_buffer_length_
+              << " stream_usage: " << stream_usage;
+  */
+}
+
+GrallocFrameBuffer::~GrallocFrameBuffer() {
+  fd_ = -1;
+  if (Unmap()) {
+    LOGF(ERROR) << "Unmap failed";
+  }
+}
+
+int GrallocFrameBuffer::Map() {
+  //LOGF(ERROR) << "Map enter";
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    LOGF(ERROR) << "The buffer is already mapped";
+    return -EINVAL;
+  }
+
+  void* addr;
+  switch (fourcc_) {
+    case V4L2_PIX_FMT_YUV420:
+    case V4L2_PIX_FMT_YVU420:
+    case V4L2_PIX_FMT_YUYV:
+    case V4L2_PIX_FMT_NV21:
+    case V4L2_PIX_FMT_NV12:    
+      if (gralloc_register(buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+      } else {
+        android_ycbcr yuv_data;
+        int hal_format = v4l2_camera_hal::StreamFormat::V4L2ToHalPixelFormat(fourcc_);
+        if (hal_format < 0) {
+          LOGF(ERROR) << "map to hal pixel format failed";
+          return -EINVAL;
+        }
+        if(gralloc_lock_ycbcr(buffer_, stream_usage_, 0, 0, width_, height_, &yuv_data,
+                                  hal_format, width_, height_)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;                                  
+        }
+        addr = yuv_data.y;
+      }
+      break;
+    case V4L2_PIX_FMT_JPEG:
+      if (gralloc_register((buffer_handle_t &)buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+        } else {
+          if(gralloc_lock(buffer_, stream_usage_, 0, 0, device_buffer_length_, 1, &addr)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;
+          }
+        }
+      break;    
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      if (gralloc_register((buffer_handle_t &)buffer_)) {
+          LOGF(ERROR) << "register buffer failed";
+          return -EINVAL;
+        } else {
+          if(gralloc_lock(buffer_, stream_usage_, 0, 0, width_, height_, &addr)) {
+            LOGF(ERROR) << "lock buffer failed";
+            return -EINVAL;
+          }
+        }
+      break;
+    default:
+      LOGF(ERROR) << "Unsupported fourcc";
+      return -EINVAL;
+  }
+
+  data_ = static_cast<uint8_t*>(addr);
+  if (fourcc_ == V4L2_PIX_FMT_YVU420 || fourcc_ == V4L2_PIX_FMT_YUV420 ||
+      fourcc_ == V4L2_PIX_FMT_NV21 || fourcc_ == V4L2_PIX_FMT_RGB32 ||
+      fourcc_ == V4L2_PIX_FMT_BGR32 || fourcc_ == V4L2_PIX_FMT_JPEG ||
+      fourcc_ == V4L2_PIX_FMT_NV12) {
+    buffer_size_ = ImageProcessor::GetConvertedSize(fourcc_, width_, height_);
+  }
+
+  is_mapped_ = true;
+  return 0;
+}
+
+int GrallocFrameBuffer::Unmap() {
+  //LOGF(ERROR) << "Unmap enter";
+  base::AutoLock l(lock_);
+  if (is_mapped_) {
+    if (gralloc_unlock(buffer_)) {
+      LOGF(ERROR) << "Failed to unmap buffer";
+      return -EINVAL;
+    }
+
+    if (gralloc_unregister(buffer_)){
+      LOGF(ERROR) << "Failed to unmap buffer";
+      return -EINVAL;
+    }
+
+    is_mapped_ = false;
+  }
+
+  return 0;
+}
+
+int IonFrameBuffer:: CreateIONBuffer(int len)
+{
+  #define ALIGN(x, y) (((x) + ((y) - 1)) & (~((y) - 1)))
+  #define HEAP_MASK_FROM_TYPE(type) (1 << type)
+  #define ION_HEAP_TYPE_SYSTEM 0
+  #define ION_FLAG_CACHED 1
+  
+  int fd;
+  int rc = ion_alloc_fd(v4l2_camera_hal::ion_fd, ALIGN(len,4096), 0, HEAP_MASK_FROM_TYPE(ION_HEAP_TYPE_SYSTEM), 
+    ION_FLAG_CACHED, &fd);
+  if (rc || fd < 0) {
+    LOGF(ERROR) << "ION ALLOC memory failed " << len << " bytes with error " << rc;      
+    return -1;
+  }
+
+  //LOGF(INFO) << "ion_fd: " << v4l2_camera_hal::ion_fd << " alloc_data.fd: " << fd;
+  return fd;
+}  
+
+char * IonFrameBuffer::IonMap(int fd, int len)
+{
+  VLOGF_ENTER();
+  char *bufaddr = (char*)mmap(NULL, len, PROT_READ|PROT_WRITE, MAP_SHARED, fd, 0);
+  if (bufaddr != MAP_FAILED)
+      cache_clean_invalidate(fd);
+  //LOGF(ERROR) << "mnmap " << " bufaddr: " << bufaddr << " len: " << len;
+  return bufaddr;
+}
+
+int IonFrameBuffer::IonUnmap(int fd, void *bufaddr, int len)
+{
+  VLOGF_ENTER();
+  cache_clean_invalidate(fd);
+  //LOGF(ERROR) << "munmap " << " bufaddr: " << bufaddr << " len: " << len;
+  if (-1 == munmap(bufaddr, len)) {
+      LOGF(ERROR) << "munmap failed " << strerror(errno) << " bufaddr: " << bufaddr << " len: " << len;
+      return -1;
+  }
+  return 0;
+}
+
+bool IonFrameBuffer:: AllocIonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height, size_t data_size){
+  width_ = width;
+  height_ = height;
+  fourcc_ = fourcc;
+  fd_ = CreateIONBuffer(data_size);
+  if (fd_ < 0) {
+    return false;
+  }
+  data_ = (unsigned char *)IonMap(fd_, data_size);
+  if (data_ == (unsigned char *)MAP_FAILED) {
+    LOGF(ERROR) << "IonMap() failed";
+    return false;
+  }
+
+  data_size_ = data_size;
+  buffer_size_ = data_size;  
+  return true; 
+}
+
+IonFrameBuffer::IonFrameBuffer(){
+    data_ = (unsigned char *)MAP_FAILED;
+    data_size_ = 0;
+    buffer_size_ = 0;  
+    fd_ = -1;   
+ }
+
+IonFrameBuffer:: IonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height){
+  size_t data_size = ImageProcessor::GetConvertedSize(fourcc, width, height);
+  AllocIonFrameBuffer(fourcc, width, height, data_size);
+}
+
+IonFrameBuffer:: ~IonFrameBuffer( ){
+  VLOGF_ENTER();
+  if (data_ != MAP_FAILED && data_size_ != 0) {
+    if (IonUnmap(fd_, data_, data_size_) == -1) {
+      LOGF(ERROR) << "mummap() failed: " << strerror(errno);
+    }
+    data_ = (unsigned char *)MAP_FAILED;
+    data_size_ = 0;
+    buffer_size_ = 0;  
+
+    close(fd_);
+    fd_ = -1;    
+  }
+}
+
+int IonFrameBuffer:: SetDataSize(size_t data_size)  {
+  VLOGF_ENTER();
+  //LOGF(INFO) << " buffer_size_ " << buffer_size_ << " data_size_ " << data_size_;
+  if (data_size_ < data_size) {
+    if (AllocIonFrameBuffer(fourcc_, width_, height_, data_size)){
+      VLOGF_EXIT();      
+      return 0;
+    } else {
+      VLOGF_EXIT();                 
+      return -1;
+    }
+  }
+
+  VLOGF_EXIT();
+  return 0;
+}
+
+void do_sync_ioctl(int fd, struct dma_buf_sync* sync) {
+    int rc = ioctl(fd, DMA_BUF_IOCTL_SYNC, sync);
+    if (rc < 0) {
+        LOGF(ERROR) << "Failed DMA_BUF_IOCTL_SYNC flags " << sync->flags << " rc " << rc;
+        return;
+    }
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/frame_buffer.h b/hardware/ntimespace/camera/arc/frame_buffer.h
new file mode 100644
index 0000000000..d2464ad719
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/frame_buffer.h
@@ -0,0 +1,268 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_FRAME_BUFFER_H_
+#define HAL_USB_FRAME_BUFFER_H_
+
+#include <cstdint>
+#include <memory>
+
+#include <base/files/scoped_file.h>
+#include <base/synchronization/lock.h>
+#include <hardware/gralloc.h>
+#include "common.h"
+#include <sys/mman.h>
+#include "linux/ion.h"
+#include <linux/dma-buf.h>
+
+namespace arc {
+
+class FrameBuffer {
+ public:
+  FrameBuffer();
+  virtual ~FrameBuffer();
+
+  // If mapped successfully, the address will be assigned to |data_| and return
+  // 0. Otherwise, returns -EINVAL.
+  virtual int Map() = 0;
+
+  // Unmaps the mapped address. Returns 0 for success.
+  virtual int Unmap() = 0;
+
+  uint8_t* GetData() const { return data_; }
+  size_t GetDataSize() const { return data_size_; }
+  size_t GetBufferSize() const { return buffer_size_; }
+  uint32_t GetWidth() const { return width_; }
+  uint32_t GetHeight() const { return height_; }
+  uint32_t GetFourcc() const { return fourcc_; }
+
+  void SetFourcc(uint32_t fourcc) { fourcc_ = fourcc; }
+  virtual int SetDataSize(size_t data_size);
+
+  int GetFd() const { return fd_; }
+  void SetFd(int fd) {fd_ = fd;}
+
+ protected:
+  uint8_t* data_;
+
+  // The number of bytes used in the buffer.
+  size_t data_size_;
+
+  // The number of bytes allocated in the buffer.
+  size_t buffer_size_;
+
+  // Frame resolution.
+  uint32_t width_;
+  uint32_t height_;
+
+  // This is V4L2_PIX_FMT_* in linux/videodev2.h.
+  uint32_t fourcc_;
+
+  //for v4l2 buffer, it's dma fd
+  //for gralloc buffer, it's ion fd
+  //for allocated buffer, it's backup fd for ion fd
+  int fd_;   
+};
+
+// AllocatedFrameBuffer is used for the buffer from hal malloc-ed. User should
+// be aware to manage the memory.
+class AllocatedFrameBuffer : public FrameBuffer {
+ public:
+  explicit AllocatedFrameBuffer(int buffer_size);
+  explicit AllocatedFrameBuffer(uint8_t* buffer, int buffer_size);
+  ~AllocatedFrameBuffer() override;
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+  int SetDataSize(size_t data_size) override;
+
+  void Reset();
+
+ private:
+  std::unique_ptr<uint8_t[]> buffer_;
+};
+
+
+// V4L2FrameBuffer is used for the buffer from V4L2CameraDevice. Maps the fd
+// in constructor. Unmaps and closes the fd in destructor.
+class V4L2FrameBuffer : public FrameBuffer {
+ public:
+  V4L2FrameBuffer();
+  // Unmaps |data_| and closes |fd_|.
+  ~V4L2FrameBuffer();
+
+  int Map() override;
+  int Unmap() override;
+
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+  int SetDataSize(size_t data_size);
+  void Reset();
+  void SetData(uint8_t* data);
+  uint8_t* GetMapStart() {return map_start_;}
+  void SetBufferSize(int buffer_size) { buffer_size_ = buffer_size;}
+  void SetOffset(int offset) { offset_ = offset;}
+
+ private:
+  static bool is_mapped_;
+  static uint8_t* map_start_;
+  int offset_;
+
+  // Lock to guard |is_mapped_|.
+  base::Lock lock_;
+};
+
+// GrallocFrameBuffer is used for the buffer from Android framework. Uses
+// CameraBufferMapper to lock and unlock the buffer.
+class GrallocFrameBuffer : public FrameBuffer {
+ public:
+  GrallocFrameBuffer(buffer_handle_t buffer, uint32_t width, uint32_t height,
+                     uint32_t fourcc, uint32_t device_buffer_length,
+                     uint32_t stream_usage);
+  ~GrallocFrameBuffer();
+
+  int Map() override;
+  int Unmap() override;
+
+  // The currently used buffer for |buffer_mapper_| operations.
+  buffer_handle_t buffer_;
+
+ private:
+  // Used to import gralloc buffer.
+  //const gralloc_module_t* gralloc_module_;
+
+  bool is_mapped_;
+
+  // Lock to guard |is_mapped_|.
+  base::Lock lock_;
+
+  // Camera stream and device buffer context.
+  uint32_t device_buffer_length_;
+  uint32_t stream_usage_;
+};
+
+class UnitTestFrameBuffer: public FrameBuffer {
+public:	
+	UnitTestFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height){
+		width_ = width;
+		height_ = height;
+		fourcc_ = fourcc;
+    data_size_ = 1280*1280*4;
+    data_ = new uint8_t[data_size_];
+	}
+  ~UnitTestFrameBuffer( ){
+    delete data_;
+	}
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size)  { data_size_ = data_size; return 0;}
+};
+
+class IonFrameBuffer: public FrameBuffer {
+public:	
+  IonFrameBuffer();
+  IonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height);
+  ~IonFrameBuffer( );
+
+  int CreateIONBuffer(int len);
+	bool AllocIonFrameBuffer(uint32_t fourcc, uint32_t width, uint32_t height, size_t data_size);  
+ 
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size);
+  void SetWidth(uint32_t width) { width_ = width; }
+  void SetHeight(uint32_t height) { height_ = height; }
+
+  char * IonMap(int fd, int len); 
+  int IonUnmap(int fd, void *bufaddr, int len);   
+};
+
+class SimpleFrameBuffer: public FrameBuffer {
+public:	
+	SimpleFrameBuffer(uint8_t* data, uint32_t fourcc, uint32_t width, uint32_t height, int fd, uint32_t data_size){
+		width_ = width;
+		height_ = height;
+		fourcc_ = fourcc;
+    data_size_ = data_size;
+    data_ = data;
+    fd_ = fd;
+	}
+  ~SimpleFrameBuffer( ){
+    data_ = nullptr;
+    data_size_ = 0;
+	}
+
+  // No-op for the two functions.
+  int Map() override { return 0; }
+  int Unmap() override { return 0; }
+  int SetDataSize(size_t data_size)  { data_size_ = data_size; return 0;}
+};
+
+
+void do_sync_ioctl(int fd, struct dma_buf_sync* sync);
+
+static inline void sync_start_write(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_WRITE;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_write(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_WRITE;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_start_read(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_READ;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_read(int fd) {
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_READ;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_start_rw(int fd) {
+    VLOGF_ENTER();
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_START | DMA_BUF_SYNC_RW;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void sync_end_rw(int fd) {
+    VLOGF_ENTER();
+    struct dma_buf_sync sync = {0};
+    sync.flags = DMA_BUF_SYNC_END | DMA_BUF_SYNC_RW;
+    do_sync_ioctl(fd, &sync);
+}
+
+static inline void cache_clean(int fd) {
+    sync_start_write(fd);
+    sync_end_write(fd);
+}
+
+static inline void cache_invalidate(int fd) {
+    sync_start_write(fd);
+    sync_end_read(fd);
+}
+
+static inline void cache_clean_invalidate(int /*fd*/) {
+    //sync_start_rw(fd);
+    //sync_end_rw(fd);
+}
+
+}  // namespace arc
+
+#endif  // HAL_USB_FRAME_BUFFER_H_
diff --git a/hardware/ntimespace/camera/arc/image_processor.cpp b/hardware/ntimespace/camera/arc/image_processor.cpp
new file mode 100644
index 0000000000..99f6f726fc
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/image_processor.cpp
@@ -0,0 +1,663 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/image_processor.h"
+
+#include <cerrno>
+#include <ctime>
+#include <string>
+
+#include <libyuv.h>
+#include "arc/common.h"
+#include "arc/exif_utils.h"
+#include "arc/jpeg_compressor.h"
+#include "debug.h"
+#include "android-base/properties.h"
+#include <cutils/properties.h>
+//#include "hardware/hw_converter.h"
+
+
+namespace arc {
+
+using android::CameraMetadata;
+
+/*
+ * Formats have different names in different header files. Here is the mapping
+ * table:
+ *
+ * android_pixel_format_t          videodev2.h           FOURCC in libyuv
+ * -----------------------------------------------------------------------------
+ * HAL_PIXEL_FORMAT_YV12         = V4L2_PIX_FMT_YVU420 = FOURCC_YV12
+ * HAL_PIXEL_FORMAT_YCrCb_420_SP = V4L2_PIX_FMT_NV21   = FOURCC_NV21
+ * HAL_PIXEL_FORMAT_RGBA_8888    = V4L2_PIX_FMT_RGB32  = FOURCC_BGR4 //wrong, should be V4L2_PIX_FMT_BGR32
+ * HAL_PIXEL_FORMAT_YCbCr_422_I  = V4L2_PIX_FMT_YUYV   = FOURCC_YUYV
+ *                                                     = FOURCC_YUY2
+ *                                 V4L2_PIX_FMT_YUV420 = FOURCC_I420
+ *                                                     = FOURCC_YU12
+ *                                 V4L2_PIX_FMT_MJPEG  = FOURCC_MJPG
+ *
+ * Camera device generates FOURCC_YUYV and FOURCC_MJPG.
+ * Preview needs FOURCC_ARGB format.
+ * Software video encoder needs FOURCC_YU12.
+ * CTS requires FOURCC_YV12 and FOURCC_NV21 for applications.
+ *
+ * Android stride requirement:
+ * YV12 horizontal stride should be a multiple of 16 pixels. See
+ * android.graphics.ImageFormat.YV12.
+ * The stride of ARGB, YU12, and NV21 are always equal to the width.
+ *
+ * Conversion Path:
+ * MJPG/YUYV (from camera) -> YU12 -> ARGB (preview)
+ *                                 -> NV21 (apps)
+ *                                 -> YV12 (apps)
+ *                                 -> YU12 (video encoder)
+ */
+
+// YV12 horizontal stride should be a multiple of 16 pixels for each plane.
+// |dst_stride_uv| is the pixel stride of u or v plane.
+static int YU12ToYV12(const void* yv12, void* yu12, int width, int height,
+                      int dst_stride_y, int dst_stride_uv);
+static int YU12ToNV21(const void* yv12, void* nv21, int width, int height);
+static bool ConvertToJpeg(const CameraMetadata& metadata,
+                          const FrameBuffer& in_frame, FrameBuffer* out_frame);
+static bool SetExifTags(const CameraMetadata& metadata, ExifUtils* utils);
+
+// How precise the float-to-rational conversion for EXIF tags would be.
+static const int kRationalPrecision = 10000;
+
+// Default JPEG quality settings.
+static const int DEFAULT_JPEG_QUALITY = 80;
+
+inline static size_t Align16(size_t value) { return (value + 15) & ~15; }
+
+size_t ImageProcessor::GetConvertedSize(int fourcc, uint32_t width,
+                                        uint32_t height) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return 0;
+  }
+
+  switch (fourcc) {
+    case V4L2_PIX_FMT_YVU420:  // YV12
+      return Align16(width) * height + Align16(width / 2) * height;
+    case V4L2_PIX_FMT_YUV420:  // YU12
+    // Fall-through.
+    case V4L2_PIX_FMT_NV21:  // NV21
+    case V4L2_PIX_FMT_NV12:  // NV12
+      return (width) * height * 3 / 2;
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      return (width) * height * 4;
+    case V4L2_PIX_FMT_JPEG:
+      return (width) * height * 4; // For JPEG real size will be calculated after conversion.
+    default:
+      LOGF(ERROR) << "Pixel format " << FormatToString(fourcc)
+                  << " is unsupported.";
+      return 0;
+  }
+}
+
+bool ImageProcessor::SupportsConversion(uint32_t from_fourcc,
+                                        uint32_t to_fourcc) {
+  switch (from_fourcc) {
+    case V4L2_PIX_FMT_YUYV:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420);
+    case V4L2_PIX_FMT_YUV420:
+      return (
+          to_fourcc == V4L2_PIX_FMT_YUV420 ||
+          to_fourcc == V4L2_PIX_FMT_YVU420 || to_fourcc == V4L2_PIX_FMT_NV21 ||
+          to_fourcc == V4L2_PIX_FMT_RGB32 || to_fourcc == V4L2_PIX_FMT_BGR32 ||
+          to_fourcc == V4L2_PIX_FMT_JPEG  || to_fourcc == V4L2_PIX_FMT_NV12);
+    case V4L2_PIX_FMT_MJPEG:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420);
+    case V4L2_PIX_FMT_RGB32:
+      return (to_fourcc == V4L2_PIX_FMT_YUV420 || to_fourcc == V4L2_PIX_FMT_NV12
+             || to_fourcc == V4L2_PIX_FMT_NV21);      
+    default:
+      return false;
+  }
+}
+
+int ImageProcessor::ConvertFormat(const CameraMetadata& metadata,
+                                  const FrameBuffer& in_frame,
+                                  FrameBuffer* out_frame) {
+/*  LOGF(INFO) << "[libYUV] in_frame: "
+              << FormatToString(in_frame.GetFourcc())
+              << " "
+              << in_frame.GetFourcc()
+              << " width "
+              << in_frame.GetWidth()
+              << " height "
+              << in_frame.GetHeight()
+              << " size "
+              << in_frame.GetDataSize();   
+
+  LOGF(INFO) << "[libYUV] out_frame: "
+              << FormatToString(out_frame->GetFourcc())
+              << " "
+              << out_frame->GetFourcc()
+              << " width "
+              << out_frame->GetWidth()
+              << " height "
+              << out_frame->GetHeight()
+              << " size "
+              << out_frame->GetDataSize();              
+*/
+  if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                << " x " << in_frame.GetHeight() << ")";
+    return -EINVAL;
+  }
+
+  if (in_frame.GetFourcc() == out_frame->GetFourcc() &&
+      in_frame.GetWidth() == out_frame->GetWidth() &&
+      in_frame.GetHeight() == out_frame->GetHeight())
+  {
+    memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+    return 0;        
+  }
+  size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+
+  if (out_frame->SetDataSize(data_size)) {
+    LOGF(ERROR) << "Set data size failed";
+    return -EINVAL;
+  }
+
+  if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUYV) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int res = libyuv::YUY2ToI420(
+            in_frame.GetData(),      /* src_yuy2 */
+            in_frame.GetWidth() * 2, /* src_stride_yuy2 */
+            out_frame->GetData(),    /* dst_y */
+            out_frame->GetWidth(),   /* dst_stride_y */
+            out_frame->GetData() +
+                out_frame->GetWidth() * out_frame->GetHeight(), /* dst_u */
+            out_frame->GetWidth() / 2, /* dst_stride_u */
+            out_frame->GetData() + out_frame->GetWidth() *
+                                       out_frame->GetHeight() * 5 /
+                                       4, /* dst_v */
+            out_frame->GetWidth() / 2,    /* dst_stride_v */
+            in_frame.GetWidth(), in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "YUY2ToI420() for YU12 returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for YUYV source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUV420) { //YU12
+    // V4L2_PIX_FMT_YVU420 is YV12. I420 is usually referred to YU12
+    // (V4L2_PIX_FMT_YUV420), and YV12 is similar to YU12 except that U/V
+    // planes are swapped.
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YVU420:  // YV12
+      {  
+        int ystride = Align16(in_frame.GetWidth());
+        int uvstride = Align16(in_frame.GetWidth() / 2);
+        int res = YU12ToYV12(in_frame.GetData(), out_frame->GetData(),
+                             in_frame.GetWidth(), in_frame.GetHeight(), ystride,
+                             uvstride);
+        LOGF_IF(ERROR, res) << "YU12ToYV12() returns " << res;
+        return res ? -EINVAL : 0;    
+      }
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        memcpy(out_frame->GetData(), in_frame.GetData(),
+               in_frame.GetDataSize());
+        return 0;
+      }
+      case V4L2_PIX_FMT_NV21:  // NV21
+      {
+        // TODO(henryhsu): Use libyuv::I420ToNV21.
+        int res = YU12ToNV21(in_frame.GetData(), out_frame->GetData(),
+                             in_frame.GetWidth(), in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "YU12ToNV21() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_NV12:  
+      {
+        int res = libyuv::I420ToNV12(
+          in_frame.GetData(),  /* src_y */
+          in_frame.GetWidth(), /* src_stride_y */
+          in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+          in_frame.GetWidth() / 2,                        /* src_stride_u */
+          in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+          in_frame.GetWidth() / 2,   /* src_stride_v */
+          out_frame->GetData(),  /*dst_y*/
+          out_frame->GetWidth(),  /*dst_stride_y*/
+          out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(), /*dst_uv*/
+          out_frame->GetWidth(), /*dst_stride_uv*/
+          in_frame.GetWidth(), 
+          in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "I420ToNV12() returns " << res;
+        return res ? -EINVAL : 0;
+      }   
+      case V4L2_PIX_FMT_BGR32: {
+        int res = libyuv::I420ToABGR(
+            in_frame.GetData(),  /* src_y */
+            in_frame.GetWidth(), /* src_stride_y */
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+            in_frame.GetWidth() / 2,                        /* src_stride_u */
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+            in_frame.GetWidth() / 2,   /* src_stride_v */
+            out_frame->GetData(),      /* dst_abgr */
+            out_frame->GetWidth() * 4, /* dst_stride_abgr */
+            in_frame.GetWidth(), 
+            in_frame.GetHeight());
+        LOGF_IF(ERROR, res) << "I420ToABGR() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_RGB32: {
+        LOG(INFO) << "libyuv::I420ToABGR";
+        int res = libyuv::I420ToABGR(
+            in_frame.GetData(),  /* src_y */
+            in_frame.GetWidth(), /* src_stride_y */
+            in_frame.GetData() +
+                in_frame.GetWidth() * in_frame.GetHeight(), /* src_u */
+            in_frame.GetWidth() / 2,                        /* src_stride_u */
+            in_frame.GetData() +
+                in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4, /* src_v */
+            in_frame.GetWidth() / 2,   /* src_stride_v */
+            out_frame->GetData(),      /* dst_argb */
+            out_frame->GetWidth() * 4, /* dst_stride_argb */
+            in_frame.GetWidth(), in_frame.GetHeight());                
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_JPEG: {
+        bool res = ConvertToJpeg(metadata, in_frame, out_frame);
+        LOGF_IF(ERROR, !res) << "ConvertToJpeg() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for YU12 source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_MJPEG) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int res = libyuv::MJPGToI420(
+            in_frame.GetData(),     /* sample */
+            in_frame.GetDataSize(), /* sample_size */
+            out_frame->GetData(),   /* dst_y */
+            out_frame->GetWidth(),  /* dst_stride_y */
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(), /* dst_u */
+            out_frame->GetWidth() / 2, /* dst_stride_u */
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4, /* dst_v */
+            out_frame->GetWidth() / 2,    /* dst_stride_v */
+            in_frame.GetWidth(), 
+            in_frame.GetHeight(), 
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "MJPEGToI420() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for MJPEG source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:  // YU12
+      {
+        int dst_stride = (out_frame->GetWidth());
+        int res = libyuv::ABGRToI420(  //memory map r/g/b/a
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),     /*dest y*/  
+            dst_stride,    /*dst_stride_y*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),  /*dst_u*/
+            dst_stride / 2,  /*dst_stide_u*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,       /*dst_v*/
+            dst_stride / 2,       /*dst_stride*/
+            out_frame->GetWidth(),
+            out_frame->GetHeight());          
+        LOGF_IF(ERROR, res) << "ABGRToI420() returns " << res;
+        return res ? -EINVAL : 0;   
+      }
+      case V4L2_PIX_FMT_NV12:  
+      {
+        uint32_t dst_c_stride = out_frame->GetWidth();
+        int res = libyuv::ARGBToNV12(
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),   
+            dst_c_stride,
+            out_frame->GetData() + dst_c_stride * out_frame->GetHeight(), 
+            dst_c_stride,  
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "ABGRToNV12() returns " << res;
+        return res ? -EINVAL : 0;        
+      }
+      case V4L2_PIX_FMT_NV21:  
+      {
+        uint32_t dst_c_stride = out_frame->GetWidth();
+        int res = libyuv::ARGBToNV21(
+            in_frame.GetData(),     
+            in_frame.GetWidth() * 4, 
+            out_frame->GetData(),   
+            dst_c_stride,
+            out_frame->GetData() + dst_c_stride * out_frame->GetHeight(), 
+            dst_c_stride,  
+            out_frame->GetWidth(),
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "ARGBToI420() returns " << res;
+        return res ? -EINVAL : 0;        
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for RGB32 source format.";
+        return -EINVAL;
+    }
+  } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+    switch (out_frame->GetFourcc()) {
+      case V4L2_PIX_FMT_YUV420:   //yu12, I420
+      {
+        int res = libyuv::NV12ToI420(
+            in_frame.GetData(),      /*src_y*/
+            in_frame.GetWidth(),     /*src_y_stride*/
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(),  /* src_uv */
+            in_frame.GetWidth(),    /*src_uv_stride*/
+            out_frame->GetData(),    /*dst_y*/
+            out_frame->GetWidth(),    /*dst_w*/
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+            out_frame->GetWidth() / 2,
+            out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+            out_frame->GetWidth() / 2,
+            out_frame->GetWidth(), 
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "YUY2ToI420() for YU12 returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      case V4L2_PIX_FMT_RGB32: 
+      {
+        int res = libyuv::NV12ToARGB(
+            in_frame.GetData(),  
+            in_frame.GetWidth(), 
+            in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(), 
+            in_frame.GetWidth(),
+            out_frame->GetData(),      
+            out_frame->GetWidth() * 4, 
+            out_frame->GetWidth(), 
+            out_frame->GetHeight());
+        LOGF_IF(ERROR, res) << "NV12ToARGB() returns " << res;
+        return res ? -EINVAL : 0;
+      }
+      default:
+        LOGF(ERROR) << "Destination pixel format "
+                    << FormatToString(out_frame->GetFourcc())
+                    << " is unsupported for NV12 source format.";
+        return -EINVAL;
+    }
+  } else {
+    LOGF(ERROR) << "Convert format doesn't support source format "
+                << FormatToString(in_frame.GetFourcc())
+                << "   "
+                << in_frame.GetFourcc();
+    return -EINVAL;
+  }
+}
+
+int ImageProcessor::Scale(const FrameBuffer& in_frame, FrameBuffer* out_frame, int buf_id) {
+  dump_data(dump_data_index, (unsigned char *)in_frame.GetData(), 
+                          in_frame.GetWidth(), 
+                          in_frame.GetHeight(), 
+                          in_frame.GetFourcc(),
+                          buf_id, "scale_pre");
+  if (in_frame.GetFourcc() != V4L2_PIX_FMT_YUV420) {
+    LOGF(ERROR) << "Pixel format " << FormatToString(in_frame.GetFourcc())
+                << " is unsupported.";
+    return -EINVAL;
+  }
+
+  size_t data_size = GetConvertedSize(
+      in_frame.GetFourcc(), out_frame->GetWidth(), out_frame->GetHeight());
+
+  if (out_frame->SetDataSize(data_size)) {
+    LOGF(ERROR) << "Set data size failed";
+    return -EINVAL;
+  }
+  out_frame->SetFourcc(in_frame.GetFourcc());
+
+  VLOGF(1) << "Scale image from " << in_frame.GetWidth() << "x"
+           << in_frame.GetHeight() << " to " << out_frame->GetWidth() << "x"
+           << out_frame->GetHeight();
+
+  int ret = libyuv::I420Scale(
+      in_frame.GetData(), in_frame.GetWidth(),
+      in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight(),
+      in_frame.GetWidth() / 2,
+      in_frame.GetData() + in_frame.GetWidth() * in_frame.GetHeight() * 5 / 4,
+      in_frame.GetWidth() / 2, in_frame.GetWidth(), in_frame.GetHeight(),
+      out_frame->GetData(), out_frame->GetWidth(),
+      out_frame->GetData() + out_frame->GetWidth() * out_frame->GetHeight(),
+      out_frame->GetWidth() / 2,
+      out_frame->GetData() +
+          out_frame->GetWidth() * out_frame->GetHeight() * 5 / 4,
+      out_frame->GetWidth() / 2, out_frame->GetWidth(), out_frame->GetHeight(),
+      libyuv::FilterMode::kFilterNone);
+  LOGF_IF(ERROR, ret) << "I420Scale failed: " << ret;
+
+  dump_data(dump_data_index, (unsigned char *)out_frame->GetData(), 
+                        out_frame->GetWidth(), 
+                        out_frame->GetHeight(), 
+                        out_frame->GetFourcc(),
+                        buf_id, "scale_post");
+  return ret;
+}
+
+static int YU12ToYV12(const void* yu12, void* yv12, int width, int height,
+                      int dst_stride_y, int dst_stride_uv) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return -EINVAL;
+  }
+  if (dst_stride_y < width || dst_stride_uv < width / 2) {
+    LOGF(ERROR) << "Y plane stride (" << dst_stride_y
+                << ") or U/V plane stride (" << dst_stride_uv
+                << ") is invalid for width " << width;
+    return -EINVAL;
+  }
+
+  const uint8_t* src = reinterpret_cast<const uint8_t*>(yu12);
+  uint8_t* dst = reinterpret_cast<uint8_t*>(yv12);
+  const uint8_t* u_src = src + width * height;
+  uint8_t* u_dst = dst + dst_stride_y * height + dst_stride_uv * height / 2;
+  const uint8_t* v_src = src + width * height * 5 / 4;
+  uint8_t* v_dst = dst + dst_stride_y * height;
+
+  return libyuv::I420Copy(src, width, u_src, width / 2, v_src, width / 2, dst,
+                          dst_stride_y, u_dst, dst_stride_uv, v_dst,
+                          dst_stride_uv, width, height);
+}
+
+static int YU12ToNV21(const void* yu12, void* nv21, int width, int height) {
+  if ((width % 2) || (height % 2)) {
+    LOGF(ERROR) << "Width or height is not even (" << width << " x " << height
+                << ")";
+    return -EINVAL;
+  }
+
+  const uint8_t* src = reinterpret_cast<const uint8_t*>(yu12);
+  uint8_t* dst = reinterpret_cast<uint8_t*>(nv21);
+  const uint8_t* u_src = src + width * height;
+  const uint8_t* v_src = src + width * height * 5 / 4;
+  uint8_t* vu_dst = dst + width * height;
+
+  memcpy(dst, src, width * height);
+
+  for (int i = 0; i < height / 2; i++) {
+    for (int j = 0; j < width / 2; j++) {
+      *vu_dst++ = *v_src++;
+      *vu_dst++ = *u_src++;
+    }
+  }
+  return 0;
+}
+
+static bool ConvertToJpeg(const CameraMetadata& metadata,
+                          const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+  ExifUtils utils;
+  int jpeg_quality, thumbnail_jpeg_quality;
+#if 0  
+  camera_metadata_ro_entry entry;
+
+  if (metadata.exists(ANDROID_JPEG_QUALITY)) {
+    entry = metadata.find(ANDROID_JPEG_QUALITY);
+    jpeg_quality = entry.data.u8[0];
+  } else {
+    LOGF(ERROR) << "Could not find jpeg quality in metadata, defaulting to "
+                << DEFAULT_JPEG_QUALITY;
+    jpeg_quality = DEFAULT_JPEG_QUALITY;
+  }
+  if (metadata.exists(ANDROID_JPEG_THUMBNAIL_QUALITY)) {
+    entry = metadata.find(ANDROID_JPEG_THUMBNAIL_QUALITY);
+    thumbnail_jpeg_quality = entry.data.u8[0];
+  } else {
+    thumbnail_jpeg_quality = jpeg_quality;
+  }
+#else
+  jpeg_quality = DEFAULT_JPEG_QUALITY;
+  thumbnail_jpeg_quality = DEFAULT_JPEG_QUALITY;
+#endif
+
+  if (!utils.Initialize(in_frame.GetData(), in_frame.GetWidth(),
+                        in_frame.GetHeight(), thumbnail_jpeg_quality)) {
+    LOGF(ERROR) << "ExifUtils initialization failed.";
+    return false;
+  }
+  if (!SetExifTags(metadata, &utils)) {
+    LOGF(ERROR) << "Setting Exif tags failed.";
+    return false;
+  }
+  if (!utils.GenerateApp1()) {
+    LOGF(ERROR) << "Generating APP1 segment failed.";
+    return false;
+  }
+  JpegCompressor compressor;
+  if (!compressor.CompressImage(in_frame.GetData(), in_frame.GetWidth(),
+                                in_frame.GetHeight(), jpeg_quality,
+                                utils.GetApp1Buffer(), utils.GetApp1Length())) {
+    LOGF(ERROR) << "JPEG image compression failed";
+    return false;
+  }
+  size_t buffer_length = compressor.GetCompressedImageSize();
+  if (out_frame->SetDataSize(buffer_length)) {
+    return false;
+  }
+  memcpy(out_frame->GetData(), compressor.GetCompressedImagePtr(),
+         buffer_length);
+  return true;
+}
+
+static bool SetExifTags(const CameraMetadata& metadata, ExifUtils* utils) {
+  time_t raw_time = 0;
+  struct tm time_info;
+  bool time_available = time(&raw_time) != -1;
+  localtime_r(&raw_time, &time_info);
+  if (!utils->SetDateTime(time_info)) {
+    LOGF(ERROR) << "Setting data time failed.";
+    return false;
+  }
+
+  float focal_length;
+  camera_metadata_ro_entry entry = metadata.find(ANDROID_LENS_FOCAL_LENGTH);
+  if (entry.count) {
+    focal_length = entry.data.f[0];
+  } else {
+    LOGF(ERROR) << "Cannot find focal length in metadata.";
+    return false;
+  }
+  if (!utils->SetFocalLength(
+          static_cast<uint32_t>(focal_length * kRationalPrecision),
+          kRationalPrecision)) {
+    LOGF(ERROR) << "Setting focal length failed.";
+    return false;
+  }
+
+  if (metadata.exists(ANDROID_JPEG_GPS_COORDINATES)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_COORDINATES);
+    if (entry.count < 3) {
+      LOGF(ERROR) << "Gps coordinates in metadata is not complete.";
+      return false;
+    }
+    if (!utils->SetGpsLatitude(entry.data.d[0])) {
+      LOGF(ERROR) << "Setting gps latitude failed.";
+      return false;
+    }
+    if (!utils->SetGpsLongitude(entry.data.d[1])) {
+      LOGF(ERROR) << "Setting gps longitude failed.";
+      return false;
+    }
+    if (!utils->SetGpsAltitude(entry.data.d[2])) {
+      LOGF(ERROR) << "Setting gps altitude failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_GPS_PROCESSING_METHOD)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_PROCESSING_METHOD);
+    std::string method_str(reinterpret_cast<const char*>(entry.data.u8));
+    if (!utils->SetGpsProcessingMethod(method_str)) {
+      LOGF(ERROR) << "Setting gps processing method failed.";
+      return false;
+    }
+  }
+
+  if (time_available && metadata.exists(ANDROID_JPEG_GPS_TIMESTAMP)) {
+    entry = metadata.find(ANDROID_JPEG_GPS_TIMESTAMP);
+    time_t timestamp = static_cast<time_t>(entry.data.i64[0]);
+    if (gmtime_r(&timestamp, &time_info)) {
+      if (!utils->SetGpsTimestamp(time_info)) {
+        LOGF(ERROR) << "Setting gps timestamp failed.";
+        return false;
+      }
+    } else {
+      LOGF(ERROR) << "Time tranformation failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_ORIENTATION)) {
+    entry = metadata.find(ANDROID_JPEG_ORIENTATION);
+    LOGF(ERROR) << "Hit ANDROID_JPEG_ORIENTATION: " << entry.data.i32[0];
+    if (!utils->SetOrientation(entry.data.i32[0])) {
+      LOGF(ERROR) << "Setting orientation failed.";
+      return false;
+    }
+  }
+
+  if (metadata.exists(ANDROID_JPEG_THUMBNAIL_SIZE)) {
+    entry = metadata.find(ANDROID_JPEG_THUMBNAIL_SIZE);
+    if (entry.count < 2) {
+      LOGF(ERROR) << "Thumbnail size in metadata is not complete.";
+      return false;
+    }
+    int thumbnail_width = entry.data.i32[0];
+    int thumbnail_height = entry.data.i32[1];
+    if (thumbnail_width > 0 && thumbnail_height > 0) {
+      if (!utils->SetThumbnailSize(static_cast<uint16_t>(thumbnail_width),
+                                   static_cast<uint16_t>(thumbnail_height))) {
+        LOGF(ERROR) << "Setting thumbnail size failed.";
+        return false;
+      }
+    }
+  }
+  return true;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/image_processor.h b/hardware/ntimespace/camera/arc/image_processor.h
new file mode 100644
index 0000000000..cc25eb1b84
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/image_processor.h
@@ -0,0 +1,47 @@
+/* Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef HAL_USB_IMAGE_PROCESSOR_H_
+#define HAL_USB_IMAGE_PROCESSOR_H_
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+// FourCC pixel formats (defined as V4L2_PIX_FMT_*).
+#include <linux/videodev2.h>
+// Declarations of HAL_PIXEL_FORMAT_XXX.
+#include <system/graphics.h>
+
+#include "frame_buffer.h"
+
+namespace arc {
+
+// V4L2_PIX_FMT_YVU420(YV12) in ImageProcessor has alignment requirement.
+// The stride of Y, U, and V planes should a multiple of 16 pixels.
+struct ImageProcessor {
+  // Calculate the output buffer size when converting to the specified pixel
+  // format. |fourcc| is defined as V4L2_PIX_FMT_* in linux/videodev2.h.
+  // Return 0 on error.
+  static size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height);
+
+  // Return whether this class supports the provided conversion.
+  static bool SupportsConversion(uint32_t from_fourcc, uint32_t to_fourcc);
+
+  // Convert format from |in_frame.fourcc| to |out_frame->fourcc|. Caller should
+  // fill |data|, |buffer_size|, |width|, and |height| of |out_frame|. The
+  // function will fill |out_frame->data_size|. Return non-zero error code on
+  // failure; return 0 on success.
+  static int ConvertFormat(const android::CameraMetadata& metadata,
+                           const FrameBuffer& in_frame, FrameBuffer* out_frame);
+
+  // Scale image size according to |in_frame| and |out_frame|. Only support
+  // V4L2_PIX_FMT_YUV420 format. Caller should fill |data|, |width|, |height|,
+  // and |buffer_size| of |out_frame|. The function will fill |data_size| and
+  // |fourcc| of |out_frame|.
+  static int Scale(const FrameBuffer& in_frame, FrameBuffer* out_frame, int buf_id);
+};
+
+}  // namespace arc
+
+#endif  // HAL_USB_IMAGE_PROCESSOR_H_
diff --git a/hardware/ntimespace/camera/arc/jpeg_compressor.cpp b/hardware/ntimespace/camera/arc/jpeg_compressor.cpp
new file mode 100644
index 0000000000..0a7b20bd69
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/jpeg_compressor.cpp
@@ -0,0 +1,188 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#include "arc/jpeg_compressor.h"
+
+#include <memory>
+
+#include "arc/common.h"
+
+namespace arc {
+
+// The destination manager that can access |result_buffer_| in JpegCompressor.
+struct destination_mgr {
+ public:
+  struct jpeg_destination_mgr mgr;
+  JpegCompressor* compressor;
+};
+
+JpegCompressor::JpegCompressor() {}
+
+JpegCompressor::~JpegCompressor() {}
+
+bool JpegCompressor::CompressImage(const void* image, int width, int height,
+                                   int quality, const void* app1Buffer,
+                                   unsigned int app1Size) {
+  if (width % 8 != 0 || height % 2 != 0) {
+    LOGF(ERROR) << "Image size can not be handled: " << width << "x" << height;
+    return false;
+  }
+
+  result_buffer_.clear();
+  if (!Encode(image, width, height, quality, app1Buffer, app1Size)) {
+    return false;
+  }
+  LOGF(INFO) << "Compressed JPEG: " << (width * height * 12) / 8 << "[" << width
+             << "x" << height << "] -> " << result_buffer_.size() << " bytes";
+  return true;
+}
+
+const void* JpegCompressor::GetCompressedImagePtr() {
+  return result_buffer_.data();
+}
+
+size_t JpegCompressor::GetCompressedImageSize() {
+  return result_buffer_.size();
+}
+
+void JpegCompressor::InitDestination(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  buffer.resize(kBlockSize);
+  dest->mgr.next_output_byte = &buffer[0];
+  dest->mgr.free_in_buffer = buffer.size();
+}
+
+boolean JpegCompressor::EmptyOutputBuffer(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  size_t oldsize = buffer.size();
+  buffer.resize(oldsize + kBlockSize);
+  dest->mgr.next_output_byte = &buffer[oldsize];
+  dest->mgr.free_in_buffer = kBlockSize;
+  return true;
+}
+
+void JpegCompressor::TerminateDestination(j_compress_ptr cinfo) {
+  destination_mgr* dest = reinterpret_cast<destination_mgr*>(cinfo->dest);
+  std::vector<JOCTET>& buffer = dest->compressor->result_buffer_;
+  buffer.resize(buffer.size() - dest->mgr.free_in_buffer);
+}
+
+void JpegCompressor::OutputErrorMessage(j_common_ptr cinfo) {
+  char buffer[JMSG_LENGTH_MAX];
+
+  /* Create the message */
+  (*cinfo->err->format_message)(cinfo, buffer);
+  LOGF(ERROR) << buffer;
+}
+
+bool JpegCompressor::Encode(const void* inYuv, int width, int height,
+                            int jpegQuality, const void* app1Buffer,
+                            unsigned int app1Size) {
+  jpeg_compress_struct cinfo;
+  jpeg_error_mgr jerr;
+
+  cinfo.err = jpeg_std_error(&jerr);
+  // Override output_message() to print error log with ALOGE().
+  cinfo.err->output_message = &OutputErrorMessage;
+  jpeg_create_compress(&cinfo);
+  SetJpegDestination(&cinfo);
+
+  SetJpegCompressStruct(width, height, jpegQuality, &cinfo);
+  jpeg_start_compress(&cinfo, TRUE);
+
+  if (app1Buffer != nullptr && app1Size > 0) {
+    jpeg_write_marker(&cinfo, JPEG_APP0 + 1,
+                      static_cast<const JOCTET*>(app1Buffer), app1Size);
+  }
+
+  if (!Compress(&cinfo, static_cast<const uint8_t*>(inYuv))) {
+    return false;
+  }
+  jpeg_finish_compress(&cinfo);
+  return true;
+}
+
+void JpegCompressor::SetJpegDestination(jpeg_compress_struct* cinfo) {
+  destination_mgr* dest =
+      static_cast<struct destination_mgr*>((*cinfo->mem->alloc_small)(
+          (j_common_ptr)cinfo, JPOOL_PERMANENT, sizeof(destination_mgr)));
+  dest->compressor = this;
+  dest->mgr.init_destination = &InitDestination;
+  dest->mgr.empty_output_buffer = &EmptyOutputBuffer;
+  dest->mgr.term_destination = &TerminateDestination;
+  cinfo->dest = reinterpret_cast<struct jpeg_destination_mgr*>(dest);
+}
+
+void JpegCompressor::SetJpegCompressStruct(int width, int height, int quality,
+                                           jpeg_compress_struct* cinfo) {
+  cinfo->image_width = width;
+  cinfo->image_height = height;
+  cinfo->input_components = 3;
+  cinfo->in_color_space = JCS_YCbCr;
+  jpeg_set_defaults(cinfo);
+
+  jpeg_set_quality(cinfo, quality, TRUE);
+  jpeg_set_colorspace(cinfo, JCS_YCbCr);
+  cinfo->raw_data_in = TRUE;
+  cinfo->dct_method = JDCT_IFAST;
+
+  // Configure sampling factors. The sampling factor is JPEG subsampling 420
+  // because the source format is YUV420.
+  cinfo->comp_info[0].h_samp_factor = 2;
+  cinfo->comp_info[0].v_samp_factor = 2;
+  cinfo->comp_info[1].h_samp_factor = 1;
+  cinfo->comp_info[1].v_samp_factor = 1;
+  cinfo->comp_info[2].h_samp_factor = 1;
+  cinfo->comp_info[2].v_samp_factor = 1;
+}
+
+bool JpegCompressor::Compress(jpeg_compress_struct* cinfo, const uint8_t* yuv) {
+  JSAMPROW y[kCompressBatchSize];
+  JSAMPROW cb[kCompressBatchSize / 2];
+  JSAMPROW cr[kCompressBatchSize / 2];
+  JSAMPARRAY planes[3]{y, cb, cr};
+
+  size_t y_plane_size = cinfo->image_width * cinfo->image_height;
+  size_t uv_plane_size = y_plane_size / 4;
+  uint8_t* y_plane = const_cast<uint8_t*>(yuv);
+  uint8_t* u_plane = const_cast<uint8_t*>(yuv + y_plane_size);
+  uint8_t* v_plane = const_cast<uint8_t*>(yuv + y_plane_size + uv_plane_size);
+  std::unique_ptr<uint8_t[]> empty(new uint8_t[cinfo->image_width]);
+  memset(empty.get(), 0, cinfo->image_width);
+
+  while (cinfo->next_scanline < cinfo->image_height) {
+    for (int i = 0; i < kCompressBatchSize; ++i) {
+      size_t scanline = cinfo->next_scanline + i;
+      if (scanline < cinfo->image_height) {
+        y[i] = y_plane + scanline * cinfo->image_width;
+      } else {
+        y[i] = empty.get();
+      }
+    }
+    // cb, cr only have half scanlines
+    for (int i = 0; i < kCompressBatchSize / 2; ++i) {
+      size_t scanline = cinfo->next_scanline / 2 + i;
+      if (scanline < cinfo->image_height / 2) {
+        int offset = scanline * (cinfo->image_width / 2);
+        cb[i] = u_plane + offset;
+        cr[i] = v_plane + offset;
+      } else {
+        cb[i] = cr[i] = empty.get();
+      }
+    }
+
+    int processed = jpeg_write_raw_data(cinfo, planes, kCompressBatchSize);
+    if (processed != kCompressBatchSize) {
+      LOGF(ERROR) << "Number of processed lines does not equal input lines.";
+      return false;
+    }
+  }
+  return true;
+}
+
+}  // namespace arc
diff --git a/hardware/ntimespace/camera/arc/jpeg_compressor.h b/hardware/ntimespace/camera/arc/jpeg_compressor.h
new file mode 100644
index 0000000000..499b9aaffc
--- /dev/null
+++ b/hardware/ntimespace/camera/arc/jpeg_compressor.h
@@ -0,0 +1,73 @@
+/*
+ * Copyright 2017 The Chromium OS Authors. All rights reserved.
+ * Use of this source code is governed by a BSD-style license that can be
+ * found in the LICENSE file.
+ */
+
+#ifndef INCLUDE_ARC_JPEG_COMPRESSOR_H_
+#define INCLUDE_ARC_JPEG_COMPRESSOR_H_
+
+// We must include cstdio before jpeglib.h. It is a requirement of libjpeg.
+#include <cstdio>
+#include <vector>
+
+extern "C" {
+#include <jerror.h>
+#include <jpeglib.h>
+}
+
+namespace arc {
+
+// Encapsulates a converter from YU12 to JPEG format. This class is not
+// thread-safe.
+class JpegCompressor {
+ public:
+  JpegCompressor();
+  ~JpegCompressor();
+
+  // Compresses YU12 image to JPEG format. After calling this method, call
+  // GetCompressedImagePtr() to get the image. |quality| is the resulted jpeg
+  // image quality. It ranges from 1 (poorest quality) to 100 (highest quality).
+  // |app1Buffer| is the buffer of APP1 segment (exif) which will be added to
+  // the compressed image. Returns false if errors occur during compression.
+  bool CompressImage(const void* image, int width, int height, int quality,
+                     const void* app1Buffer, unsigned int app1Size);
+
+  // Returns the compressed JPEG buffer pointer. This method must be called only
+  // after calling CompressImage().
+  const void* GetCompressedImagePtr();
+
+  // Returns the compressed JPEG buffer size. This method must be called only
+  // after calling CompressImage().
+  size_t GetCompressedImageSize();
+
+ private:
+  // InitDestination(), EmptyOutputBuffer() and TerminateDestination() are
+  // callback functions to be passed into jpeg library.
+  static void InitDestination(j_compress_ptr cinfo);
+  static boolean EmptyOutputBuffer(j_compress_ptr cinfo);
+  static void TerminateDestination(j_compress_ptr cinfo);
+  static void OutputErrorMessage(j_common_ptr cinfo);
+
+  // Returns false if errors occur.
+  bool Encode(const void* inYuv, int width, int height, int jpegQuality,
+              const void* app1Buffer, unsigned int app1Size);
+  void SetJpegDestination(jpeg_compress_struct* cinfo);
+  void SetJpegCompressStruct(int width, int height, int quality,
+                             jpeg_compress_struct* cinfo);
+  // Returns false if errors occur.
+  bool Compress(jpeg_compress_struct* cinfo, const uint8_t* yuv);
+
+  // The block size for encoded jpeg image buffer.
+  static const int kBlockSize = 16384;
+  // Process 16 lines of Y and 16 lines of U/V each time.
+  // We must pass at least 16 scanlines according to libjpeg documentation.
+  static const int kCompressBatchSize = 16;
+
+  // The buffer that holds the compressed result.
+  std::vector<JOCTET> result_buffer_;
+};
+
+}  // namespace arc
+
+#endif  // INCLUDE_ARC_JPEG_COMPRESSOR_H_
diff --git a/hardware/ntimespace/camera/camera.cpp b/hardware/ntimespace/camera/camera.cpp
new file mode 100644
index 0000000000..fae8c51fbb
--- /dev/null
+++ b/hardware/ntimespace/camera/camera.cpp
@@ -0,0 +1,643 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/Camera.cpp
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "v4l2_camera"
+
+#include "camera.h"
+
+#include <cstdlib>
+#include <memory>
+
+#include <hardware/camera3.h>
+#include <sync/sync.h>
+#include <system/camera_metadata.h>
+#include <system/graphics.h>
+#include "metadata/metadata_common.h"
+#include "static_properties.h"
+#include "flash.h"
+#include "debug.h"
+#define ATRACE_TAG (ATRACE_TAG_CAMERA | ATRACE_TAG_HAL)
+#include <utils/Trace.h>
+#define CAMERA_SYNC_TIMEOUT 5000 // in msecs
+
+namespace default_camera_hal {
+
+extern "C" {
+// Shim passed to the framework to close an opened device.
+static int close_device(hw_device_t* dev)
+{
+    camera3_device_t* cam_dev = reinterpret_cast<camera3_device_t*>(dev);
+    Camera* cam = static_cast<Camera*>(cam_dev->priv);
+    return cam->close();
+}
+} // extern "C"
+
+Camera::Camera(int id)
+  : mBusy(false),
+    mId(id),    
+    mSettingsSet(false),
+    mCallbackOps(NULL),
+    mInFlightTracker(new RequestTracker)
+{
+    memset(&mTemplates, 0, sizeof(mTemplates));
+    memset(&mDevice, 0, sizeof(mDevice));
+    mDevice.common.tag    = HARDWARE_DEVICE_TAG;
+    mDevice.common.version = CAMERA_DEVICE_API_VERSION_3_4;
+    mDevice.common.close  = close_device;
+    mDevice.ops           = const_cast<camera3_device_ops_t*>(&sOps);
+    mDevice.priv          = this;
+
+    getDebugLevel();
+}
+
+Camera::~Camera()
+{
+}
+
+int Camera::openDevice(const hw_module_t *module, hw_device_t **device)
+{
+    HAL_LOGI("%s:%d: Opening camera device", __func__, mId);
+    ATRACE_CALL();
+    getDebugLevel();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    if (mBusy) {
+        HAL_LOGE("%s:%d: Error! Camera device already opened", __func__, mId);
+        return -EBUSY;
+    }
+
+    int connectResult = connect();
+    if (connectResult != 0) {
+      return connectResult;
+    }
+    mBusy = true;
+    mDevice.common.module = const_cast<hw_module_t*>(module);
+    *device = &mDevice.common;
+
+    HAL_LOGI("%s:%d: Opening camera device done", __func__, mId);
+    
+    return 0;
+}
+
+int Camera::getInfo(struct camera_info *info)
+{
+    info->device_version = mDevice.common.version;
+    initDeviceInfo(info);
+    if (!mStaticInfo) {
+        int res = loadStaticInfo();
+        if (res) {
+            return res;
+        }
+    }
+    info->static_camera_characteristics = mStaticInfo->raw_metadata();
+    info->facing = mStaticInfo->facing();
+    info->orientation = mStaticInfo->orientation();
+
+    return 0;
+}
+
+int Camera::loadStaticInfo() {
+  // Using a lock here ensures |mStaticInfo| will only ever be set once,
+  // even in concurrent situations.
+  android::Mutex::Autolock sl(mStaticInfoLock);
+
+  if (mStaticInfo) {
+    return 0;
+  }
+
+  std::unique_ptr<android::CameraMetadata> static_metadata =
+      std::make_unique<android::CameraMetadata>();
+  int res = initStaticInfo(static_metadata.get());
+  if (res) {
+    HAL_LOGE("%s:%d: Failed to get static info from device.",
+          __func__, mId);
+    return res;
+  }
+
+  mStaticInfo.reset(StaticProperties::NewStaticProperties(
+      std::move(static_metadata)));
+  if (!mStaticInfo) {
+    HAL_LOGE("%s:%d: Failed to initialize static properties from device metadata.",
+          __func__, mId);
+    return -ENODEV;
+  }
+
+  return 0;
+}
+
+int Camera::close()   
+{     
+    HAL_LOGI("%s:%d: Closing camera device", __func__, mId);
+    ATRACE_CALL();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    if (!mBusy) {
+        HAL_LOGE("%s:%d: Error! Camera device not open", __func__, mId);
+        return -EINVAL;
+    }
+
+#if SUPPORT_FLASH    
+    if (qcamera::CameraFlash::getInstance().releaseFlashFromCamera(mId) != 0) {
+        HAL_LOGW("Failed to release flash for camera id: %d", mId);
+    }
+#endif
+
+    flush();
+    disconnect();
+    mBusy = false;
+    return 0;
+}
+
+int Camera::initialize(const camera3_callback_ops_t *callback_ops)
+{
+    HAL_LOGV("%s:%d: callback_ops=%p", __func__, mId, callback_ops);
+    mCallbackOps = callback_ops;
+    // per-device specific initialization
+    return 0;
+}
+
+int Camera::configureStreams(camera3_stream_configuration_t *stream_config)
+{
+    android::Mutex::Autolock dl(mDeviceLock);
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    HAL_LOGD("%s:%d: stream_config=%p", __func__, mId, stream_config);
+    ATRACE_CALL();
+
+    // Check that there are no in-flight requests.
+    /*
+    if (!mInFlightTracker->Empty()) {
+        HAL_LOGE("%s:%d: Can't configure streams while frames are in flight.",
+              __func__, mId);
+        return -EINVAL;
+    }
+    */
+    
+
+    // Verify the set of streams in aggregate, and perform configuration if valid.
+    int res = validateStreamConfiguration(stream_config);
+    if (res) {
+        HAL_LOGE("%s:%d: Failed to validate stream set", __func__, mId);
+    } else {
+        // Set up all streams. Since they've been validated,
+        // this should only result in fatal (-ENODEV) errors.
+        // This occurs after validation to ensure that if there
+        // is a non-fatal error, the stream configuration doesn't change states.
+        res = setupStreams(stream_config);
+        if (res) {
+            HAL_LOGE("%s:%d: Failed to setup stream set", __func__, mId);
+        }
+    }
+
+    // Set trackers based on result.
+    if (!res) {
+        // Success, set up the in-flight trackers for the new streams.
+        mInFlightTracker->SetStreamConfiguration(*stream_config);
+        // Must provide new settings for the new configuration.
+        mSettingsSet = false;
+    } else if (res != -EINVAL) {
+        // Fatal error, the old configuration is invalid.
+        mInFlightTracker->ClearStreamConfiguration();
+    }
+    // On a non-fatal error the old configuration, if any, remains valid.
+    return res;
+}
+
+int Camera::validateStreamConfiguration(
+    const camera3_stream_configuration_t* stream_config)
+{
+    // Check that the configuration is well-formed.
+    if (stream_config == nullptr) {
+        HAL_LOGE("%s:%d: NULL stream configuration array", __func__, mId);
+        return -EINVAL;
+    } else if (stream_config->num_streams == 0) {
+        HAL_LOGE("%s:%d: Empty stream configuration array", __func__, mId);
+        return -EINVAL;
+    } else if (stream_config->streams == nullptr) {
+        HAL_LOGE("%s:%d: NULL stream configuration streams", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Check that the configuration is supported.
+    // Make sure static info has been initialized before trying to use it.
+    if (!mStaticInfo) {
+        int res = loadStaticInfo();
+        if (res) {
+            return res;
+        }
+    }
+    if (!mStaticInfo->StreamConfigurationSupported(stream_config)) {
+        HAL_LOGE("%s:%d: Stream configuration does not match static "
+              "metadata restrictions.", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Dataspace support is poorly documented - unclear if the expectation
+    // is that a device supports ALL dataspaces that could match a given
+    // format. For now, defer to child class implementation.
+    // Rotation support isn't described by metadata, so must defer to device.
+    if (!validateDataspacesAndRotations(stream_config)) {
+        HAL_LOGE("%s:%d: Device can not handle configuration "
+              "dataspaces or rotations.", __func__, mId);
+        return -EINVAL;
+    }
+
+    return 0;
+}
+
+bool Camera::isValidTemplateType(int type)
+{
+    return type > 0 && type < CAMERA3_TEMPLATE_COUNT;
+}
+
+const camera_metadata_t* Camera::constructDefaultRequestSettings(int type)
+{
+    HAL_LOGV("%s:%d: type=%d", __func__, mId, type);
+
+    if (!isValidTemplateType(type)) {
+        HAL_LOGE("%s:%d: Invalid template request type: %d", __func__, mId, type);
+        return NULL;
+    }
+
+    if (!mTemplates[type]) {
+        // Check if the device has the necessary features
+        // for the requested template. If not, don't bother.
+        if (!mStaticInfo->TemplateSupported(type)) {
+            HAL_LOGW("%s:%d: Camera does not support template type %d",
+                  __func__, mId, type);
+            return NULL;
+        }
+
+        // Initialize this template if it hasn't been initialized yet.
+        std::unique_ptr<android::CameraMetadata> new_template =
+            std::make_unique<android::CameraMetadata>();
+        int res = initTemplate(type, new_template.get());
+        if (res || !new_template) {
+            HAL_LOGE("%s:%d: Failed to generate template of type: %d",
+                  __func__, mId, type);
+            return NULL;
+        }
+        mTemplates[type] = std::move(new_template);
+    }
+
+    // The "locking" here only causes non-const methods to fail,
+    // which is not a problem since the CameraMetadata being locked
+    // is already const. Destructing automatically "unlocks".
+    return mTemplates[type]->getAndLock();
+}
+
+int Camera::processCaptureRequest(camera3_capture_request_t *temp_request)
+{
+    int res;
+    // TODO(b/32917568): A capture request submitted or ongoing during a flush
+    // should be returned with an error; for now they are mutually exclusive.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    ATRACE_CALL();
+
+    if (temp_request == NULL) {
+        HAL_LOGE("stream:%d NULL request recieved", mId);
+        return -EINVAL;
+    }
+
+    // Make a persistent copy of request, since otherwise it won't live
+    // past the end of this method.
+    std::shared_ptr<CaptureRequest> request = std::make_shared<CaptureRequest>(temp_request);
+
+    HAL_LOGD("stream:%d frame: %d", mId, request->frame_number);
+    if (GetStreamStatus() == 0)
+    {
+        HAL_LOGE("stream:%d is off, can not process request", mId);
+        completeRequestWithError(request);
+        return 0;
+    }
+
+    if (!mInFlightTracker->CanAddRequest(*request)) {
+        // Streams are full or frame number is not unique.
+        HAL_LOGE("%s:%d: Can not add request.", __func__, mId);
+        return -EINVAL;
+    }
+
+    // Null/Empty indicates use last settings
+    if (request->settings.isEmpty() && !mSettingsSet) {
+        HAL_LOGE("%s:%d: NULL settings without previous set Frame:%d",
+              __func__, mId, request->frame_number);
+        return -EINVAL;
+    }
+
+    if (request->input_buffer != NULL) {
+        HAL_LOGV("%s:%d: Reprocessing input buffer %p", __func__, mId,
+              request->input_buffer.get());
+    } else {
+        HAL_LOGV("%s:%d: Capturing new frame.", __func__, mId);
+    }
+#if 0
+    if (!isValidRequestSettings(request->settings)) {
+        HAL_LOGE("%s:%d: Invalid request settings.", __func__, mId);
+        return -EINVAL;
+    }
+#endif
+    // Pre-process output buffers.
+    if (request->output_buffers.size() <= 0) {
+        HAL_LOGE("%s:%d: Invalid number of output buffers: %zu", __func__, mId,
+              request->output_buffers.size());
+        return -EINVAL;
+    }
+    for (auto& output_buffer : request->output_buffers) {
+        res = preprocessCaptureBuffer(&output_buffer);
+        if (res)
+            return -ENODEV;
+    }
+
+    // Add the request to tracking.
+    if (!mInFlightTracker->Add(request)) {
+        HAL_LOGE("%s:%d: Failed to track request for frame %d.",
+              __func__, mId, request->frame_number);
+        return -ENODEV;
+    }
+
+    // Valid settings have been provided (mSettingsSet is a misnomer;
+    // all that matters is that a previous request with valid settings
+    // has been passed to the device, not that they've been set).
+    mSettingsSet = true;
+
+    // Send the request off to the device for completion.
+    enqueueRequest(request);
+
+    // Request is now in flight. The device will call completeRequest
+    // asynchronously when it is done filling buffers and metadata.
+    return 0;
+}
+
+void Camera::completeRequest(std::shared_ptr<CaptureRequest> request, int err)
+{
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    if (!mInFlightTracker->Remove(request)) {
+        HAL_LOGE("%s:%d: Completed request %p is not being tracked. "
+              "It may have been cleared out during a flush.",
+              __func__, mId, request.get());
+        return;
+    }
+
+    // Since |request| has been removed from the tracking, this method
+    // MUST call sendResult (can still return a result in an error state, e.g.
+    // through completeRequestWithError) so the frame doesn't get lost.
+
+    if (err) {
+      HAL_LOGE("%s:%d: Error completing request for frame %d.",
+            __func__, mId, request->frame_number);
+      completeRequestWithError(request);
+      return;
+    }
+
+    // Notify the framework with the shutter time (extracted from the result).
+    int64_t timestamp = systemTime();
+    // TODO(b/31360070): The general metadata methods should be part of the
+    // default_camera_hal namespace, not the v4l2_camera_hal namespace.
+    int res = v4l2_camera_hal::SingleTagValue(
+        request->settings, ANDROID_SENSOR_TIMESTAMP, &timestamp);
+    if (res) {
+        HAL_LOGE("%s:%d: Request for frame %d is missing required metadata.",
+              __func__, mId, request->frame_number);
+        // TODO(b/31653322): Send RESULT error.
+        // For now sending REQUEST error instead.
+        completeRequestWithError(request);
+        return;
+    }
+    notifyShutter(request->frame_number, timestamp);
+
+    // TODO(b/31653322): Check all returned buffers for errors
+    // (if any, send BUFFER error).
+
+    sendResult(request);
+}
+
+int Camera::flush()
+{
+    HAL_LOGV("%s:%d: Flushing.", __func__, mId);
+    // TODO(b/32917568): Synchronization. Behave "appropriately"                                                                                                                                          
+    // (i.e. according to camera3.h) if process_capture_request()
+    // is called concurrently with this (in either order).
+    // Since the callback to completeRequest also may happen on a separate
+    // thread, this function should behave nicely concurrently with that too.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    std::set<std::shared_ptr<CaptureRequest>> requests;
+    mInFlightTracker->Clear(&requests);
+    for (auto& request : requests) {
+        // TODO(b/31653322): See camera3.h. Should return different error
+        // depending on status of the request.
+        completeRequestWithError(request);
+    }
+
+    HAL_LOGD("%s:%d: Flushed %zu requests.", __func__, mId, requests.size());
+
+    // Call down into the device flushing.
+    return flushBuffers();
+}
+
+int Camera::flush_lite()
+{
+    HAL_LOGV("%s:%d: Flushing.", __func__, mId);
+
+    // TODO(b/32917568): Synchronization. Behave "appropriately"                                                                                                                                          
+    // (i.e. according to camera3.h) if process_capture_request()
+    // is called concurrently with this (in either order).
+    // Since the callback to completeRequest also may happen on a separate
+    // thread, this function should behave nicely concurrently with that too.
+    android::Mutex::Autolock tl(mInFlightTrackerLock);
+
+    std::set<std::shared_ptr<CaptureRequest>> requests;
+    mInFlightTracker->Clear(&requests);
+    for (auto& request : requests) {
+        // TODO(b/31653322): See camera3.h. Should return different error
+        // depending on status of the request.
+        completeRequestWithError(request);
+    }
+
+    HAL_LOGD("%s:%d: Flushed %zu requests.", __func__, mId, requests.size());
+
+    return 0;
+}
+
+int Camera::preprocessCaptureBuffer(camera3_stream_buffer_t *buffer)
+{
+    int res;
+    // TODO(b/29334616): This probably should be non-blocking; part
+    // of the asynchronous request processing.
+    if (buffer->acquire_fence != -1) {
+        res = sync_wait(buffer->acquire_fence, CAMERA_SYNC_TIMEOUT);
+        if (res == -ETIME) {
+            HAL_LOGE("%s:%d: Timeout waiting on buffer acquire fence",
+                    __func__, mId);
+            return res;
+        } else if (res) {
+            HAL_LOGE("%s:%d: Error waiting on buffer acquire fence: %s(%d)",
+                    __func__, mId, strerror(-res), res);
+            return res;
+        }
+        ::close(buffer->acquire_fence);
+    }
+
+    // Acquire fence has been waited upon.
+    buffer->acquire_fence = -1;
+    // No release fence waiting unless the device sets it.
+    buffer->release_fence = -1;
+
+    buffer->status = CAMERA3_BUFFER_STATUS_OK;
+    return 0;
+}
+
+void Camera::notifyShutter(uint32_t frame_number, uint64_t timestamp)
+{
+    camera3_notify_msg_t message;
+    memset(&message, 0, sizeof(message));
+    message.type = CAMERA3_MSG_SHUTTER;
+    message.message.shutter.frame_number = frame_number;
+    message.message.shutter.timestamp = timestamp;
+    mCallbackOps->notify(mCallbackOps, &message);
+}
+
+void Camera::completeRequestWithError(std::shared_ptr<CaptureRequest> request)
+{
+    // Send an error notification.
+    camera3_notify_msg_t message;
+    memset(&message, 0, sizeof(message));
+    message.type = CAMERA3_MSG_ERROR;
+    message.message.error.frame_number = request->frame_number;
+    message.message.error.error_stream = nullptr;
+    message.message.error.error_code = CAMERA3_MSG_ERROR_REQUEST;
+    mCallbackOps->notify(mCallbackOps, &message);
+
+    // TODO(b/31856611): Ensure all the buffers indicate their error status.
+
+    // Send the errored out result.
+    sendResult(request);
+}
+
+void Camera::sendResult(std::shared_ptr<CaptureRequest> request) {
+    // Fill in the result struct
+    // (it only needs to live until the end of the framework callback).
+    camera3_capture_result_t result {
+        request->frame_number,
+        request->settings.getAndLock(),
+        static_cast<uint32_t>(request->output_buffers.size()),
+        request->output_buffers.data(),
+        request->input_buffer.get(),
+        1,  // Total result; only 1 part.
+        0,  // Number of physical camera metadata.
+        nullptr,
+        nullptr
+    };
+    // Make the framework callback.
+    mCallbackOps->process_capture_result(mCallbackOps, &result);
+
+    ShowCallbackFPS();
+
+    HAL_LOGD("send result end, frame=%d", request->frame_number);
+
+}
+
+void Camera::dump(int fd)
+{
+    HAL_LOGV("%s:%d: Dumping to fd %d", __func__, mId, fd);
+    ATRACE_CALL();
+    android::Mutex::Autolock dl(mDeviceLock);
+
+    dprintf(fd, "Camera ID: %d (Busy: %d)\n", mId, mBusy);
+
+    // TODO: dump all settings
+}
+
+const char* Camera::templateToString(int type)
+{
+    switch (type) {
+    case CAMERA3_TEMPLATE_PREVIEW:
+        return "CAMERA3_TEMPLATE_PREVIEW";
+    case CAMERA3_TEMPLATE_STILL_CAPTURE:
+        return "CAMERA3_TEMPLATE_STILL_CAPTURE";
+    case CAMERA3_TEMPLATE_VIDEO_RECORD:
+        return "CAMERA3_TEMPLATE_VIDEO_RECORD";
+    case CAMERA3_TEMPLATE_VIDEO_SNAPSHOT:
+        return "CAMERA3_TEMPLATE_VIDEO_SNAPSHOT";
+    case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+        return "CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG";
+    }
+    // TODO: support vendor templates
+    return "Invalid template type!";
+}
+
+extern "C" {
+// Get handle to camera from device priv data
+static Camera *camdev_to_camera(const camera3_device_t *dev)
+{
+    return reinterpret_cast<Camera*>(dev->priv);
+}
+
+static int initialize(const camera3_device_t *dev,
+        const camera3_callback_ops_t *callback_ops)
+{
+    return camdev_to_camera(dev)->initialize(callback_ops);
+}
+
+static int configure_streams(const camera3_device_t *dev,
+        camera3_stream_configuration_t *stream_list)
+{
+    return camdev_to_camera(dev)->configureStreams(stream_list);
+}
+
+static const camera_metadata_t *construct_default_request_settings(
+        const camera3_device_t *dev, int type)
+{
+    return camdev_to_camera(dev)->constructDefaultRequestSettings(type);
+}
+
+static int process_capture_request(const camera3_device_t *dev,
+        camera3_capture_request_t *request)
+{
+    return camdev_to_camera(dev)->processCaptureRequest(request);
+}
+
+static void dump(const camera3_device_t *dev, int fd)
+{
+    camdev_to_camera(dev)->dump(fd);
+}
+
+static int flush(const camera3_device_t *dev)
+{
+    return camdev_to_camera(dev)->flush();
+}
+
+} // extern "C"
+
+const camera3_device_ops_t Camera::sOps = {
+    .initialize = default_camera_hal::initialize,
+    .configure_streams = default_camera_hal::configure_streams,
+    .register_stream_buffers = nullptr,
+    .construct_default_request_settings
+        = default_camera_hal::construct_default_request_settings,
+    .process_capture_request = default_camera_hal::process_capture_request,
+    .get_metadata_vendor_tag_ops = nullptr,
+    .dump = default_camera_hal::dump,
+    .flush = default_camera_hal::flush,
+    .reserved = {0},
+};
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/camera.h b/hardware/ntimespace/camera/camera.h
new file mode 100644
index 0000000000..a2ab39752d
--- /dev/null
+++ b/hardware/ntimespace/camera/camera.h
@@ -0,0 +1,151 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/Camera.h
+
+#ifndef DEFAULT_CAMERA_HAL_CAMERA_H_
+#define DEFAULT_CAMERA_HAL_CAMERA_H_
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/hardware.h>
+#include <hardware/camera3.h>
+#include <utils/Mutex.h>
+
+#include "capture_request.h"
+#include "metadata/metadata.h"
+#include "request_tracker.h"
+#include "static_properties.h"
+
+namespace default_camera_hal {
+// Camera represents a physical camera on a device.
+// This is constructed when the HAL module is loaded, one per physical camera.
+// TODO(b/29185945): Support hotplugging.
+// It is opened by the framework, and must be closed before it can be opened
+// again.
+// This is an abstract class, containing all logic and data shared between all
+// camera devices (front, back, etc) and common to the ISP.
+class Camera {
+    public:
+        // id is used to distinguish cameras. 0 <= id < NUM_CAMERAS.
+        // module is a handle to the HAL module, used when the device is opened.
+        Camera(int id);
+        virtual ~Camera();
+
+        // Common Camera Device Operations (see <hardware/camera_common.h>)
+        int openDevice(const hw_module_t *module, hw_device_t **device);
+        int getInfo(struct camera_info *info);
+        int close();
+
+        // Camera v3 Device Operations (see <hardware/camera3.h>)
+        int initialize(const camera3_callback_ops_t *callback_ops);
+        int configureStreams(camera3_stream_configuration_t *stream_list);
+        const camera_metadata_t *constructDefaultRequestSettings(int type);
+        int processCaptureRequest(camera3_capture_request_t *temp_request);
+        void dump(int fd);
+        int flush();
+        int flush_lite();
+        int getCameraId() {return mId;}
+        
+    protected:
+        // Connect to the device: open dev nodes, etc.
+        virtual int connect() = 0;
+        // Disconnect from the device: close dev nodes, etc.
+        virtual void disconnect() = 0;
+        // Initialize static camera characteristics for individual device
+        virtual int initStaticInfo(android::CameraMetadata* out) = 0;
+        // Initialize a template of the given type
+        virtual int initTemplate(int type, android::CameraMetadata* out) = 0;
+        // Initialize device info: resource cost and conflicting devices
+        // (/conflicting devices length)
+        virtual void initDeviceInfo(struct camera_info *info) = 0;
+        // Separate initialization method for individual devices when opened
+        virtual int initDevice() = 0;
+        // Verify stream configuration dataspaces and rotation values
+        virtual bool validateDataspacesAndRotations(
+            const camera3_stream_configuration_t* stream_config) = 0;
+        // Set up the streams, including seting usage & max_buffers
+        virtual int setupStreams(
+            camera3_stream_configuration_t* stream_config) = 0;
+        // Verify settings are valid for a capture or reprocessing
+        virtual bool isValidRequestSettings(
+            const android::CameraMetadata& settings) = 0;
+        // Enqueue a request to receive data from the camera
+        virtual int enqueueRequest(
+            std::shared_ptr<CaptureRequest> request) = 0;
+        // Flush in flight buffers.
+        virtual int flushBuffers() = 0;
+
+        virtual int GetStreamStatus() = 0;
+
+
+        // Callback for when the device has filled in the requested data.
+        // Fills in the result struct, validates the data, sends appropriate
+        // notifications, and returns the result to the framework.
+        void completeRequest(
+            std::shared_ptr<CaptureRequest> request, int err);
+        // Prettyprint template names
+        const char* templateToString(int type);
+        // Busy flag indicates camera is in use
+        bool mBusy;
+        
+    private:
+        // Camera device handle returned to framework for use
+        camera3_device_t mDevice;
+        // Get static info from the device and store it in mStaticInfo.
+        int loadStaticInfo();
+        // Confirm that a stream configuration is valid.
+        int validateStreamConfiguration(
+            const camera3_stream_configuration_t* stream_config);
+        // Verify settings are valid for reprocessing an input buffer
+        bool isValidReprocessSettings(const camera_metadata_t *settings);
+        // Pre-process an output buffer
+        int preprocessCaptureBuffer(camera3_stream_buffer_t *buffer);
+        // Send a shutter notify message with start of exposure time
+        void notifyShutter(uint32_t frame_number, uint64_t timestamp);
+        // Send an error message and return the errored out result.
+        void completeRequestWithError(std::shared_ptr<CaptureRequest> request);
+        // Send a capture result for a request.
+        void sendResult(std::shared_ptr<CaptureRequest> request);
+        // Is type a valid template type (and valid index into mTemplates)
+        bool isValidTemplateType(int type);
+
+        // Identifier used by framework to distinguish cameras
+        const int mId;
+        // CameraMetadata containing static characteristics
+        std::unique_ptr<StaticProperties> mStaticInfo;
+        // Flag indicating if settings have been set since
+        // the last configure_streams() call.
+        bool mSettingsSet;
+
+        // Camera device operations handle shared by all devices
+        const static camera3_device_ops_t sOps;
+        // Methods used to call back into the framework
+        const camera3_callback_ops_t *mCallbackOps;
+        // Lock protecting the Camera object for modifications
+        android::Mutex mDeviceLock;
+        // Lock protecting only static camera characteristics, which may
+        // be accessed without the camera device open
+        android::Mutex mStaticInfoLock;
+        // Standard camera settings templates
+        std::unique_ptr<const android::CameraMetadata> mTemplates[CAMERA3_TEMPLATE_COUNT];
+        // Track in flight requests.
+        std::unique_ptr<RequestTracker> mInFlightTracker;
+        android::Mutex mInFlightTrackerLock;
+};
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_CAMERA_H_
diff --git a/hardware/ntimespace/camera/camera_init.rc b/hardware/ntimespace/camera/camera_init.rc
new file mode 100755
index 0000000000..fd48a34efc
--- /dev/null
+++ b/hardware/ntimespace/camera/camera_init.rc
@@ -0,0 +1,5 @@
+
+
+on property:sys.boot_completed=1
+    exec root root -- /system/bin/sh -c /system/bin/camera_init.sh
+
diff --git a/hardware/ntimespace/camera/camera_init.sh b/hardware/ntimespace/camera/camera_init.sh
new file mode 100755
index 0000000000..2356a77b48
--- /dev/null
+++ b/hardware/ntimespace/camera/camera_init.sh
@@ -0,0 +1,13 @@
+!/system/bin/sh
+
+Camera_Tid=$(getprop ro.container.container_id)
+num0=$((Camera_Tid * 2 + 100))
+num1=$((Camera_Tid * 2 + 101))
+mv /dev/video${num0} /dev/camera0
+mv /dev/video${num1} /dev/camera1
+chmod 666 /dev/camera0
+chmod 666 /dev/camera1
+ps -ef | grep -i camera | grep -v grep | grep -v camera_init | awk '{print $2}' | xargs -r kill -9
+
+
+
diff --git a/hardware/ntimespace/camera/capture_request.cpp b/hardware/ntimespace/camera/capture_request.cpp
new file mode 100644
index 0000000000..5b8e037e7d
--- /dev/null
+++ b/hardware/ntimespace/camera/capture_request.cpp
@@ -0,0 +1,54 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "capture_request.h"
+
+namespace default_camera_hal {
+
+CaptureRequest::CaptureRequest() : CaptureRequest(nullptr) {}
+
+CaptureRequest::CaptureRequest(const camera3_capture_request_t* request) {
+  if (!request) {
+    return;
+  }
+
+  frame_number = request->frame_number;
+
+  // CameraMetadata makes copies of camera_metadata_t through the
+  // assignment operator (the constructor taking a camera_metadata_t*
+  // takes ownership instead).
+  settings = request->settings;
+
+  // camera3_stream_buffer_t can be default copy constructed,
+  // as its pointer values are handles, not ownerships.
+
+  // Copy the input buffer.
+  if (request->input_buffer) {
+    input_buffer =
+        std::make_unique<camera3_stream_buffer_t>(*request->input_buffer);
+  }
+
+  // Safely copy all the output buffers.
+  uint32_t num_output_buffers = request->num_output_buffers;
+  if (/*num_output_buffers < 0 ||*/ !request->output_buffers) {
+    num_output_buffers = 0;
+  }
+  output_buffers.insert(output_buffers.end(),
+                        request->output_buffers,
+                        request->output_buffers + num_output_buffers);
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/capture_request.h b/hardware/ntimespace/camera/capture_request.h
new file mode 100644
index 0000000000..0bbd967b03
--- /dev/null
+++ b/hardware/ntimespace/camera/capture_request.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
+#define DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
+
+#include <memory>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/camera3.h>
+
+namespace default_camera_hal {
+
+// A simple wrapper for camera3_capture_request_t,
+// with a constructor that makes a deep copy from the original struct.
+struct CaptureRequest {
+  uint32_t frame_number;
+  android::CameraMetadata settings;
+  std::unique_ptr<camera3_stream_buffer_t> input_buffer;
+  std::vector<camera3_stream_buffer_t> output_buffers;
+
+  CaptureRequest();
+  // Create a deep copy of |request|.
+  CaptureRequest(const camera3_capture_request_t* request);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_CAPTURE_REQUEST_H_
diff --git a/hardware/ntimespace/camera/common.h b/hardware/ntimespace/camera/common.h
new file mode 100644
index 0000000000..9a56e6faf9
--- /dev/null
+++ b/hardware/ntimespace/camera/common.h
@@ -0,0 +1,65 @@
+/*
+ * Copyright 2015 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_COMMON_H_
+#define V4L2_CAMERA_HAL_COMMON_H_
+
+#include <log/log.h>
+extern int debug;
+#define V4L2_CAMERA_TAG "[v4l2_camera] "
+
+// Helpers of logging (showing function name and line number).
+#define HAL_LOGE(fmt, args...) do { \
+    ALOGE(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGE_IF(cond, fmt, args...) do { \
+    ALOGE_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGW(fmt, args...) do { \
+    ALOGW(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGW_IF(cond, fmt, args...) do { \
+    ALOGW_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGI(fmt, args...) do { \
+    ALOGI(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0)
+
+#define HAL_LOGI_IF(cond, fmt, args...) do { \
+    ALOGI_IF(cond, V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);  \
+  } while(0)
+
+#define HAL_LOGD(fmt, args...) if (debug >= 2) { \
+    do { \
+    ALOGD(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0); \
+  }
+
+#define HAL_LOGV(fmt, args...) if (debug >= 3) { \
+    do { \
+    ALOGV(V4L2_CAMERA_TAG"%s:%d: " fmt, __func__, __LINE__, ##args);   \
+  } while(0); \
+  }
+
+// Log enter/exit of methods.
+#define HAL_LOG_ENTER() HAL_LOGV("enter")
+#define HAL_LOG_EXIT() HAL_LOGV("exit")
+
+#endif  // V4L2_CAMERA_HAL_COMMON_H_
diff --git a/hardware/ntimespace/camera/debug.cpp b/hardware/ntimespace/camera/debug.cpp
new file mode 100644
index 0000000000..7c237c8154
--- /dev/null
+++ b/hardware/ntimespace/camera/debug.cpp
@@ -0,0 +1,316 @@
+//#define LOG_NDEBUG 0
+#define LOG_TAG "v4l2_camera"
+
+#include "debug.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <sys/time.h>
+#include "android-base/properties.h"
+#include <dlfcn.h>
+#include <utils/Timers.h>
+
+int debug = 0;
+
+uint64_t timeNanos() {
+  struct timespec spec;
+  clock_gettime(CLOCK_MONOTONIC, &spec);
+  return spec.tv_sec * 1000000000 + spec.tv_nsec;
+}
+
+uint32_t toMilliSeconds(uint64_t ns) {
+  return (uint32_t)(ns/1000000);
+}
+
+
+
+uint32_t dump_data_index;
+bool     data_dump;
+std::string  dump_data_path = "/data/local/bmp";
+
+
+int yuv_write(unsigned char *image, int imageWidth, int imageHeight, char *filename)
+{ 
+    //printf("yuv_write width %d height %d\n", imageWidth, imageHeight);
+    long file_size = (long)(imageWidth) * (long)imageHeight * 3/2;
+
+    FILE *fp;
+    if (!(fp = fopen(filename, "wb")))
+      return -1;
+ 
+    fwrite(image, sizeof(unsigned char), (size_t)(long)file_size, fp); 
+    fclose(fp);
+
+    return 0;
+}
+
+void dump_yuv(int index, unsigned char *image, int imageWidth, int imageHeight, int bufId, 
+              std::string prefix, int formatcc) {
+  data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGV("width %d height %d ", imageWidth, imageHeight);
+
+    char pc[256] = "";
+    sprintf(pc, "%s/%d_%d_%s_%s_%d_%d.yuv", dump_data_path.c_str(), index, bufId, prefix.c_str(), 
+            FormatToString(formatcc).c_str(), imageWidth, imageHeight);
+    HAL_LOGD("save_%s_yuv: %s \n ", prefix.c_str(), pc);
+    yuv_write(image, imageWidth, imageHeight, pc);
+  }
+}
+
+///////////////////////////////////////////////////////////
+int bmp_write(unsigned char *image, int imageWidth, int imageHeight, char *filename, bool padding)
+{ 
+#if 1
+    #define HEADER_SZ 54
+    /*bitmap file header(14B) + bitmap info header(40B)*/
+    unsigned char header[54] = {
+      0x42, 0x4d, 
+      0, 0, 0, 0, /*file size, LE*/
+      0, 0, 0, 0, /*reserve*/
+      54, 0, 0, 0,
+      /*bitmap info header*/
+      40, 0, 0, 0,  /*size*/
+      0, 0, 0, 0,   /*width*/
+      0, 0, 0, 0,   /*height*/
+      1, 0,         /*color plane, MUST 1*/
+      32, 0,        /*bit per pixel*/
+      0, 0, 0, 0,   /*compress methond*/
+      0, 0, 0, 0,   /*original size before compress*/
+      0, 0, 0, 0,   /*pixel per meter in width*/
+      0, 0, 0, 0,  
+      0, 0, 0, 0,  /*pattle color number*/
+      0, 0, 0, 0,
+    };
+#else
+#define BMP_HEADER 108
+#define FILE_HEADER 14
+#define HEADER_SZ (BMP_HEADER + FILE_HEADER)
+    /*bitmap file header(14B) + bitmap info header(108B)*/
+    unsigned char header[HEADER_SZ] = {
+      0x42, 0x4d, 
+      0, 0, 0, 0, /*file size, LE*/
+      0, 0, 0, 0, /*reserve*/
+      HEADER_SZ, 0, 0, 0,
+      /*bitmap info header*/
+      BMP_HEADER, 0, 0, 0,  /*size*/
+      0, 0, 0, 0,   /*width*/
+      0, 0, 0, 0,   /*height*/
+      1, 0,         /*color plane, MUST 1*/
+      32, 0,        /*bit per pixel*/
+      3, 0, 0, 0,   /*BI_BITFIELDS, no pixel array compression used*/
+      0, 0, 0, 0,   /*original size before compress*/
+      0, 0, 0, 0,   /*pixel per meter in width*/
+      0, 0, 0, 0,  
+      0, 0, 0, 0,  /*pattle color number*/
+      0, 0, 0, 0,  /*important colors*/
+      0xFF, 0, 0, 0, /*Red bitmask*/
+      0, 0xFF, 0, 0, /*Green bitmask*/
+      0, 0, 0xFF, 0, /*Blue bitmask*/
+      0, 0, 0, 0xFF, /*Alpha bitmask*/
+      0, 0, 0, 0, /*little-endian "Win "*/
+      0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,0, 0, 0, 0,
+      0, 0, 0, 0,
+      0, 0, 0, 0,
+      0, 0, 0, 0
+    };
+#endif
+    long file_size = (long)imageWidth * (long)imageHeight * 4 + HEADER_SZ;
+    header[2] = (unsigned char)(file_size &0x000000ff);
+    header[3] = (file_size >> 8) & 0x000000ff;
+    header[4] = (file_size >> 16) & 0x000000ff;
+    header[5] = (file_size >> 24) & 0x000000ff;
+ 
+    long width = imageWidth;
+    header[18] = width & 0x000000ff;
+    header[19] = (width >> 8) &0x000000ff;
+    header[20] = (width >> 16) &0x000000ff;
+    header[21] = (width >> 24) &0x000000ff;
+ 
+    long height = imageHeight;
+    header[22] = height &0x000000ff;
+    header[23] = (height >> 8) &0x000000ff;
+    header[24] = (height >> 16) &0x000000ff;
+    header[25] = (height >> 24) &0x000000ff;
+ 
+    FILE *fp;
+    if (!(fp = fopen(filename, "wb")))
+      return -1;
+
+    fwrite(header, sizeof(unsigned char), HEADER_SZ, fp);
+ #if 0    
+    fwrite(image, sizeof(unsigned char), (size_t)(long)imageWidth * imageHeight * 4, fp);
+ #else
+    int curPos = 0;
+    // BMP 存储像素数据与y轴方向相反（即，位图是底朝上的）, b/g/r
+    for (int row = imageHeight - 1; row >= 0; row--)  // 遍历所有行
+    {
+      for (int col = 0; col < imageWidth; col++)   // 遍历所有列
+      {
+          curPos = (row * imageWidth + col) * 4;
+          fwrite((unsigned char *)(image + curPos + 2), sizeof(unsigned char), 1, fp); //B
+          fwrite((unsigned char *)(image + curPos + 1), sizeof(unsigned char), 1, fp); //G
+          fwrite((unsigned char *)(image + curPos), sizeof(unsigned char), 1, fp); //R
+          fwrite((unsigned char *)(image + curPos + 3), sizeof(unsigned char), 1, fp); //A
+      }
+
+      if (padding)
+        fwrite((unsigned char *)(image + curPos + 4), sizeof(unsigned char), Align32(imageWidth) - imageWidth, fp); 
+    }    
+ #endif
+
+    fclose(fp);
+    return 0;
+}
+
+void dump_bmp(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, int bufId, 
+              std::string prefix) {
+  data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGV("width %d height %d format %d ", imageWidth, imageHeight, formatcc);
+
+    if (!access(dump_data_path.c_str(), F_OK)) {
+      mkdir(dump_data_path.c_str(), 0777);
+    }
+
+    char pc[256] = "";
+    sprintf(pc, "%s/%d_%d_%s_%s_%d_%d.bmp", dump_data_path.c_str(), index, bufId, prefix.c_str(),
+        FormatToString(formatcc).c_str(), imageWidth, imageHeight);
+    HAL_LOGD("save_%s_bmp: %s ",  prefix.c_str(), pc);
+    bmp_write(image, imageWidth, imageHeight, pc, false);
+  }
+}
+
+void dump_data_init() {
+  dump_data_index = 0;
+  bool data_dump = android::base::GetBoolProperty("camera.debug.dump", false);
+  if (data_dump) {
+    HAL_LOGE( "dump image data Flag found");  
+    if (access(dump_data_path.c_str(), F_OK) == 0) {
+      data_dump = true;
+      rmdir(dump_data_path.c_str());
+    }
+
+    mkdir(dump_data_path.c_str(), 0777);
+  }
+
+  return;
+}
+
+void dump_data(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, 
+               int bufId, std::string prefix)
+{  
+  if (image) {
+    if (formatcc == V4L2_PIX_FMT_RGB32)
+      dump_bmp(index, image, imageWidth, imageHeight, formatcc, bufId, prefix);  
+    else
+      dump_yuv(index, image, imageWidth, imageHeight, bufId, prefix, formatcc);
+  }
+}
+
+void get_gpu_pixel_alignment(){
+  int (*LINK_get_surface_pixel_alignment)();
+  uint32_t SurfaceStridePadding = 0;  
+  void * lib_surface_utils = dlopen("libadreno_utils.so", RTLD_NOW);
+  if (lib_surface_utils) {
+      *(void **)&LINK_get_surface_pixel_alignment =
+              dlsym(lib_surface_utils, "get_gpu_pixel_alignment");
+        if (LINK_get_surface_pixel_alignment) {
+            SurfaceStridePadding = LINK_get_surface_pixel_alignment();
+        }
+        dlclose(lib_surface_utils);
+  }
+
+  HAL_LOGI("%s: stride %d", __FUNCTION__, SurfaceStridePadding);
+}
+
+void getDebugLevel()
+{
+    debug = android::base::GetIntProperty("camera.debug.level", 0);
+}
+
+bool isDebug()
+{
+    return debug >= 1;
+}
+
+void ShowPreviewFPS()
+{
+    bool fps_dump = android::base::GetBoolProperty("camera.debug.fps", false);
+    if (fps_dump) {
+      static int n_pFrameCount = 0; 
+      static int n_pLastFrameCount = 0; 
+      static int64_t n_pLastFpsTime = 0; 
+      static double n_pFps = 0; 
+      n_pFrameCount++;
+      int64_t now = systemTime();
+      int64_t diff = now - n_pLastFpsTime;
+      if (diff > ms2ns(1000)) {
+          n_pFps = (double)(n_pFrameCount - n_pLastFrameCount);
+          HAL_LOGI("[fps] %.4f", n_pFps);
+          n_pLastFpsTime = now; 
+          n_pLastFrameCount = n_pFrameCount;
+      }    
+    }
+}
+
+void ShowCallbackFPS()
+{
+    bool fps_dump = android::base::GetBoolProperty("camera.debug.fps", false);
+    if (fps_dump) {
+      static int n_pFrameCount_cb = 0;
+      static int n_pLastFrameCount_cb = 0;
+      static int64_t n_pLastFpsTime_cb = 0;
+      static double n_pFps_cb = 0;
+      n_pFrameCount_cb++;
+      int64_t now = systemTime();
+      int64_t diff = now - n_pLastFpsTime_cb;
+      if (diff > ms2ns(1000)) {
+          n_pFps_cb = (double)(n_pFrameCount_cb - n_pLastFrameCount_cb);
+          HAL_LOGI("[callback fps] %.4f", n_pFps_cb);
+          n_pLastFpsTime_cb = now;
+          n_pLastFrameCount_cb = n_pFrameCount_cb;
+      }
+    }
+}
+
+int get_cpuoccupy(CPU_OCCUPY *cpust) 
+{  
+    FILE *fd;  
+    char buff[256];  
+    CPU_OCCUPY * occupy;  
+    occupy = cpust;  
+      
+    fd = fopen("/proc/stat", "r");  
+    fgets(buff, sizeof(buff), fd);  
+      
+    sscanf(buff, "%s %u %u %u %u %u %u %u", occupy->name, &occupy->user, &occupy->nice, &occupy->system, 
+      &occupy->idle, &occupy->lowait, &occupy->irq, &occupy->softirq);  
+    fclose(fd);  
+      
+    return 0;  
+}  
+  
+int cal_cpuoccupy(CPU_OCCUPY *o, CPU_OCCUPY *n)  
+{  
+    unsigned long od, nd;  
+    double cpu_use = 0;  
+      
+    od = (unsigned long)(o->user + o->nice + o->system + o->idle + o->lowait + o->irq + o->softirq); 
+    nd = (unsigned long)(n->user + n->nice + n->system + n->idle + n->lowait + n->irq + n->softirq);  
+    double sum = nd - od;  
+    double idle = n->idle - o->idle;  
+    cpu_use = 100 - idle * 100 / sum; 
+    //idle = n->user + n->system + n->nice - o->user - o->system - o->nice;  
+    return cpu_use;  
+}  
+
+void msleep(int msecs)
+{
+	const struct timespec ts = { msecs / 1000, (msecs % 1000) * 1000000L };
+	nanosleep(&ts, NULL);
+}
diff --git a/hardware/ntimespace/camera/debug.h b/hardware/ntimespace/camera/debug.h
new file mode 100644
index 0000000000..32cd5ad7c9
--- /dev/null
+++ b/hardware/ntimespace/camera/debug.h
@@ -0,0 +1,58 @@
+#ifndef V4L2_CAMERA_HAL_DEBUG_H_
+#define V4L2_CAMERA_HAL_DEBUG_H_
+
+#include <array>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <string>
+#include <vector>
+#include <android-base/unique_fd.h>
+#include "common.h"
+#include "arc/common.h"
+
+uint64_t timeNanos();
+uint32_t toMilliSeconds(uint64_t ns);
+
+
+extern uint32_t dump_data_index;
+extern bool     data_dump;
+extern std::string  dump_data_path;
+
+inline size_t Align64(size_t value) { return (value + 63) & ~63; };
+inline size_t Align32(size_t value) { return (value + 31) & ~31; };
+inline size_t Align16(size_t value) { return (value + 15) & ~15; }
+
+int bmp_write(unsigned char *image, int imageWidth, int imageHeight, char *filename, bool padding=true);
+int yuv_write(unsigned char *image, int imageWidth, int imageHeight, char *filename);
+
+void dump_data_init();
+void dump_data(int index, unsigned char *image, int imageWidth, int imageHeight, int formatcc, int bufId, 
+               std::string prefix);
+
+void get_gpu_pixel_alignment();
+void ShowPreviewFPS();
+void ShowCallbackFPS();
+bool isDebug();
+void getDebugLevel();
+
+typedef struct _CPU_OCCUPY         //定义一个cpu occupy的结构体  
+{  
+    char name[256];      //定义一个char类型的数组名name有20个元素  
+    unsigned int user; //定义一个无符号的int类型的user  
+    unsigned int nice; //定义一个无符号的int类型的nice  
+    unsigned int system;//定义一个无符号的int类型的system  
+    unsigned int idle; //定义一个无符号的int类型的idle  
+    unsigned int lowait;  
+    unsigned int irq;  
+    unsigned int softirq;  
+} CPU_OCCUPY;  
+
+int get_cpuoccupy(CPU_OCCUPY *cpust);
+int cal_cpuoccupy(CPU_OCCUPY *o, CPU_OCCUPY *n);
+
+
+void msleep(int msecs);
+
+#endif
+
diff --git a/hardware/ntimespace/camera/flash.cpp b/hardware/ntimespace/camera/flash.cpp
new file mode 100644
index 0000000000..ebeaada953
--- /dev/null
+++ b/hardware/ntimespace/camera/flash.cpp
@@ -0,0 +1,340 @@
+/* Copyright (c) 2015-2016, The Linux Foundation. All rights reserved.
+*
+* Redistribution and use in source and binary forms, with or without
+* modification, are permitted provided that the following conditions are
+* met:
+*     * Redistributions of source code must retain the above copyright
+*       notice, this list of conditions and the following disclaimer.
+*     * Redistributions in binary form must reproduce the above
+*       copyright notice, this list of conditions and the following
+*       disclaimer in the documentation and/or other materials provided
+*       with the distribution.
+*     * Neither the name of The Linux Foundation nor the names of its
+*       contributors may be used to endorse or promote products derived
+*       from this software without specific prior written permission.
+*
+* THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+* WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+* ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+* BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+* CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+* SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+* BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+* WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+* OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+* IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+*
+*/
+
+// System dependencies
+#include <stdio.h>
+#include <fcntl.h>
+
+// Camera dependencies
+#include "flash.h"
+
+
+#define STRING_LENGTH_OF_64_BIT_NUMBER 21
+
+namespace qcamera {
+
+/*===========================================================================
+ * FUNCTION   : getInstance
+ *
+ * DESCRIPTION: Get and create the CameraFlash singleton.
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash& CameraFlash::getInstance()
+{
+    static CameraFlash flashInstance;
+    return flashInstance;
+}
+
+/*===========================================================================
+ * FUNCTION   : CameraFlash
+ *
+ * DESCRIPTION: default constructor of CameraFlash
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash::CameraFlash() : m_callbacks(NULL)
+{
+    memset(&m_flashOn, 0, sizeof(m_flashOn));
+    memset(&m_cameraOpen, 0, sizeof(m_cameraOpen));
+    for (int pos = 0; pos < MM_CAMERA_MAX_NUM_SENSORS; pos++) {
+        m_flashFds[pos] = -1;
+    }
+}
+
+/*===========================================================================
+ * FUNCTION   : ~CameraFlash
+ *
+ * DESCRIPTION: deconstructor of CameraFlash
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+CameraFlash::~CameraFlash()
+{
+    for (int pos = 0; pos < MM_CAMERA_MAX_NUM_SENSORS; pos++) {
+        if (m_flashFds[pos] >= 0)
+            {
+                setFlashMode(pos, false);
+                close(m_flashFds[pos]);
+                m_flashFds[pos] = -1;
+            }
+    }
+}
+
+/*===========================================================================
+ * FUNCTION   : registerCallbacks
+ *
+ * DESCRIPTION: provide flash module with reference to callbacks to framework
+ *
+ * PARAMETERS : None
+ *
+ * RETURN     : None
+ *==========================================================================*/
+int32_t CameraFlash::registerCallbacks(
+        const camera_module_callbacks_t* callbacks)
+{
+    int32_t retVal = 0;
+    m_callbacks = callbacks;
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : initFlash
+ *
+ * DESCRIPTION: Reserve and initialize the flash unit associated with a
+ *              given camera id. This function is blocking until the
+ *              operation completes or fails. Each flash unit can be "inited"
+ *              by only one process at a time.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EBUSY   : The flash unit or the resource needed to turn on the
+ *              the flash is busy, typically because the flash is
+ *              already in use.
+ *   -EINVAL  : No flash present at camera_id.
+ *==========================================================================*/
+int32_t CameraFlash::initFlash(const int camera_id)
+{
+    int32_t retVal = 0;
+    bool hasFlash = true;
+    char flashPath[256] = "/dev/";
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        return -EINVAL;
+    }
+
+    sprintf(flashPath, "/dev/camera%d",  camera_id);
+
+    if (!hasFlash) {
+        HAL_LOGE("No flash available for camera id: %d", camera_id);
+        retVal = -ENOSYS;
+    } else if (m_cameraOpen[camera_id]) {
+        HAL_LOGE("Camera in use for camera id: %d", camera_id);
+        retVal = -EBUSY;
+    } else if (m_flashFds[camera_id] >= 0) {
+        HAL_LOGD("Flash is already inited for camera id: %d", camera_id);
+    } else {
+        m_flashFds[camera_id] = open(flashPath, O_RDONLY | O_NONBLOCK);
+
+        if (m_flashFds[camera_id] < 0) {
+            HAL_LOGE("Unable to open node '%s'", flashPath);
+            retVal = -EBUSY;
+        } 
+    }
+
+    HAL_LOGD("X, retVal = %d", retVal);
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : setFlashMode
+ *
+ * DESCRIPTION: Turn on or off the flash associated with a given handle.
+ *              This function is blocking until the operation completes or
+ *              fails.
+ *
+ * PARAMETERS :
+ *   @camera_id  : Camera id of the flash
+ *   @on         : Whether to turn flash on (true) or off (false)
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id, or it is not inited.
+ *   -EALREADY: Flash is already in requested state
+ *==========================================================================*/
+int32_t CameraFlash::setFlashMode(const int camera_id, const bool mode)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (mode == m_flashOn[camera_id]) {
+        HAL_LOGD("flash %d is already in requested state: %d",
+                camera_id,
+                mode);
+        retVal = -EALREADY;
+    } else if (m_flashFds[camera_id] < 0) {
+        HAL_LOGE("called for uninited flash: %d", camera_id);
+        retVal = -EINVAL;
+    }  else {
+        int cfg = mode ? 1 : 0;
+        retVal = ioctl(m_flashFds[camera_id], RFVIDEO_SET_FLASH_CFG, &cfg);
+        if (retVal < 0) {
+            HAL_LOGE("Unable to change flash mode to %d for camera id: %d",
+                     mode, camera_id);
+        } else
+        {
+            m_flashOn[camera_id] = mode;
+        }
+    }
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : deinitFlash
+ *
+ * DESCRIPTION: Release the flash unit associated with a given camera
+ *              position. This function is blocking until the operation
+ *              completes or fails.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *==========================================================================*/
+int32_t CameraFlash::deinitFlash(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (m_flashFds[camera_id] < 0) {
+        HAL_LOGE("called deinitFlash for uninited flash");
+        retVal = -EINVAL;
+    } else {
+        setFlashMode(camera_id, false);
+        close(m_flashFds[camera_id]);
+        m_flashFds[camera_id] = -1;
+    }
+
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : reserveFlashForCamera
+ *
+ * DESCRIPTION: Give control of the flash to the camera, and notify
+ *              framework that the flash has become unavailable.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *   -ENOSYS  : No callback available for torch_mode_status_change.
+ *==========================================================================*/
+int32_t CameraFlash::reserveFlashForCamera(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (m_cameraOpen[camera_id]) {
+        HAL_LOGD("Flash already reserved for camera id: %d", camera_id);
+    } else {
+        if (m_flashOn[camera_id]) {
+            setFlashMode(camera_id, false);
+            deinitFlash(camera_id);
+        }
+        m_cameraOpen[camera_id] = true;
+        bool hasFlash = true;
+
+        if (m_callbacks == NULL || m_callbacks->torch_mode_status_change == NULL) {
+            HAL_LOGE("Callback is not defined!");
+            retVal = -ENOSYS;
+        } else if (!hasFlash) {
+            HAL_LOGD("Suppressing callback "
+                    "because no flash exists for camera id: %d",
+                    camera_id);
+        } else {
+            char cameraIdStr[STRING_LENGTH_OF_64_BIT_NUMBER];
+            snprintf(cameraIdStr, STRING_LENGTH_OF_64_BIT_NUMBER, "%d", camera_id);
+            m_callbacks->torch_mode_status_change(m_callbacks,
+                    cameraIdStr,
+                    TORCH_MODE_STATUS_NOT_AVAILABLE);
+        }
+    }
+
+    return retVal;
+}
+
+/*===========================================================================
+ * FUNCTION   : releaseFlashFromCamera
+ *
+ * DESCRIPTION: Release control of the flash from the camera, and notify
+ *              framework that the flash has become available.
+ *
+ * PARAMETERS :
+ *   @camera_id : Camera id of the flash.
+ *
+ * RETURN     :
+ *   0        : success
+ *   -EINVAL  : No camera present at camera_id or not inited.
+ *   -ENOSYS  : No callback available for torch_mode_status_change.
+ *==========================================================================*/
+int32_t CameraFlash::releaseFlashFromCamera(const int camera_id)
+{
+    int32_t retVal = 0;
+
+    if (camera_id < 0 || camera_id >= MM_CAMERA_MAX_NUM_SENSORS) {
+        HAL_LOGE("Invalid camera id: %d", camera_id);
+        retVal = -EINVAL;
+    } else if (!m_cameraOpen[camera_id]) {
+        HAL_LOGD("Flash not reserved for camera id: %d",
+                camera_id);
+    } else {
+        m_cameraOpen[camera_id] = false;
+        bool hasFlash = true;
+
+        if (m_callbacks == NULL ||
+                m_callbacks->torch_mode_status_change == NULL) {
+            HAL_LOGE("Callback is not defined!");
+            retVal = -ENOSYS;
+        } else if (!hasFlash) {
+            HAL_LOGD("Suppressing callback "
+                    "because no flash exists for camera id: %d",
+                    camera_id);
+        } else {
+            char cameraIdStr[STRING_LENGTH_OF_64_BIT_NUMBER];
+            snprintf(cameraIdStr, STRING_LENGTH_OF_64_BIT_NUMBER, "%d", camera_id);
+            m_callbacks->torch_mode_status_change(m_callbacks, cameraIdStr,
+                    TORCH_MODE_STATUS_AVAILABLE_OFF);
+        }
+    }
+
+    return retVal;
+}
+
+}; // namespace qcamera
diff --git a/hardware/ntimespace/camera/flash.h b/hardware/ntimespace/camera/flash.h
new file mode 100644
index 0000000000..89f9216547
--- /dev/null
+++ b/hardware/ntimespace/camera/flash.h
@@ -0,0 +1,70 @@
+/* Copyright (c) 2015-2016, The Linux Foundation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions are
+ * met:
+ *     * Redistributions of source code must retain the above copyright
+ *       notice, this list of conditions and the following disclaimer.
+ *     * Redistributions in binary form must reproduce the above
+ *       copyright notice, this list of conditions and the following
+ *       disclaimer in the documentation and/or other materials provided
+ *       with the distribution.
+ *     * Neither the name of The Linux Foundation nor the names of its
+ *       contributors may be used to endorse or promote products derived
+ *       from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED "AS IS" AND ANY EXPRESS OR IMPLIED
+ * WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT
+ * ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS
+ * BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR
+ * CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF
+ * SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR
+ * BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY,
+ * WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE
+ * OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN
+ * IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ *
+ */
+
+#ifndef __CAMERA_FLASH_H__
+#define __CAMERA_FLASH_H__
+
+// Camera dependencies
+#include "hardware/camera_common.h"
+#include "v4l2_camera_hal.h"
+
+#define SUPPORT_FLASH 0
+
+
+namespace qcamera {
+
+#define RFVIDEO_SET_FLASH_CFG   0x9F0FFF02
+#define RFVIDEO_GET_FLASH_CFG	0x9F0FFF03
+
+class CameraFlash {
+public:
+    static CameraFlash& getInstance();
+
+    int32_t registerCallbacks(const camera_module_callbacks_t* callbacks);
+    int32_t initFlash(const int camera_id);
+    int32_t setFlashMode(const int camera_id, const bool on);
+    int32_t deinitFlash(const int camera_id);
+    int32_t reserveFlashForCamera(const int camera_id);
+    int32_t releaseFlashFromCamera(const int camera_id);
+
+private:
+    CameraFlash();
+    virtual ~CameraFlash();
+    CameraFlash(const CameraFlash&);
+    CameraFlash& operator=(const CameraFlash&);
+
+    const camera_module_callbacks_t *m_callbacks;
+    int32_t m_flashFds[MM_CAMERA_MAX_NUM_SENSORS];
+    bool m_flashOn[MM_CAMERA_MAX_NUM_SENSORS];
+    bool m_cameraOpen[MM_CAMERA_MAX_NUM_SENSORS];
+};
+
+}; // namespace qcamera
+
+#endif /* __CAMERA_FLASH_H__ */
diff --git a/hardware/ntimespace/camera/format_metadata_factory.cpp b/hardware/ntimespace/camera/format_metadata_factory.cpp
new file mode 100644
index 0000000000..49ce25e6ee
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory.cpp
@@ -0,0 +1,271 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "FormatMetadataFactory"
+
+#include "format_metadata_factory.h"
+
+#include <algorithm>
+#include <set>
+
+#include "arc/image_processor.h"
+#include "common.h"
+#include "metadata/array_vector.h"
+#include "metadata/partial_metadata_factory.h"
+#include "metadata/property.h"
+
+namespace v4l2_camera_hal {
+
+static int GetHalFormats(const std::shared_ptr<V4L2Wrapper>& device,
+                         std::set<int32_t>* result_formats) {
+  if (!result_formats) {
+    HAL_LOGE("Null result formats pointer passed");
+    return -EINVAL;
+  }
+
+  std::set<uint32_t> v4l2_formats;
+  int res = device->GetFormats(&v4l2_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return res;
+  }
+
+  for (auto v4l2_format : v4l2_formats) {
+    int32_t hal_format = StreamFormat::V4L2ToHalPixelFormat(v4l2_format);
+    if (hal_format < 0) {
+      // Unrecognized/unused format. Skip it.
+      continue;
+    }
+    result_formats->insert(hal_format);
+  }
+
+  return 0;
+}
+
+static int FpsRangesCompare(std::array<int32_t, 2> a,
+                            std::array<int32_t, 2> b) {
+  if (a[1] == b[1]) {
+    return a[0] > b[0];
+  }
+  return a[1] > b[1];
+}
+
+int AddFormatComponents(
+    std::shared_ptr<V4L2Wrapper> device,
+    std::insert_iterator<PartialMetadataSet> insertion_point) {
+  HAL_LOG_ENTER();
+
+  // Get all supported formats.
+  std::set<int32_t> hal_formats;
+  int res = GetHalFormats(device, &hal_formats);
+  if (res) {
+    return res;
+  }
+
+  std::set<int32_t> unsupported_hal_formats;
+  if (hal_formats.find(HAL_PIXEL_FORMAT_YCbCr_420_888) == hal_formats.end()) {
+    HAL_LOGV("YCbCr_420_888 (0x%x) not directly supported by device.",
+             HAL_PIXEL_FORMAT_YCbCr_420_888);
+    hal_formats.insert(HAL_PIXEL_FORMAT_YCbCr_420_888);
+    unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_YCbCr_420_888);
+  }
+  if (hal_formats.find(HAL_PIXEL_FORMAT_BLOB) == hal_formats.end()) {
+    HAL_LOGV("JPEG (0x%x) not directly supported by device.",
+             HAL_PIXEL_FORMAT_BLOB);
+    hal_formats.insert(HAL_PIXEL_FORMAT_BLOB);
+    unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_BLOB);
+  }
+
+  // As hal_formats is populated by reading and converting V4L2 formats to the
+  // matching HAL formats, we will never see an implementation defined format in
+  // the list. We populate it ourselves and map it to a qualified format. If no
+  // qualified formats exist, this will be the first available format.
+  hal_formats.insert(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+  unsupported_hal_formats.insert(HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED);
+
+  // Qualified formats are the set of formats supported by this camera that the
+  // image processor can translate into the YU12 format. We additionally check
+  // that the conversion from YU12 to the desired hal format is supported.
+  std::vector<uint32_t> qualified_formats;
+  res = device->GetQualifiedFormats(&qualified_formats);
+  if (res && unsupported_hal_formats.size() > 1) {
+    HAL_LOGE(
+        "Failed to retrieve qualified formats, cannot perform conversions.");
+    return res;
+  }
+
+  HAL_LOGI("Supports %zu qualified formats.", qualified_formats.size());
+
+  // Find sizes and frame/stall durations for all formats.
+  // We also want to find the smallest max frame duration amongst all formats,
+  // And the largest min frame duration amongst YUV (i.e. largest max frame rate
+  // supported by all YUV sizes).
+  // Stream configs are {format, width, height, direction} (input or output).
+  ArrayVector<int32_t, 4> stream_configs;
+  // Frame durations are {format, width, height, duration} (duration in ns).
+  ArrayVector<int64_t, 4> min_frame_durations;
+  // Stall durations are {format, width, height, duration} (duration in ns).
+  ArrayVector<int64_t, 4> stall_durations;
+  int64_t min_max_frame_duration = std::numeric_limits<int64_t>::max();
+  std::vector<std::array<int32_t, 2>> fps_ranges;
+  for (auto hal_format : hal_formats) {
+    // Get the corresponding V4L2 format.
+    uint32_t v4l2_format = StreamFormat::HalToV4L2PixelFormat(hal_format);
+    if (v4l2_format == 0) {
+      // Unrecognized/unused format. Should never happen since hal_formats
+      // came from translating a bunch of V4L2 formats above.
+      HAL_LOGE("Couldn't find V4L2 format for HAL format %d", hal_format);
+      return -ENODEV;
+    } else if (unsupported_hal_formats.find(hal_format) !=
+               unsupported_hal_formats.end()) {
+      if (hal_format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+        if (qualified_formats.size() != 0) {
+          v4l2_format = qualified_formats[0];
+        } else if (unsupported_hal_formats.size() == 1) {
+          v4l2_format = StreamFormat::HalToV4L2PixelFormat(
+              HAL_PIXEL_FORMAT_YCbCr_420_888);
+        } else {
+          // No-op. If there are no qualified formats, and implementation
+          // defined is not the only unsupported format, then other unsupported
+          // formats will throw an error.
+        }
+        HAL_LOGW(
+            "Implementation-defined format is set to V4L2 pixel format 0x%x",
+            v4l2_format);
+      } else if (qualified_formats.size() == 0) {
+        HAL_LOGE(
+            "Camera does not support required format: 0x%x, and there are no "
+            "qualified"
+            "formats to transform from.",
+            hal_format);
+        return -ENODEV;
+      } else if (!arc::ImageProcessor::SupportsConversion(V4L2_PIX_FMT_YUV420,
+                                                          v4l2_format)) {
+        HAL_LOGE(
+            "The image processor does not support conversion to required "
+            "format: 0x%x",
+            hal_format);
+        return -ENODEV;
+      } else {
+        v4l2_format = qualified_formats[0];
+        HAL_LOGW(
+            "Hal format 0x%x will be converted from V4L2 pixel format 0x%x",
+            hal_format, v4l2_format);
+      }
+    }
+
+    // Get the available sizes for this format.
+    std::set<std::array<int32_t, 2>> frame_sizes;
+    res = device->GetFormatFrameSizes(v4l2_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get all frame sizes for format %d", v4l2_format);
+      return res;
+    }
+
+    for (const auto& frame_size : frame_sizes) {
+      // Note the format and size combination in stream configs.
+      stream_configs.push_back(
+          {{hal_format,
+            frame_size[0],
+            frame_size[1],
+            ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}});
+
+      // Find the duration range for this format and size.
+      std::array<int64_t, 2> duration_range;
+      res = device->GetFormatFrameDurationRange(
+          v4l2_format, frame_size, &duration_range);
+      if (res) {
+        HAL_LOGE(
+            "Failed to get frame duration range for format %d, "
+            "size %u x %u",
+            v4l2_format,
+            frame_size[0],
+            frame_size[1]);
+        return res;
+      }
+      int64_t size_min_frame_duration = duration_range[0];
+      int64_t size_max_frame_duration = duration_range[1];
+      min_frame_durations.push_back({{hal_format,
+                                      frame_size[0],
+                                      frame_size[1],
+                                      size_min_frame_duration}});
+
+      // Note the stall duration for this format and size.
+      // Usually 0 for non-jpeg, non-zero for JPEG.
+      // Randomly choosing absurd 1 sec for JPEG. Unsure what this breaks.
+      int64_t stall_duration = 0;
+      if (hal_format == HAL_PIXEL_FORMAT_BLOB) {
+        stall_duration = 1000000000;
+      }
+      stall_durations.push_back(
+          {{hal_format, frame_size[0], frame_size[1], stall_duration}});
+
+      // Update our search for general min & max frame durations.
+      // In theory max frame duration (min frame rate) should be consistent
+      // between all formats, but we check and only advertise the smallest
+      // available max duration just in case.
+      if (size_max_frame_duration < min_max_frame_duration) {
+        min_max_frame_duration = size_max_frame_duration;
+      }
+      // ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES will contain all
+      // the fps ranges for YUV_420_888 only since YUV_420_888 format is
+      // the default camera format by Android.
+      if (hal_format == HAL_PIXEL_FORMAT_YCbCr_420_888) {
+        // Convert from frame durations measured in ns.
+        // Min, max fps supported by all YUV formats.
+        const int32_t min_fps = 1000000000 / size_max_frame_duration;
+        const int32_t max_fps = 1000000000 / size_min_frame_duration;
+        if (std::find(fps_ranges.begin(), fps_ranges.end(),
+                      std::array<int32_t, 2>{{min_fps, max_fps}}) ==
+            fps_ranges.end()) {
+          fps_ranges.push_back({{min_fps, max_fps}});
+        }
+      }
+    }
+  }
+
+  // Sort fps ranges in descending order.
+  std::sort(fps_ranges.begin(), fps_ranges.end(), FpsRangesCompare);
+
+  // Construct the metadata components.
+  insertion_point = std::make_unique<Property<ArrayVector<int32_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+      std::move(stream_configs));
+
+  insertion_point = std::make_unique<Property<ArrayVector<int64_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS,
+      std::move(min_frame_durations));
+
+  insertion_point = std::make_unique<Property<ArrayVector<int64_t, 4>>>(
+      ANDROID_SCALER_AVAILABLE_STALL_DURATIONS, std::move(stall_durations));
+
+  //HAL_LOGE("min_max_frame_duration %d", min_max_frame_duration); 
+  insertion_point = std::make_unique<Property<int64_t>>(
+      ANDROID_SENSOR_INFO_MAX_FRAME_DURATION, min_max_frame_duration);
+
+  // TODO(b/31019725): This should probably not be a NoEffect control.
+ #if 0
+  insertion_point = NoEffectMenuControl<std::array<int32_t, 2>>(
+      ANDROID_CONTROL_AE_TARGET_FPS_RANGE,
+      ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES, fps_ranges,
+      {{CAMERA3_TEMPLATE_VIDEO_RECORD, fps_ranges.front()},
+       {OTHER_TEMPLATES, fps_ranges.back()}});
+#endif
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/format_metadata_factory.h b/hardware/ntimespace/camera/format_metadata_factory.h
new file mode 100644
index 0000000000..cd25f9c281
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory.h
@@ -0,0 +1,36 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
+#define V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
+
+#include <iterator>
+#include <memory>
+
+#include "metadata/metadata_common.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A factory method to construct all the format-related
+// partial metadata for a V4L2 device.
+int AddFormatComponents(
+    std::shared_ptr<V4L2Wrapper> device,
+    std::insert_iterator<PartialMetadataSet> insertion_point);
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_FORMAT_METADATA_FACTORY_H_
diff --git a/hardware/ntimespace/camera/format_metadata_factory_test.cpp b/hardware/ntimespace/camera/format_metadata_factory_test.cpp
new file mode 100644
index 0000000000..864553dc09
--- /dev/null
+++ b/hardware/ntimespace/camera/format_metadata_factory_test.cpp
@@ -0,0 +1,198 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "format_metadata_factory.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "metadata/test_common.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::AtLeast;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class FormatMetadataFactoryTest : public Test {
+ protected:
+  virtual void SetUp() { mock_device_.reset(new V4L2WrapperMock()); }
+
+  virtual void ExpectMetadataTagCount(const android::CameraMetadata& metadata,
+                                      uint32_t tag,
+                                      size_t count) {
+    camera_metadata_ro_entry_t entry = metadata.find(tag);
+    EXPECT_EQ(entry.count, count);
+  }
+
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+};
+
+TEST_F(FormatMetadataFactoryTest, GetFormatMetadata) {
+  std::set<uint32_t> formats{V4L2_PIX_FMT_JPEG, V4L2_PIX_FMT_YUV420,
+                             V4L2_PIX_FMT_YUYV};
+  std::map<uint32_t, std::set<std::array<int32_t, 2>>> sizes{
+      {V4L2_PIX_FMT_JPEG, {{{10, 20}}, {{30, 60}}, {{120, 240}}}},
+      {V4L2_PIX_FMT_YUV420, {{{1, 2}}, {{3, 6}}, {{12, 24}}}},
+      {V4L2_PIX_FMT_YUYV, {{{20, 40}}, {{80, 160}}, {{320, 640}}}}};
+  // These need to be on the correct order of magnitude,
+  // as there is a check for min fps > 15.
+  std::map<uint32_t, std::map<std::array<int32_t, 2>, std::array<int64_t, 2>>>
+      durations{{V4L2_PIX_FMT_JPEG,
+                 {{{{10, 20}}, {{100000000, 200000000}}},
+                  {{{30, 60}}, {{1000000000, 2000000000}}},
+                  {{{120, 240}}, {{700000000, 1200000000}}}}},
+                {V4L2_PIX_FMT_YUV420,
+                 {{{{1, 2}}, {{10000000000, 20000000000}}},
+                  {{{3, 6}}, {{11000000000, 21000000000}}},
+                  {{{12, 24}}, {{10500000000, 19000000000}}}}},
+                {V4L2_PIX_FMT_YUYV,
+                 {{{{20, 40}}, {{11000000000, 22000000000}}},
+                  {{{80, 160}}, {{13000000000, 25000000000}}},
+                  {{{320, 640}}, {{10100000000, 19000000000}}}}}};
+  // The camera must report at least one qualified format.
+  std::vector<uint32_t> qualified_formats = {V4L2_PIX_FMT_YUYV};
+
+  // Device must support IMPLEMENTATION_DEFINED (as well as JPEG & YUV).
+  // For USB cameras, we assume that this format will not be present, and it
+  // will default to a qualified format or one of the other required formats.
+
+  EXPECT_CALL(*mock_device_, GetFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(formats), Return(0)));
+
+  EXPECT_CALL(*mock_device_, GetQualifiedFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(qualified_formats), Return(0)));
+
+  for (auto format : formats) {
+    std::set<std::array<int32_t, 2>> format_sizes = sizes[format];
+    EXPECT_CALL(*mock_device_, GetFormatFrameSizes(format, _))
+        .Times(AtLeast(1))
+        .WillRepeatedly(DoAll(SetArgPointee<1>(format_sizes), Return(0)));
+    for (auto size : format_sizes) {
+      EXPECT_CALL(*mock_device_, GetFormatFrameDurationRange(format, size, _))
+          .Times(AtLeast(1))
+          .WillRepeatedly(
+              DoAll(SetArgPointee<2>(durations[format][size]), Return(0)));
+    }
+  }
+
+  PartialMetadataSet components;
+  ASSERT_EQ(AddFormatComponents(mock_device_,
+                                std::inserter(components, components.end())),
+            0);
+
+  for (auto& component : components) {
+    android::CameraMetadata metadata;
+    component->PopulateStaticFields(&metadata);
+    ASSERT_EQ(metadata.entryCount(), 1u);
+    int32_t tag = component->StaticTags()[0];
+    switch (tag) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS:  // Fall through.
+      case ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS:    // Fall through.
+      case ANDROID_SCALER_AVAILABLE_STALL_DURATIONS:        // Fall through.
+        // 3 sizes per format, 4 elements per config.
+        // # formats + 1 for IMPLEMENTATION_DEFINED.
+        ExpectMetadataTagCount(metadata, tag, (formats.size() + 1) * 3 * 4);
+        break;
+      case ANDROID_SENSOR_INFO_MAX_FRAME_DURATION:
+        // The lowest max duration from above.
+        ExpectMetadataEq(metadata, tag, 200000000);
+        break;
+      case ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES:
+        // 2 ranges ({min, max} and {max, max}), each with a min and max.
+        ExpectMetadataTagCount(metadata, tag, 4);
+        break;
+      default:
+        FAIL() << "Unexpected component created.";
+        break;
+    }
+  }
+}
+
+TEST_F(FormatMetadataFactoryTest, GetFormatMetadataMissingRequired) {
+  std::set<uint32_t> formats{V4L2_PIX_FMT_YUYV};
+  std::map<uint32_t, std::set<std::array<int32_t, 2>>> sizes{
+      {V4L2_PIX_FMT_YUYV, {{{640, 480}}, {{320, 240}}}}};
+  std::map<uint32_t, std::map<std::array<int32_t, 2>, std::array<int64_t, 2>>>
+      durations{{V4L2_PIX_FMT_YUYV,
+                 {{{{640, 480}}, {{100000000, 200000000}}},
+                  {{{320, 240}}, {{100000000, 200000000}}}}}};
+
+  EXPECT_CALL(*mock_device_, GetFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(formats), Return(0)));
+  // If a qualified format is present, we expect that required fields are
+  // populated as if they are supported.
+  std::vector<uint32_t> qualified_formats = {V4L2_PIX_FMT_YUYV};
+
+  EXPECT_CALL(*mock_device_, GetQualifiedFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(qualified_formats), Return(0)));
+
+  for (auto format : formats) {
+    std::set<std::array<int32_t, 2>> format_sizes = sizes[format];
+    EXPECT_CALL(*mock_device_, GetFormatFrameSizes(format, _))
+        .Times(AtLeast(1))
+        .WillRepeatedly(DoAll(SetArgPointee<1>(format_sizes), Return(0)));
+    for (auto size : format_sizes) {
+      EXPECT_CALL(*mock_device_, GetFormatFrameDurationRange(format, size, _))
+          .Times(AtLeast(1))
+          .WillRepeatedly(
+              DoAll(SetArgPointee<2>(durations[format][size]), Return(0)));
+    }
+  }
+
+  // Check that all required formats are present.
+  PartialMetadataSet components;
+  ASSERT_EQ(AddFormatComponents(mock_device_,
+                                std::inserter(components, components.end())),
+            0);
+
+  std::vector<std::array<int32_t, 2>> target_fps_ranges{{{5, 10}}, {{10, 10}}};
+  for (auto& component : components) {
+    android::CameraMetadata metadata;
+    component->PopulateStaticFields(&metadata);
+    ASSERT_EQ(metadata.entryCount(), 1u);
+    int32_t tag = component->StaticTags()[0];
+    switch (tag) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS:  // Fall through.
+      case ANDROID_SCALER_AVAILABLE_MIN_FRAME_DURATIONS:    // Fall through.
+      case ANDROID_SCALER_AVAILABLE_STALL_DURATIONS:        // Fall through.
+        // Two sizes per format, four elements per config.
+        // # formats + 3 for YUV420, JPEG, IMPLEMENTATION_DEFINED.
+        ExpectMetadataTagCount(metadata, tag, (formats.size() + 3) * 2 * 4);
+        break;
+      case ANDROID_SENSOR_INFO_MAX_FRAME_DURATION:
+        // The lowest max duration from above.
+        ExpectMetadataEq(metadata, tag, 200000000);
+        break;
+      case ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES:
+        // 2 ranges ({min, max} and {max, max}), each with a min and max.
+        ExpectMetadataTagCount(metadata, tag, 4);
+        ExpectMetadataEq(metadata, tag, target_fps_ranges);
+        break;
+      default:
+        FAIL() << "Unexpected component created.";
+        break;
+    }
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/function_thread.h b/hardware/ntimespace/camera/function_thread.h
new file mode 100644
index 0000000000..44bf061821
--- /dev/null
+++ b/hardware/ntimespace/camera/function_thread.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
+#define V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
+
+#include <functional>
+
+#include <utils/Thread.h>
+
+namespace v4l2_camera_hal {
+
+class FunctionThread : public android::Thread {
+ public:
+  FunctionThread(std::function<bool()> function) : function_(function){};
+
+ private:
+  bool threadLoop() override {
+    bool result = function_();
+    return result;
+  };
+
+  std::function<bool()> function_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_FUNCTION_THREAD_H_
diff --git a/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp b/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
new file mode 100644
index 0000000000..f19cb6eccf
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/gralloc3_impl.cpp
@@ -0,0 +1,317 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#define LOG_TAG "HandleImporter"
+#include "gralloc3_impl.h"
+#include <log/log.h>
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+
+using MapperErrorV2 = android::hardware::graphics::mapper::V2_0::Error;
+using MapperErrorV3 = android::hardware::graphics::mapper::V3_0::Error;
+using IMapperV3 = android::hardware::graphics::mapper::V3_0::IMapper;
+
+HandleImporter::HandleImporter() : mInitialized(false) {}
+
+void HandleImporter::initializeLocked() {
+    if (mInitialized) {
+        return;
+    }
+
+    mMapperV3 = IMapperV3::getService();
+    if (mMapperV3 != nullptr) {
+        mInitialized = true;
+        return;
+    }
+
+    mMapperV2 = IMapper::getService();
+    if (mMapperV2 == nullptr) {
+        ALOGE("%s: cannnot acccess graphics mapper HAL!", __FUNCTION__);
+        return;
+    }
+
+    mInitialized = true;
+    return;
+}
+
+void HandleImporter::cleanup() {
+    mMapperV3.clear();
+    mMapperV2.clear();
+    mInitialized = false;
+}
+
+template<class M, class E>
+bool HandleImporter::importBufferInternal(const sp<M> mapper, buffer_handle_t& handle, buffer_handle_t& outhandle) {
+    E error;
+    buffer_handle_t importedHandle;
+    auto ret = mapper->importBuffer(
+        hidl_handle(handle),
+        [&](const auto& tmpError, const auto& tmpBufferHandle) {
+            error = tmpError;
+            importedHandle = static_cast<buffer_handle_t>(tmpBufferHandle);
+        });
+
+    if (!ret.isOk()) {
+        ALOGE("%s: mapper importBuffer failed: %s",
+                __FUNCTION__, ret.description().c_str());
+        return false;
+    }
+
+    if (error != E::NONE) {
+        return false;
+    }
+
+    handle = importedHandle;  
+    outhandle = importedHandle;
+    return true;
+}
+
+template<class M, class E>
+YCbCrLayout HandleImporter::lockYCbCrInternal(const sp<M> mapper, buffer_handle_t& buf,
+        uint64_t cpuUsage, const IMapper::Rect& accessRegion) {
+    hidl_handle acquireFenceHandle;
+    auto buffer = const_cast<native_handle_t*>(buf);
+    YCbCrLayout layout = {};
+
+    typename M::Rect accessRegionCopy = {accessRegion.left, accessRegion.top,
+            accessRegion.width, accessRegion.height};
+    mapper->lockYCbCr(buffer, cpuUsage, accessRegionCopy, acquireFenceHandle,
+            [&](const auto& tmpError, const auto& tmpLayout) {
+                if (tmpError == E::NONE) {
+                    // Member by member copy from different versions of YCbCrLayout.
+                    layout.y = tmpLayout.y;
+                    layout.cb = tmpLayout.cb;
+                    layout.cr = tmpLayout.cr;
+                    layout.yStride = tmpLayout.yStride;
+                    layout.cStride = tmpLayout.cStride;
+                    layout.chromaStep = tmpLayout.chromaStep;
+                } else {
+                    ALOGE("%s: failed to lockYCbCr error %d!", __FUNCTION__, tmpError);
+                }
+           });
+
+
+
+
+
+
+
+
+
+
+
+    return layout;
+}
+
+template<class M, class E>
+int HandleImporter::unlockInternal(const sp<M> mapper, buffer_handle_t& buf) {
+    int releaseFence = -1;
+    auto buffer = const_cast<native_handle_t*>(buf);
+
+    mapper->unlock(
+        buffer, [&](const auto& tmpError, const auto& tmpReleaseFence) {
+            if (tmpError == E::NONE) {
+                auto fenceHandle = tmpReleaseFence.getNativeHandle();
+                if (fenceHandle) {
+                    if (fenceHandle->numInts != 0 || fenceHandle->numFds != 1) {
+                        ALOGE("%s: bad release fence numInts %d numFds %d",
+                                __FUNCTION__, fenceHandle->numInts, fenceHandle->numFds);
+                        return;
+                    }
+                    releaseFence = dup(fenceHandle->data[0]);
+                    if (releaseFence < 0) {
+                        ALOGE("%s: bad release fence FD %d",
+                                __FUNCTION__, releaseFence);
+                    }
+                }
+            } else {
+                ALOGE("%s: failed to unlock error %d!", __FUNCTION__, tmpError);
+            }
+        });
+    return releaseFence;
+}
+
+// In IComposer, any buffer_handle_t is owned by the caller and we need to
+// make a clone for hwcomposer2.  We also need to translate empty handle
+// to nullptr.  This function does that, in-place.
+bool HandleImporter::importBuffer(buffer_handle_t& handle, buffer_handle_t& outhandle) {
+    if (!handle->numFds && !handle->numInts) {
+        handle = nullptr;
+        return true;
+    }
+
+    Mutex::Autolock lock(mLock);
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    if (mMapperV3 != nullptr) {
+        return importBufferInternal<IMapperV3, MapperErrorV3>(mMapperV3, handle, outhandle);
+    }
+
+    if (mMapperV2 != nullptr) {
+        return importBufferInternal<IMapper, MapperErrorV2>(mMapperV2, handle, outhandle);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return false;
+}
+
+void HandleImporter::freeBuffer(buffer_handle_t handle) {
+    if (!handle) {
+        return;
+    }
+
+    Mutex::Autolock lock(mLock);
+    if (mMapperV3 == nullptr && mMapperV2 == nullptr) {
+        ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+        return;
+        }
+
+    if (mMapperV3 != nullptr) {
+        auto ret = mMapperV3->freeBuffer(const_cast<native_handle_t*>(handle));
+        if (!ret.isOk()) {
+            ALOGE("%s: mapper freeBuffer failed: %s",
+                    __FUNCTION__, ret.description().c_str());
+        }
+    } else {
+        auto ret = mMapperV2->freeBuffer(const_cast<native_handle_t*>(handle));
+        if (!ret.isOk()) {
+            ALOGE("%s: mapper freeBuffer failed: %s",
+                    __FUNCTION__, ret.description().c_str());
+        }
+    }
+}
+
+bool HandleImporter::importFence(const native_handle_t* handle, int& fd) const {
+    if (handle == nullptr || handle->numFds == 0) {
+        fd = -1;
+    } else if (handle->numFds == 1) {
+        fd = dup(handle->data[0]);
+        if (fd < 0) {
+            ALOGE("failed to dup fence fd %d", handle->data[0]);
+            return false;
+        }
+    } else {
+        ALOGE("invalid fence handle with %d file descriptors",
+                handle->numFds);
+        return false;
+    }
+
+    return true;
+}
+
+void HandleImporter::closeFence(int fd) const {
+    if (fd >= 0) {
+        close(fd);
+    }
+}
+
+void* HandleImporter::lock(buffer_handle_t& buf, uint64_t cpuUsage,
+                           const IMapper::Rect& accessRegion) {
+    Mutex::Autolock lock(mLock);
+
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    void* ret = nullptr;
+
+    if (mMapperV3 == nullptr && mMapperV2 == nullptr) {
+        ALOGE("%s: mMapperV3 and mMapperV2 are all null!", __FUNCTION__);
+        return ret;
+    }
+
+    hidl_handle acquireFenceHandle; 
+    auto buffer = const_cast<native_handle_t*>(buf);
+    if (mMapperV3 != nullptr) {
+        IMapperV3::Rect accessRegionV3{accessRegion.left, accessRegion.top, accessRegion.width,
+                                       accessRegion.height};
+
+        mMapperV3->lock(buffer, cpuUsage, accessRegionV3, acquireFenceHandle,
+                        [&](const auto& tmpError, const auto& tmpPtr, const auto& /*bytesPerPixel*/,
+                            const auto& /*bytesPerStride*/) {
+                            if (tmpError == MapperErrorV3::NONE) {
+                                ret = tmpPtr;
+                            } else {
+                                ALOGE("%s: failed to lock error %d!", __FUNCTION__, tmpError);
+                            }
+                        });
+    } else {
+        mMapperV2->lock(buffer, cpuUsage, accessRegion, acquireFenceHandle,
+                [&](const auto& tmpError, const auto& tmpPtr) {
+                    if (tmpError == MapperErrorV2::NONE) {
+                        ret = tmpPtr;
+                    } else {
+                        ALOGE("%s: failed to lock error %d!", __FUNCTION__, tmpError);
+                    }
+               });
+    }
+
+    ALOGV("%s: ptr %p accessRegion.top: %d accessRegion.left: %d accessRegion.width: %d "
+          "accessRegion.height: %d",
+          __FUNCTION__, ret, accessRegion.top, accessRegion.left, accessRegion.width,
+          accessRegion.height);
+    return ret;
+}
+
+YCbCrLayout HandleImporter::lockYCbCr(
+        buffer_handle_t& buf, uint64_t cpuUsage,
+        const IMapper::Rect& accessRegion) {
+    Mutex::Autolock lock(mLock);
+
+    if (!mInitialized) {
+        initializeLocked();
+    }
+
+    if (mMapperV3 != nullptr) {
+        return lockYCbCrInternal<IMapperV3, MapperErrorV3>(
+                mMapperV3, buf, cpuUsage, accessRegion);
+    }
+
+    if (mMapperV2 != nullptr) {
+        return lockYCbCrInternal<IMapper, MapperErrorV2>(
+                mMapperV2, buf, cpuUsage, accessRegion);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return {};
+}
+
+
+int HandleImporter::unlock(buffer_handle_t& buf) {
+    if (mMapperV3 != nullptr) {
+        return unlockInternal<IMapperV3, MapperErrorV3>(mMapperV3, buf);
+    }
+    if (mMapperV2 != nullptr) {
+        return unlockInternal<IMapper, MapperErrorV2>(mMapperV2, buf);
+    }
+
+    ALOGE("%s: mMapperV3 and mMapperV2 are both null!", __FUNCTION__);
+    return -1;
+}
+
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+} // namespace android
diff --git a/hardware/ntimespace/camera/gralloc/gralloc3_impl.h b/hardware/ntimespace/camera/gralloc/gralloc3_impl.h
new file mode 100644
index 0000000000..9406c8bf39
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/gralloc3_impl.h
@@ -0,0 +1,84 @@
+/*
+ * Copyright (C) 2017 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef CAMERA_COMMON_1_0_HANDLEIMPORTED_H
+#define CAMERA_COMMON_1_0_HANDLEIMPORTED_H
+
+#include <utils/Mutex.h>
+#include <android/hardware/graphics/mapper/2.0/IMapper.h>
+#include <android/hardware/graphics/mapper/3.0/IMapper.h>
+#include <cutils/native_handle.h>
+
+using android::hardware::graphics::mapper::V2_0::IMapper;
+using android::hardware::graphics::mapper::V2_0::YCbCrLayout;
+
+namespace android {
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+
+// Borrowed from graphics HAL. Use this until gralloc mapper HAL is working
+class HandleImporter {
+public:
+    HandleImporter();
+
+    // In IComposer, any buffer_handle_t is owned by the caller and we need to
+    // make a clone for hwcomposer2.  We also need to translate empty handle
+    // to nullptr.  This function does that, in-place.
+    bool importBuffer(buffer_handle_t& handle, buffer_handle_t& outhandle);
+    void freeBuffer(buffer_handle_t handle);
+    bool importFence(const native_handle_t* handle, int& fd) const;
+    void closeFence(int fd) const;
+
+    // Assume caller has done waiting for acquire fences
+    void* lock(buffer_handle_t& buf, uint64_t cpuUsage,
+                           const IMapper::Rect& accessRegion);
+
+    // Assume caller has done waiting for acquire fences
+    YCbCrLayout lockYCbCr(buffer_handle_t& buf, uint64_t cpuUsage,
+                          const IMapper::Rect& accessRegion);
+
+
+    int unlock(buffer_handle_t& buf); // returns release fence
+
+private:
+    void initializeLocked();
+    void cleanup();
+
+    template<class M, class E>
+    bool importBufferInternal(const sp<M> mapper, buffer_handle_t& handle, buffer_handle_t& outhandle);
+    template<class M, class E>
+    YCbCrLayout lockYCbCrInternal(const sp<M> mapper, buffer_handle_t& buf, uint64_t cpuUsage,
+            const IMapper::Rect& accessRegion);
+    template<class M, class E>
+    int unlockInternal(const sp<M> mapper, buffer_handle_t& buf);
+
+    Mutex mLock;
+    bool mInitialized;
+    sp<IMapper> mMapperV2;
+    sp<graphics::mapper::V3_0::IMapper> mMapperV3;
+};
+
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+} // namespace android
+
+#endif // CAMERA_COMMON_1_0_HANDLEIMPORTED_H
diff --git a/hardware/ntimespace/camera/gralloc/hal_public.h b/hardware/ntimespace/camera/gralloc/hal_public.h
new file mode 100644
index 0000000000..19910c10f7
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/hal_public.h
@@ -0,0 +1,215 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef HAL_PUBLIC_H
+#define HAL_PUBLIC_H
+
+#define PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE
+#define PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2
+
+#include "img_gralloc_common_public.h"
+
+/* Extension pixel formats used by Intel components */
+
+#undef  HAL_PIXEL_FORMAT_NV12
+
+#define HAL_PIXEL_FORMAT_UYVY                 0x107
+#define HAL_PIXEL_FORMAT_INTEL_YV12           0x108
+#define HAL_PIXEL_FORMAT_INTEL_ZSL            0x109
+#define HAL_PIXEL_FORMAT_NV12                 0x3231564E
+#define HAL_PIXEL_FORMAT_NV21                 0x3132564E
+#define HAL_PIXEL_FORMAT_I420                 0x30323449
+#define HAL_PIXEL_FORMAT_YUY2                 0x32595559
+#define HAL_PIXEL_FORMAT_NV12_VED             0x7FA00E00
+#define HAL_PIXEL_FORMAT_NV12_VEDT            0x7FA00F00
+
+/* Extension API used by Intel components */
+
+#define GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG  108
+#define GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG  109
+
+#define GRALLOC_GET_DISPLAY_DEVICE_IMG        1000
+#define GRALLOC_GET_DISPLAY_STATUS_IMG        1001
+
+#include "img_gralloc.h"
+#include "img_gralloc1.h"
+
+typedef const gralloc_module_t gralloc0_t;
+typedef gralloc1_device_t      gralloc1_t;
+
+static inline int gralloc_is_v1_img(const hw_module_t *m)
+{
+	return ((m->module_api_version >> 8) & 0xff) == 1;
+}
+
+static inline int gralloc_open_img(const hw_device_t **d)
+{
+	const hw_module_t *m;
+	int err;
+
+	err = hw_get_module(GRALLOC_HARDWARE_MODULE_ID, &m);
+	if (err)
+		return err;
+
+	if (gralloc_is_v1_img(m))
+		return gralloc1_open(m, (gralloc1_t **)d);
+	else
+		return gralloc_open(m, (alloc_device_t **)d);
+}
+
+static inline int gralloc_close_img(const hw_device_t *d)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_close((gralloc1_t *)d);
+	else
+		return gralloc_close((alloc_device_t *)d);
+}
+
+static inline int gralloc_register_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_register_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_register_img((gralloc0_t *)d->module, handle);
+}
+
+static inline int gralloc_unregister_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_unregister_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_unregister_img((gralloc0_t *)d->module, handle);
+}
+
+static inline int gralloc_device_alloc_img
+	(const hw_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	if (gralloc_is_v1_img(d->module)) {
+		usage = (usage | ((usage & 0x33) << 1)) & ~0x11;
+		return gralloc1_device_alloc_img((gralloc1_t *)d, w, h, format,
+										 usage, handle, stride);
+	} else
+		return gralloc0_device_alloc_img((alloc_device_t *)d, w, h, format,
+										 usage, handle, stride);
+}
+
+static inline int gralloc_device_free_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_device_free_img((gralloc1_t *)d, handle);
+	else
+		return gralloc0_device_free_img((alloc_device_t *)d, handle);
+}
+
+static inline int gralloc_lock_async_img
+	(const hw_device_t *d, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	if (gralloc_is_v1_img(d->module)) {
+		usage = (usage | ((usage & 0x33) << 1)) & ~0x11;
+		return gralloc1_lock_async_img((gralloc1_t *)d,
+									   handle, usage, r, vaddr, acquireFence);
+	} else
+		return gralloc0_lock_async_img((gralloc0_t *)d->module,
+									   handle, usage, r, vaddr, acquireFence);
+}
+
+static inline int gralloc_unlock_async_img
+	(const hw_device_t *d, buffer_handle_t handle, int *releaseFence)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_unlock_async_img((gralloc1_t *)d,
+										 handle, releaseFence);
+	else
+		return gralloc0_unlock_async_img((gralloc0_t *)d->module,
+										 handle, releaseFence);
+}
+
+static inline int gralloc_blit_handle_to_handle_img
+	(const hw_device_t *d, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_blit_handle_to_handle_img((gralloc1_t *)d,
+												  src, dest, w, h, x, y,
+												  transform, input_fence,
+												  output_fence);
+	else
+		return gralloc0_blit_handle_to_handle_img((gralloc0_t *)d->module,
+												  src, dest, w, h, x, y,
+												  transform, input_fence,
+												  output_fence);
+}
+
+
+static inline int gralloc_get_buffer_cpu_addresses_img
+	(const hw_device_t *d, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_buffer_cpu_addresses_img((gralloc1_t *)d,
+													 handle, vaddrs, sizes);
+	else
+		return gralloc0_get_buffer_cpu_addresses_img((gralloc0_t *)d->module,
+													 handle, vaddrs, sizes);
+}
+
+static inline int gralloc_put_buffer_cpu_addresses_img
+	(const hw_device_t *d, buffer_handle_t handle)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_put_buffer_cpu_addresses_img((gralloc1_t *)d,
+													 handle);
+	else
+		return gralloc0_put_buffer_cpu_addresses_img((gralloc0_t *)d->module,
+													 handle);
+}
+
+static inline int gralloc_get_display_device_img
+	(const hw_device_t *d, void **ppvDispDev)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_display_device_img((gralloc1_t *)d,
+											   ppvDispDev);
+	else
+		return gralloc0_get_display_device_img((gralloc0_t *)d->module,
+											   ppvDispDev);
+}
+
+static inline int gralloc_get_display_status_img
+	(const hw_device_t *d, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	if (gralloc_is_v1_img(d->module))
+		return gralloc1_get_display_status_img((gralloc1_t *)d,
+											   handle, pui32Status);
+	else
+		return gralloc0_get_display_status_img((gralloc0_t *)d->module,
+											   handle, pui32Status);
+}
+
+#endif /* HAL_PUBLIC_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc.h b/hardware/ntimespace/camera/gralloc/img_gralloc.h
new file mode 100644
index 0000000000..d9560fa83b
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc.h
@@ -0,0 +1,107 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC_H
+#define IMG_GRALLOC_H
+
+#include <hardware/gralloc.h>
+
+/* for gralloc1_rect_t */
+#include <hardware/gralloc1.h>
+
+static inline int gralloc0_register_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->registerBuffer(g, handle);
+}
+
+static inline int gralloc0_unregister_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->unregisterBuffer(g, handle);
+}
+
+static inline int gralloc0_device_alloc_img
+	(alloc_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	return d->alloc(d, w, h, format, usage, handle, stride);
+}
+
+static inline int gralloc0_device_free_img
+	(alloc_device_t *d, buffer_handle_t handle)
+{
+	return d->free(d, handle);
+}
+
+static inline int gralloc0_lock_async_img
+	(const gralloc_module_t *g, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	return g->lockAsync(g, handle, usage,
+						r->left, r->top, r->width, r->height,
+						vaddr, acquireFence);
+}
+
+static inline int gralloc0_unlock_async_img
+	(const gralloc_module_t *g, buffer_handle_t handle, int *releaseFence)
+{
+	return g->unlockAsync(g, handle, releaseFence);
+}
+
+static inline int gralloc0_blit_handle_to_handle_img
+	(const gralloc_module_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	return g->perform(g, GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG, src, dest, w, h,
+					  x, y, transform, input_fence, output_fence);
+}
+
+static inline int gralloc0_get_buffer_cpu_addresses_img
+	(const gralloc_module_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	return g->perform(g, GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG, handle, vaddrs,
+					  sizes);
+}
+
+static inline int gralloc0_put_buffer_cpu_addresses_img
+	(const gralloc_module_t *g, buffer_handle_t handle)
+{
+	return g->perform(g, GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG, handle);
+}
+
+static inline int gralloc0_get_display_device_img
+	(const gralloc_module_t *g, void **ppvDispDev)
+{
+	return g->perform(g, GRALLOC_GET_DISPLAY_DEVICE_IMG, ppvDispDev);
+}
+
+static inline int gralloc0_get_display_status_img
+	(const gralloc_module_t *g, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	return g->perform(g, GRALLOC_GET_DISPLAY_STATUS_IMG, handle, pui32Status);
+}
+
+#endif /* IMG_GRALLOC_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc1.h b/hardware/ntimespace/camera/gralloc/img_gralloc1.h
new file mode 100644
index 0000000000..5e7659a6a0
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc1.h
@@ -0,0 +1,305 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC1_H
+#define IMG_GRALLOC1_H
+
+#include <hardware/gralloc1.h>
+
+#include <stdlib.h>
+
+#define GRALLOC1_FUNCTION_IMG_EXT_OFF 1000
+
+enum
+{
+	GRALLOC1_FUNCTION_BLIT_HANDLE_TO_HANDLE_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG),
+	GRALLOC1_FUNCTION_GET_BUFFER_CPU_ADDRESSES_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_BUFFER_CPU_ADDRESSES_IMG),
+	GRALLOC1_FUNCTION_PUT_BUFFER_CPU_ADDRESSES_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_PUT_BUFFER_CPU_ADDRESSES_IMG),
+	GRALLOC1_FUNCTION_GET_DISPLAY_DEVICE_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_DISPLAY_DEVICE_IMG),
+	GRALLOC1_FUNCTION_GET_DISPLAY_STATUS_IMG =
+		(GRALLOC1_FUNCTION_IMG_EXT_OFF + GRALLOC_GET_DISPLAY_STATUS_IMG),
+};
+
+static inline int gralloc1_register_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_RETAIN f =
+		(GRALLOC1_PFN_RETAIN)
+			g->getFunction(g, GRALLOC1_FUNCTION_RETAIN);
+	int32_t err;
+
+	err = f(g, handle);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			return -EAGAIN;
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_unregister_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_RELEASE f =
+		(GRALLOC1_PFN_RELEASE)
+			g->getFunction(g, GRALLOC1_FUNCTION_RELEASE);
+	int32_t err;
+
+	err = f(g, handle);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_device_alloc_img
+	(gralloc1_device_t *d, int w, int h, int format, int usage,
+	 buffer_handle_t *handle, int *stride)
+{
+	GRALLOC1_PFN_ALLOCATE allocate =
+		(GRALLOC1_PFN_ALLOCATE)
+			d->getFunction(d, GRALLOC1_FUNCTION_ALLOCATE);
+	GRALLOC1_PFN_CREATE_DESCRIPTOR createDescriptor =
+		(GRALLOC1_PFN_CREATE_DESCRIPTOR)
+			d->getFunction(d, GRALLOC1_FUNCTION_CREATE_DESCRIPTOR);
+	GRALLOC1_PFN_DESTROY_DESCRIPTOR destroyDescriptor =
+		(GRALLOC1_PFN_DESTROY_DESCRIPTOR)
+			d->getFunction(d, GRALLOC1_FUNCTION_DESTROY_DESCRIPTOR);
+	GRALLOC1_PFN_SET_CONSUMER_USAGE setConsumerUsage =
+		(GRALLOC1_PFN_SET_CONSUMER_USAGE)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_CONSUMER_USAGE);
+	GRALLOC1_PFN_SET_DIMENSIONS setDimensions =
+		(GRALLOC1_PFN_SET_DIMENSIONS)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_DIMENSIONS);
+	GRALLOC1_PFN_SET_FORMAT setFormat =
+		(GRALLOC1_PFN_SET_FORMAT)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_FORMAT);
+	GRALLOC1_PFN_SET_PRODUCER_USAGE setProducerUsage =
+		(GRALLOC1_PFN_SET_PRODUCER_USAGE)
+			d->getFunction(d, GRALLOC1_FUNCTION_SET_PRODUCER_USAGE);
+	GRALLOC1_PFN_GET_STRIDE getStride =
+		(GRALLOC1_PFN_GET_STRIDE)
+			d->getFunction(d, GRALLOC1_FUNCTION_GET_STRIDE);
+	uint64_t producerUsage =
+		(usage & (GRALLOC1_PRODUCER_USAGE_CPU_READ_OFTEN    |
+		          GRALLOC1_PRODUCER_USAGE_CPU_WRITE_OFTEN   |
+		          GRALLOC1_PRODUCER_USAGE_GPU_RENDER_TARGET |
+		          GRALLOC1_PRODUCER_USAGE_PROTECTED         |
+		          GRALLOC1_PRODUCER_USAGE_CAMERA            |
+		          GRALLOC1_PRODUCER_USAGE_VIDEO_DECODER));
+	uint64_t consumerUsage =
+		(usage & (GRALLOC1_CONSUMER_USAGE_CPU_READ_OFTEN    |
+		          GRALLOC1_CONSUMER_USAGE_GPU_TEXTURE       |
+		          GRALLOC1_CONSUMER_USAGE_HWCOMPOSER        |
+		          GRALLOC1_CONSUMER_USAGE_CLIENT_TARGET     |
+		          GRALLOC1_CONSUMER_USAGE_CURSOR            |
+		          GRALLOC1_CONSUMER_USAGE_VIDEO_ENCODER     |
+		          GRALLOC1_CONSUMER_USAGE_CAMERA            |
+		          GRALLOC1_CONSUMER_USAGE_RENDERSCRIPT));
+	gralloc1_buffer_descriptor_t descriptor;
+	uint32_t stride32;
+	int err = -EINVAL;
+	int32_t err32;
+
+	err32 = createDescriptor(d, &descriptor);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_out;
+
+	err32 = setDimensions(d, descriptor, w, h);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setFormat(d, descriptor, format);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setConsumerUsage(d, descriptor, consumerUsage);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = setProducerUsage(d, descriptor, producerUsage);
+	if (err32 != GRALLOC1_ERROR_NONE)
+		goto err_destroy_descriptor;
+
+	err32 = allocate(d, 1, &descriptor, handle);
+	switch (err32)
+	{
+		case GRALLOC1_ERROR_NOT_SHARED:
+		case GRALLOC1_ERROR_NONE:
+			break;
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			err = -EAGAIN;
+			goto err_destroy_descriptor;
+			break;			
+		default:
+			goto err_destroy_descriptor;
+	}
+
+	err32 = getStride(d, *handle, &stride32);
+	if (err32 != GRALLOC1_ERROR_NONE)
+	{
+		gralloc1_unregister_img(d, *handle);
+		goto err_destroy_descriptor;
+	}
+
+	*stride = (int)stride32;
+	err = 0;
+err_destroy_descriptor:
+	destroyDescriptor(d, descriptor);
+err_out:
+	return err;
+}
+
+static inline int gralloc1_device_free_img
+	(gralloc1_device_t *d, buffer_handle_t handle)
+{
+	return gralloc1_unregister_img(d, handle);
+}
+
+static inline int gralloc1_lock_async_img
+	(gralloc1_device_t *g, buffer_handle_t handle, int usage,
+	 const gralloc1_rect_t *r, void **vaddr, int acquireFence)
+{
+	GRALLOC1_PFN_LOCK f =
+		(GRALLOC1_PFN_LOCK)
+			g->getFunction(g, GRALLOC1_FUNCTION_LOCK);
+	uint64_t producerUsage =
+		(usage & (GRALLOC1_PRODUCER_USAGE_CPU_READ_OFTEN |
+		          GRALLOC1_PRODUCER_USAGE_CPU_WRITE_OFTEN));
+	uint64_t consumerUsage =
+		(usage &  GRALLOC1_CONSUMER_USAGE_CPU_READ_OFTEN);
+	int32_t err;
+
+	err = f(g, handle, producerUsage, consumerUsage, r, vaddr, acquireFence);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			return 0;
+		case GRALLOC1_ERROR_NO_RESOURCES:
+			return -EAGAIN;
+		default:
+			return -EINVAL;
+	}
+}
+
+static inline int gralloc1_unlock_async_img
+	(gralloc1_device_t *g, buffer_handle_t handle, int *releaseFence)
+{
+	GRALLOC1_PFN_UNLOCK f =
+		(GRALLOC1_PFN_UNLOCK)
+			g->getFunction(g, GRALLOC1_FUNCTION_UNLOCK);
+	int32_t err, releaseFence32;
+
+	err = f(g, handle, &releaseFence32);
+	switch (err)
+	{
+		case GRALLOC1_ERROR_NONE:
+			*releaseFence = releaseFence32;
+			return 0;
+		default:
+			return -EINVAL;
+	}
+}
+
+typedef int (*GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG)
+	(gralloc1_device_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence);
+
+static inline int gralloc1_blit_handle_to_handle_img
+	(gralloc1_device_t *g, buffer_handle_t src, buffer_handle_t dest,
+	 int w, int h, int x, int y, int transform, int input_fence,
+	 int *output_fence)
+{
+	GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG f =
+		(GRALLOC1_PFN_BLIT_HANDLE_TO_HANDLE_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_BLIT_HANDLE_TO_HANDLE_IMG);
+
+	return f(g, src, dest, w, h, x, y, transform, input_fence, output_fence);
+}
+
+typedef int (*GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes);
+
+static inline int gralloc1_get_buffer_cpu_addresses_img
+	(gralloc1_device_t *g, buffer_handle_t handle, void **vaddrs,
+	 size_t *sizes)
+{
+	GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG f =
+		(GRALLOC1_PFN_GET_BUFFER_CPU_ADDRESSES_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_BUFFER_CPU_ADDRESSES_IMG);
+
+	return f(g, handle, vaddrs, sizes);
+}
+
+typedef int (*GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle);
+
+static inline int gralloc1_put_buffer_cpu_addresses_img
+	(gralloc1_device_t *g, buffer_handle_t handle)
+{
+	GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG f =
+		(GRALLOC1_PFN_PUT_BUFFER_CPU_ADDRESSES_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_PUT_BUFFER_CPU_ADDRESSES_IMG);
+
+	return f(g, handle);
+}
+
+typedef int (*GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG)
+	(gralloc1_device_t *g, void **ppvDispDev);
+
+static inline int gralloc1_get_display_device_img
+	(gralloc1_device_t *g, void **ppvDispDev)
+{
+	GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG f =
+		(GRALLOC1_PFN_GET_DISPLAY_DEVICE_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_DISPLAY_DEVICE_IMG);
+
+	return f(g, ppvDispDev);
+}
+
+typedef int (*GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG)
+	(gralloc1_device_t *g, buffer_handle_t handle, uint32_t *pui32Status);
+
+static inline int gralloc1_get_display_status_img
+	(gralloc1_device_t *g, buffer_handle_t handle, uint32_t *pui32Status)
+{
+	GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG f =
+		(GRALLOC1_PFN_GET_DISPLAY_STATUS_IMG)
+			g->getFunction(g, GRALLOC1_FUNCTION_GET_DISPLAY_STATUS_IMG);
+
+	return f(g, handle, pui32Status);
+}
+
+#endif /* IMG_GRALLOC1_H */
diff --git a/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h b/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
new file mode 100644
index 0000000000..98f7e24117
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/img_gralloc_common_public.h
@@ -0,0 +1,370 @@
+/* Copyright (c) Imagination Technologies Ltd.
+ *
+ * The contents of this file are subject to the MIT license as set out below.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the "Software"), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in
+ * all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN
+ * THE SOFTWARE.
+ */
+
+#ifndef IMG_GRALLOC_COMMON_PUBLIC_H
+#define IMG_GRALLOC_COMMON_PUBLIC_H
+
+#include <cutils/native_handle.h>
+#include <system/graphics.h>
+#include <linux/ion.h>
+
+#define ALIGN(x,a)	((((x) + (a) - 1L) / (a)) * (a))
+#define HW_ALIGN	32
+
+/* Use bits [0-3] of "vendor format" bits as real format. Customers should
+ * use *only* the unassigned bits below for custom pixel formats, YUV or RGB.
+ *
+ * If there are no bits set in this part of the field, or other bits are set
+ * in the format outside of the "vendor format" mask, the non-extension format
+ * is used instead. Reserve 0 for this purpose.
+ */
+
+#define HAL_PIXEL_FORMAT_VENDOR_EXT(fmt) (0x100 | (fmt & 0xF))
+
+/*      Reserved ** DO NOT USE **    HAL_PIXEL_FORMAT_VENDOR_EXT(0) */
+#define HAL_PIXEL_FORMAT_BGRX_8888   HAL_PIXEL_FORMAT_VENDOR_EXT(1)
+#define HAL_PIXEL_FORMAT_sBGR_A_8888 HAL_PIXEL_FORMAT_VENDOR_EXT(2)
+#define HAL_PIXEL_FORMAT_sBGR_X_8888 HAL_PIXEL_FORMAT_VENDOR_EXT(3)
+/*      HAL_PIXEL_FORMAT_RGB_565     HAL_PIXEL_FORMAT_VENDOR_EXT(4) */
+/*      HAL_PIXEL_FORMAT_BGRA_8888   HAL_PIXEL_FORMAT_VENDOR_EXT(5) */
+#define HAL_PIXEL_FORMAT_NV12        HAL_PIXEL_FORMAT_VENDOR_EXT(6)
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(7) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(8) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(9) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(10) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(11) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(12) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(13) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(14) */
+/*      Free for customer use        HAL_PIXEL_FORMAT_VENDOR_EXT(15) */
+
+/* One of the below compression modes is OR'ed into bits [4-6] of the 8 bit
+ * "vendor format" field. If no bits are set in this "compression mask", the
+ * normal memory format for the pixel format is used. Otherwise the pixel
+ * data will be compressed in memory with the Rogue framebuffer compressor.
+ */
+
+#define HAL_FB_COMPRESSION_NONE                0
+#define HAL_FB_COMPRESSION_DIRECT_8x8          1
+#define HAL_FB_COMPRESSION_DIRECT_16x4         2
+#define HAL_FB_COMPRESSION_DIRECT_32x2         3
+#define HAL_FB_COMPRESSION_INDIRECT_8x8        4
+#define HAL_FB_COMPRESSION_INDIRECT_16x4       5
+#define HAL_FB_COMPRESSION_INDIRECT_4TILE_8x8  6
+#define HAL_FB_COMPRESSION_INDIRECT_4TILE_16x4 7
+
+/* The memory layout is OR'ed into bit 7 (top bit) of the 8 bit "vendor
+ * format" field. Only STRIDED and TWIDDLED are supported; there is no space
+ * for PAGETILED.
+ */
+#define HAL_FB_MEMLAYOUT_STRIDED               0
+#define HAL_FB_MEMLAYOUT_TWIDDLED              1
+
+/* This can be tuned down as appropriate for the SOC.
+ *
+ * IMG formats are usually a single sub-alloc.
+ * Some OEM video formats are two sub-allocs (Y, UV planes).
+ * Future OEM video formats might be three sub-allocs (Y, U, V planes).
+ */
+#define MAX_SUB_ALLOCS (3)
+
+typedef struct
+{
+	native_handle_t base;
+
+	/* These fields can be sent cross process. They are also valid
+	 * to duplicate within the same process.
+	 *
+	 * A table is stored within the gralloc implementation's private data
+	 * structure (which is per-process) which maps stamps to a mapped
+	 * PVRSRV_MEMDESC in that process. Each map entry has a lock count
+	 * associated with it, satisfying the requirements of the gralloc API.
+	 * This also prevents us from leaking maps/allocations.
+	 */
+
+#define IMG_NATIVE_HANDLE_NUMFDS (MAX_SUB_ALLOCS)
+	/* The `fd' field is used to "export" a meminfo to another process. */
+	int fd[IMG_NATIVE_HANDLE_NUMFDS];
+
+	/* This define should represent the number of packed 'int's required to
+	 * represent the fields following it. If you add a data type that is
+	 * 64-bit, for example using 'unsigned long long', you should write that
+	 * as "sizeof(unsigned long long) / sizeof(int)". Please keep the order
+	 * of the additions the same as the defined field order.
+	 */
+#define IMG_NATIVE_HANDLE_NUMINTS \
+	(sizeof(unsigned long long) / sizeof(int) + \
+	 6 + MAX_SUB_ALLOCS + MAX_SUB_ALLOCS + \
+	 sizeof(unsigned long long) / sizeof(int) * MAX_SUB_ALLOCS + \
+	 1)
+	/* A KERNEL unique identifier for any exported kernel memdesc. Each
+	 * exported kernel memdesc will have a unique stamp, but note that in
+	 * userspace, several memdescs across multiple processes could have
+	 * the same stamp. As the native_handle can be dup(2)'d, there could be
+	 * multiple handles with the same stamp but different file descriptors.
+	 */
+	unsigned long long ui64Stamp;
+
+	/* This is used for buffer usage validation */
+	int usage;
+
+	/* In order to do efficient cache flushes we need the buffer dimensions,
+	 * format and bits per pixel. There are ANativeWindow queries for the
+	 * width, height and format, but the graphics HAL might have remapped the
+	 * request to different values at allocation time. These are the 'true'
+	 * values of the buffer allocation.
+	 */
+	int iWidth;
+	int iHeight;
+	int iFormat;
+	unsigned int uiBpp;
+
+	/* Planes are not the same as the `fd' suballocs. A multi-planar YUV
+	 * allocation has different planes (interleaved = 1, semi-planar = 2,
+	 * fully-planar = 3) but might be spread across 1, 2 or 3 independent
+	 * memory allocations (or not).
+	 */
+	int iPlanes;
+
+	/* For multi-planar allocations, there will be multiple hstrides */
+	int aiStride[MAX_SUB_ALLOCS];
+
+	/* For multi-planar allocations, there will be multiple vstrides */
+	int aiVStride[MAX_SUB_ALLOCS];
+
+	/* These byte offsets are reconciled with the number of sub-allocs used
+	 * for a multi-planar allocation. If there is a 1:1 mapping between the
+	 * number of planes and the number of sub-allocs, these will all be zero.
+	 *
+	 * Otherwise, normally the zeroth entry will be zero, and the latter
+	 * entries will be non-zero.
+	 */
+	unsigned long long aulPlaneOffset[MAX_SUB_ALLOCS];
+
+	/* This records the number of MAX_SUB_ALLOCS fds actually used by the
+	 * buffer allocation. File descriptors up to fd[iNumSubAllocs - 1] are
+	 * guaranteed to be valid. (This does not have any bearing on the aiStride,
+	 * aiVStride or aulPlaneOffset fields, as `iPlanes' of those arrays should
+	 * be initialized, not `iNumSubAllocs'.)
+	 */
+	int iNumSubAllocs;
+}
+__attribute__((aligned(sizeof(int)),packed)) IMG_native_handle_t;
+
+/* Channel encoding of buffer data.
+ *
+ * If the buffer has only one plane, the ENCODING bits should be interpreted
+ * as a definition of the interleaving pattern. Only two of the possible four
+ * permutations are defined; this is because the YVYU and VYUY patterns are
+ * not seen in the wild.
+ *
+ * If the buffer has more than one plane, the ENCODING bits should be
+ * interpreted as a definition of the plane order in memory. Assuming a YUV
+ * format, Y is always first, but U and V may be defined in 'V then U' or
+ * 'U then V' orders.
+ *
+ * Some bits are not used, to maximize compatibility with older DDKs which
+ * used them in semantically different ways.
+ */
+#define IMG_BFF_ENCODING_MASK                (3 << 0)
+/* For uiPlanes == 1 **********************************/
+/*   Reserved for VYUY (check IsYUV if used) (0 << 0) */
+#define IMG_BFF_ENCODING_INTERLEAVED_YUYV    (1 << 0)
+/*   Reserved for YVYU                       (2 << 0) */
+#define IMG_BFF_ENCODING_INTERLEAVED_UYVY    (3 << 0)
+/* For uiPlanes > 1 ***********************************/
+/*   Unused (check IsYUV if used)            (0 << 0) */
+#define IMG_BFF_ENCODING_VUCrCb              (1 << 0)
+/*   Unused                                  (2 << 0) */
+#define IMG_BFF_ENCODING_UVCbCr              (3 << 0)
+
+/* Whether the buffer should be cleared to zero from userspace, or via the
+ * PowerVR services at import time. This is deprecated functionality as most
+ * platforms use dma-buf or ion now, and for security reasons these allocators
+ * should never return uncleared memory.
+ */
+#define IMG_BFF_CPU_CLEAR                    (1 << 2)
+
+/* Deprecated, do not use */
+#define IMG_BFF_DONT_GPU_CLEAR               (1 << 3)
+
+/* Deprecated, do not use */
+#define IMG_BFF_PARTIAL_ALLOC                (1 << 4)
+
+/* Guarantee that GPU framebuffer compression is never used for buffers in
+ * this format, even if the format is supported by the compressor. This might
+ * be useful if the buffer is being fed to hardware blocks that cannot handle
+ * the framebuffer compression encoding, and the existing HAL overrides are
+ * not sufficiently expressive.
+ */
+#define IMG_BFF_NEVER_COMPRESS               (1 << 5)
+
+/* Indicates that the buffer should be mapped into the GPU 'tiling range'
+ * heaps, rather than the 'linear' general heap. This implies that the raw
+ * buffer data is tiled in physical memory. (The GPU BIF will de-tile it, so
+ * this is distinct from 'tiled texture' support.) The graphics HAL will
+ * select the correct 'tiling range' based on the buffer dimensions.
+ */
+#define IMG_BFF_BIFTILED                     (1 << 6)
+
+/* YUV subsampling encoding of buffer data.
+ * Many YUV formats have less chroma information than luma information. If
+ * this is not the case, use SUBSAMPLING_4_4_4. If each of the U and V channel
+ * data are 1/4 the size of the Y channel data, use SUBSAMPLING_4_2_0.
+ * Otherwise, use SUBSAMPLING_4_2_2.
+ */
+#define IMG_BFF_YUV_SUBSAMPLING_MASK         (3 << 7)
+#define IMG_BFF_YUV_SUBSAMPLING_4_2_0        (0 << 7)
+/* Unused: 4:1:1, 4:2:1, 4:1:0, 3:1:1?       (1 << 7) */
+#define IMG_BFF_YUV_SUBSAMPLING_4_2_2        (2 << 7)
+#define IMG_BFF_YUV_SUBSAMPLING_4_4_4        (3 << 7)
+
+/* Backwards compatibility */
+#define IMG_BFF_YUV             IMG_BFF_ENCODING_VUCrCb
+#define IMG_BFF_UVCbCrORDERING  IMG_BFF_ENCODING_UVCbCr
+
+/* Keep this in sync with SGX */
+typedef struct IMG_buffer_format_public_t
+{
+	/* Buffer formats are returned as a linked list */
+	struct IMG_buffer_format_public_t *psNext;
+
+	/* HAL_PIXEL_FORMAT_... enumerant */
+	int iHalPixelFormat;
+
+	/* IMG_PIXFMT_... enumerant */
+	int iIMGPixelFormat;
+
+	/* Friendly name for format */
+	const char *const szName;
+
+	/* Bits (not bytes) per pixel */
+	unsigned int uiBpp;
+
+	/* Supported HW usage bits. If this is GRALLOC_USAGE_HW_MASK, all usages
+	 * are supported. Used for HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED.
+	 */
+	int iSupportedUsage;
+
+	/* Allocation description flags */
+	unsigned int uiFlags;
+}
+IMG_buffer_format_public_t;
+
+typedef int ion_user_handle_t;
+
+typedef struct
+{
+	enum
+	{
+		IMG_BUFFER_HANDLE_TYPE_ION    = 0,
+		IMG_BUFFER_HANDLE_TYPE_DMABUF = 1,
+	}
+	eType;
+
+	union
+	{
+		ion_user_handle_t aiIonUserHandle[MAX_SUB_ALLOCS];
+		int aiDmaBufShareFd[MAX_SUB_ALLOCS];
+	};
+}
+IMG_buffer_handle_t;
+
+/* Public extensions, common to v0 and v1 HALs */
+
+#define GRALLOC_GET_BUFFER_FORMAT_IMG     1
+#define GRALLOC_GET_BUFFER_FORMATS_IMG    2
+#define GRALLOC_BLIT_HANDLE_TO_HANDLE_IMG 3
+#define GRALLOC_BLIT_STAMP_TO_HANDLE_IMG  4
+#define GRALLOC_SET_DATA_SPACE_IMG        5
+#define GRALLOC_GET_ION_CLIENT_IMG        6
+#define GRALLOC_GET_BUFFER_HANDLE_IMG     7
+
+#if !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE)
+
+enum
+{
+	HAL_DATASPACE_SRGB_LINEAR         = 0x200,
+	HAL_DATASPACE_SRGB                = 0x201,
+	HAL_DATASPACE_BT601_625           = 0x102,
+	HAL_DATASPACE_BT601_525           = 0x103,
+	HAL_DATASPACE_BT709               = 0x104,
+};
+
+#endif /* !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE) */
+
+#if !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2)
+
+enum
+{
+	HAL_DATASPACE_STANDARD_SHIFT      = 16,
+	HAL_DATASPACE_TRANSFER_SHIFT      = 22,
+	HAL_DATASPACE_RANGE_SHIFT         = 27,
+
+	HAL_DATASPACE_STANDARD_BT2020     = 6 << HAL_DATASPACE_STANDARD_SHIFT,
+
+	HAL_DATASPACE_TRANSFER_SMPTE_170M = 3 << HAL_DATASPACE_TRANSFER_SHIFT,
+
+	HAL_DATASPACE_RANGE_MASK          = 7 << HAL_DATASPACE_RANGE_SHIFT,
+	HAL_DATASPACE_RANGE_FULL          = 1 << HAL_DATASPACE_RANGE_SHIFT,
+	HAL_DATASPACE_RANGE_LIMITED       = 2 << HAL_DATASPACE_RANGE_SHIFT,
+};
+
+#endif /* !defined(PVR_ANDROID_HAS_SET_BUFFERS_DATASPACE_2) */
+
+/* We want to add BT.2020 and 'full range' versions of the existing dataspace
+ * enums. These are extensions, so define a new android_dataspace_ext_t.
+ * If you only have an android_dataspace_t, you can simply cast it.
+ */
+typedef enum
+{
+	/* Identical to upstream enum android_dataspace */
+	HAL_DATASPACE_EXT_UNKNOWN         = HAL_DATASPACE_UNKNOWN,
+	HAL_DATASPACE_EXT_SRGB_LINEAR     = HAL_DATASPACE_SRGB_LINEAR,
+	HAL_DATASPACE_EXT_SRGB            = HAL_DATASPACE_SRGB,
+	HAL_DATASPACE_EXT_BT601_625       = HAL_DATASPACE_BT601_625,
+	HAL_DATASPACE_EXT_BT601_525       = HAL_DATASPACE_BT601_525,
+	HAL_DATASPACE_EXT_BT709           = HAL_DATASPACE_BT709,
+
+	/* IMG extension for BT.2020 support */
+	HAL_DATASPACE_EXT_BT2020          = HAL_DATASPACE_STANDARD_BT2020     |
+	                                    HAL_DATASPACE_TRANSFER_SMPTE_170M |
+	                                    HAL_DATASPACE_RANGE_LIMITED,
+
+	/* IMG extensions for 'full range' versions of previous enums */
+	HAL_DATASPACE_EXT_BT601_625_FULL  = ( HAL_DATASPACE_BT601_625 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT601_525_FULL  = ( HAL_DATASPACE_BT601_525 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT709_FULL      = ( HAL_DATASPACE_BT709 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+	HAL_DATASPACE_EXT_BT2020_FULL     = ( HAL_DATASPACE_EXT_BT2020 &
+	                                     ~HAL_DATASPACE_RANGE_MASK) |
+	                                    HAL_DATASPACE_RANGE_FULL,
+}
+android_dataspace_ext_t;
+
+#endif /* IMG_GRALLOC_COMMON_PUBLIC_H */
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp b/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
new file mode 100644
index 0000000000..8a6dd294d6
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc.cpp
@@ -0,0 +1,242 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *    Austin Yuan <austin.yuan@intel.com>
+ *
+ */
+
+#include "psb_gralloc.h"
+#include <log/log.h>
+#include <utils/threads.h>
+#include <ui/PixelFormat.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <hardware/hardware.h>
+#ifdef BAYTRAIL
+#include <ufo/gralloc.h>
+#else
+#include "hal_public.h"
+#include <sync/sync.h>
+#endif
+
+using namespace android;
+
+#ifdef  LOG_TAG
+#undef  LOG_TAG
+#endif
+
+#define LOG_TAG "v4l2_camera"
+
+#ifdef BAYTRAIL
+static const gralloc_module_t *mGralloc;
+#else
+static const hw_device_t *mGralloc;
+#endif
+
+int gralloc_lock(buffer_handle_t handle,
+                 int usage, int left, int top, int width, int height,
+                 void** vaddr)
+{
+    int err;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized. Should initialize it first", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__, GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+#ifdef BAYTRAIL
+    err = mGralloc->lock(mGralloc, handle, usage,
+                         left, top, width, height,
+                         vaddr);
+#else
+    const gralloc1_rect_t r = {
+        .left   = left,
+        .top    = top,
+        .width  = width,
+        .height = height
+    };
+    err = gralloc_lock_async_img(mGralloc, handle, usage, &r, vaddr, -1);
+#endif
+    ALOGV("gralloc_lock: handle is %p, usage is %x, vaddr is %p.\n", handle, usage, *vaddr);
+    if (err){
+        ALOGE("lock(...) failed %d (%s).\n", err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("lock returned with address %p\n", *vaddr);
+    }
+
+    return err;
+}
+
+int gralloc_unlock(buffer_handle_t handle)
+{
+    int err;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized. Should initialize it first", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__, GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+#ifdef BAYTRAIL
+    err = mGralloc->unlock(mGralloc, handle);
+#else
+    int releaseFence = -1;
+    err = gralloc_unlock_async_img(mGralloc, handle, &releaseFence);
+    if (releaseFence >= 0) {
+        sync_wait(releaseFence, -1);
+        close(releaseFence);
+    }
+#endif
+    if (err) {
+        ALOGE("unlock(...) failed %d (%s)", err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unlock returned\n");
+    }
+
+    return err;
+}
+
+int gralloc_register(buffer_handle_t handle)
+{
+    int err = 0;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized.", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__,
+                    GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+    err = gralloc_register_img(mGralloc, handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("registered buffer %p successfully\n", handle);
+    }
+
+    return err;
+}
+
+int gralloc_unregister(buffer_handle_t handle)
+{
+    int err = 0;
+
+    if (!mGralloc) {
+        ALOGW("%s: gralloc module has not been initialized.", __func__);
+        if (gralloc_init()) {
+            ALOGE("%s: can't find the %s module", __func__,
+                    GRALLOC_HARDWARE_MODULE_ID);
+            return -1;
+        }
+    }
+
+    err = gralloc_unregister_img(mGralloc, handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unregistered buffer %p successfully\n", handle);
+    }
+
+    return err;
+}
+
+int gralloc_init(void)
+{
+    int err;
+
+#ifdef BAYTRAIL
+    err = hw_get_module(GRALLOC_HW_MODULE_ID, (const hw_module_t **)&mGralloc);
+#else
+    err = gralloc_open_img(&mGralloc);
+#endif
+    if (err) {
+        ALOGE("FATAL: can't find the %s module", GRALLOC_HARDWARE_MODULE_ID);
+        return -1;
+    } else
+        ALOGD("hw_get_module returned OK\n");
+
+    return 0;
+}
+
+int gralloc_getdisplaystatus(buffer_handle_t handle,  int* status)
+{
+    int err;
+
+#ifdef BAYTRAIL
+    *status = mGralloc->perform(mGralloc, INTEL_UFO_GRALLOC_MODULE_PERFORM_GET_BO_STATUS, handle);
+    err = 0;
+#else
+    uint32_t _status = 0U;
+    err = gralloc_get_display_status_img(mGralloc, handle, &_status);
+    *status = (int)_status;
+#endif
+    if (err){
+        ALOGE("gralloc_getdisplaystatus(...) failed %d (%s).\n", err, strerror(-err));
+        return -1;
+    }
+
+    return err;
+}
+
+int gralloc_getbuffd(buffer_handle_t handle)
+{
+    return ((IMG_native_handle_t*)handle)->fd[0];
+}
+
+
+#define GRALLOC_ALIGN(value, base) (((value) + ((base)-1)) & ~((base)-1))
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h)
+{
+    (void)format;
+    (void)buf_w;
+    (void)buf_h;
+
+    void *addr = 0;
+    int err;
+
+    ALOGV("handle %p, usage 0x%x", handle, usage);
+
+    err = gralloc_lock(handle, usage, x, y, w, h, &addr);
+    if (err)
+        return err;
+
+    ycbcr->y = addr;
+
+    return 0;
+}
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc.h b/hardware/ntimespace/camera/gralloc/psb_gralloc.h
new file mode 100644
index 0000000000..6de28cb824
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc.h
@@ -0,0 +1,60 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *
+ */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <hardware/gralloc.h>
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+int gralloc_lock(buffer_handle_t handle, int usage,
+        int left, int top, int width, int height, void** vaddr);
+
+int gralloc_unlock(buffer_handle_t handle);
+
+int gralloc_register(buffer_handle_t handle);
+
+int gralloc_unregister(buffer_handle_t handle);
+
+int gralloc_init(void);
+
+int gralloc_getdisplaystatus(buffer_handle_t handle,  int* status);
+
+int gralloc_getbuffd(buffer_handle_t handle);
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h);
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp b/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
new file mode 100644
index 0000000000..4f860c6da0
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc3.cpp
@@ -0,0 +1,151 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *    Austin Yuan <austin.yuan@intel.com>
+ *
+ */
+
+#include <log/log.h>
+#include <utils/threads.h>
+#include <ui/PixelFormat.h>
+#include <hardware/gralloc.h>
+#include <system/graphics.h>
+#include <hardware/hardware.h>
+#include <sync/sync.h>
+#include "gralloc3_impl.h"
+#include "psb_gralloc3.h"
+
+#include <memory>
+#include <unordered_map>
+#include <utility>
+
+#undef  LOG_NDEBUG
+//#define LOG_NDEBUG 0
+
+using namespace android;
+using hardware::camera::common::V1_0::helper::HandleImporter;
+
+#ifdef  LOG_TAG
+#undef  LOG_TAG
+#endif
+
+#define LOG_TAG "v4l2_camera"
+
+
+// static
+HandleImporter * GetInstance() {
+    static HandleImporter instance;    
+    return &instance;
+}
+
+int gralloc_lock(buffer_handle_t handle,
+                 int usage, int left, int top, int width, int height,
+                 void** vaddr)
+{
+    IMapper::Rect outRect {left, top, static_cast<int32_t>(width), static_cast<int32_t>(height)};    
+    *vaddr = GetInstance()->lock(handle, (uint64_t)usage, outRect);
+    ALOGV("gralloc_lock: handle is %p, fd %d usage is %x, vaddr is %p.\n", handle, handle->data[0], usage, *vaddr);
+    if (*vaddr == NULL){
+        ALOGE("lock(...) failed.\n");
+        return -1;
+    } else {
+        ALOGV("lock returned with address %p\n", *vaddr);
+    }
+
+    return 0;
+}
+
+int gralloc_unlock(buffer_handle_t handle)
+{
+    int releaseFence = -1;
+
+    ALOGV("%s fd %d new fd %d  \n", __func__, handle->data[0], handle->data[0]);
+    releaseFence = GetInstance()->unlock(handle);
+    ALOGV("unlock fence %d", releaseFence);
+    if (releaseFence >= 0) {
+        sync_wait(releaseFence, -1);
+        close(releaseFence);
+    }   
+    
+    return 0;
+}
+
+int gralloc_register(buffer_handle_t & handle)
+{
+    ALOGV("%s fd %d.\n", __func__, handle->data[0]);
+
+    buffer_handle_t outhandle;
+    bool ret = GetInstance()->importBuffer(handle, outhandle);
+    if (!ret) {
+        ALOGE("%s failed.\n", __func__);
+        return -1;     
+    } else {
+        ALOGV("registered buffer %p with new fd %d successfully\n", handle, outhandle->data[0]);
+    }
+   
+    ALOGV("%s new handle fd %d.\n", __func__, handle->data[0]);
+    
+    return ret ? 0 : -1;
+}
+
+int gralloc_unregister(buffer_handle_t handle)
+{
+    int err = 0;
+
+    ALOGV("%s fd %d \n", __func__, handle->data[0]);
+    GetInstance()->freeBuffer(handle);
+    if (err) {
+        ALOGE("%s failed with %d (%s).\n", __func__, err, strerror(-err));
+        return -1;
+    } else {
+        ALOGV("unregistered buffer %p with fd %d successfully\n", handle, handle->data[0]);
+    }    
+
+    return err;
+}
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h)
+{
+    (void)format;
+    (void)buf_w;
+    (void)buf_h;
+
+    YCbCrLayout layout;
+
+    ALOGV("%s fd %d \n", __func__, handle->data[0]);
+    IMapper::Rect outRect {x, y, static_cast<int32_t>(w), static_cast<int32_t>(h)};
+    layout = GetInstance()->lockYCbCr(handle, usage, outRect);
+    if (layout.y == nullptr)
+    {
+        ALOGE("layout.y error");
+        return -1;
+    }
+
+    ycbcr->y = layout.y;
+
+    return 0;
+}
diff --git a/hardware/ntimespace/camera/gralloc/psb_gralloc3.h b/hardware/ntimespace/camera/gralloc/psb_gralloc3.h
new file mode 100644
index 0000000000..67abd0dd5f
--- /dev/null
+++ b/hardware/ntimespace/camera/gralloc/psb_gralloc3.h
@@ -0,0 +1,55 @@
+/*
+ * Copyright (c) 2011 Intel Corporation. All Rights Reserved.
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a
+ * copy of this software and associated documentation files (the
+ * "Software"), to deal in the Software without restriction, including
+ * without limitation the rights to use, copy, modify, merge, publish,
+ * distribute, sub license, and/or sell copies of the Software, and to
+ * permit persons to whom the Software is furnished to do so, subject to
+ * the following conditions:
+ *
+ * The above copyright notice and this permission notice (including the
+ * next paragraph) shall be included in all copies or substantial portions
+ * of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
+ * OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
+ * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT.
+ * IN NO EVENT SHALL PRECISION INSIGHT AND/OR ITS SUPPLIERS BE LIABLE FOR
+ * ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT,
+ * TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE
+ * SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+ *
+ * Authors:
+ *    Fei Jiang  <fei.jiang@intel.com>
+ *
+ */
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <stdint.h>
+#include <hardware/gralloc.h>
+#include "gralloc3_impl.h"
+
+#ifdef __cplusplus
+extern "C"
+{
+#endif
+
+int gralloc_lock(buffer_handle_t handle, int usage,
+        int left, int top, int width, int height, void** vaddr);
+
+int gralloc_unlock(buffer_handle_t handle);
+
+int gralloc_register(buffer_handle_t & handle);
+
+int gralloc_unregister(buffer_handle_t handle);
+
+int gralloc_lock_ycbcr(buffer_handle_t handle,
+		int usage, int x, int y, int w, int h,
+		struct android_ycbcr *ycbcr, int format, int buf_w, int buf_h);
+
+#ifdef __cplusplus
+}
+#endif
diff --git a/hardware/ntimespace/camera/hardware/hw_converter.h b/hardware/ntimespace/camera/hardware/hw_converter.h
new file mode 100644
index 0000000000..e2e61c76ae
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/hw_converter.h
@@ -0,0 +1,94 @@
+#ifndef __V4L2_HARDWARE_CONVERTER_HEADER
+#define __V4L2_HARDWARE_CONVERTER_HEADER
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <sys/mman.h>
+#include <pthread.h>
+#include <semaphore.h>
+#include <linux/videodev2.h>
+#include <dlfcn.h>
+#include <vector>
+#include <utils/Log.h>
+#include "debug.h"
+#include "android-base/properties.h"
+#include "metadata/camera_metadata.h"
+#include "arc/frame_buffer.h"
+
+#ifdef HAS_C2D2
+#include "C2DColorConverter.h"
+#endif
+
+namespace hw_conv {
+using android::CameraMetadata;
+using arc::FrameBuffer;
+
+
+class hw_conv
+{
+    public:
+        hw_conv();
+        virtual ~hw_conv();
+        virtual bool init() = 0;
+        //virtual bool convert(int src_fd, void *src_base, void *src_viraddr,
+        //        int dest_fd, void *dest_base, void *dest_viraddr) = 0;
+        virtual bool deinit() = 0;
+};
+
+#ifdef HAS_C2D2
+class qc_c2d_conv: public hw_conv
+{
+    public:
+        qc_c2d_conv();
+        ~qc_c2d_conv();
+        bool init() { return true;}
+        bool deinit() { return true;}        
+        bool convert(int src_fd, void *src_base, void *src_viraddr, int dest_fd, void *dest_base, void *dest_viraddr);
+        bool setResolution(size_t srcWidth, size_t srcHeight,
+                                      size_t dstWidth, size_t dstHeight,
+                                      ColorConvertFormat srcFormat,
+                                      ColorConvertFormat dstFormat,
+                                      int32_t flags, size_t srcStride);
+
+        void updateSavedResolution(size_t srcWidth, size_t srcHeight,
+                                        size_t dstWidth, size_t dstHeight,
+                                        ColorConvertFormat srcFormat,
+                                        ColorConvertFormat dstFormat,
+                                        int32_t flags, size_t srcStride);
+
+        C2DColorConverter c2dcc;
+        //pthread_mutex_t c_lock;
+
+        size_t srcWidth_;
+        size_t srcHeight_;
+        size_t dstWidth_; 
+        size_t dstHeight_;                                
+        ColorConvertFormat srcFormat_;
+        ColorConvertFormat dstFormat_;
+        int32_t flags_; 
+        size_t srcStride_;        
+};
+#endif
+
+#ifdef HAS_RGA
+class rk_rga_conv: public hw_conv
+{
+    public:
+        rk_rga_conv();
+        ~rk_rga_conv();
+        bool init() { return true;}
+        bool deinit() { return true;}        
+        bool convert(int src_fd, void *src_base, void *src_viraddr,
+                    int dest_fd, void *dest_base, void *dest_viraddr,
+                    int src_width, int src_height,
+                    int src_wstride, int src_hstride,
+                    int dst_width, int dst_height,
+                    int srcFormat, int dstFormat);
+};
+#endif
+
+int convert_format(const CameraMetadata& metadata, const FrameBuffer& in_frame, FrameBuffer* out_frame);
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height);
+
+}
+#endif
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp b/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
new file mode 100644
index 0000000000..5c3e546d06
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/qc_hw_converter.cpp
@@ -0,0 +1,252 @@
+#include <inttypes.h>
+#include <string.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <sys/prctl.h>
+#include <sys/ioctl.h>
+#include "common.h"
+#include "hw_converter.h"
+#include "arc/image_processor.h"
+
+namespace hw_conv {
+
+using android::CameraMetadata;
+
+hw_conv:: hw_conv() {};
+hw_conv:: ~hw_conv() {};
+
+qc_c2d_conv::qc_c2d_conv()
+{
+    LOGF(ERROR) << "convert perf";
+    //pthread_mutex_init(&c_lock, NULL);
+    updateSavedResolution(0, 0, 0, 0, NO_COLOR_FORMAT, NO_COLOR_FORMAT, 0, 0);
+}
+
+void qc_c2d_conv::updateSavedResolution(size_t srcWidth, size_t srcHeight,
+                                size_t dstWidth, size_t dstHeight,
+                                ColorConvertFormat srcFormat,
+                                ColorConvertFormat dstFormat,
+                                int32_t flags, size_t srcStride) {
+    srcWidth_ = srcWidth;
+    srcHeight_ = srcHeight;
+    dstWidth_ = dstWidth; 
+    dstHeight_ = dstHeight;                                
+    srcFormat_ = srcFormat;
+    dstFormat_ = dstFormat;
+    flags_ = flags;  
+    srcStride_ = srcStride;     
+}
+
+bool qc_c2d_conv::setResolution(size_t srcWidth, size_t srcHeight,
+                                size_t dstWidth, size_t dstHeight,
+                                ColorConvertFormat srcFormat,
+                                ColorConvertFormat dstFormat,
+                                int32_t flags, size_t srcStride)
+{
+    if ( srcWidth_ != srcWidth || srcHeight_ != srcHeight || srcFormat_ != srcFormat
+      || dstWidth_ != dstWidth || dstHeight_ != dstHeight || dstFormat_ != dstFormat
+      || flags_ != flags || srcStride_ != srcStride) {
+        updateSavedResolution(srcWidth, srcHeight, dstWidth, dstHeight, srcFormat, dstFormat, flags, srcStride);
+        c2dcc.setConversionNeeded(true);
+        if (!c2dcc.setResolution(srcWidth, srcHeight, dstWidth, dstHeight, srcFormat, dstFormat, flags, srcStride)) {
+            LOGF(ERROR) << "C2D2 setResolution failed";
+            return false;
+        } 
+      }
+
+    return true; 
+}
+
+bool qc_c2d_conv::convert(int src_fd, void *src_base, void *src_viraddr,
+                          int dest_fd, void *dest_base, void *dest_viraddr)
+{
+    bool result;
+    if (!src_viraddr || !dest_viraddr || !src_base || !dest_base) {
+        HAL_LOGE("Invalid arguments qc_c2d_conv::convert");
+        return false;
+    }
+
+    //pthread_mutex_lock(&c_lock);
+    result =  c2dcc.convertC2D(src_fd, src_base, src_viraddr, dest_fd, dest_base, dest_viraddr);
+    //pthread_mutex_unlock(&c_lock);
+
+    HAL_LOGV("Color convert status %s", result ? "OK" : "Fail");
+    return result;
+}
+
+qc_c2d_conv::~qc_c2d_conv()
+{
+    //pthread_mutex_destroy(&c_lock);
+}
+
+qc_c2d_conv c2d_conv;
+
+int convert_format(const CameraMetadata& /*metadata*/, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+    /*
+    LOGF(INFO) << "[C2D2] in_frame: " << FormatToString(in_frame.GetFourcc())
+                << " " << in_frame.GetFourcc()
+                << " width " << in_frame.GetWidth()
+                << " height " << in_frame.GetHeight()
+                << " size " << in_frame.GetDataSize();   
+
+    LOGF(INFO) << "[C2D2] out_frame: " << FormatToString(out_frame->GetFourcc())
+                << " " << out_frame->GetFourcc()
+                << " width " << out_frame->GetWidth()
+                << " height " << out_frame->GetHeight()
+                << " size " << out_frame->GetDataSize();              
+    */
+
+    if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+      LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                  << " x " << in_frame.GetHeight() << ")";
+      return -EINVAL;
+    }
+
+    if (in_frame.GetFourcc() == out_frame->GetFourcc() && in_frame.GetWidth() == out_frame->GetWidth() &&
+        in_frame.GetHeight() == out_frame->GetHeight())
+    {
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+
+    size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+    if (out_frame->SetDataSize(data_size)) {
+      LOGF(ERROR) << "Set data size failed";
+      return -EINVAL;
+    }
+  #if 0
+    if (true){
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+  #endif
+    ColorConvertFormat src_fmt;
+    ColorConvertFormat dst_fmt;
+    int ystride = 0;
+    
+    if (in_frame.GetFourcc() == V4L2_PIX_FMT_YUV420) { //YU12
+      src_fmt = YCbCr420P;
+      // V4L2_PIX_FMT_YVU420 is YV12. I420 is usually referred to YU12
+      // (V4L2_PIX_FMT_YUV420), and YV12 is similar to YU12 except that U/V
+      // planes are swapped.
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = YCbCr420SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT; 
+        }   
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT; 
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+      src_fmt = RGBA8888;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:  // YU12
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        break;
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = YCbCr420SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT;      
+        }
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }           
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+      src_fmt = YCbCr420SP;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:   //yu12, I420
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_YVU420:  // YV12
+        {  
+          dst_fmt = YCrCb420P;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }      
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_YVU420) {
+      src_fmt = YCrCb420P;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_YUV420:   //yu12, I420
+        {
+          dst_fmt = YCbCr420P;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RGBA8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        case V4L2_PIX_FMT_NV12:  
+        {  
+          dst_fmt = YCbCr420SP;
+          ystride = Align16(in_frame.GetWidth());
+          goto DO_CONVERT;   
+        }      
+        default:
+          goto UNSUPPORT;
+      }
+    }
+
+    UNSUPPORT:
+      return -EINVAL; 
+
+    DO_CONVERT:
+      if (!c2d_conv.setResolution(in_frame.GetWidth(),in_frame.GetHeight(), 
+                                  out_frame->GetWidth(),out_frame->GetHeight(),
+                                  src_fmt, dst_fmt, 0, ystride)) {
+          return -EINVAL;
+      }
+      if (!c2d_conv.convert(in_frame.GetFd(), in_frame.GetData(), in_frame.GetData(), 
+                            out_frame->GetFd(), out_frame->GetData(), out_frame->GetData())) {
+          return -EINVAL;
+      } 
+
+    return 0;
+}
+
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height) {
+    return arc::ImageProcessor::GetConvertedSize(fourcc, width, height);
+}
+
+}
diff --git a/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp b/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
new file mode 100644
index 0000000000..baf7dac138
--- /dev/null
+++ b/hardware/ntimespace/camera/hardware/rk_hw_converter.cpp
@@ -0,0 +1,159 @@
+#include <inttypes.h>
+#include <string.h>
+#include <stdlib.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+#include <sys/prctl.h>
+#include <sys/ioctl.h>
+#include "common.h"
+#include "hw_converter.h"
+#include "arc/image_processor.h"
+#include "hw_converter.h"
+#include "RgaApi.h"
+
+namespace hw_conv {
+
+using android::CameraMetadata;
+
+hw_conv:: hw_conv() {};
+hw_conv:: ~hw_conv() {};
+
+rk_rga_conv::rk_rga_conv()
+{
+    //LOGF(ERROR) << "convert perf";
+}
+
+bool rk_rga_conv::convert(int src_fd, void *src_base, void *src_viraddr,
+                            int dest_fd, void *dest_base, void *dest_viraddr,
+                            int src_width, int src_height,
+                            int src_wstride, int src_hstride,
+                            int dst_width, int dst_height,
+                            int srcFormat, int dstFormat)
+{
+    (void)src_base;
+    (void)dest_base;
+    (void)src_viraddr;
+    (void)dest_viraddr;
+
+    int ret = 0;
+    static int g_rga_init = 0;    
+    void *rgaCtx = NULL;
+    rga_info_t rgasrc, rgadst;
+
+    if (!g_rga_init) {
+        RgaInit(&rgaCtx);
+        g_rga_init = 1;
+        HAL_LOGD("init rga ctx done");
+    } 
+
+    memset(&rgasrc, 0, sizeof(rga_info_t));
+    rgasrc.fd = src_fd;
+
+    memset(&rgadst, 0, sizeof(rga_info_t));
+    rgadst.fd = dest_fd;
+
+    rga_set_rect(&rgasrc.rect, 0, 0, src_width, src_height,
+                 src_wstride, src_hstride, srcFormat);
+    rga_set_rect(&rgadst.rect, 0, 0, dst_width, dst_height,
+                 src_wstride, src_hstride, dstFormat);
+
+    ret = RgaBlit(&rgasrc, &rgadst, NULL);
+    if (ret) {
+        HAL_LOGE("failed to rga blit ret %d", ret);
+        return false;
+    }
+
+    return true;
+}
+
+rk_rga_conv::~rk_rga_conv()
+{
+}
+
+rk_rga_conv rga_conv;
+
+int convert_format(const CameraMetadata& /*metadata*/, const FrameBuffer& in_frame, FrameBuffer* out_frame) {
+    LOGF(INFO) << "[RGA] in_frame: " << FormatToString(in_frame.GetFourcc())
+                << " " << in_frame.GetFourcc()
+                << " width " << in_frame.GetWidth()
+                << " height " << in_frame.GetHeight()
+                << " size " << in_frame.GetDataSize();   
+
+    LOGF(INFO) << "[RGA] out_frame: " << FormatToString(out_frame->GetFourcc())
+                << " " << out_frame->GetFourcc()
+                << " width " << out_frame->GetWidth()
+                << " height " << out_frame->GetHeight()
+                << " size " << out_frame->GetDataSize();              
+
+    if ((in_frame.GetWidth() % 2) || (in_frame.GetHeight() % 2)) {
+      LOGF(ERROR) << "Width or height is not even (" << in_frame.GetWidth()
+                  << " x " << in_frame.GetHeight() << ")";
+      return -EINVAL;
+    }
+
+    if (in_frame.GetFourcc() == out_frame->GetFourcc() && in_frame.GetWidth() == out_frame->GetWidth() &&
+        in_frame.GetHeight() == out_frame->GetHeight())
+    {
+      memcpy(out_frame->GetData(), in_frame.GetData(), in_frame.GetDataSize());       
+      return 0;        
+    }
+
+    size_t data_size = GetConvertedSize(out_frame->GetFourcc(), in_frame.GetWidth(), in_frame.GetHeight());
+    if (out_frame->SetDataSize(data_size)) {
+      LOGF(ERROR) << "Set data size failed";
+      return -EINVAL;
+    }
+
+    int src_fmt;
+    int dst_fmt;
+    int ystride = 0;
+    
+    if (in_frame.GetFourcc() == V4L2_PIX_FMT_RGB32) { //memory map: r/g/b/a
+      src_fmt = RK_FORMAT_RGBA_8888;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_NV12:  
+        {
+          dst_fmt = RK_FORMAT_YCbCr_420_SP;
+          ystride = out_frame->GetWidth();
+          goto DO_CONVERT;      
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } else if (in_frame.GetFourcc() == V4L2_PIX_FMT_NV12) {
+      src_fmt = RK_FORMAT_YCbCr_420_SP;
+      switch (out_frame->GetFourcc()) {
+        case V4L2_PIX_FMT_RGB32: 
+        {
+          dst_fmt = RK_FORMAT_RGBA_8888;
+          ystride = Align64(in_frame.GetWidth());
+          goto DO_CONVERT;
+        }
+        default:
+          goto UNSUPPORT;
+      }
+    } 
+
+    UNSUPPORT:
+      LOGF(ERROR) << "RGA don't support the convert"; 
+      return -EINVAL; 
+
+    DO_CONVERT:
+      if (!rga_conv.convert(in_frame.GetFd(), in_frame.GetData(), in_frame.GetData(), 
+                            out_frame->GetFd(), out_frame->GetData(), out_frame->GetData(),
+                            in_frame.GetWidth(), in_frame.GetHeight(),
+                            ystride, in_frame.GetHeight(),
+                            out_frame->GetWidth(), out_frame->GetHeight(),
+                            src_fmt, dst_fmt)) {
+          return -EINVAL;
+      } 
+
+    return 0;
+}
+
+size_t GetConvertedSize(int fourcc, uint32_t width, uint32_t height) {
+    return arc::ImageProcessor::GetConvertedSize(fourcc, width, height);
+}
+
+}
\ No newline at end of file
diff --git a/hardware/ntimespace/camera/metadata/array_vector.h b/hardware/ntimespace/camera/metadata/array_vector.h
new file mode 100644
index 0000000000..0481ed4424
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/array_vector.h
@@ -0,0 +1,52 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
+#define V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
+
+#include <array>
+#include <vector>
+
+namespace v4l2_camera_hal {
+// ArrayVector behaves like a std::vector of fixed length C arrays,
+// with push_back accepting std::arrays to standardize length.
+// Specific methods to get number of arrays/number of elements
+// are provided and an ambiguous "size" is not, to avoid accidental
+// incorrect use.
+template <class T, size_t N>
+class ArrayVector {
+ public:
+  const T* data() const { return mItems.data(); }
+  // The number of arrays.
+  size_t num_arrays() const { return mItems.size() / N; }
+  // The number of elements amongst all arrays.
+  size_t total_num_elements() const { return mItems.size(); }
+
+  // Access the ith array.
+  const T* operator[](int i) const { return mItems.data() + (i * N); }
+  T* operator[](int i) { return mItems.data() + (i * N); }
+
+  void push_back(const std::array<T, N>& values) {
+    mItems.insert(mItems.end(), values.begin(), values.end());
+  }
+
+ private:
+  std::vector<T> mItems;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_ARRAY_VECTOR_H_
diff --git a/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp b/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
new file mode 100644
index 0000000000..b0544a892a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/boottime_state_delegate.cpp
@@ -0,0 +1,47 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "BoottimeStateDelegate"
+
+#include "boottime_state_delegate.h"
+
+#include <unistd.h>
+#include <time.h>
+
+#include <cerrno>
+#include <cstring>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+int BoottimeStateDelegate::GetValue(int64_t* value) {
+  struct timespec ts;
+
+  int res = clock_gettime(CLOCK_BOOTTIME, &ts);
+  if (res) {
+    HAL_LOGE("Failed to get BOOTTIME for state delegate: %d (%s)",
+             errno,
+             strerror(errno));
+    return -errno;
+  }
+  *value = ts.tv_sec * 1000000000ULL + ts.tv_nsec;
+
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/boottime_state_delegate.h b/hardware/ntimespace/camera/metadata/boottime_state_delegate.h
new file mode 100644
index 0000000000..e31e12f9ee
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/boottime_state_delegate.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
+
+#include <cstdint>
+
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A StateDelegate is simply a dynamic value that can be queried.
+// The value may change between queries.
+class BoottimeStateDelegate : public StateDelegateInterface<int64_t> {
+ public:
+  BoottimeStateDelegate(){};
+  ~BoottimeStateDelegate(){};
+
+  int GetValue(int64_t* value) override;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_BOOTTIME_STATE_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/camera_metadata.cpp b/hardware/ntimespace/camera/metadata/camera_metadata.cpp
new file mode 100644
index 0000000000..0692fdef3e
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/camera_metadata.cpp
@@ -0,0 +1,565 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+
+#define LOG_TAG "CamComm1.0-MD"
+#include <log/log.h>
+#include <utils/Errors.h>
+#include "camera_metadata.h"
+
+
+namespace android {
+#if 0
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+#endif
+
+#define ALIGN_TO(val, alignment) \
+    (((uintptr_t)(val) + ((alignment) - 1)) & ~((alignment) - 1))
+
+CameraMetadata::CameraMetadata() :
+        mBuffer(NULL), mLocked(false) {
+}
+
+CameraMetadata::CameraMetadata(size_t entryCapacity, size_t dataCapacity) :
+        mLocked(false)
+{
+    mBuffer = allocate_camera_metadata(entryCapacity, dataCapacity);
+}
+
+CameraMetadata::CameraMetadata(const CameraMetadata &other) :
+        mLocked(false) {
+    mBuffer = clone_camera_metadata(other.mBuffer);
+}
+
+CameraMetadata::CameraMetadata(camera_metadata_t *buffer) :
+        mBuffer(NULL), mLocked(false) {
+    acquire(buffer);
+}
+
+CameraMetadata &CameraMetadata::operator=(const CameraMetadata &other) {
+    return operator=(other.mBuffer);
+}
+
+CameraMetadata &CameraMetadata::operator=(const camera_metadata_t *buffer) {
+    if (mLocked) {
+        HAL_LOGE("%s: Assignment to a locked CameraMetadata!", __FUNCTION__);
+        return *this;
+    }
+
+    if (CC_LIKELY(buffer != mBuffer)) {
+        camera_metadata_t *newBuffer = clone_camera_metadata(buffer);
+        clear();
+        mBuffer = newBuffer;
+    }
+    return *this;
+}
+
+CameraMetadata::~CameraMetadata() {
+    mLocked = false;
+    clear();
+}
+
+const camera_metadata_t* CameraMetadata::getAndLock() const {
+    mLocked = true;
+    return mBuffer;
+}
+
+status_t CameraMetadata::unlock(const camera_metadata_t *buffer) const {
+    if (!mLocked) {
+        HAL_LOGE("%s: Can't unlock a non-locked CameraMetadata!", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if (buffer != mBuffer) {
+        HAL_LOGE("%s: Can't unlock CameraMetadata with wrong pointer!",
+                __FUNCTION__);
+        return BAD_VALUE;
+    }
+    mLocked = false;
+    return OK;
+}
+
+camera_metadata_t* CameraMetadata::release() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return NULL;
+    }
+    camera_metadata_t *released = mBuffer;
+    mBuffer = NULL;
+    return released;
+}
+
+void CameraMetadata::clear() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    if (mBuffer) {
+        free_camera_metadata(mBuffer);
+        mBuffer = NULL;
+    }
+}
+
+void CameraMetadata::acquire(camera_metadata_t *buffer) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    clear();
+    mBuffer = buffer;
+
+    HAL_LOGE_IF(validate_camera_metadata_structure(mBuffer, /*size*/NULL) != OK,
+             "%s: Failed to validate metadata structure %p",
+             __FUNCTION__, buffer);
+}
+
+void CameraMetadata::acquire(CameraMetadata &other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+    acquire(other.release());
+}
+
+status_t CameraMetadata::append(const CameraMetadata &other) {
+    return append(other.mBuffer);
+}
+
+status_t CameraMetadata::append(const camera_metadata_t* other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    size_t extraEntries = get_camera_metadata_entry_count(other);
+    size_t extraData = get_camera_metadata_data_count(other);
+    resizeIfNeeded(extraEntries, extraData);
+
+    return append_camera_metadata(mBuffer, other);
+}
+
+size_t CameraMetadata::entryCount() const {
+    return (mBuffer == NULL) ? 0 :
+            get_camera_metadata_entry_count(mBuffer);
+}
+
+bool CameraMetadata::isEmpty() const {
+    return entryCount() == 0;
+}
+
+status_t CameraMetadata::sort() {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    return sort_camera_metadata(mBuffer);
+}
+
+status_t CameraMetadata::checkType(uint32_t tag, uint8_t expectedType) {
+    int tagType = get_local_camera_metadata_tag_type(tag, mBuffer);
+    if ( CC_UNLIKELY(tagType == -1)) {
+        HAL_LOGE("Update metadata entry: Unknown tag %d", tag);
+        return INVALID_OPERATION;
+    }
+    if ( CC_UNLIKELY(tagType != expectedType) ) {
+        HAL_LOGE("Mismatched tag type when updating entry %s (%d) of type %s; "
+              "got type %s data instead ",
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag,
+              camera_metadata_type_names[tagType], camera_metadata_type_names[expectedType]);
+        return INVALID_OPERATION;
+    }
+    return OK;
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const int32_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_INT32)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const uint8_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_BYTE)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const float *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_FLOAT)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const int64_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_INT64)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const double *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_DOUBLE)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const camera_metadata_rational_t *data, size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_RATIONAL)) != OK) {
+        return res;
+    }
+    return updateImpl(tag, (const void*)data, data_count);
+}
+
+status_t CameraMetadata::update(uint32_t tag,
+        const String8 &string) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(tag, TYPE_BYTE)) != OK) {
+        return res;
+    }
+    // string.size() doesn't count the null termination character.
+    return updateImpl(tag, (const void*)string.string(), string.size() + 1);
+}
+
+status_t CameraMetadata::update(const camera_metadata_ro_entry &entry) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    if ( (res = checkType(entry.tag, entry.type)) != OK) {
+        return res;
+    }
+    return updateImpl(entry.tag, (const void*)entry.data.u8, entry.count);
+}
+
+status_t CameraMetadata::updateImpl(uint32_t tag, const void *data,
+        size_t data_count) {
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    int type = get_local_camera_metadata_tag_type(tag, mBuffer);
+    if (type == -1) {
+        HAL_LOGE("%s: Tag %d not found", __FUNCTION__, tag);
+        return BAD_VALUE;
+    }
+    // Safety check - ensure that data isn't pointing to this metadata, since
+    // that would get invalidated if a resize is needed
+    size_t bufferSize = get_camera_metadata_size(mBuffer);
+    uintptr_t bufAddr = reinterpret_cast<uintptr_t>(mBuffer);
+    uintptr_t dataAddr = reinterpret_cast<uintptr_t>(data);
+    if (dataAddr > bufAddr && dataAddr < (bufAddr + bufferSize)) {
+        HAL_LOGE("%s: Update attempted with data from the same metadata buffer!",
+                __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+
+    size_t data_size = calculate_camera_metadata_entry_data_size(type,
+            data_count);
+
+    res = resizeIfNeeded(1, data_size);
+
+    if (res == OK) {
+        camera_metadata_entry_t entry;
+        res = find_camera_metadata_entry(mBuffer, tag, &entry);
+        if (res == NAME_NOT_FOUND) {
+            res = add_camera_metadata_entry(mBuffer,
+                    tag, data, data_count);
+        } else if (res == OK) {
+            res = update_camera_metadata_entry(mBuffer,
+                    entry.index, data, data_count, NULL);
+        }
+    }
+
+    if (res != OK) {
+        HAL_LOGE("%s: Unable to update metadata entry %s.%s (%x): %s (%d)", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+    }
+
+    IF_ALOGV() {
+        HAL_LOGE_IF(validate_camera_metadata_structure(mBuffer, /*size*/NULL) !=
+                 OK,
+
+                 "%s: Failed to validate metadata structure after update %p",
+                 __FUNCTION__, mBuffer);
+    }
+
+    return res;
+}
+
+bool CameraMetadata::exists(uint32_t tag) const {
+    camera_metadata_ro_entry entry;
+    return find_camera_metadata_ro_entry(mBuffer, tag, &entry) == 0;
+}
+
+camera_metadata_entry_t CameraMetadata::find(uint32_t tag) {
+    status_t res;
+    camera_metadata_entry entry;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        entry.count = 0;
+        return entry;
+    }
+    res = find_camera_metadata_entry(mBuffer, tag, &entry);
+    if (CC_UNLIKELY( res != OK )) {
+        entry.count = 0;
+        entry.data.u8 = NULL;
+    }
+    return entry;
+}
+
+camera_metadata_ro_entry_t CameraMetadata::find(uint32_t tag) const {
+    status_t res;
+    camera_metadata_ro_entry entry;
+    res = find_camera_metadata_ro_entry(mBuffer, tag, &entry);
+    if (CC_UNLIKELY( res != OK )) {
+        entry.count = 0;
+        entry.data.u8 = NULL;
+    }
+    return entry;
+}
+
+status_t CameraMetadata::erase(uint32_t tag) {
+    camera_metadata_entry_t entry;
+    status_t res;
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return INVALID_OPERATION;
+    }
+    res = find_camera_metadata_entry(mBuffer, tag, &entry);
+    if (res == NAME_NOT_FOUND) {
+        return OK;
+    } else if (res != OK) {
+        HAL_LOGE("%s: Error looking for entry %s.%s (%x): %s %d", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+        return res;
+    }
+    res = delete_camera_metadata_entry(mBuffer, entry.index);
+    if (res != OK) {
+        HAL_LOGE("%s: Error deleting entry %s.%s (%x): %s %d", __FUNCTION__,
+              get_local_camera_metadata_section_name(tag, mBuffer),
+              get_local_camera_metadata_tag_name(tag, mBuffer), tag, strerror(-res), res);
+    }
+    return res;
+}
+
+void CameraMetadata::dump(int fd, int verbosity, int indentation) const {
+    dump_indented_camera_metadata(mBuffer, fd, verbosity, indentation);
+}
+
+status_t CameraMetadata::resizeIfNeeded(size_t extraEntries, size_t extraData) {
+    if (mBuffer == NULL) {
+        mBuffer = allocate_camera_metadata(extraEntries * 2, extraData * 2);
+        if (mBuffer == NULL) {
+            HAL_LOGE("%s: Can't allocate larger metadata buffer", __FUNCTION__);
+            return NO_MEMORY;
+        }
+    } else {
+        size_t currentEntryCount = get_camera_metadata_entry_count(mBuffer);
+        size_t currentEntryCap = get_camera_metadata_entry_capacity(mBuffer);
+        size_t newEntryCount = currentEntryCount +
+                extraEntries;
+        newEntryCount = (newEntryCount > currentEntryCap) ?
+                newEntryCount * 2 : currentEntryCap;
+
+        size_t currentDataCount = get_camera_metadata_data_count(mBuffer);
+        size_t currentDataCap = get_camera_metadata_data_capacity(mBuffer);
+        size_t newDataCount = currentDataCount +
+                extraData;
+        newDataCount = (newDataCount > currentDataCap) ?
+                newDataCount * 2 : currentDataCap;
+
+        if (newEntryCount > currentEntryCap ||
+                newDataCount > currentDataCap) {
+            camera_metadata_t *oldBuffer = mBuffer;
+            mBuffer = allocate_camera_metadata(newEntryCount,
+                    newDataCount);
+            if (mBuffer == NULL) {
+                HAL_LOGE("%s: Can't allocate larger metadata buffer", __FUNCTION__);
+                return NO_MEMORY;
+            }
+            append_camera_metadata(mBuffer, oldBuffer);
+            free_camera_metadata(oldBuffer);
+        }
+    }
+    return OK;
+}
+
+void CameraMetadata::swap(CameraMetadata& other) {
+    if (mLocked) {
+        HAL_LOGE("%s: CameraMetadata is locked", __FUNCTION__);
+        return;
+    } else if (other.mLocked) {
+        HAL_LOGE("%s: Other CameraMetadata is locked", __FUNCTION__);
+        return;
+    }
+
+    camera_metadata* thisBuf = mBuffer;
+    camera_metadata* otherBuf = other.mBuffer;
+
+    other.mBuffer = thisBuf;
+    mBuffer = otherBuf;
+}
+#if 0
+status_t CameraMetadata::getTagFromName(const char *name,
+        const VendorTagDescriptor* vTags, uint32_t *tag) {
+
+    if (name == nullptr || tag == nullptr) return BAD_VALUE;
+
+    size_t nameLength = strlen(name);
+
+    const SortedVector<String8> *vendorSections;
+    size_t vendorSectionCount = 0;
+
+    if (vTags != NULL) {
+        vendorSections = vTags->getAllSectionNames();
+        vendorSectionCount = vendorSections->size();
+    }
+
+    // First, find the section by the longest string match
+    const char *section = NULL;
+    size_t sectionIndex = 0;
+    size_t sectionLength = 0;
+    size_t totalSectionCount = ANDROID_SECTION_COUNT + vendorSectionCount;
+    for (size_t i = 0; i < totalSectionCount; ++i) {
+
+        const char *str = (i < ANDROID_SECTION_COUNT) ? camera_metadata_section_names[i] :
+                (*vendorSections)[i - ANDROID_SECTION_COUNT].string();
+
+        HAL_LOGV("%s: Trying to match against section '%s'", __FUNCTION__, str);
+
+        if (strstr(name, str) == name) { // name begins with the section name
+            size_t strLength = strlen(str);
+
+            HAL_LOGV("%s: Name begins with section name", __FUNCTION__);
+
+            // section name is the longest we've found so far
+            if (section == NULL || sectionLength < strLength) {
+                section = str;
+                sectionIndex = i;
+                sectionLength = strLength;
+
+                HAL_LOGV("%s: Found new best section (%s)", __FUNCTION__, section);
+            }
+        }
+    }
+
+    if (section == NULL) {
+        return NAME_NOT_FOUND;
+    } else {
+        HAL_LOGV("%s: Found matched section '%s' (%zu)",
+              __FUNCTION__, section, sectionIndex);
+    }
+
+    // Get the tag name component of the name
+    const char *nameTagName = name + sectionLength + 1; // x.y.z -> z
+    if (sectionLength + 1 >= nameLength) {
+        return BAD_VALUE;
+    }
+
+    // Match rest of name against the tag names in that section only
+    uint32_t candidateTag = 0;
+    if (sectionIndex < ANDROID_SECTION_COUNT) {
+        // Match built-in tags (typically android.*)
+        uint32_t tagBegin, tagEnd; // [tagBegin, tagEnd)
+        tagBegin = camera_metadata_section_bounds[sectionIndex][0];
+        tagEnd = camera_metadata_section_bounds[sectionIndex][1];
+
+        for (candidateTag = tagBegin; candidateTag < tagEnd; ++candidateTag) {
+            const char *tagName = get_camera_metadata_tag_name(candidateTag);
+
+            if (strcmp(nameTagName, tagName) == 0) {
+                HAL_LOGV("%s: Found matched tag '%s' (%d)",
+                      __FUNCTION__, tagName, candidateTag);
+                break;
+            }
+        }
+
+        if (candidateTag == tagEnd) {
+            return NAME_NOT_FOUND;
+        }
+    } else if (vTags != NULL) {
+        // Match vendor tags (typically com.*)
+        const String8 sectionName(section);
+        const String8 tagName(nameTagName);
+
+        status_t res = OK;
+        if ((res = vTags->lookupTag(tagName, sectionName, &candidateTag)) != OK) {
+            return NAME_NOT_FOUND;
+        }
+    }
+
+    *tag = candidateTag;
+    return OK;
+}
+#endif
+#if 0
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+#endif
+} // namespace android
diff --git a/hardware/ntimespace/camera/metadata/camera_metadata.h b/hardware/ntimespace/camera/metadata/camera_metadata.h
new file mode 100644
index 0000000000..472af5693a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/camera_metadata.h
@@ -0,0 +1,234 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef CAMERA_COMMON_1_0_CAMERAMETADATA_H
+#define CAMERA_COMMON_1_0_CAMERAMETADATA_H
+
+#include "system/camera_metadata.h"
+
+#include <utils/String8.h>
+#include <utils/Vector.h>
+#include "common.h"
+
+namespace android {
+#if 0
+namespace hardware {
+namespace camera {
+namespace common {
+namespace V1_0 {
+namespace helper {
+#endif
+//class VendorTagDescriptor;
+
+/**
+ * A convenience wrapper around the C-based camera_metadata_t library.
+ */
+class CameraMetadata {
+  public:
+    /** Creates an empty object; best used when expecting to acquire contents
+     * from elsewhere */
+    CameraMetadata();
+    /** Creates an object with space for entryCapacity entries, with
+     * dataCapacity extra storage */
+    CameraMetadata(size_t entryCapacity, size_t dataCapacity = 10);
+
+    ~CameraMetadata();
+
+    /** Takes ownership of passed-in buffer */
+    CameraMetadata(camera_metadata_t *buffer);
+    /** Clones the metadata */
+    CameraMetadata(const CameraMetadata &other);
+
+    /**
+     * Assignment clones metadata buffer.
+     */
+    CameraMetadata &operator=(const CameraMetadata &other);
+    CameraMetadata &operator=(const camera_metadata_t *buffer);
+
+    /**
+     * Get reference to the underlying metadata buffer. Ownership remains with
+     * the CameraMetadata object, but non-const CameraMetadata methods will not
+     * work until unlock() is called. Note that the lock has nothing to do with
+     * thread-safety, it simply prevents the camera_metadata_t pointer returned
+     * here from being accidentally invalidated by CameraMetadata operations.
+     */
+    const camera_metadata_t* getAndLock() const;
+
+    /**
+     * Unlock the CameraMetadata for use again. After this unlock, the pointer
+     * given from getAndLock() may no longer be used. The pointer passed out
+     * from getAndLock must be provided to guarantee that the right object is
+     * being unlocked.
+     */
+    status_t unlock(const camera_metadata_t *buffer) const;
+
+    /**
+     * Release a raw metadata buffer to the caller. After this call,
+     * CameraMetadata no longer references the buffer, and the caller takes
+     * responsibility for freeing the raw metadata buffer (using
+     * free_camera_metadata()), or for handing it to another CameraMetadata
+     * instance.
+     */
+    camera_metadata_t* release();
+
+    /**
+     * Clear the metadata buffer and free all storage used by it
+     */
+    void clear();
+
+    /**
+     * Acquire a raw metadata buffer from the caller. After this call,
+     * the caller no longer owns the raw buffer, and must not free or manipulate it.
+     * If CameraMetadata already contains metadata, it is freed.
+     */
+    void acquire(camera_metadata_t* buffer);
+
+    /**
+     * Acquires raw buffer from other CameraMetadata object. After the call, the argument
+     * object no longer has any metadata.
+     */
+    void acquire(CameraMetadata &other);
+
+    /**
+     * Append metadata from another CameraMetadata object.
+     */
+    status_t append(const CameraMetadata &other);
+
+    /**
+     * Append metadata from a raw camera_metadata buffer
+     */
+    status_t append(const camera_metadata* other);
+
+    /**
+     * Number of metadata entries.
+     */
+    size_t entryCount() const;
+
+    /**
+     * Is the buffer empty (no entires)
+     */
+    bool isEmpty() const;
+
+    /**
+     * Sort metadata buffer for faster find
+     */
+    status_t sort();
+
+    /**
+     * Update metadata entry. Will create entry if it doesn't exist already, and
+     * will reallocate the buffer if insufficient space exists. Overloaded for
+     * the various types of valid data.
+     */
+    status_t update(uint32_t tag,
+            const uint8_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const int32_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const float *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const int64_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const double *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const camera_metadata_rational_t *data, size_t data_count);
+    status_t update(uint32_t tag,
+            const String8 &string);
+    status_t update(const camera_metadata_ro_entry &entry);
+
+
+    template<typename T>
+    status_t update(uint32_t tag, Vector<T> data) {
+        return update(tag, data.array(), data.size());
+    }
+
+    /**
+     * Check if a metadata entry exists for a given tag id
+     *
+     */
+    bool exists(uint32_t tag) const;
+
+    /**
+     * Get metadata entry by tag id
+     */
+    camera_metadata_entry find(uint32_t tag);
+
+    /**
+     * Get metadata entry by tag id, with no editing
+     */
+    camera_metadata_ro_entry find(uint32_t tag) const;
+
+    /**
+     * Delete metadata entry by tag
+     */
+    status_t erase(uint32_t tag);
+
+    /**
+     * Swap the underlying camera metadata between this and the other
+     * metadata object.
+     */
+    void swap(CameraMetadata &other);
+
+    /**
+     * Dump contents into FD for debugging. The verbosity levels are
+     * 0: Tag entry information only, no data values
+     * 1: Level 0 plus at most 16 data values per entry
+     * 2: All information
+     *
+     * The indentation parameter sets the number of spaces to add to the start
+     * each line of output.
+     */
+    void dump(int fd, int verbosity = 1, int indentation = 0) const;
+#if 0
+    /**
+     * Find tag id for a given tag name, also checking vendor tags if available.
+     * On success, returns OK and writes the tag id into tag.
+     *
+     * This is a slow method.
+     */
+    static status_t getTagFromName(const char *name,
+            const VendorTagDescriptor* vTags, uint32_t *tag);
+#endif
+  private:
+    camera_metadata_t *mBuffer;
+    mutable bool       mLocked;
+
+    /**
+     * Check if tag has a given type
+     */
+    status_t checkType(uint32_t tag, uint8_t expectedType);
+
+    /**
+     * Base update entry method
+     */
+    status_t updateImpl(uint32_t tag, const void *data, size_t data_count);
+
+    /**
+     * Resize metadata buffer if needed by reallocating it and copying it over.
+     */
+    status_t resizeIfNeeded(size_t extraEntries, size_t extraData);
+
+};
+
+#if 0
+} // namespace helper
+} // namespace V1_0
+} // namespace common
+} // namespace camera
+} // namespace hardware
+#endif
+} // namespace android
+
+#endif
diff --git a/hardware/ntimespace/camera/metadata/control.h b/hardware/ntimespace/camera/metadata/control.h
new file mode 100644
index 0000000000..3b7086fa1c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control.h
@@ -0,0 +1,221 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_H_
+
+#include <vector>
+
+#include <android-base/macros.h>
+#include <system/camera_metadata.h>
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+#include "tagged_control_delegate.h"
+#include "tagged_control_options.h"
+//#include <utils/CallStack.h>
+
+namespace v4l2_camera_hal {
+
+// A Control is a PartialMetadata with values that can be gotten/set.
+template <typename T>
+class Control : public PartialMetadataInterface {
+ public:
+  // Options are optional (i.e. nullable), delegate is not.
+  Control(std::unique_ptr<TaggedControlDelegate<T>> delegate,
+          std::unique_ptr<TaggedControlOptions<T>> options = nullptr);
+
+  virtual std::vector<int32_t> StaticTags() const override;
+  virtual std::vector<int32_t> ControlTags() const override;
+  virtual std::vector<int32_t> DynamicTags() const override;
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const override;
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const override;
+  virtual int SetRequestValues(
+      const android::CameraMetadata& metadata) override;
+
+ private:
+  std::unique_ptr<TaggedControlDelegate<T>> delegate_;
+  std::unique_ptr<TaggedControlOptions<T>> options_;
+
+  DISALLOW_COPY_AND_ASSIGN(Control);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+Control<T>::Control(std::unique_ptr<TaggedControlDelegate<T>> delegate,
+                    std::unique_ptr<TaggedControlOptions<T>> options)
+    : delegate_(std::move(delegate)), options_(std::move(options)) {}
+
+template <typename T>
+std::vector<int32_t> Control<T>::StaticTags() const {
+  std::vector<int32_t> result;
+  if (options_ && options_->tag() != DO_NOT_REPORT_OPTIONS) {
+    result.push_back(options_->tag());
+  }
+  return result;
+}
+
+template <typename T>
+std::vector<int32_t> Control<T>::ControlTags() const {
+  return {delegate_->tag()};
+}
+
+template <typename T>
+std::vector<int32_t> Control<T>::DynamicTags() const {
+  return {delegate_->tag()};
+}
+
+template <typename T>
+int Control<T>::PopulateStaticFields(android::CameraMetadata* metadata) const {
+  if (!options_) {
+    HAL_LOGV("No options for control %d, nothing to populate.",
+             delegate_->tag());
+    return 0;
+  } else if (options_->tag() == DO_NOT_REPORT_OPTIONS) {
+    HAL_LOGV(
+        "Options for control %d are not reported, "
+        "probably are set values defined and already known by the API.",
+        delegate_->tag());
+    return 0;
+  }
+
+  return UpdateMetadata(
+      metadata, options_->tag(), options_->MetadataRepresentation());
+}
+
+template <typename T>
+int Control<T>::PopulateDynamicFields(android::CameraMetadata* metadata) const {
+  // Populate the current setting.
+  T value;
+  int res = delegate_->GetValue(&value);
+  if (res) {
+    return res;
+  }
+  return UpdateMetadata(metadata, delegate_->tag(), value);
+}
+
+template <typename T>
+int Control<T>::PopulateTemplateRequest(
+    int template_type, android::CameraMetadata* metadata) const {
+  // Populate with a default.
+  T value;
+  int res;
+  if (options_) {
+    res = options_->DefaultValueForTemplate(template_type, &value);
+  } else {
+    // If there's no options (and thus no default option),
+    // fall back to whatever the current value is.
+    res = delegate_->GetValue(&value);
+  }
+  if (res) {
+    return res;
+  }
+
+  return UpdateMetadata(metadata, delegate_->tag(), value);
+}
+
+template <typename T>
+bool Control<T>::SupportsRequestValues(
+    const android::CameraMetadata& metadata) const {
+  if (metadata.isEmpty()) {
+    // Implicitly supported.
+    return true;
+  }
+
+  HAL_LOGV("Checking tag %d", delegate_->tag());
+
+  // Get the requested setting for this control.
+  T requested;
+  int res = SingleTagValue(metadata, delegate_->tag(), &requested);
+  if (res == -ENOENT) {
+    // Nothing requested of this control, that's fine.
+    return true;
+  } else if (res) {
+    HAL_LOGE("Failure while searching for request value for tag %d",
+             delegate_->tag());
+    return false;
+  }
+
+  // Check that the requested setting is in the supported options.
+  if (!options_) {
+    HAL_LOGV("No options for control %d; request implicitly supported.",
+             delegate_->tag());
+    return true;
+  }
+
+  bool ret = options_->IsSupported(requested);
+  if (!ret) {
+      /*
+      android::CallStack stack;
+      stack.update( );
+      stack.log("stack:");
+      */
+      HAL_LOGE("Checking tag %d fail, not supported.", delegate_->tag());
+      /*
+      HAL_LOGE("Dump metadata: /data/local/metadata.log");
+      
+      if (access("/data/local/metadata.log", F_OK|R_OK|W_OK) == 0) {
+          unlink("/data/local/metadata.log");
+      }
+      int fp = open("/data/local/metadata.log", O_CREAT |O_RDWR | O_CLOEXEC, 0);
+      if (fp != -1) {
+        metadata.dump(fp);
+      }
+      close(fp);
+      */
+  }
+
+  return ret;
+}
+
+template <typename T>
+int Control<T>::SetRequestValues(const android::CameraMetadata& metadata) {
+  if (metadata.isEmpty()) {
+    // No changes necessary.
+    return 0;
+  }
+
+  // Get the requested value.
+  T requested;
+  int res = SingleTagValue(metadata, delegate_->tag(), &requested);
+  if (res == -ENOENT) {
+    // Nothing requested of this control, nothing to do.
+    return 0;
+  } else if (res) {
+    HAL_LOGE("Failure while searching for request value for tag %d",
+             delegate_->tag());
+    return res;
+  }
+
+  // Check that the value is supported.
+  if (options_ && !options_->IsSupported(requested)) {
+    HAL_LOGE("Unsupported value requested for control %d.", delegate_->tag());
+    return -EINVAL;
+  }
+
+  return delegate_->SetValue(requested);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_H_
diff --git a/hardware/ntimespace/camera/metadata/control_delegate_interface.h b/hardware/ntimespace/camera/metadata/control_delegate_interface.h
new file mode 100644
index 0000000000..8896e7255e
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_delegate_interface.h
@@ -0,0 +1,41 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
+
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A ControlDelegate extends StateDelegate with a setter method.
+template <typename T>
+class ControlDelegateInterface : public StateDelegateInterface<T> {
+ public:
+  virtual ~ControlDelegateInterface(){};
+
+  // ControlDelegates are allowed to be unreliable, so SetValue is best-effort;
+  // GetValue immediately after may not match (SetValue may, for example,
+  // automatically replace invalid values with valid ones,
+  // or have a delay before setting the requested value).
+  // Returns 0 on success, error code on failure.
+  virtual int SetValue(const T& value) = 0;
+  // Children must also override GetValue from StateDelegateInterface.
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h b/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
new file mode 100644
index 0000000000..9a0ca0446f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_delegate_interface_mock.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for control delegate interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
+
+#include "control_delegate_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class ControlDelegateInterfaceMock : public ControlDelegateInterface<T> {
+ public:
+  ControlDelegateInterfaceMock(){};
+  MOCK_METHOD1_T(GetValue, int(T*));
+  MOCK_METHOD1_T(SetValue, int(const T&));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/control_options_interface.h b/hardware/ntimespace/camera/metadata/control_options_interface.h
new file mode 100644
index 0000000000..438cefa502
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_options_interface.h
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
+
+#include <vector>
+
+namespace v4l2_camera_hal {
+
+// A ControlOptions defines acceptable values for a control.
+template <typename T>
+class ControlOptionsInterface {
+ public:
+  virtual ~ControlOptionsInterface(){};
+
+  // Get a metadata-acceptable representation of the options.
+  // For enums this will be a list of values, for ranges this
+  // will be min and max, etc.
+  virtual std::vector<T> MetadataRepresentation() = 0;
+  // Get whether or not a given value is acceptable.
+  virtual bool IsSupported(const T& option);
+  // Get a default option for a given template type, from the available options.
+  // Because a default must be available, any ControlOptions should have at
+  // least one supported value.
+  virtual int DefaultValueForTemplate(int template_type, T* default_value);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/control_options_interface_mock.h b/hardware/ntimespace/camera/metadata/control_options_interface_mock.h
new file mode 100644
index 0000000000..2492880c6f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_options_interface_mock.h
@@ -0,0 +1,39 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for control options interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
+
+#include "control_options_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class ControlOptionsInterfaceMock : public ControlOptionsInterface<T> {
+ public:
+  ControlOptionsInterfaceMock(){};
+  MOCK_METHOD0_T(MetadataRepresentation, std::vector<T>());
+  MOCK_METHOD1_T(IsSupported, bool(const T&));
+  MOCK_METHOD2_T(DefaultValueForTemplate, int(int, T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/control_test.cpp b/hardware/ntimespace/camera/metadata/control_test.cpp
new file mode 100644
index 0000000000..d7ebe3212b
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/control_test.cpp
@@ -0,0 +1,458 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "control.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_delegate_interface_mock.h"
+#include "control_options_interface_mock.h"
+#include "metadata_common.h"
+#include "test_common.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class ControlTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new ControlDelegateInterfaceMock<uint8_t>());
+    mock_options_.reset(new ControlOptionsInterfaceMock<uint8_t>());
+    // Nullify control so an error will be thrown if a test doesn't call
+    // PrepareControl.
+    control_.reset();
+  }
+
+  virtual void PrepareControl() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the mocks
+    // to the device.
+    std::unique_ptr<TaggedControlDelegate<uint8_t>> delegate =
+        std::make_unique<TaggedControlDelegate<uint8_t>>(
+            delegate_tag_, std::move(mock_delegate_));
+    std::unique_ptr<TaggedControlOptions<uint8_t>> options =
+        std::make_unique<TaggedControlOptions<uint8_t>>(
+            report_options_ ? options_tag_ : DO_NOT_REPORT_OPTIONS,
+            std::move(mock_options_));
+    if (use_options_) {
+      control_.reset(
+          new Control<uint8_t>(std::move(delegate), std::move(options)));
+    } else {
+      control_.reset(new Control<uint8_t>(std::move(delegate)));
+    }
+  }
+
+  virtual void ExpectTags() {
+    if (use_options_ && report_options_) {
+      ASSERT_EQ(control_->StaticTags().size(), 1u);
+      EXPECT_EQ(control_->StaticTags()[0], options_tag_);
+    } else {
+      EXPECT_TRUE(control_->StaticTags().empty());
+    }
+    // Controls use the same delgate, and thus tag, for getting and setting.
+    ASSERT_EQ(control_->ControlTags().size(), 1u);
+    EXPECT_EQ(control_->ControlTags()[0], delegate_tag_);
+    ASSERT_EQ(control_->DynamicTags().size(), 1u);
+    EXPECT_EQ(control_->DynamicTags()[0], delegate_tag_);
+  }
+
+  virtual void ExpectOptions(const std::vector<uint8_t>& options) {
+    // Options should be available.
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateStaticFields(&metadata), 0);
+    if (use_options_ && report_options_) {
+      EXPECT_EQ(metadata.entryCount(), 1u);
+      ExpectMetadataEq(metadata, options_tag_, options);
+    } else {
+      EXPECT_EQ(metadata.entryCount(), 0u);
+      // Shouldn't be expecting any options.
+      EXPECT_TRUE(options.empty());
+    }
+  }
+
+  virtual void ExpectValue(uint8_t value) {
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateDynamicFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, delegate_tag_, value);
+  }
+
+  std::unique_ptr<Control<uint8_t>> control_;
+  std::unique_ptr<ControlDelegateInterfaceMock<uint8_t>> mock_delegate_;
+  std::unique_ptr<ControlOptionsInterfaceMock<uint8_t>> mock_options_;
+  bool use_options_ = true;
+  bool report_options_ = true;
+
+  // Need tags that match the data type (uint8_t) being passed.
+  const int32_t delegate_tag_ = ANDROID_COLOR_CORRECTION_ABERRATION_MODE;
+  const int32_t options_tag_ =
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES;
+};
+
+TEST_F(ControlTest, Tags) {
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, TagsNoOptions) {
+  use_options_ = false;
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, TagsUnreportedOptions) {
+  report_options_ = false;
+  PrepareControl();
+  ExpectTags();
+}
+
+TEST_F(ControlTest, PopulateStatic) {
+  std::vector<uint8_t> expected{1, 10, 20};
+  EXPECT_CALL(*mock_options_, MetadataRepresentation())
+      .WillOnce(Return(expected));
+  PrepareControl();
+  ExpectOptions(expected);
+}
+
+TEST_F(ControlTest, PopulateStaticNoOptions) {
+  use_options_ = false;
+  PrepareControl();
+  ExpectOptions({});
+}
+
+TEST_F(ControlTest, PopulateStaticUnreportedOptions) {
+  report_options_ = false;
+  PrepareControl();
+  ExpectOptions({});
+}
+
+TEST_F(ControlTest, PopulateDynamic) {
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicNoOptions) {
+  // Lack of options shouldn't change anything for PopulateDynamic.
+  use_options_ = false;
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicUnreportedOptions) {
+  // Lack of reported options shouldn't change anything for PopulateDynamic.
+  report_options_ = false;
+  uint8_t test_option = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(test_option), Return(0)));
+  PrepareControl();
+  ExpectValue(test_option);
+}
+
+TEST_F(ControlTest, PopulateDynamicFail) {
+  int err = -99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateDynamicFields(&metadata), err);
+
+  // Should not have added an entry.
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(ControlTest, PopulateTemplate) {
+  int template_type = 3;
+  uint8_t default_value = 123;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, default_value);
+}
+
+TEST_F(ControlTest, PopulateTemplateFail) {
+  int template_type = 3;
+  int err = 10;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, PopulateTemplateOptionless) {
+  use_options_ = false;
+  int template_type = 3;
+  uint8_t value = 12;
+  // Should use delegate instead of options if no options.
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, value);
+}
+
+TEST_F(ControlTest, PopulateTemplateOptionlessFail) {
+  use_options_ = false;
+  int template_type = 3;
+  int err = 10;
+  // Should use delegate instead of options if no options.
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, PopulateTemplateUnreportedOptions) {
+  report_options_ = false;
+  int template_type = 3;
+  uint8_t default_value = 123;
+  // Unreported options should behave just like reported ones for templating.
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_value), Return(0)));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), 0);
+  ExpectMetadataEq(metadata, delegate_tag_, default_value);
+}
+
+TEST_F(ControlTest, PopulateTemplateUnreportedOptionsFail) {
+  report_options_ = false;
+  int template_type = 3;
+  int err = 10;
+  // Unreported options should behave just like reported ones for templating.
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_type, _))
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(control_->PopulateTemplateRequest(template_type, &metadata), err);
+}
+
+TEST_F(ControlTest, SupportsRequest) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(true));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestNoOptions) {
+  use_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestUnreportedOptions) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(true));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SupportsRequestFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestUnreportedOptionsFail) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // Unreported options should still be checked against.
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestInvalidNumber) {
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+  PrepareControl();
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestInvalidNumberNoOptions) {
+  use_options_ = false;
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+  PrepareControl();
+  // Not having any explicit options does not exempt a control
+  // from requiring the right number of values.
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), false);
+}
+
+TEST_F(ControlTest, SupportsRequestEmpty) {
+  android::CameraMetadata metadata;
+  PrepareControl();
+  EXPECT_EQ(control_->SupportsRequestValues(metadata), true);
+}
+
+TEST_F(ControlTest, SetRequest) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestNoOptions) {
+  use_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // No options, no validation check.
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option)).WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestUnreportedOptions) {
+  report_options_ = false;
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  // Unreported options still get a validation check.
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(0));
+  PrepareControl();
+
+  // Make the request.
+  ASSERT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(ControlTest, SetRequestSettingFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  int err = 99;
+  Expectation validation_check =
+      EXPECT_CALL(*mock_options_, IsSupported(test_option))
+          .WillOnce(Return(true));
+  EXPECT_CALL(*mock_delegate_, SetValue(test_option))
+      .After(validation_check)
+      .WillOnce(Return(err));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SetRequestValues(metadata), err);
+}
+
+TEST_F(ControlTest, SetRequestValidationFail) {
+  android::CameraMetadata metadata;
+  uint8_t test_option = 123;
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_option), 0);
+
+  EXPECT_CALL(*mock_options_, IsSupported(test_option)).WillOnce(Return(false));
+  PrepareControl();
+
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestInvalidNumber) {
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+
+  PrepareControl();
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestInvalidNumberNoOptions) {
+  use_options_ = false;
+  // Start with a request for multiple values.
+  android::CameraMetadata metadata;
+  std::vector<uint8_t> test_data = {1, 2, 3};
+  ASSERT_EQ(UpdateMetadata(&metadata, delegate_tag_, test_data), 0);
+
+  PrepareControl();
+  // Not having explicit options does not change that an incorrect
+  // number of values is invalid.
+  EXPECT_EQ(control_->SetRequestValues(metadata), -EINVAL);
+}
+
+TEST_F(ControlTest, SetRequestEmpty) {
+  // Should do nothing.
+  android::CameraMetadata metadata;
+  PrepareControl();
+  EXPECT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/converter_interface.h b/hardware/ntimespace/camera/metadata/converter_interface.h
new file mode 100644
index 0000000000..fa960e910d
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/converter_interface.h
@@ -0,0 +1,35 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
+
+namespace v4l2_camera_hal {
+
+// A ConverterInterface converts metadata values to V4L2 values vice-versa.
+template <typename TMetadata, typename TV4L2>
+class ConverterInterface {
+ public:
+  virtual ~ConverterInterface(){};
+
+  // Convert.
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) = 0;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/converter_interface_mock.h b/hardware/ntimespace/camera/metadata/converter_interface_mock.h
new file mode 100644
index 0000000000..19d618ada6
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/converter_interface_mock.h
@@ -0,0 +1,38 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for converter interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
+
+#include "converter_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename TMetadata, typename TV4L2>
+class ConverterInterfaceMock : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  ConverterInterfaceMock(){};
+  MOCK_METHOD2_T(MetadataToV4L2, int(TMetadata, TV4L2*));
+  MOCK_METHOD2_T(V4L2ToMetadata, int(TV4L2, TMetadata*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONVERTER_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate.h b/hardware/ntimespace/camera/metadata/default_option_delegate.h
new file mode 100644
index 0000000000..d3d66c5ca8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate.h
@@ -0,0 +1,60 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
+
+#include <map>
+
+#include <hardware/camera3.h>
+
+namespace v4l2_camera_hal {
+
+// A constant that can be used to identify an overall default.
+static constexpr int OTHER_TEMPLATES = CAMERA3_TEMPLATE_COUNT;
+
+// DefaultingOptionDelegate provides an interface to get default options from.
+template <typename T>
+class DefaultOptionDelegate {
+ public:
+  // |defaults| maps template types to default values
+  DefaultOptionDelegate(std::map<int, T> defaults)
+      : defaults_(std::move(defaults)){};
+  virtual ~DefaultOptionDelegate(){};
+
+  // Get a default value for a template type. Returns false if no default
+  // provided.
+  virtual bool DefaultValueForTemplate(int template_type, T* default_value) {
+    if (defaults_.count(template_type) > 0) {
+      // Best option is template-specific.
+      *default_value = defaults_[template_type];
+      return true;
+    } else if (defaults_.count(OTHER_TEMPLATES)) {
+      // Fall back to a general default.
+      *default_value = defaults_[OTHER_TEMPLATES];
+      return true;
+    }
+
+    return false;
+  };
+
+ private:
+  std::map<int, T> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h b/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
new file mode 100644
index 0000000000..6b80071880
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate_mock.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for default option delegates.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
+
+#include "default_option_delegate.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class DefaultOptionDelegateMock : public DefaultOptionDelegate<T> {
+ public:
+  DefaultOptionDelegateMock() : DefaultOptionDelegate<T>({}){};
+  MOCK_METHOD2_T(DefaultValueForTemplate, bool(int, T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_DEFAULT_OPTION_DELEGATE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp b/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
new file mode 100644
index 0000000000..7b61dd454a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/default_option_delegate_test.cpp
@@ -0,0 +1,62 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "default_option_delegate.h"
+
+#include <memory>
+
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class DefaultOptionDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    dut_.reset(new DefaultOptionDelegate<int>(defaults_));
+  }
+
+  std::unique_ptr<DefaultOptionDelegate<int>> dut_;
+  std::map<int, int> defaults_{{CAMERA3_TEMPLATE_STILL_CAPTURE, 10},
+                               {OTHER_TEMPLATES, 20},
+                               {CAMERA3_TEMPLATE_VIDEO_SNAPSHOT, 30}};
+};
+
+TEST_F(DefaultOptionDelegateTest, SpecificDefault) {
+  int actual = 0;
+  EXPECT_TRUE(
+      dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_STILL_CAPTURE, &actual));
+  EXPECT_EQ(actual, defaults_[CAMERA3_TEMPLATE_STILL_CAPTURE]);
+}
+
+TEST_F(DefaultOptionDelegateTest, GeneralDefault) {
+  int actual = 0;
+  // No ZSL default; should fall back to the OTHER_TEMPLATES default.
+  EXPECT_TRUE(dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+                                            &actual));
+  EXPECT_EQ(actual, defaults_[OTHER_TEMPLATES]);
+}
+
+TEST_F(DefaultOptionDelegateTest, NoDefaults) {
+  dut_.reset(new DefaultOptionDelegate<int>({}));
+  int actual = 0;
+  EXPECT_FALSE(dut_->DefaultValueForTemplate(CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+                                             &actual));
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/enum_converter.cpp b/hardware/ntimespace/camera/metadata/enum_converter.cpp
new file mode 100644
index 0000000000..580e7e1a1a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter.cpp
@@ -0,0 +1,81 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "EnumConverter"
+
+#include "enum_converter.h"
+
+#include <cerrno>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+EnumConverter::EnumConverter(
+    const std::multimap<int32_t, uint8_t>& v4l2_to_metadata)
+    : v4l2_to_metadata_(v4l2_to_metadata) {
+  HAL_LOG_ENTER();
+}
+
+int EnumConverter::MetadataToV4L2(uint8_t value, int32_t* conversion) {
+  // Unfortunately no bi-directional map lookup in C++.
+  // Breaking on second, not first found so that a warning
+  // can be given if there are multiple values.
+  size_t count = 0;
+  for (auto kv : v4l2_to_metadata_) {
+    if (kv.second == value) {
+      ++count;
+      if (count == 1) {
+        // First match.
+        *conversion = kv.first;
+      } else {
+        // second match.
+        break;
+      }
+    }
+  }
+
+  if (count == 0) {
+    HAL_LOGV("Couldn't find V4L2 conversion of metadata value %d.", value);
+    return -EINVAL;
+  } else if (count > 1) {
+    HAL_LOGV(
+        "Multiple V4L2 conversions found for metadata value %d, using first.",
+        value);
+  }
+  return 0;
+}
+
+int EnumConverter::V4L2ToMetadata(int32_t value, uint8_t* conversion) {
+  auto element_range = v4l2_to_metadata_.equal_range(value);
+  if (element_range.first == element_range.second) {
+    HAL_LOGV("Couldn't find metadata conversion of V4L2 value %d.", value);
+    return -EINVAL;
+  }
+
+  auto element = element_range.first;
+  *conversion = element->second;
+
+  if (++element != element_range.second) {
+    HAL_LOGV(
+        "Multiple metadata conversions found for V4L2 value %d, using first.",
+        value);
+  }
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/enum_converter.h b/hardware/ntimespace/camera/metadata/enum_converter.h
new file mode 100644
index 0000000000..855f4306a7
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
+
+#include <map>
+
+#include <android-base/macros.h>
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An EnumConverter converts between enum values.
+class EnumConverter : public ConverterInterface<uint8_t, int32_t> {
+ public:
+  EnumConverter(const std::multimap<int32_t, uint8_t>& v4l2_to_metadata);
+
+  virtual int MetadataToV4L2(uint8_t value, int32_t* conversion) override;
+  virtual int V4L2ToMetadata(int32_t value, uint8_t* conversion) override;
+
+ private:
+  const std::multimap<int32_t, uint8_t> v4l2_to_metadata_;
+
+  DISALLOW_COPY_AND_ASSIGN(EnumConverter);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_ENUM_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/enum_converter_test.cpp b/hardware/ntimespace/camera/metadata/enum_converter_test.cpp
new file mode 100644
index 0000000000..1f27884bdb
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/enum_converter_test.cpp
@@ -0,0 +1,99 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "enum_converter.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class EnumConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(
+        new EnumConverter({{one_to_one_v4l2_, one_to_one_metadata_},
+                           {one_to_many_v4l2_, many_to_one_metadata_1_},
+                           {one_to_many_v4l2_, many_to_one_metadata_2_},
+                           {many_to_one_v4l2_1_, one_to_many_metadata_},
+                           {many_to_one_v4l2_2_, one_to_many_metadata_},
+                           {unused_v4l2_, unused_metadata_}}));
+  }
+
+  std::unique_ptr<EnumConverter> converter_;
+
+  const int32_t one_to_one_v4l2_ = 12;
+  const int32_t one_to_many_v4l2_ = 34;
+  const int32_t many_to_one_v4l2_1_ = 56;
+  const int32_t many_to_one_v4l2_2_ = 78;
+  const int32_t unused_v4l2_ = 910;
+  const uint8_t one_to_one_metadata_ = 109;
+  const uint8_t one_to_many_metadata_ = 87;
+  const uint8_t many_to_one_metadata_1_ = 65;
+  const uint8_t many_to_one_metadata_2_ = 43;
+  const uint8_t unused_metadata_ = 21;
+};
+
+// Convert single.
+TEST_F(EnumConverterTest, OneToOneConversion) {
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(one_to_one_v4l2_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_one_metadata_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(one_to_one_metadata_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_one_v4l2_);
+}
+
+TEST_F(EnumConverterTest, OneToManyConversion) {
+  // Should be one of the acceptable values.
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(one_to_many_v4l2_, &metadata_val), 0);
+  EXPECT_TRUE(metadata_val == many_to_one_metadata_1_ ||
+              metadata_val == many_to_one_metadata_2_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(one_to_many_metadata_, &v4l2_val), 0);
+  EXPECT_TRUE(v4l2_val == many_to_one_v4l2_1_ ||
+              v4l2_val == many_to_one_v4l2_2_);
+}
+
+TEST_F(EnumConverterTest, ManyToOneConversion) {
+  uint8_t metadata_val = 1;
+  ASSERT_EQ(converter_->V4L2ToMetadata(many_to_one_v4l2_1_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_many_metadata_);
+  metadata_val = 1;  // Reset.
+  ASSERT_EQ(converter_->V4L2ToMetadata(many_to_one_v4l2_2_, &metadata_val), 0);
+  EXPECT_EQ(metadata_val, one_to_many_metadata_);
+
+  int32_t v4l2_val = 1;
+  ASSERT_EQ(converter_->MetadataToV4L2(many_to_one_metadata_1_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_many_v4l2_);
+  v4l2_val = 1;  // Reset.
+  ASSERT_EQ(converter_->MetadataToV4L2(many_to_one_metadata_2_, &v4l2_val), 0);
+  EXPECT_EQ(v4l2_val, one_to_many_v4l2_);
+}
+
+TEST_F(EnumConverterTest, InvalidConversion) {
+  uint8_t metadata_val = 1;
+  EXPECT_EQ(converter_->V4L2ToMetadata(1, &metadata_val), -EINVAL);
+
+  int32_t v4l2_val = 1;
+  EXPECT_EQ(converter_->MetadataToV4L2(1, &v4l2_val), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/ignored_control_delegate.h b/hardware/ntimespace/camera/metadata/ignored_control_delegate.h
new file mode 100644
index 0000000000..dce457b1df
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ignored_control_delegate.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An IgnoredControlDelegate, as the name implies,
+// has a fixed value and ignores all requests to set it.
+template <typename T>
+class IgnoredControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  IgnoredControlDelegate(T value) : value_(value){};
+
+  int GetValue(T* value) override {
+    *value = value_;
+    return 0;
+  };
+  int SetValue(const T& /*value*/) override { return 0; };
+
+ private:
+  const T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_IGNORED_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
new file mode 100644
index 0000000000..80c30df93c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ignored_control_delegate_test.cpp
@@ -0,0 +1,44 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "ignored_control_delegate.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+TEST(IgnoredControlDelegateTest, DefaultGet) {
+  int32_t value = 12;
+  IgnoredControlDelegate<int32_t> control(value);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST(IgnoredControlDelegateTest, GetAndSet) {
+  int32_t value = 12;
+  IgnoredControlDelegate<int32_t> control(value);
+  int32_t new_value = 13;
+  ASSERT_EQ(control.SetValue(new_value), 0);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  // Should still be the default.
+  EXPECT_EQ(actual, value);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/map_converter.h b/hardware/ntimespace/camera/metadata/map_converter.h
new file mode 100644
index 0000000000..aa11981898
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/map_converter.h
@@ -0,0 +1,139 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
+
+#include <cerrno>
+#include <map>
+#include <memory>
+
+#include <android-base/macros.h>
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A MapConverter fits values converted by a wrapped converter
+// to a map entry corresponding to the key with the nearest value.
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+class MapConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  MapConverter(
+      std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter,
+      std::map<TMapKey, TV4L2> conversion_map);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter_;
+  std::map<TMapKey, TV4L2> conversion_map_;
+
+  DISALLOW_COPY_AND_ASSIGN(MapConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+MapConverter<TMetadata, TV4L2, TMapKey>::MapConverter(
+    std::shared_ptr<ConverterInterface<TMetadata, TMapKey>> wrapped_converter,
+    std::map<TMapKey, TV4L2> conversion_map)
+    : wrapped_converter_(std::move(wrapped_converter)),
+      conversion_map_(conversion_map) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+int MapConverter<TMetadata, TV4L2, TMapKey>::MetadataToV4L2(TMetadata value,
+                                                            TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  if (conversion_map_.empty()) {
+    HAL_LOGE("Empty conversion map.");
+    return -EINVAL;
+  }
+
+  TMapKey raw_conversion = 0;
+  int res = wrapped_converter_->MetadataToV4L2(value, &raw_conversion);
+  if (res) {
+    HAL_LOGE("Failed to perform underlying conversion.");
+    return res;
+  }
+
+  // Find nearest key.
+  auto kv = conversion_map_.lower_bound(raw_conversion);
+  // lower_bound finds the first >= element.
+  if (kv == conversion_map_.begin()) {
+    // Searching for less than the smallest key, so that will be the nearest.
+    *conversion = kv->second;
+  } else if (kv == conversion_map_.end()) {
+    // Searching for greater than the largest key, so that will be the nearest.
+    --kv;
+    *conversion = kv->second;
+  } else {
+    // Since kv points to the first >= element, either that or the previous
+    // element will be nearest.
+    *conversion = kv->second;
+    TMapKey diff = kv->first - raw_conversion;
+
+    // Now compare to the previous. This element will be < raw conversion,
+    // so reverse the order of the subtraction.
+    --kv;
+    if (raw_conversion - kv->first < diff) {
+      *conversion = kv->second;
+    }
+  }
+
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2, typename TMapKey>
+int MapConverter<TMetadata, TV4L2, TMapKey>::V4L2ToMetadata(
+    TV4L2 value, TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  // Unfortunately no bi-directional map lookup in C++.
+  // Breaking on second, not first found so that a warning
+  // can be given if there are multiple values.
+  size_t count = 0;
+  int res;
+  for (auto kv : conversion_map_) {
+    if (kv.second == value) {
+      ++count;
+      if (count == 1) {
+        // First match.
+        res = wrapped_converter_->V4L2ToMetadata(kv.first, conversion);
+      } else {
+        // second match.
+        break;
+      }
+    }
+  }
+
+  if (count == 0) {
+    HAL_LOGE("Couldn't find map conversion of V4L2 value %d.", value);
+    return -EINVAL;
+  } else if (count > 1) {
+    HAL_LOGW("Multiple map conversions found for V4L2 value %d, using first.",
+             value);
+  }
+  return res;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_MAP_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/map_converter_test.cpp b/hardware/ntimespace/camera/metadata/map_converter_test.cpp
new file mode 100644
index 0000000000..0361810725
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/map_converter_test.cpp
@@ -0,0 +1,110 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "map_converter.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MapConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(new ConverterInterfaceMock<int, int32_t>());
+    dut_.reset(new MapConverter<int, int32_t, int32_t>(converter_, map_));
+  }
+
+  virtual void ExpectConvertToV4L2(int32_t converted, int32_t expected) {
+    int initial = 99;
+    EXPECT_CALL(*converter_, MetadataToV4L2(initial, _))
+        .WillOnce(DoAll(SetArgPointee<1>(converted), Return(0)));
+
+    int32_t actual = expected + 1;  // Initialize to non-expected value.
+    ASSERT_EQ(dut_->MetadataToV4L2(initial, &actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+
+  std::shared_ptr<ConverterInterfaceMock<int, int32_t>> converter_;
+  std::unique_ptr<MapConverter<int, int32_t, int32_t>> dut_;
+
+  const std::map<int32_t, int32_t> map_{{10, 1}, {40, 4}, {20, 2}, {30, 3}};
+};
+
+TEST_F(MapConverterTest, NormalConversionToV4L2) {
+  // A value that matches the map perfectly.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first, kv->second);
+}
+
+TEST_F(MapConverterTest, RoundingDownConversionToV4L2) {
+  // A value that's in range but not an exact key value.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first + 1, kv->second);
+}
+
+TEST_F(MapConverterTest, RoundingUpConversionToV4L2) {
+  // A value that's in range but not an exact key value.
+  auto kv = map_.begin();
+  ++kv;
+  ExpectConvertToV4L2(kv->first - 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ClampUpConversionToV4L2) {
+  // A value that's below range.
+  auto kv = map_.begin();
+  ExpectConvertToV4L2(kv->first - 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ClampDownConversionToV4L2) {
+  // A value that's above range (even after fitting to step).
+  auto kv = map_.rbegin();
+  ExpectConvertToV4L2(kv->first + 1, kv->second);
+}
+
+TEST_F(MapConverterTest, ConversionErrorToV4L2) {
+  int initial = 99;
+  int err = -99;
+  EXPECT_CALL(*converter_, MetadataToV4L2(initial, _)).WillOnce(Return(err));
+
+  int32_t unused;
+  EXPECT_EQ(dut_->MetadataToV4L2(initial, &unused), err);
+}
+
+TEST_F(MapConverterTest, NormalConversionToMetadata) {
+  auto kv = map_.begin();
+  int expected = 99;
+  EXPECT_CALL(*converter_, V4L2ToMetadata(kv->first, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(0)));
+
+  int actual = expected + 1;  // Initialize to non-expected value.
+  ASSERT_EQ(dut_->V4L2ToMetadata(kv->second, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MapConverterTest, NotFoundConversionToMetadata) {
+  int unused;
+  ASSERT_EQ(dut_->V4L2ToMetadata(100, &unused), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/menu_control_options.h b/hardware/ntimespace/camera/metadata/menu_control_options.h
new file mode 100644
index 0000000000..03f31aec04
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/menu_control_options.h
@@ -0,0 +1,77 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
+
+#include <cerrno>
+
+#include "common.h"
+#include "control_options_interface.h"
+#include "default_option_delegate.h"
+
+namespace v4l2_camera_hal {
+
+// MenuControlOptions offer a fixed list of acceptable values.
+template <typename T>
+class MenuControlOptions : public ControlOptionsInterface<T> {
+ public:
+  // |options| must be non-empty.
+  MenuControlOptions(std::vector<T> options,
+                     std::shared_ptr<DefaultOptionDelegate<T>> defaults)
+      : options_(options), defaults_(defaults){};
+  MenuControlOptions(std::vector<T> options, std::map<int, T> defaults)
+      : options_(options),
+        defaults_(std::make_shared<DefaultOptionDelegate<T>>(defaults)){};
+
+  virtual std::vector<T> MetadataRepresentation() override { return options_; };
+  virtual bool IsSupported(const T& option) override {
+    HAL_LOG_ENTER();
+    bool ret = (std::find(options_.begin(), options_.end(), option) !=
+            options_.end());
+    if (!ret) {
+      HAL_LOGV("fail");
+    }
+
+    return ret;
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    // Default to the first option.
+    if (options_.empty()) {
+      HAL_LOGE("Can't get default value, options are empty.");
+      return -ENODEV;
+    }
+
+    // Try to get it from the defaults delegate.
+    if (defaults_->DefaultValueForTemplate(template_type, default_value) &&
+        IsSupported(*default_value)) {
+      return 0;
+    }
+
+    // Fall back to the first available.
+    *default_value = options_[0];
+    return 0;
+  };
+
+ private:
+  std::vector<T> options_;
+  std::shared_ptr<DefaultOptionDelegate<T>> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_MENU_CONTROL_OPTIONS_H_
diff --git a/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp b/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
new file mode 100644
index 0000000000..b8eea74a82
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/menu_control_options_test.cpp
@@ -0,0 +1,108 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "menu_control_options.h"
+
+#include <memory>
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "default_option_delegate_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MenuControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_defaults_.reset(new DefaultOptionDelegateMock<int>());
+    dut_.reset(new MenuControlOptions<int>(options_, mock_defaults_));
+  }
+
+  std::unique_ptr<MenuControlOptions<int>> dut_;
+  const std::vector<int> options_{1, 10, 19, 30};
+  std::shared_ptr<DefaultOptionDelegateMock<int>> mock_defaults_;
+};
+
+TEST_F(MenuControlOptionsTest, MetadataRepresentation) {
+  // Technically order doesn't matter, but this is faster to write,
+  // and still passes.
+  EXPECT_EQ(dut_->MetadataRepresentation(), options_);
+}
+
+TEST_F(MenuControlOptionsTest, IsSupported) {
+  for (auto option : options_) {
+    EXPECT_TRUE(dut_->IsSupported(option));
+  }
+  // And at least one unsupported.
+  EXPECT_FALSE(dut_->IsSupported(99));
+}
+
+TEST_F(MenuControlOptionsTest, DelegateDefaultValue) {
+  int template_index = 3;
+  int expected = options_[2];
+  ASSERT_TRUE(dut_->IsSupported(expected));
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(true)));
+  int actual = expected - 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MenuControlOptionsTest, InvalidDelegateDefaultValue) {
+  // -1 is not a supported option.
+  int template_index = 3;
+  int default_val = -1;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  // Should just give any supported option instead.
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(MenuControlOptionsTest, NoDelegateDefaultValue) {
+  int template_index = 3;
+  int actual = -1;
+  ASSERT_FALSE(dut_->IsSupported(actual));
+
+  // Have delegate error.
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(Return(false));
+
+  // Should still give *some* supported value.
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(MenuControlOptionsTest, NoDefaultValue) {
+  // Invalid options don't have a valid default.
+  MenuControlOptions<int> bad_options({}, mock_defaults_);
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    int value = -1;
+    EXPECT_EQ(bad_options.DefaultValueForTemplate(i, &value), -ENODEV);
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata.cpp b/hardware/ntimespace/camera/metadata/metadata.cpp
new file mode 100644
index 0000000000..503faba5a0
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata.cpp
@@ -0,0 +1,232 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "Metadata"
+
+#include "metadata.h"
+
+#include <hardware/camera3.h>
+
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+Metadata::Metadata(PartialMetadataSet components)
+    : components_(std::move(components)) {
+  HAL_LOG_ENTER();
+}
+
+Metadata::~Metadata() {
+  HAL_LOG_ENTER();
+}
+
+int Metadata::FillStaticMetadata(android::CameraMetadata* metadata) {
+  HAL_LOG_ENTER();
+  if (!metadata) {
+    HAL_LOGE("Can't fill null metadata.");
+    return -EINVAL;
+  }
+
+  std::vector<int32_t> static_tags;
+  std::vector<int32_t> control_tags;
+  std::vector<int32_t> dynamic_tags;
+  int res = 0;
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    // Populate the fields.
+    res = component->PopulateStaticFields(&additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all static properties.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all static properties.");
+        return res;
+      }
+    }
+
+    // Note what tags the component adds.
+    std::vector<int32_t> tags = component->StaticTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(static_tags, static_tags.end()));
+    tags = component->ControlTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(control_tags, control_tags.end()));
+    tags = component->DynamicTags();
+    std::move(tags.begin(),
+              tags.end(),
+              std::inserter(dynamic_tags, dynamic_tags.end()));
+  }
+
+  // Populate the meta fields.
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS, control_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add request keys meta key.");
+    return -ENODEV;
+  }
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_RESULT_KEYS, dynamic_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add result keys meta key.");
+    return -ENODEV;
+  }
+  static_tags.push_back(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS);
+  res = UpdateMetadata(
+      metadata, ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS, static_tags);
+  if (res != android::OK) {
+    HAL_LOGE("Failed to add characteristics keys meta key.");
+    return -ENODEV;
+  }
+
+  // TODO(b/31018853): cache result.
+  return 0;
+}
+
+bool Metadata::IsValidRequest(const android::CameraMetadata& metadata) {
+  HAL_LOG_ENTER();
+
+  // Empty means "use previous settings", which are inherently valid.
+  if (metadata.isEmpty())
+    return true;
+
+  for (auto& component : components_) {
+    // Check that all components support the values requested of them.
+    bool valid_request = component->SupportsRequestValues(metadata);
+    if (!valid_request) {
+      // Exit early if possible.
+      return false;
+    }
+  }
+
+  return true;
+}
+
+int Metadata::GetRequestTemplate(int template_type,
+                                 android::CameraMetadata* template_metadata) {
+  HAL_LOG_ENTER();
+  if (!template_metadata) {
+    HAL_LOGE("Can't fill null template.");
+    return -EINVAL;
+  }
+
+  // Templates are numbered 1 through COUNT-1 for some reason.
+  if (template_type < 1 || template_type >= CAMERA3_TEMPLATE_COUNT) {
+    HAL_LOGE("Unrecognized template type %d.", template_type);
+    return -EINVAL;
+  }
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    int res =
+        component->PopulateTemplateRequest(template_type, &additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all default request fields.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = template_metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all default request fields.");
+        return res;
+      }
+    }
+  }
+
+  // TODO(b/31018853): cache result.
+  return 0;
+}
+
+int Metadata::SetRequestSettings(const android::CameraMetadata& metadata) {
+  HAL_LOG_ENTER();
+
+  // Empty means "use previous settings".
+  if (metadata.isEmpty()) {
+    HAL_LOGV("warning: metadata isEmpty");
+    return 0;
+  }
+
+#if 0
+  for (auto& component : components_) {
+    int res = component->SetRequestValues(metadata);
+    if (res) {
+      HAL_LOGE("Failed to set all requested settings.");
+      return res;
+    }
+  }
+#endif
+
+  return 0;
+}
+
+int Metadata::FillResultMetadata(android::CameraMetadata* metadata) {
+  HAL_LOG_ENTER();
+  if (!metadata) {
+    HAL_LOGE("Can't fill null metadata.");
+    return -EINVAL;
+  }
+
+  for (auto& component : components_) {
+    // Prevent components from potentially overriding others.
+    android::CameraMetadata additional_metadata;
+    int res = component->PopulateDynamicFields(&additional_metadata);
+    if (res) {
+      HAL_LOGE("Failed to get all dynamic result fields.");
+      return res;
+    }
+    // Add it to the overall result.
+    if (!additional_metadata.isEmpty()) {
+      res = metadata->append(additional_metadata);
+      if (res != android::OK) {
+        HAL_LOGE("Failed to append all dynamic result fields.");
+        return res;
+      }
+    }
+  }
+
+  return 0;
+}
+
+int Metadata::Dump(std::string file) {
+  HAL_LOG_ENTER();
+  android::CameraMetadata metadata;
+
+  FillStaticMetadata(&metadata);
+  int fp = open(file.c_str(), O_CREAT |O_RDWR | O_CLOEXEC, 0);
+  if (fp != -1) {
+    metadata.dump(fp);
+  }
+  else {
+    HAL_LOGE("Dump metadata failed: %s", file.c_str());
+  }
+  ::close(fp);
+
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata.h b/hardware/ntimespace/camera/metadata/metadata.h
new file mode 100644
index 0000000000..c92628b0ce
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_H_
+#define V4L2_CAMERA_HAL_METADATA_H_
+
+#include <android-base/macros.h>
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+
+#include "metadata_common.h"
+
+namespace v4l2_camera_hal {
+class Metadata {
+ public:
+  Metadata(PartialMetadataSet components);
+  virtual ~Metadata();
+
+  int FillStaticMetadata(android::CameraMetadata* metadata);
+  bool IsValidRequest(const android::CameraMetadata& metadata);
+  int GetRequestTemplate(int template_type,
+                         android::CameraMetadata* template_metadata);
+  int SetRequestSettings(const android::CameraMetadata& metadata);
+  int FillResultMetadata(android::CameraMetadata* metadata);
+  int Dump(std::string file);
+
+ private:
+  // The overall metadata is broken down into several distinct pieces.
+  // Note: it is undefined behavior if multiple components share tags.
+  PartialMetadataSet components_;
+
+  DISALLOW_COPY_AND_ASSIGN(Metadata);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_METADATA_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_common.h b/hardware/ntimespace/camera/metadata/metadata_common.h
new file mode 100644
index 0000000000..ba266a61c8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_common.h
@@ -0,0 +1,323 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
+#define V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
+
+#include <array>
+#include <memory>
+#include <set>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include "array_vector.h"
+#include "common.h"
+#include "partial_metadata_interface.h"
+
+namespace v4l2_camera_hal {
+
+typedef std::set<std::unique_ptr<PartialMetadataInterface>> PartialMetadataSet;
+
+// Templated helper functions effectively extending android::CameraMetadata.
+// Will cause a compile-time errors if CameraMetadata doesn't support
+// using the templated type. Templates are provided to extend this support
+// to std::arrays, std::vectors, and ArrayVectors of supported types as
+// appropriate.
+
+// UpdateMetadata(metadata, tag, data):
+//
+// Updates the entry for |tag| in |metadata| (functionally similar to
+// android::CameraMetadata::update).
+//
+// Args:
+//   metadata: the android::CameraMetadata to update.
+//   tag: the tag within |metadata| to update.
+//   data: A reference to the data to update |tag| with.
+//
+// Returns:
+//   0: Success.
+//   -ENODEV: The type of |data| does not match the expected type for |tag|,
+//     or another error occured. Note: no errors are given for updating a
+//     metadata entry with an incorrect amount of data (e.g. filling a tag
+//     that expects to have only one value with multiple values), as this
+//     information is not encoded in the type associated with the tag by
+//     get_camera_metadata_tag_type (from <system/camera_metadata.h>).
+
+// Generic (pointer & size).
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const T* data,
+                          size_t count) {
+  int res = metadata->update(tag, data, count);
+  if (res) {
+    HAL_LOGE("Failed to update metadata tag %d", tag);
+    return -ENODEV;
+  }
+  return 0;
+}
+
+// Generic (single item reference).
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const T& val) {
+  return UpdateMetadata(metadata, tag, &val, 1);
+}
+
+// Specialization for vectors.
+template <typename T>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::vector<T>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), val.size());
+}
+
+// Specialization for arrays.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::array<T, N>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), N);
+}
+
+// Specialization for ArrayVectors.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const ArrayVector<T, N>& val) {
+  return UpdateMetadata(metadata, tag, val.data(), val.total_num_elements());
+}
+
+// Specialization for vectors of arrays.
+template <typename T, size_t N>
+static int UpdateMetadata(android::CameraMetadata* metadata,
+                          int32_t tag,
+                          const std::vector<std::array<T, N>>& val) {
+  // Convert to array vector so we know all the elements are contiguous.
+  ArrayVector<T, N> array_vector;
+  for (const auto& array : val) {
+    array_vector.push_back(array);
+  }
+  return UpdateMetadata(metadata, tag, array_vector);
+}
+
+// GetDataPointer(entry, val)
+//
+// A helper for other methods in this file.
+// Gets the data pointer of a given metadata entry into |*val|.
+
+template <typename T>
+inline void GetDataPointer(camera_metadata_ro_entry_t&, const T**);
+
+template <>
+inline void GetDataPointer<uint8_t>(camera_metadata_ro_entry_t& entry,
+                           const uint8_t** val) {
+  *val = entry.data.u8;
+}
+
+template <>
+inline void GetDataPointer<int32_t>(camera_metadata_ro_entry_t& entry,
+                           const int32_t** val) {
+  *val = entry.data.i32;
+}
+
+template <>
+inline void GetDataPointer<float>(camera_metadata_ro_entry_t& entry,
+                           const float** val) {
+  *val = entry.data.f;
+}
+
+template <>
+inline void GetDataPointer<int64_t>(camera_metadata_ro_entry_t& entry,
+                           const int64_t** val) {
+  *val = entry.data.i64;
+}
+
+template <>
+inline void GetDataPointer<double>(camera_metadata_ro_entry_t& entry,
+                           const double** val) {
+  *val = entry.data.d;
+}
+
+template <>
+inline void GetDataPointer<camera_metadata_rational_t>(camera_metadata_ro_entry_t& entry,
+                           const camera_metadata_rational_t** val) {
+  *val = entry.data.r;
+}
+
+// SingleTagValue(metadata, tag, val)
+//
+// Get the value of the |tag| entry in |metadata|.
+// |tag| is expected to refer to an entry with a single item
+// of the templated type (a "single item" is exactly N values
+// if the templated type is an array of size N). An error will be
+// returned if it the wrong number of items are present.
+//
+// Returns:
+//   -ENOENT: The tag couldn't be found or was empty.
+//   -EINVAL: The tag contained more than one item, or |val| is null.
+//   -ENODEV: The tag claims to be non-empty, but the data pointer is null.
+//   0: Success. |*val| will contain the value for |tag|.
+
+// Singleton.
+template <typename T>
+static int SingleTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          T* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to SingleTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENOENT;
+  } else if (entry.count != 1) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain exactly 1 value "
+        "(had %zu).",
+        tag,
+        entry.count);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENODEV;
+  }
+  *val = *data;
+  return 0;
+}
+
+// Specialization for std::array.
+template <typename T, size_t N>
+static int SingleTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::array<T, N>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to SingleTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENOENT;
+  } else if (entry.count != N) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain a single array of "
+        "exactly %zu values (had %zu).",
+        tag,
+        N,
+        entry.count);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d is empty.", tag);
+    return -ENODEV;
+  }
+  // Fill in the array.
+  for (size_t i = 0; i < N; ++i) {
+    (*val)[i] = data[i];
+  }
+  return 0;
+}
+
+// VectorTagValue(metadata, tag, val)
+//
+// Get the value of the |tag| entry in |metadata|.
+// |tag| is expected to refer to an entry with a vector
+// of the templated type. For arrays, an error will be
+// returned if it the wrong number of items are present.
+//
+// Returns:
+//   -ENOENT: The tag couldn't be found or was empty. While technically an
+//            empty vector may be valid, this error is returned for consistency
+//            with SingleTagValue.
+//   -EINVAL: The tag contained an invalid number of entries (e.g. 6 entries for
+//            a vector of length 4 arrays), or |val| is null.
+//   -ENODEV: The tag claims to be non-empty, but the data pointer is null.
+//   0: Success. |*val| will contain the values for |tag|.
+template <typename T>
+static int VectorTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::vector<T>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to VectorTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    return -ENOENT;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d claims to have elements but is empty.", tag);
+    return -ENODEV;
+  }
+  // Copy the data for |tag| into the output vector.
+  *val = std::vector<T>(data, data + entry.count);
+  return 0;
+}
+
+// Specialization for std::array.
+template <typename T, size_t N>
+static int VectorTagValue(const android::CameraMetadata& metadata,
+                          int32_t tag,
+                          std::vector<std::array<T, N>>* val) {
+  if (!val) {
+    HAL_LOGE("Null pointer passed to VectorTagValue.");
+    return -EINVAL;
+  }
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  if (entry.count == 0) {
+    return -ENOENT;
+  }
+  if (entry.count % N != 0) {
+    HAL_LOGE(
+        "Error: expected metadata tag %d to contain a vector of arrays of "
+        "length %zu (had %zu entries, which is not divisible by %zu).",
+        tag,
+        N,
+        entry.count,
+        N);
+    return -EINVAL;
+  }
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  if (data == nullptr) {
+    HAL_LOGE("Metadata tag %d claims to have elements but is empty.", tag);
+    return -ENODEV;
+  }
+  // Copy the data for |tag| into separate arrays for the output vector.
+  size_t num_arrays = entry.count / N;
+  *val = std::vector<std::array<T, N>>(num_arrays);
+  for (size_t i = 0; i < num_arrays; ++i) {
+    for (size_t j = 0; j < N; ++j) {
+      val->at(i)[j] = data[i * N + j];
+    }
+  }
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_METADATA_COMMON_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader.cpp b/hardware/ntimespace/camera/metadata/metadata_reader.cpp
new file mode 100644
index 0000000000..2556f9c449
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader.cpp
@@ -0,0 +1,297 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "MetadataReader"
+
+#include "metadata_reader.h"
+
+#include <log/log.h>
+#include <system/camera.h>
+
+#include "metadata_common.h"
+
+namespace default_camera_hal {
+
+MetadataReader::MetadataReader(
+    std::unique_ptr<const android::CameraMetadata> metadata)
+    : metadata_(std::move(metadata)) {}
+
+MetadataReader::~MetadataReader() {}
+
+int MetadataReader::Facing(int* facing) const {
+  uint8_t metadata_facing = 0;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_LENS_FACING, &metadata_facing);
+  if (res) {
+    HAL_LOGE("%s: Failed to get facing from static metadata.", __func__);
+    return res;
+  }
+
+  switch (metadata_facing) {
+    case (ANDROID_LENS_FACING_FRONT):
+      *facing = CAMERA_FACING_FRONT;
+      break;
+    case (ANDROID_LENS_FACING_BACK):
+      *facing = CAMERA_FACING_BACK;
+      break;
+    case (ANDROID_LENS_FACING_EXTERNAL):
+      *facing = CAMERA_FACING_EXTERNAL;
+      break;
+    default:
+      HAL_LOGE("%s: Invalid facing from static metadata: %d.",
+            __func__,
+            metadata_facing);
+      return -EINVAL;
+  }
+
+  HAL_LOGE("%s: facing from static metadata: %d.",
+            __func__,
+            metadata_facing);
+  return 0;
+}
+
+int MetadataReader::Orientation(int* orientation) const {
+  HAL_LOG_ENTER();
+  int32_t metadata_orientation = 0;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_SENSOR_ORIENTATION, &metadata_orientation);
+  if (res) {
+    HAL_LOGE("%s: Failed to get orientation from static metadata.", __func__);
+    return res;
+  }
+
+  // Orientation must be 0, 90, 180, or 270.
+  if (metadata_orientation < 0 || metadata_orientation > 270 ||
+      metadata_orientation % 90 != 0) {
+    HAL_LOGE(
+        "%s: Invalid orientation %d "
+        "(must be a 90-degree increment in [0, 360)).",
+        __func__,
+        metadata_orientation);
+    return -EINVAL;
+  }
+
+  *orientation = static_cast<int>(metadata_orientation);
+  HAL_LOGE(
+        "%s: orientation %d "
+        "(must be a 90-degree increment in [0, 360)).",
+        __func__,
+        metadata_orientation);
+  return 0;
+}
+
+int MetadataReader::MaxInputStreams(int32_t* max_input) const {
+  HAL_LOG_ENTER();
+
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, max_input);
+  if (res == -ENOENT) {
+    // Not required; default to 0.
+    *max_input = 0;
+  } else if (res) {
+    HAL_LOGE("%s: Failed to get max output streams from static metadata.",
+          __func__);
+    return res;
+  }
+
+  return 0;
+}
+
+int MetadataReader::MaxOutputStreams(int32_t* max_raw,
+                                     int32_t* max_non_stalling,
+                                     int32_t* max_stalling) const {
+  HAL_LOG_ENTER();                                
+                            
+  std::array<int32_t, 3> max_output_streams;
+  int res = v4l2_camera_hal::SingleTagValue(
+      *metadata_, ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS, &max_output_streams);
+  if (res) {
+    HAL_LOGE("%s: Failed to get max output streams from static metadata.",
+          __func__);
+    return res;
+  }
+  *max_raw = max_output_streams[2];
+  *max_non_stalling = max_output_streams[1];
+  *max_stalling = max_output_streams[0];
+
+  return 0;
+}
+
+int MetadataReader::RequestCapabilities(std::set<uint8_t>* capabilities) const {
+  HAL_LOG_ENTER();
+  std::vector<uint8_t> raw_capabilities;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_, ANDROID_REQUEST_AVAILABLE_CAPABILITIES, &raw_capabilities);
+  if (res) {
+    HAL_LOGE("%s: Failed to get request capabilities from static metadata.",
+          __func__);
+    return res;
+  }
+
+  // Move from vector to set.
+  capabilities->insert(raw_capabilities.begin(), raw_capabilities.end());
+  return 0;
+}
+
+int MetadataReader::StreamConfigurations(
+    std::vector<StreamConfiguration>* configs) const {
+  HAL_LOG_ENTER();
+  std::vector<RawStreamConfiguration> raw_stream_configs;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_,
+      ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+      &raw_stream_configs);
+  if (res) {
+    HAL_LOGE("%s: Failed to get stream configs from static metadata.", __func__);
+    return res;
+  }
+
+  // TODO(b/31384253): check for required configs.
+
+  // Convert from raw.
+  configs->insert(
+      configs->end(), raw_stream_configs.begin(), raw_stream_configs.end());
+
+  // Check that all configs are valid.
+  for (const auto& config : *configs) {
+    HAL_LOGV("%s: format: %d width: %d height: %d direction: %d.",
+              __func__,
+              config.spec.format,
+              config.spec.width,
+              config.spec.height,
+              config.direction);
+    // Must have positive dimensions.
+    if (config.spec.width < 1 || config.spec.height < 1) {
+      HAL_LOGE("%s: Invalid stream config: non-positive dimensions (%d, %d).",
+            __func__,
+            config.spec.width,
+            config.spec.height);
+      return -EINVAL;
+    }
+    // Must have a known direction enum.
+    switch (config.direction) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT:
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT:
+        break;
+      default:
+        HAL_LOGE("%s: Invalid stream config direction: %d.",
+              __func__,
+              config.direction);
+        return -EINVAL;
+    }
+  }
+  return 0;
+}
+
+int MetadataReader::StreamStallDurations(
+    std::vector<StreamStallDuration>* stalls) const {
+  HAL_LOG_ENTER();
+  std::vector<RawStreamStallDuration> raw_stream_stall_durations;
+  int res =
+      v4l2_camera_hal::VectorTagValue(*metadata_,
+                                      ANDROID_SCALER_AVAILABLE_STALL_DURATIONS,
+                                      &raw_stream_stall_durations);
+  if (res) {
+    HAL_LOGE("%s: Failed to get stall durations from static metadata.", __func__);
+    return res;
+  }
+
+  // Convert from raw.
+  stalls->insert(stalls->end(),
+                 raw_stream_stall_durations.begin(),
+                 raw_stream_stall_durations.end());
+  // Check that all stalls are valid.
+  for (const auto& stall : *stalls) {
+    HAL_LOGE("%s: stream format: %d width: %d height: %d.",
+              __func__,
+              stall.spec.format,
+              stall.spec.width,
+              stall.spec.height); 
+
+    // Must have positive dimensions.
+    if (stall.spec.width < 1 || stall.spec.height < 1) {
+      HAL_LOGE("%s: Invalid stall duration: non-positive dimensions (%d, %d).",
+            __func__,
+            stall.spec.width,
+            stall.spec.height);
+      return -EINVAL;
+    }
+    // Must have a non-negative stall.
+    if (stall.duration < 0) {
+      HAL_LOGE("%s: Invalid stall duration: negative stall %lld.",
+            __func__,
+            static_cast<long long>(stall.duration));
+      return -EINVAL;
+    }
+    // TODO(b/31384253): YUV_420_888, RAW10, RAW12, RAW_OPAQUE,
+    // and IMPLEMENTATION_DEFINED must have 0 stall duration.
+  }
+
+  return 0;
+}
+
+int MetadataReader::ReprocessFormats(ReprocessFormatMap* reprocess_map) const {
+  HAL_LOG_ENTER();
+  std::vector<int32_t> input_output_formats;
+  int res = v4l2_camera_hal::VectorTagValue(
+      *metadata_,
+      ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP,
+      &input_output_formats);
+  if (res) {
+    HAL_LOGE("%s: Failed to get input output format map from static metadata.",
+          __func__);
+    return res;
+  }
+
+  // Convert from the raw vector.
+  for (size_t i = 0; i < input_output_formats.size();) {
+    // The map is represented as variable-length entries of the format
+    // input, num_outputs, <outputs>.
+
+    // Get the input format.
+    int32_t input_format = input_output_formats[i++];
+
+    // Find the output begin and end for this format.
+    int32_t num_output_formats = input_output_formats[i++];
+    if (num_output_formats < 1) {
+      HAL_LOGE(
+          "%s: No output formats for input format %d.", __func__, input_format);
+      return -EINVAL;
+    }
+    size_t outputs_end = i + num_output_formats;
+    if (outputs_end > input_output_formats.size()) {
+      HAL_LOGE("%s: Input format %d requests more data than available.",
+            __func__,
+            input_format);
+      return -EINVAL;
+    }
+
+    // Copy all the output formats into the map.
+    (*reprocess_map)[input_format].insert(
+        input_output_formats.data() + i,
+        input_output_formats.data() + outputs_end);
+
+    // Move on to the next entry.
+    i = outputs_end;
+  }
+
+  // TODO(b/31384253): check for required mappings.
+
+  return 0;
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader.h b/hardware/ntimespace/camera/metadata/metadata_reader.h
new file mode 100644
index 0000000000..58a206107a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader.h
@@ -0,0 +1,76 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
+#define DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
+
+#include <memory>
+#include <set>
+#include <vector>
+
+#include <android-base/macros.h>
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include "types.h"
+
+namespace default_camera_hal {
+
+// A MetadataReader reads and converts/validates various metadata entries.
+class MetadataReader {
+ public:
+  MetadataReader(std::unique_ptr<const android::CameraMetadata> metadata);
+  virtual ~MetadataReader();
+
+  // Get a pointer to the underlying metadata being read.
+  // The pointer is valid only as long as this object is alive.
+  // The "locking" here only causes non-const methods to fail,
+  // which is not a problem since the CameraMetadata being locked
+  // is already const. This could be a problem if the metadata was
+  // shared more widely, but |metadata_| is a unique_ptr,
+  // guaranteeing the safety of this. Destructing automatically "unlocks".
+  virtual const camera_metadata_t* raw_metadata() const {
+    return metadata_->getAndLock();
+  }
+
+  // All accessor methods must be given a valid pointer. They will return:
+  // 0: Success.
+  // -ENOENT: The necessary entry is missing.
+  // -EINVAL: The entry value is invalid.
+  // -ENODEV: Some other error occured.
+
+  // The |facing| returned will be one of the enum values from system/camera.h.
+  virtual int Facing(int* facing) const;
+  virtual int Orientation(int* orientation) const;
+  virtual int MaxInputStreams(int32_t* max_input_streams) const;
+  virtual int MaxOutputStreams(int32_t* max_raw_output_streams,
+                               int32_t* max_non_stalling_output_streams,
+                               int32_t* max_stalling_output_streams) const;
+  virtual int RequestCapabilities(std::set<uint8_t>* capabilites) const;
+  virtual int StreamConfigurations(
+      std::vector<StreamConfiguration>* configs) const;
+  virtual int StreamStallDurations(
+      std::vector<StreamStallDuration>* stalls) const;
+  virtual int ReprocessFormats(ReprocessFormatMap* reprocess_map) const;
+
+ private:
+  std::unique_ptr<const android::CameraMetadata> metadata_;
+
+  DISALLOW_COPY_AND_ASSIGN(MetadataReader);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader_mock.h b/hardware/ntimespace/camera/metadata/metadata_reader_mock.h
new file mode 100644
index 0000000000..3a91d172ca
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader_mock.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for metadata readers.
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
+#define DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
+
+#include "metadata_reader.h"
+
+#include <gmock/gmock.h>
+
+namespace default_camera_hal {
+
+class MetadataReaderMock : public MetadataReader {
+ public:
+  MetadataReaderMock() : MetadataReader(nullptr){};
+  MOCK_CONST_METHOD0(raw_metadata, const camera_metadata_t*());
+  MOCK_CONST_METHOD1(Facing, int(int*));
+  MOCK_CONST_METHOD1(Orientation, int(int*));
+  MOCK_CONST_METHOD1(MaxInputStreams, int(int32_t*));
+  MOCK_CONST_METHOD3(MaxOutputStreams, int(int32_t*, int32_t*, int32_t*));
+  MOCK_CONST_METHOD1(RequestCapabilities, int(std::set<uint8_t>*));
+  MOCK_CONST_METHOD1(StreamConfigurations,
+                     int(std::vector<StreamConfiguration>*));
+  MOCK_CONST_METHOD1(StreamStallDurations,
+                     int(std::vector<StreamStallDuration>*));
+  MOCK_CONST_METHOD1(ReprocessFormats, int(ReprocessFormatMap*));
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_METADATA_READER_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp b/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
new file mode 100644
index 0000000000..45865214c2
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_reader_test.cpp
@@ -0,0 +1,368 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "metadata_reader.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include <system/camera.h>
+
+#include "array_vector.h"
+#include "metadata_common.h"
+
+using testing::Test;
+
+namespace default_camera_hal {
+
+class MetadataReaderTest : public Test {
+ protected:
+  void SetUp() {
+    ResetMetadata();
+    // FillDUT should be called before using the device under test.
+    dut_.reset();
+  }
+
+  void ResetMetadata() {
+    metadata_ = std::make_unique<android::CameraMetadata>();
+  }
+
+  void FillDUT() {
+    dut_ = std::make_unique<MetadataReader>(std::move(metadata_));
+    ResetMetadata();
+  }
+
+  std::unique_ptr<MetadataReader> dut_;
+  std::unique_ptr<android::CameraMetadata> metadata_;
+
+  const int32_t facing_tag_ = ANDROID_LENS_FACING;
+  const int32_t orientation_tag_ = ANDROID_SENSOR_ORIENTATION;
+  const int32_t max_inputs_tag_ = ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS;
+  const int32_t max_outputs_tag_ = ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS;
+  const int32_t configs_tag_ = ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS;
+  const int32_t stalls_tag_ = ANDROID_SCALER_AVAILABLE_STALL_DURATIONS;
+  const int32_t reprocess_formats_tag_ =
+      ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP;
+
+  const std::vector<int32_t> valid_orientations_ = {0, 90, 180, 270};
+  // TODO(b/31384253): check for required configs/reprocess formats.
+};
+
+TEST_F(MetadataReaderTest, FacingTranslations) {
+  // Check that the enums are converting properly.
+  std::map<uint8_t, int> translations{
+      {ANDROID_LENS_FACING_FRONT, CAMERA_FACING_FRONT},
+      {ANDROID_LENS_FACING_BACK, CAMERA_FACING_BACK},
+      {ANDROID_LENS_FACING_EXTERNAL, CAMERA_FACING_EXTERNAL}};
+  for (const auto& translation : translations) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), facing_tag_, translation.first),
+              0);
+    FillDUT();
+
+    int expected = translation.second;
+    int actual = expected + 1;
+    EXPECT_EQ(dut_->Facing(&actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+}
+
+TEST_F(MetadataReaderTest, InvalidFacing) {
+  uint8_t invalid = 99;
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), facing_tag_, invalid),
+      0);
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Facing(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyFacing) {
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Facing(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, ValidOrientations) {
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation),
+              0);
+    FillDUT();
+
+    int actual = orientation + 1;
+    EXPECT_EQ(dut_->Orientation(&actual), 0);
+    EXPECT_EQ(actual, orientation);
+  }
+}
+
+TEST_F(MetadataReaderTest, InvalidOrientations) {
+  // High.
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation + 1),
+              0);
+    FillDUT();
+    int actual = 0;
+    EXPECT_EQ(dut_->Orientation(&actual), -EINVAL);
+  }
+  // Low.
+  for (int32_t orientation : valid_orientations_) {
+    ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                  metadata_.get(), orientation_tag_, orientation - 1),
+              0);
+    FillDUT();
+    int actual = 0;
+    EXPECT_EQ(dut_->Orientation(&actual), -EINVAL);
+  }
+}
+
+TEST_F(MetadataReaderTest, EmptyOrientation) {
+  FillDUT();
+  int actual = 0;
+  EXPECT_EQ(dut_->Orientation(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, MaxInputs) {
+  int32_t expected = 12;
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_inputs_tag_, expected),
+            0);
+  FillDUT();
+  int32_t actual = expected + 1;
+  ASSERT_EQ(dut_->MaxInputStreams(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, EmptyMaxInputs) {
+  FillDUT();
+  // Max inputs is an optional key; if not present the default is 0.
+  int32_t expected = 0;
+  int32_t actual = expected + 1;
+  ASSERT_EQ(dut_->MaxInputStreams(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, MaxOutputs) {
+  std::array<int32_t, 3> expected = {{12, 34, 56}};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_outputs_tag_, expected),
+            0);
+  FillDUT();
+  std::array<int32_t, 3> actual;
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual[0], &actual[1], &actual[2]), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, InvalidMaxOutputs) {
+  // Must be a 3-tuple to be valid.
+  std::array<int32_t, 4> invalid = {{12, 34, 56, 78}};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), max_outputs_tag_, invalid),
+            0);
+  FillDUT();
+  int32_t actual;
+  // Don't mind the aliasing since we don't care about the value.
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual, &actual, &actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyMaxOutputs) {
+  FillDUT();
+  int32_t actual;
+  // Don't mind the aliasing since we don't care about the value.
+  ASSERT_EQ(dut_->MaxOutputStreams(&actual, &actual, &actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, StreamConfigurations) {
+  v4l2_camera_hal::ArrayVector<int32_t, 4> configs;
+  std::array<int32_t, 4> config1{
+      {1, 2, 3, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}};
+  std::array<int32_t, 4> config2{
+      {5, 6, 7, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}};
+  configs.push_back(config1);
+  configs.push_back(config2);
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, configs),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), 0);
+  ASSERT_EQ(actual.size(), configs.num_arrays());
+  EXPECT_EQ(actual[0].spec.format, config1[0]);
+  EXPECT_EQ(actual[0].spec.width, config1[1]);
+  EXPECT_EQ(actual[0].spec.height, config1[2]);
+  EXPECT_EQ(actual[0].direction, config1[3]);
+  EXPECT_EQ(actual[1].spec.format, config2[0]);
+  EXPECT_EQ(actual[1].spec.width, config2[1]);
+  EXPECT_EQ(actual[1].spec.height, config2[2]);
+  EXPECT_EQ(actual[1].direction, config2[3]);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationDirection) {
+  // -1 is not a valid direction.
+  std::array<int32_t, 4> config{{1, 2, 3, -1}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationSize) {
+  // Both size dimensions must be > 0.
+  std::array<int32_t, 4> config{
+      {1, 2, 0, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamConfigurationNumElements) {
+  // Should be a multiple of 4.
+  std::array<int32_t, 5> config{
+      {1, 2, 3, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT, 5}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), configs_tag_, config),
+      0);
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -EINVAL);
+}
+
+// TODO(b/31384253): Test that failure occurs if
+// required configurations are not present.
+
+TEST_F(MetadataReaderTest, NoStreamConfigurations) {
+  FillDUT();
+  std::vector<StreamConfiguration> actual;
+  ASSERT_EQ(dut_->StreamConfigurations(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, StreamStallDurations) {
+  v4l2_camera_hal::ArrayVector<int64_t, 4> stalls;
+  std::array<int64_t, 4> stall1{{1, 2, 3, 4}};
+  std::array<int64_t, 4> stall2{{5, 6, 7, 8}};
+  stalls.push_back(stall1);
+  stalls.push_back(stall2);
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stalls), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), 0);
+  ASSERT_EQ(actual.size(), stalls.num_arrays());
+  EXPECT_EQ(actual[0].spec.format, stall1[0]);
+  EXPECT_EQ(actual[0].spec.width, stall1[1]);
+  EXPECT_EQ(actual[0].spec.height, stall1[2]);
+  EXPECT_EQ(actual[0].duration, stall1[3]);
+  EXPECT_EQ(actual[1].spec.format, stall2[0]);
+  EXPECT_EQ(actual[1].spec.width, stall2[1]);
+  EXPECT_EQ(actual[1].spec.height, stall2[2]);
+  EXPECT_EQ(actual[1].duration, stall2[3]);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationDuration) {
+  // -1 is not a valid duration.
+  std::array<int64_t, 4> stall{{1, 2, 3, -1}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationSize) {
+  // Both size dimensions must be > 0.
+  std::array<int64_t, 4> stall{{1, 2, 0, 3}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, InvalidStreamStallDurationNumElements) {
+  // Should be a multiple of 4.
+  std::array<int64_t, 5> stall{{1, 2, 3, 4, 5}};
+  ASSERT_EQ(
+      v4l2_camera_hal::UpdateMetadata(metadata_.get(), stalls_tag_, stall), 0);
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -EINVAL);
+}
+
+// TODO(b/31384253): Test that failure occurs if
+// YUV_420_888, RAW10, RAW12, RAW_OPAQUE, or IMPLEMENTATION_DEFINED
+// formats have stall durations > 0.
+
+TEST_F(MetadataReaderTest, NoStreamStallDurations) {
+  FillDUT();
+  std::vector<StreamStallDuration> actual;
+  ASSERT_EQ(dut_->StreamStallDurations(&actual), -ENOENT);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormats) {
+  ReprocessFormatMap expected{{1, {4}}, {2, {5, 6}}, {3, {7, 8, 9}}};
+  std::vector<int32_t> raw;
+  for (const auto& input_outputs : expected) {
+    raw.push_back(input_outputs.first);
+    raw.push_back(input_outputs.second.size());
+    raw.insert(
+        raw.end(), input_outputs.second.begin(), input_outputs.second.end());
+  }
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormatsNoOutputs) {
+  // 0 indicates that there are 0 output formats for input format 1,
+  // which is not ok.
+  std::vector<int32_t> raw{1, 0};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, ReprocessFormatsPastEnd) {
+  // 3 indicates that there are 3 output formats for input format 1,
+  // which is not ok since there are only 2 here.
+  std::vector<int32_t> raw{1, 3, 0, 0};
+  ASSERT_EQ(v4l2_camera_hal::UpdateMetadata(
+                metadata_.get(), reprocess_formats_tag_, raw),
+            0);
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -EINVAL);
+}
+
+TEST_F(MetadataReaderTest, EmptyReprocessFormats) {
+  FillDUT();
+  ReprocessFormatMap actual;
+  ASSERT_EQ(dut_->ReprocessFormats(&actual), -ENOENT);
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/metadata_test.cpp b/hardware/ntimespace/camera/metadata/metadata_test.cpp
new file mode 100644
index 0000000000..d753dd7a22
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/metadata_test.cpp
@@ -0,0 +1,322 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "metadata.h"
+
+#include <memory>
+#include <set>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "metadata_common.h"
+#include "partial_metadata_interface_mock.h"
+
+using testing::AtMost;
+using testing::Return;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class MetadataTest : public Test {
+ protected:
+  virtual void SetUp() {
+    // Clear the DUT. AddComponents must be called before using it.
+    dut_.reset();
+
+    component1_.reset(new PartialMetadataInterfaceMock());
+    component2_.reset(new PartialMetadataInterfaceMock());
+    metadata_.reset(new android::CameraMetadata());
+    non_empty_metadata_.reset(new android::CameraMetadata());
+    uint8_t val = 1;
+    non_empty_metadata_->update(ANDROID_COLOR_CORRECTION_MODE, &val, 1);
+  }
+
+  // Once the component mocks have had expectations set,
+  // add them to the device under test.
+  virtual void AddComponents() {
+    // Don't mind moving; Gmock/Gtest fails on leaked mocks unless disabled by
+    // runtime flags.
+    PartialMetadataSet components;
+    components.insert(std::move(component1_));
+    components.insert(std::move(component2_));
+    dut_.reset(new Metadata(std::move(components)));
+  }
+
+  virtual void CompareTags(const std::set<int32_t>& expected,
+                           const camera_metadata_entry_t& actual) {
+    ASSERT_EQ(expected.size(), actual.count);
+    for (size_t i = 0; i < actual.count; ++i) {
+      EXPECT_NE(expected.find(actual.data.i32[i]), expected.end());
+    }
+  }
+
+  // Device under test.
+  std::unique_ptr<Metadata> dut_;
+  // Mocks.
+  std::unique_ptr<PartialMetadataInterfaceMock> component1_;
+  std::unique_ptr<PartialMetadataInterfaceMock> component2_;
+  // Metadata.
+  std::unique_ptr<android::CameraMetadata> metadata_;
+  std::unique_ptr<android::CameraMetadata> non_empty_metadata_;
+  // An empty vector to use as necessary.
+  std::vector<int32_t> empty_tags_;
+};
+
+TEST_F(MetadataTest, FillStaticSuccess) {
+  // Should populate all the component static pieces.
+  EXPECT_CALL(*component1_, PopulateStaticFields(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateStaticFields(_)).WillOnce(Return(0));
+
+  // Should populate the meta keys, by polling each component's keys.
+  std::vector<int32_t> static_tags_1({1, 2});
+  std::vector<int32_t> static_tags_2({3, 4});
+  std::vector<int32_t> control_tags_1({5, 6});
+  std::vector<int32_t> control_tags_2({7, 8});
+  std::vector<int32_t> dynamic_tags_1({9, 10});
+  std::vector<int32_t> dynamic_tags_2({11, 12});
+  EXPECT_CALL(*component1_, StaticTags()).WillOnce(Return(static_tags_1));
+  EXPECT_CALL(*component1_, ControlTags()).WillOnce(Return(control_tags_1));
+  EXPECT_CALL(*component1_, DynamicTags()).WillOnce(Return(dynamic_tags_1));
+  EXPECT_CALL(*component2_, StaticTags()).WillOnce(Return(static_tags_2));
+  EXPECT_CALL(*component2_, ControlTags()).WillOnce(Return(control_tags_2));
+  EXPECT_CALL(*component2_, DynamicTags()).WillOnce(Return(dynamic_tags_2));
+
+  AddComponents();
+  // Should succeed. If it didn't, no reason to continue checking output.
+  ASSERT_EQ(dut_->FillStaticMetadata(metadata_.get()), 0);
+
+  // Meta keys should be filled correctly.
+  // Note: sets are used here, but it is undefined behavior if
+  // the class has multiple componenets reporting overlapping tags.
+
+  // Get the expected tags = combined tags of all components.
+  std::set<int32_t> static_tags(static_tags_1.begin(), static_tags_1.end());
+  static_tags.insert(static_tags_2.begin(), static_tags_2.end());
+  std::set<int32_t> control_tags(control_tags_1.begin(), control_tags_1.end());
+  control_tags.insert(control_tags_2.begin(), control_tags_2.end());
+  std::set<int32_t> dynamic_tags(dynamic_tags_1.begin(), dynamic_tags_1.end());
+  dynamic_tags.insert(dynamic_tags_2.begin(), dynamic_tags_2.end());
+
+  // Static tags includes not only all component static tags, but also
+  // the meta AVAILABLE_*_KEYS (* = [REQUEST, RESULT, CHARACTERISTICS]).
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS);
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS);
+  static_tags.emplace(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS);
+
+  // Check against what was filled in in the metadata.
+  CompareTags(static_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_CHARACTERISTICS_KEYS));
+  CompareTags(control_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_REQUEST_KEYS));
+  CompareTags(dynamic_tags,
+              metadata_->find(ANDROID_REQUEST_AVAILABLE_RESULT_KEYS));
+}
+
+TEST_F(MetadataTest, FillStaticFail) {
+  int err = -99;
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateStaticFields(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateStaticFields(_)).WillOnce(Return(err));
+
+  // May or may not exit early, may still try to populate meta tags.
+  EXPECT_CALL(*component1_, StaticTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component1_, ControlTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component1_, DynamicTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, StaticTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, ControlTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+  EXPECT_CALL(*component2_, DynamicTags())
+      .Times(AtMost(1))
+      .WillOnce(Return(empty_tags_));
+
+  AddComponents();
+  // If any component errors, error should be returned
+  EXPECT_EQ(dut_->FillStaticMetadata(metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, FillStaticNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->FillStaticMetadata(nullptr), -EINVAL);
+}
+
+TEST_F(MetadataTest, IsValidSuccess) {
+  // Should check if all the component request values are valid.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_)).WillOnce(Return(true));
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).WillOnce(Return(true));
+
+  AddComponents();
+  // Should succeed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_TRUE(dut_->IsValidRequest(*non_empty_metadata_));
+}
+
+TEST_F(MetadataTest, IsValidFail) {
+  // Should check if all the component request values are valid.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(true));
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).WillOnce(Return(false));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_FALSE(dut_->IsValidRequest(*non_empty_metadata_));
+}
+
+TEST_F(MetadataTest, IsValidEmpty) {
+  // Setting null settings is a special case indicating to use the
+  // previous (valid) settings. As such it is inherently valid.
+  // Should not try to check any components.
+  EXPECT_CALL(*component1_, SupportsRequestValues(_)).Times(0);
+  EXPECT_CALL(*component2_, SupportsRequestValues(_)).Times(0);
+
+  AddComponents();
+  EXPECT_TRUE(dut_->IsValidRequest(*metadata_));
+}
+
+TEST_F(MetadataTest, GetTemplateSuccess) {
+  int template_type = 3;
+
+  // Should check if all the components fill the template successfully.
+  EXPECT_CALL(*component1_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), 0);
+}
+
+TEST_F(MetadataTest, GetTemplateFail) {
+  int err = -99;
+  int template_type = 3;
+
+  // Should check if all the components fill the template successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateTemplateRequest(template_type, _))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateTemplateRequest(template_type, _))
+      .WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, GetTemplateNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->GetRequestTemplate(1, nullptr), -EINVAL);
+}
+
+TEST_F(MetadataTest, GetTemplateInvalid) {
+  int template_type = 99;  // Invalid template type.
+
+  AddComponents();
+  // Should fail fast since template type is invalid.
+  EXPECT_EQ(dut_->GetRequestTemplate(template_type, metadata_.get()), -EINVAL);
+}
+
+TEST_F(MetadataTest, SetSettingsSuccess) {
+  // Should check if all the components set successfully.
+  EXPECT_CALL(*component1_, SetRequestValues(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, SetRequestValues(_)).WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_EQ(dut_->SetRequestSettings(*non_empty_metadata_), 0);
+}
+
+TEST_F(MetadataTest, SetSettingsFail) {
+  int err = -99;
+
+  // Should check if all the components set successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, SetRequestValues(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, SetRequestValues(_)).WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  // Note: getAndLock is a lock against pointer invalidation, not concurrency,
+  // and unlocks on object destruction.
+  EXPECT_EQ(dut_->SetRequestSettings(*non_empty_metadata_), err);
+}
+
+TEST_F(MetadataTest, SetSettingsEmpty) {
+  // Setting null settings is a special case indicating to use the
+  // previous settings. Should not try to set any components.
+  EXPECT_CALL(*component1_, SetRequestValues(_)).Times(0);
+  EXPECT_CALL(*component2_, SetRequestValues(_)).Times(0);
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->SetRequestSettings(*metadata_), 0);
+}
+
+TEST_F(MetadataTest, FillResultSuccess) {
+  // Should check if all the components fill results successfully.
+  EXPECT_CALL(*component1_, PopulateDynamicFields(_)).WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateDynamicFields(_)).WillOnce(Return(0));
+
+  AddComponents();
+  // Should succeed.
+  EXPECT_EQ(dut_->FillResultMetadata(metadata_.get()), 0);
+}
+
+TEST_F(MetadataTest, FillResultFail) {
+  int err = -99;
+
+  // Should check if all the components fill results successfully.
+  // Order undefined, and may or may not exit early; use AtMost.
+  EXPECT_CALL(*component1_, PopulateDynamicFields(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(0));
+  EXPECT_CALL(*component2_, PopulateDynamicFields(_)).WillOnce(Return(err));
+
+  AddComponents();
+  // Should fail since one of the components failed.
+  EXPECT_EQ(dut_->FillResultMetadata(metadata_.get()), err);
+}
+
+TEST_F(MetadataTest, FillResultNull) {
+  AddComponents();
+  EXPECT_EQ(dut_->FillResultMetadata(nullptr), -EINVAL);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h b/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
new file mode 100644
index 0000000000..e1936f1160
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/no_effect_control_delegate.h
@@ -0,0 +1,46 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A NoEffectControlDelegate, as the name implies, has no effect.
+// The value can be gotten and set, but it does nothing.
+template <typename T>
+class NoEffectControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  NoEffectControlDelegate(T default_value) : value_(default_value){};
+
+  int GetValue(T* value) override {
+    *value = value_;
+    return 0;
+  };
+  int SetValue(const T& value) override {
+    value_ = value;
+    return 0;
+  };
+
+ private:
+  T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_NO_EFFECT_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
new file mode 100644
index 0000000000..0a7a24c823
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/no_effect_control_delegate_test.cpp
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "no_effect_control_delegate.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+TEST(NoEffectControlDelegateTest, DefaultGet) {
+  int32_t value = 12;
+  NoEffectControlDelegate<int32_t> control(value);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST(NoEffectControlDelegateTest, GetAndSet) {
+  int32_t value = 12;
+  NoEffectControlDelegate<int32_t> control(value);
+  int32_t new_value = 13;
+  ASSERT_EQ(control.SetValue(new_value), 0);
+  int32_t actual = 0;
+  ASSERT_EQ(control.GetValue(&actual), 0);
+  EXPECT_EQ(actual, new_value);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_factory.h b/hardware/ntimespace/camera/metadata/partial_metadata_factory.h
new file mode 100644
index 0000000000..75aba25fcc
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_factory.h
@@ -0,0 +1,335 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
+#define V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
+
+#include "common.h"
+#include "control.h"
+#include "menu_control_options.h"
+#include "no_effect_control_delegate.h"
+#include "ranged_converter.h"
+#include "slider_control_options.h"
+#include "state.h"
+#include "tagged_control_delegate.h"
+#include "tagged_control_options.h"
+#include "v4l2_control_delegate.h"
+
+namespace v4l2_camera_hal {
+
+enum class ControlType { kMenu, kSlider };
+
+// Static functions to create partial metadata. Nullptr is returned on failures.
+
+// FixedState: A state that doesn't change.
+template <typename T>
+static std::unique_ptr<State<T>> FixedState(int32_t tag, T value);
+
+// NoEffectOptionlessControl: A control that accepts any value,
+// and has no effect. A default value is given.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectOptionlessControl(
+    int32_t delegate_tag, T default_value);
+
+// NoEffectMenuControl: Some menu options, but they have no effect.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectMenuControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    const std::vector<T>& options,
+    std::map<int, T> default_values = {});
+
+// NoEffectSliderControl: A slider of options, but they have no effect.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectSliderControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T min,
+    T max,
+    std::map<int, T> default_values = {});
+
+// NoEffectControl: A control with no effect and only a single allowable
+// value. Chooses an appropriate ControlOptionsInterface depending on type.
+template <typename T>
+static std::unique_ptr<Control<T>> NoEffectControl(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T value,
+    std::map<int, T> default_values = {});
+
+// V4L2Control: A control corresponding to a V4L2 control.
+template <typename T>
+static std::unique_ptr<Control<T>> V4L2Control(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    std::map<int, T> default_values = {});
+
+// V4L2ControlOrDefault: Like V4L2Control, but if the V4L2Control fails to
+// initialize for some reason, this method will fall back to NoEffectControl
+// with an initial value defined by |fallback_default|.
+template <typename T>
+static std::unique_ptr<Control<T>> V4L2ControlOrDefault(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    T fallback_default,
+    std::map<int, T> default_values = {});
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+std::unique_ptr<State<T>> FixedState(int32_t tag, T value) {
+  HAL_LOG_ENTER();
+
+  // Take advantage of ControlDelegate inheriting from StateDelegate;
+  // This will only expose GetValue, not SetValue, so the default will
+  // always be returned.
+  return std::make_unique<State<T>>(
+      tag, std::make_unique<NoEffectControlDelegate<T>>(value));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectOptionlessControl(int32_t delegate_tag,
+                                                      T default_value) {
+  HAL_LOG_ENTER();
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<NoEffectControlDelegate<T>>(default_value)),
+      nullptr);
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectMenuControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    const std::vector<T>& options,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  if (options.empty()) {
+    HAL_LOGE("At least one option must be provided.");
+    return nullptr;
+  }
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<NoEffectControlDelegate<T>>(options[0])),
+      std::make_unique<TaggedControlOptions<T>>(
+          options_tag,
+          std::make_unique<MenuControlOptions<T>>(options, default_values)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectSliderControl(
+    int32_t delegate_tag,
+    int32_t options_tag,
+    T min,
+    T max,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag, std::make_unique<NoEffectControlDelegate<T>>(min)),
+      std::make_unique<TaggedControlOptions<T>>(
+          options_tag,
+          std::make_unique<SliderControlOptions<T>>(min, max, default_values)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> NoEffectControl(ControlType type,
+                                            int32_t delegate_tag,
+                                            int32_t options_tag,
+                                            T value,
+                                            std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  switch (type) {
+    case ControlType::kMenu:
+      return NoEffectMenuControl<T>(
+          delegate_tag, options_tag, {value}, default_values);
+    case ControlType::kSlider:
+      return NoEffectSliderControl(
+          delegate_tag, options_tag, value, value, default_values);
+  }
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> V4L2Control(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  // Query the device.
+  v4l2_query_ext_ctrl control_query;
+  int res = device->QueryControl(control_id, &control_query);
+  if (res) {
+    HAL_LOGE("Failed to query control %d.", control_id);
+    return nullptr;
+  }
+
+  int32_t control_min = static_cast<int32_t>(control_query.minimum);
+  int32_t control_max = static_cast<int32_t>(control_query.maximum);
+  int32_t control_step = static_cast<int32_t>(control_query.step);
+  if (control_min > control_max) {
+    HAL_LOGE("No acceptable values (min %d is greater than max %d).",
+             control_min,
+             control_max);
+    return nullptr;
+  }
+
+  // Variables needed by the various switch statements.
+  std::vector<T> options;
+  T metadata_val;
+  T metadata_min;
+  T metadata_max;
+  // Set up the result converter and result options based on type.
+  std::shared_ptr<ConverterInterface<T, int32_t>> result_converter(converter);
+  std::unique_ptr<ControlOptionsInterface<T>> result_options;
+  switch (control_query.type) {
+    case V4L2_CTRL_TYPE_BOOLEAN:
+      if (type != ControlType::kMenu) {
+        HAL_LOGE(
+            "V4L2 control %d is of type %d, which isn't compatible with "
+            "desired metadata control type %d",
+            control_id,
+            control_query.type,
+            type);
+        return nullptr;
+      }
+
+      // Convert each available option,
+      // ignoring ones without a known conversion.
+      for (int32_t i = control_min; i <= control_max; i += control_step) {
+        res = converter->V4L2ToMetadata(i, &metadata_val);
+        if (res == -EINVAL) {
+          HAL_LOGV("V4L2 value %d for control %d has no metadata equivalent.",
+                   i,
+                   control_id);
+          continue;
+        } else if (res) {
+          HAL_LOGE("Error converting value %d for control %d.", i, control_id);
+          return nullptr;
+        }
+        options.push_back(metadata_val);
+      }
+      // Check to make sure there's at least one option.
+      if (options.empty()) {
+        HAL_LOGE("No valid options for control %d.", control_id);
+        return nullptr;
+      }
+
+      result_options.reset(new MenuControlOptions<T>(options, default_values));
+      // No converter changes necessary.
+      break;
+    case V4L2_CTRL_TYPE_INTEGER:
+      if (type != ControlType::kSlider) {
+        HAL_LOGE(
+            "V4L2 control %d is of type %d, which isn't compatible with "
+            "desired metadata control type %d",
+            control_id,
+            control_query.type,
+            type);
+        return nullptr;
+      }
+
+      // Upgrade to a range/step-clamping converter.
+      result_converter.reset(new RangedConverter<T, int32_t>(
+          converter, control_min, control_max, control_step));
+
+      // Convert the min and max.
+      res = result_converter->V4L2ToMetadata(control_min, &metadata_min);
+      if (res) {
+        HAL_LOGE(
+            "Failed to convert V4L2 min value %d for control %d to metadata.",
+            control_min,
+            control_id);
+        return nullptr;
+      }
+      res = result_converter->V4L2ToMetadata(control_max, &metadata_max);
+      if (res) {
+        HAL_LOGE(
+            "Failed to convert V4L2 max value %d for control %d to metadata.",
+            control_max,
+            control_id);
+        return nullptr;
+      }
+      result_options.reset(new SliderControlOptions<T>(
+          metadata_min, metadata_max, default_values));
+      break;
+    default:
+      HAL_LOGE("Control %d (%s) is of unsupported type %d",
+               control_id,
+               control_query.name,
+               control_query.type);
+      return nullptr;
+  }
+
+  // Construct the control.
+  return std::make_unique<Control<T>>(
+      std::make_unique<TaggedControlDelegate<T>>(
+          delegate_tag,
+          std::make_unique<V4L2ControlDelegate<T>>(
+              device, control_id, result_converter)),
+      std::make_unique<TaggedControlOptions<T>>(options_tag,
+                                                std::move(result_options)));
+}
+
+template <typename T>
+std::unique_ptr<Control<T>> V4L2ControlOrDefault(
+    ControlType type,
+    int32_t delegate_tag,
+    int32_t options_tag,
+    std::shared_ptr<V4L2Wrapper> device,
+    int control_id,
+    std::shared_ptr<ConverterInterface<T, int32_t>> converter,
+    T fallback_default,
+    std::map<int, T> default_values) {
+  HAL_LOG_ENTER();
+
+  std::unique_ptr<Control<T>> result = V4L2Control(type,
+                                                   delegate_tag,
+                                                   options_tag,
+                                                   device,
+                                                   control_id,
+                                                   converter,
+                                                   default_values);
+  if (!result) {
+    result = NoEffectControl(
+        type, delegate_tag, options_tag, fallback_default, default_values);
+  }
+  return result;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_FACTORY_H_
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp b/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
new file mode 100644
index 0000000000..8e0b6f2f41
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_factory_test.cpp
@@ -0,0 +1,456 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "partial_metadata_factory.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+#include "metadata_common.h"
+#include "test_common.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class PartialMetadataFactoryTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_device_.reset(new V4L2WrapperMock());
+    mock_converter_.reset(new ConverterInterfaceMock<uint8_t, int32_t>());
+    // Nullify control so an error will be thrown
+    // if a test doesn't construct it.
+    control_.reset();
+  }
+
+  virtual void ExpectControlTags() {
+    ASSERT_EQ(control_->StaticTags().size(), 1u);
+    EXPECT_EQ(control_->StaticTags()[0], options_tag_);
+    ASSERT_EQ(control_->ControlTags().size(), 1u);
+    EXPECT_EQ(control_->ControlTags()[0], delegate_tag_);
+    ASSERT_EQ(control_->DynamicTags().size(), 1u);
+    EXPECT_EQ(control_->DynamicTags()[0], delegate_tag_);
+  }
+
+  virtual void ExpectControlOptions(const std::vector<uint8_t>& options) {
+    // Options should be available.
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateStaticFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, options_tag_, options);
+  }
+
+  virtual void ExpectControlValue(uint8_t value) {
+    android::CameraMetadata metadata;
+    ASSERT_EQ(control_->PopulateDynamicFields(&metadata), 0);
+    EXPECT_EQ(metadata.entryCount(), 1u);
+    ExpectMetadataEq(metadata, delegate_tag_, value);
+  }
+
+  std::unique_ptr<Control<uint8_t>> control_;
+  std::shared_ptr<ConverterInterfaceMock<uint8_t, int32_t>> mock_converter_;
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+
+  // Need tags that match the data type (uint8_t) being passed.
+  const int32_t delegate_tag_ = ANDROID_COLOR_CORRECTION_ABERRATION_MODE;
+  const int32_t options_tag_ =
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES;
+};
+
+class DISABLED_PartialMetadataFactoryTest : public PartialMetadataFactoryTest {
+};
+
+TEST_F(PartialMetadataFactoryTest, FixedState) {
+  uint8_t value = 13;
+  std::unique_ptr<State<uint8_t>> state = FixedState(delegate_tag_, value);
+
+  ASSERT_EQ(state->StaticTags().size(), 0u);
+  ASSERT_EQ(state->ControlTags().size(), 0u);
+  ASSERT_EQ(state->DynamicTags().size(), 1u);
+  EXPECT_EQ(state->DynamicTags()[0], delegate_tag_);
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state->PopulateDynamicFields(&metadata), 0);
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  ExpectMetadataEq(metadata, delegate_tag_, value);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectMenu) {
+  std::vector<uint8_t> test_options = {9, 8, 12};
+  control_ =
+      NoEffectMenuControl<uint8_t>(delegate_tag_, options_tag_, test_options);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions(test_options);
+  // Default value should be test_options[0].
+  ExpectControlValue(test_options[0]);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectGenericMenu) {
+  uint8_t default_val = 9;
+  control_ = NoEffectControl<uint8_t>(
+      ControlType::kMenu, delegate_tag_, options_tag_, default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions({default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectSlider) {
+  std::vector<uint8_t> test_range = {9, 12};
+  control_ = NoEffectSliderControl<uint8_t>(
+      delegate_tag_, options_tag_, test_range[0], test_range[1]);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Single option should be available.
+  ExpectControlOptions(test_range);
+  // Default value should be the minimum (test_range[0]).
+  ExpectControlValue(test_range[0]);
+}
+
+TEST_F(PartialMetadataFactoryTest, NoEffectGenericSlider) {
+  uint8_t default_val = 9;
+  control_ = NoEffectControl<uint8_t>(
+      ControlType::kSlider, delegate_tag_, options_tag_, default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Range containing only |default_val| should be available.
+  ExpectControlOptions({default_val, default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryFail) {
+  int control_id = 55;
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryBadType) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_CTRL_CLASS;
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryQueryBadRange) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 10;
+  query_result.maximum = 1;  // Less than minimum.
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Failure, should return null.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryTypeRequestMenuMismatch) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+
+  // If you ask for a Menu, but the V4L2 control is a slider type, that's bad.
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryTypeRequestSliderMismatch) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+
+  // If you ask for a Slider and get a Menu, that's bad.
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenu) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1-5, by step size 2.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {3, 30}, {5, 50}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Should convert values.
+  std::vector<uint8_t> expected_options;
+  for (auto kv : conversion_map) {
+    EXPECT_CALL(*mock_converter_, V4L2ToMetadata(kv.first, _))
+        .WillOnce(DoAll(SetArgPointee<1>(kv.second), Return(0)));
+    expected_options.push_back(kv.second);
+  }
+  // Will fail to convert 7 with -EINVAL, shouldn't matter.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(7, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+  ExpectControlOptions(expected_options);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenuConversionFail) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Conversion fails with non-EINVAL error.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(_, _)).WillOnce(Return(-1));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(DISABLED_PartialMetadataFactoryTest, V4L2FactoryMenuNoConversions) {
+  // TODO(b/30921166): Correct Menu support so this can be re-enabled.
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_MENU;
+  query_result.minimum = 1;
+  query_result.maximum = 1;
+  query_result.step = 1;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Conversion fails with -EINVAL error.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(1, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kMenu,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  // Since there were no convertable options, should fail.
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryInteger) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+  // Have conversions for values 1 & 7.
+  std::map<int32_t, uint8_t> conversion_map = {{1, 10}, {7, 70}};
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Should convert values.
+  std::vector<uint8_t> expected_options;
+  for (auto kv : conversion_map) {
+    EXPECT_CALL(*mock_converter_, V4L2ToMetadata(kv.first, _))
+        .WillOnce(DoAll(SetArgPointee<1>(kv.second), Return(0)));
+    expected_options.push_back(kv.second);
+  }
+
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+  ExpectControlOptions(expected_options);
+
+  // Should be fitting converted values to steps.
+  uint8_t set_val = 10;
+  android::CameraMetadata metadata;
+  EXPECT_EQ(UpdateMetadata(&metadata, delegate_tag_, set_val), 0);
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(set_val, _))
+      .WillOnce(DoAll(SetArgPointee<1>(4), Return(0)));
+  // When it calls into the device, the 4 returned above should be
+  // rounded down to the step value of 3.
+  EXPECT_CALL(*mock_device_, SetControl(control_id, 3, _)).WillOnce(Return(0));
+  EXPECT_EQ(control_->SetRequestValues(metadata), 0);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FactoryIntegerFailedConversion) {
+  int control_id = 55;
+  v4l2_query_ext_ctrl query_result;
+  query_result.type = V4L2_CTRL_TYPE_INTEGER;
+  query_result.minimum = 1;
+  query_result.maximum = 7;
+  query_result.step = 2;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(query_result), Return(0)));
+  // Fail to convert a value. Even -EINVAL is bad in this case.
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(1, _)).WillOnce(Return(-EINVAL));
+
+  control_ = V4L2Control<uint8_t>(ControlType::kSlider,
+                                  delegate_tag_,
+                                  options_tag_,
+                                  mock_device_,
+                                  control_id,
+                                  mock_converter_);
+  ASSERT_EQ(control_, nullptr);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FallbackMenu) {
+  uint8_t default_val = 9;
+  int control_id = 55;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+
+  // Shouldn't fail, should fall back to menu control.
+  control_ = V4L2ControlOrDefault<uint8_t>(ControlType::kMenu,
+                                           delegate_tag_,
+                                           options_tag_,
+                                           mock_device_,
+                                           control_id,
+                                           mock_converter_,
+                                           default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Options should be available.
+  ExpectControlOptions({default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+TEST_F(PartialMetadataFactoryTest, V4L2FallbackSlider) {
+  uint8_t default_val = 9;
+  int control_id = 55;
+
+  // Should query the device.
+  EXPECT_CALL(*mock_device_, QueryControl(control_id, _)).WillOnce(Return(-1));
+
+  // Shouldn't fail, should fall back to slider control.
+  control_ = V4L2ControlOrDefault<uint8_t>(ControlType::kSlider,
+                                           delegate_tag_,
+                                           options_tag_,
+                                           mock_device_,
+                                           control_id,
+                                           mock_converter_,
+                                           default_val);
+  ASSERT_NE(control_, nullptr);
+
+  ExpectControlTags();
+
+  // Range containing only |default_val| should be available.
+  ExpectControlOptions({default_val, default_val});
+  // |default_val| should be default option.
+  ExpectControlValue(default_val);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_interface.h b/hardware/ntimespace/camera/metadata/partial_metadata_interface.h
new file mode 100644
index 0000000000..a72e33a312
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_interface.h
@@ -0,0 +1,64 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
+
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+
+namespace v4l2_camera_hal {
+
+// A subset of metadata.
+class PartialMetadataInterface {
+ public:
+  virtual ~PartialMetadataInterface(){};
+
+  // The metadata tags this partial metadata is responsible for.
+  // See system/media/camera/docs/docs.html for descriptions of each tag.
+  virtual std::vector<int32_t> StaticTags() const = 0;
+  virtual std::vector<int32_t> ControlTags() const = 0;
+  virtual std::vector<int32_t> DynamicTags() const = 0;
+
+  // Add all the static properties this partial metadata
+  // is responsible for to |metadata|.
+  virtual int PopulateStaticFields(android::CameraMetadata* metadata) const = 0;
+  // Add all the dynamic states this partial metadata
+  // is responsible for to |metadata|.
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const = 0;
+  // Add default request values for a given template type for all the controls
+  // this partial metadata owns.
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const = 0;
+  // Check if the requested control values from |metadata| (for controls
+  // this partial metadata owns) are supported. Empty/null values for owned
+  // control tags indicate no change, and are thus inherently supported.
+  // If |metadata| is empty all controls are implicitly supported.
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const = 0;
+  // Set all the controls this partial metadata
+  // is responsible for from |metadata|. Empty/null values for owned control
+  // tags indicate no change. If |metadata| is empty no controls should
+  // be changed.
+  virtual int SetRequestValues(const android::CameraMetadata& metadata) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_PARTIAL_METADATA_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h b/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
new file mode 100644
index 0000000000..289b978522
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/partial_metadata_interface_mock.h
@@ -0,0 +1,45 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for partial metadata interfaces.
+
+#ifndef V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
+
+#include "partial_metadata_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+class PartialMetadataInterfaceMock : public PartialMetadataInterface {
+ public:
+  PartialMetadataInterfaceMock() : PartialMetadataInterface(){};
+  MOCK_CONST_METHOD0(StaticTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD0(ControlTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD0(DynamicTags, std::vector<int32_t>());
+  MOCK_CONST_METHOD1(PopulateStaticFields, int(android::CameraMetadata*));
+  MOCK_CONST_METHOD1(PopulateDynamicFields, int(android::CameraMetadata*));
+  MOCK_CONST_METHOD2(PopulateTemplateRequest,
+                     int(int, android::CameraMetadata*));
+  MOCK_CONST_METHOD1(SupportsRequestValues,
+                     bool(const android::CameraMetadata&));
+  MOCK_METHOD1(SetRequestValues, int(const android::CameraMetadata&));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_PARTIAL_METADATA_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/property.h b/hardware/ntimespace/camera/metadata/property.h
new file mode 100644
index 0000000000..b5a996cb0f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/property.h
@@ -0,0 +1,69 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
+#define V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
+
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A Property is a PartialMetadata that only has a single static tag.
+template <typename T>
+class Property : public PartialMetadataInterface {
+ public:
+  Property(int32_t tag, T value) : tag_(tag), value_(std::move(value)){};
+
+  virtual std::vector<int32_t> StaticTags() const override { return {tag_}; };
+
+  virtual std::vector<int32_t> ControlTags() const override { return {}; };
+
+  virtual std::vector<int32_t> DynamicTags() const override { return {}; };
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override {
+    return UpdateMetadata(metadata, tag_, value_);
+  };
+
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* /*metadata*/) const override {
+    return 0;
+  };
+
+  virtual int PopulateTemplateRequest(
+      int /*template_type*/, android::CameraMetadata* /*metadata*/) const override {
+    return 0;
+  };
+
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& /*metadata*/) const override {
+    return true;
+  };
+
+  virtual int SetRequestValues(
+      const android::CameraMetadata& /*metadata*/) override {
+    return 0;
+  };
+
+ private:
+  int32_t tag_;
+  T value_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_PROPERTY_H_
diff --git a/hardware/ntimespace/camera/metadata/property_test.cpp b/hardware/ntimespace/camera/metadata/property_test.cpp
new file mode 100644
index 0000000000..5c3107ee1a
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/property_test.cpp
@@ -0,0 +1,156 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "property.h"
+
+#include <array>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "array_vector.h"
+#include "metadata_common.h"
+#include "test_common.h"
+
+using testing::Test;
+
+namespace v4l2_camera_hal {
+
+class PropertyTest : public Test {
+ protected:
+  // Need tags that match the data types being passed.
+  static constexpr int32_t byte_tag_ = ANDROID_CONTROL_SCENE_MODE_OVERRIDES;
+  static constexpr int32_t float_tag_ = ANDROID_COLOR_CORRECTION_GAINS;
+  static constexpr int32_t int_tag_ = ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION;
+  static constexpr int32_t int_tag2_ = ANDROID_JPEG_ORIENTATION;
+};
+
+TEST_F(PropertyTest, Tags) {
+  Property<int32_t> property(int_tag_, 1);
+
+  // Should have only the single tag it was constructed with.
+  EXPECT_EQ(property.ControlTags().size(), 0u);
+  EXPECT_EQ(property.DynamicTags().size(), 0u);
+  ASSERT_EQ(property.StaticTags().size(), 1u);
+  // The macro doesn't like the int_tag_ variable being passed in directly.
+  int32_t expected_tag = int_tag_;
+  EXPECT_EQ(property.StaticTags()[0], expected_tag);
+}
+
+TEST_F(PropertyTest, PopulateStaticSingleNumber) {
+  // Set up a fixed property.
+  int32_t data = 1234;
+  Property<int32_t> property(int_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, int_tag_, data);
+}
+
+// TODO(b/30839858): These tests are really testing the metadata_common.h
+// UpdateMetadata methods, and shouldn't be conducted here.
+TEST_F(PropertyTest, PopulateStaticVector) {
+  // Set up a fixed property.
+  std::vector<float> data({0.1, 2.3, 4.5, 6.7});
+  Property<std::vector<float>> property(float_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, float_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateStaticArray) {
+  // Set up a fixed property.
+  std::array<float, 4> data({{0.1, 2.3, 4.5, 6.7}});
+  Property<std::array<float, 4>> property(float_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, float_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateStaticArrayVector) {
+  // Set up a fixed property.
+  ArrayVector<uint8_t, 3> data;
+  data.push_back({{1, 2, 3}});
+  data.push_back({{4, 5, 6}});
+  Property<ArrayVector<uint8_t, 3>> property(byte_tag_, data);
+
+  // Populate static fields.
+  android::CameraMetadata metadata;
+  ASSERT_EQ(property.PopulateStaticFields(&metadata), 0);
+
+  // Check the results.
+  // Should only have added 1 entry.
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  // Should have added the right entry.
+  ExpectMetadataEq(metadata, byte_tag_, data);
+}
+
+TEST_F(PropertyTest, PopulateDynamic) {
+  Property<int32_t> property(int_tag_, 1);
+
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.PopulateDynamicFields(&metadata), 0);
+
+  // Shouldn't have added anything.
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(PropertyTest, PopulateTemplate) {
+  Property<int32_t> property(int_tag_, 1);
+
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    android::CameraMetadata metadata;
+    EXPECT_EQ(property.PopulateTemplateRequest(i, &metadata), 0);
+    // Shouldn't have added anything.
+    EXPECT_TRUE(metadata.isEmpty());
+  }
+}
+
+TEST_F(PropertyTest, SupportsRequest) {
+  Property<int32_t> property(int_tag_, 1);
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.SupportsRequestValues(metadata), true);
+}
+
+TEST_F(PropertyTest, SetRequest) {
+  Property<int32_t> property(int_tag_, 1);
+  android::CameraMetadata metadata;
+  EXPECT_EQ(property.SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/ranged_converter.h b/hardware/ntimespace/camera/metadata/ranged_converter.h
new file mode 100644
index 0000000000..abfe370533
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ranged_converter.h
@@ -0,0 +1,103 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
+
+#include <memory>
+
+#include <android-base/macros.h>
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An RangedConverter fits values converted by a wrapped converter
+// to a stepped range (when going from metadata -> v4l2. The other
+// direction remains unchanged).
+template <typename TMetadata, typename TV4L2>
+class RangedConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  RangedConverter(
+      std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter,
+      TV4L2 min,
+      TV4L2 max,
+      TV4L2 step);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter_;
+  const TV4L2 min_;
+  const TV4L2 max_;
+  const TV4L2 step_;
+
+  DISALLOW_COPY_AND_ASSIGN(RangedConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2>
+RangedConverter<TMetadata, TV4L2>::RangedConverter(
+    std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> wrapped_converter,
+    TV4L2 min,
+    TV4L2 max,
+    TV4L2 step)
+    : wrapped_converter_(std::move(wrapped_converter)),
+      min_(min),
+      max_(max),
+      step_(step) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2>
+int RangedConverter<TMetadata, TV4L2>::MetadataToV4L2(TMetadata value,
+                                                      TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  TV4L2 raw_conversion = 0;
+  int res = wrapped_converter_->MetadataToV4L2(value, &raw_conversion);
+  if (res) {
+    HAL_LOGE("Failed to perform underlying conversion.");
+    return res;
+  }
+
+  // Round down to step (steps start at min_).
+  raw_conversion -= (raw_conversion - min_) % step_;
+
+  // Clamp to range.
+  if (raw_conversion < min_) {
+    raw_conversion = min_;
+  } else if (raw_conversion > max_) {
+    raw_conversion = max_;
+  }
+
+  *conversion = raw_conversion;
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2>
+int RangedConverter<TMetadata, TV4L2>::V4L2ToMetadata(TV4L2 value,
+                                                      TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  return wrapped_converter_->V4L2ToMetadata(value, conversion);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_RANGED_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp b/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
new file mode 100644
index 0000000000..2b5ccc63ea
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/ranged_converter_test.cpp
@@ -0,0 +1,86 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "ranged_converter.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "converter_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class RangedConverterTest : public Test {
+ protected:
+  virtual void SetUp() {
+    converter_.reset(new ConverterInterfaceMock<int, int32_t>());
+    dut_.reset(
+        new RangedConverter<int, int32_t>(converter_, min_, max_, step_));
+  }
+
+  virtual void ExpectConvert(int32_t converted, int32_t expected) {
+    int initial = 99;
+    EXPECT_CALL(*converter_, MetadataToV4L2(initial, _))
+        .WillOnce(DoAll(SetArgPointee<1>(converted), Return(0)));
+
+    int32_t actual = expected + 1;  // Initialize to non-expected value.
+    ASSERT_EQ(dut_->MetadataToV4L2(initial, &actual), 0);
+    EXPECT_EQ(actual, expected);
+  }
+
+  std::shared_ptr<ConverterInterfaceMock<int, int32_t>> converter_;
+  std::unique_ptr<RangedConverter<int, int32_t>> dut_;
+
+  const int32_t min_ = -11;
+  const int32_t max_ = 10;
+  const int32_t step_ = 3;
+};
+
+TEST_F(RangedConverterTest, NormalConversion) {
+  // A value that's in range and on step.
+  ExpectConvert(max_ - step_, max_ - step_);
+}
+
+TEST_F(RangedConverterTest, RoundingConversion) {
+  // A value that's in range but off step.
+  ExpectConvert(max_ - step_ + 1, max_ - step_);
+}
+
+TEST_F(RangedConverterTest, ClampUpConversion) {
+  // A value that's below range.
+  ExpectConvert(min_ - 1, min_);
+}
+
+TEST_F(RangedConverterTest, ClampDownConversion) {
+  // A value that's above range (even after fitting to step).
+  ExpectConvert(max_ + step_, max_);
+}
+
+TEST_F(RangedConverterTest, ConversionError) {
+  int initial = 99;
+  int err = -99;
+  EXPECT_CALL(*converter_, MetadataToV4L2(initial, _)).WillOnce(Return(err));
+
+  int32_t unused;
+  EXPECT_EQ(dut_->MetadataToV4L2(initial, &unused), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/scaling_converter.h b/hardware/ntimespace/camera/metadata/scaling_converter.h
new file mode 100644
index 0000000000..bddf1f40d5
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/scaling_converter.h
@@ -0,0 +1,75 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
+#define V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
+
+#include "common.h"
+#include "converter_interface.h"
+
+namespace v4l2_camera_hal {
+
+// An ScalingConverter scales values up or down.
+template <typename TMetadata, typename TV4L2>
+class ScalingConverter : public ConverterInterface<TMetadata, TV4L2> {
+ public:
+  ScalingConverter(TMetadata v4l2_to_metadata_numerator,
+                   TMetadata v4l2_to_metadata_denominator);
+
+  virtual int MetadataToV4L2(TMetadata value, TV4L2* conversion) override;
+  virtual int V4L2ToMetadata(TV4L2 value, TMetadata* conversion) override;
+
+ private:
+  const TMetadata v4l2_to_metadata_numerator_;
+  const TMetadata v4l2_to_metadata_denominator_;
+
+  DISALLOW_COPY_AND_ASSIGN(ScalingConverter);
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename TMetadata, typename TV4L2>
+ScalingConverter<TMetadata, TV4L2>::ScalingConverter(
+    TMetadata v4l2_to_metadata_numerator,
+    TMetadata v4l2_to_metadata_denominator)
+    : v4l2_to_metadata_numerator_(v4l2_to_metadata_numerator),
+      v4l2_to_metadata_denominator_(v4l2_to_metadata_denominator) {
+  HAL_LOG_ENTER();
+}
+
+template <typename TMetadata, typename TV4L2>
+int ScalingConverter<TMetadata, TV4L2>::MetadataToV4L2(TMetadata value,
+                                                       TV4L2* conversion) {
+  HAL_LOG_ENTER();
+
+  *conversion = static_cast<TV4L2>(value * v4l2_to_metadata_denominator_ /
+                                   v4l2_to_metadata_numerator_);
+  return 0;
+}
+
+template <typename TMetadata, typename TV4L2>
+int ScalingConverter<TMetadata, TV4L2>::V4L2ToMetadata(TV4L2 value,
+                                                       TMetadata* conversion) {
+  HAL_LOG_ENTER();
+
+  *conversion = static_cast<TMetadata>(value) * v4l2_to_metadata_numerator_ /
+                v4l2_to_metadata_denominator_;
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_SCALING_CONVERTER_H_
diff --git a/hardware/ntimespace/camera/metadata/slider_control_options.h b/hardware/ntimespace/camera/metadata/slider_control_options.h
new file mode 100644
index 0000000000..b23ba34c02
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/slider_control_options.h
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
+
+#include <cerrno>
+#include <vector>
+
+#include "common.h"
+#include "control_options_interface.h"
+#include "default_option_delegate.h"
+
+namespace v4l2_camera_hal {
+
+// SliderControlOptions offer a range of acceptable values, inclusive.
+template <typename T>
+class SliderControlOptions : public ControlOptionsInterface<T> {
+ public:
+  // |min| must be <= |max|.
+  SliderControlOptions(const T& min,
+                       const T& max,
+                       std::shared_ptr<DefaultOptionDelegate<T>> defaults)
+      : min_(min), max_(max), defaults_(defaults){};
+  SliderControlOptions(const T& min, const T& max, std::map<int, T> defaults)
+      : min_(min),
+        max_(max),
+        defaults_(std::make_shared<DefaultOptionDelegate<T>>(defaults)){};
+
+  virtual std::vector<T> MetadataRepresentation() override {
+    return {min_, max_};
+  };
+  virtual bool IsSupported(const T& option) override {    
+    HAL_LOG_ENTER();
+    return option >= min_ && option <= max_;
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    if (min_ > max_) {
+      HAL_LOGE("No valid default slider option, min is greater than max.");
+      return -ENODEV;
+    }
+
+    if (defaults_->DefaultValueForTemplate(template_type, default_value)) {
+      // Get as close as we can to the desired value.
+      if (*default_value < min_) {
+        *default_value = min_;
+      } else if (*default_value > max_) {
+        *default_value = max_;
+      }
+      return 0;
+    }
+
+    // No default given, just fall back to the min of the range.
+    *default_value = min_;
+    return 0;
+  };
+
+ private:
+  T min_;
+  T max_;
+  std::shared_ptr<DefaultOptionDelegate<T>> defaults_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_SLIDER_CONTROL_OPTIONS_H_
diff --git a/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp b/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
new file mode 100644
index 0000000000..7f3a64364c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/slider_control_options_test.cpp
@@ -0,0 +1,128 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "slider_control_options.h"
+
+#include <memory>
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include "default_option_delegate_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class SliderControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_defaults_.reset(new DefaultOptionDelegateMock<int>());
+    dut_.reset(new SliderControlOptions<int>(min_, max_, mock_defaults_));
+  }
+
+  std::unique_ptr<SliderControlOptions<int>> dut_;
+  std::shared_ptr<DefaultOptionDelegateMock<int>> mock_defaults_;
+  const int min_ = 1;
+  const int max_ = 10;
+};
+
+TEST_F(SliderControlOptionsTest, MetadataRepresentation) {
+  // Technically order doesn't matter, but this is faster to write,
+  // and still passes.
+  std::vector<int> expected{min_, max_};
+  EXPECT_EQ(dut_->MetadataRepresentation(), expected);
+}
+
+TEST_F(SliderControlOptionsTest, IsSupported) {
+  for (int i = min_; i <= max_; ++i) {
+    EXPECT_TRUE(dut_->IsSupported(i));
+  }
+  // Out of range unsupported.
+  EXPECT_FALSE(dut_->IsSupported(min_ - 1));
+  EXPECT_FALSE(dut_->IsSupported(max_ + 1));
+}
+
+TEST_F(SliderControlOptionsTest, DelegateDefaultValue) {
+  int template_index = 3;
+  int expected = max_ - 1;
+  ASSERT_TRUE(dut_->IsSupported(expected));
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(expected), Return(true)));
+  int actual = expected - 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, LowDelegateDefaultValue) {
+  int template_index = 3;
+  // min - 1 is below the valid range.
+  int default_val = min_ - 1;
+  // Should get bumped up into range.
+  int expected = min_;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+  ASSERT_TRUE(dut_->IsSupported(expected));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, HighDelegateDefaultValue) {
+  int template_index = 3;
+  // max + 1 is above the valid range.
+  int default_val = max_ + 1;
+  // Should get bumped down into range.
+  int expected = max_;
+  ASSERT_FALSE(dut_->IsSupported(default_val));
+  ASSERT_TRUE(dut_->IsSupported(expected));
+
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(DoAll(SetArgPointee<1>(default_val), Return(true)));
+  int actual = default_val;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(SliderControlOptionsTest, NoDelegateDefaultValue) {
+  int template_index = 3;
+  int actual = min_ - 1;
+  ASSERT_FALSE(dut_->IsSupported(actual));
+
+  // Have delegate error.
+  EXPECT_CALL(*mock_defaults_, DefaultValueForTemplate(template_index, _))
+      .WillOnce(Return(false));
+
+  // Should still give *some* supported value.
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_index, &actual), 0);
+  EXPECT_TRUE(dut_->IsSupported(actual));
+}
+
+TEST_F(SliderControlOptionsTest, NoDefaultValue) {
+  // Invalid options don't have a valid default.
+  SliderControlOptions<int> bad_options(10, 9, mock_defaults_);  // min > max.
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    int value = -1;
+    EXPECT_EQ(bad_options.DefaultValueForTemplate(i, &value), -ENODEV);
+  }
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/state.h b/hardware/ntimespace/camera/metadata/state.h
new file mode 100644
index 0000000000..3fd844761f
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state.h
@@ -0,0 +1,96 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_H_
+
+#include "common.h"
+#include "metadata_common.h"
+#include "partial_metadata_interface.h"
+#include "state_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A State is a PartialMetadata that only has a single dynamic value.
+template <typename T>
+class State : public PartialMetadataInterface {
+ public:
+  State(int32_t tag, std::unique_ptr<StateDelegateInterface<T>> delegate)
+      : tag_(tag), delegate_(std::move(delegate)){};
+
+  virtual std::vector<int32_t> StaticTags() const override { return {}; };
+  virtual std::vector<int32_t> ControlTags() const override { return {}; };
+  virtual std::vector<int32_t> DynamicTags() const override { return {tag_}; };
+
+  virtual int PopulateStaticFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateDynamicFields(
+      android::CameraMetadata* metadata) const override;
+  virtual int PopulateTemplateRequest(
+      int template_type, android::CameraMetadata* metadata) const override;
+  virtual bool SupportsRequestValues(
+      const android::CameraMetadata& metadata) const override;
+  virtual int SetRequestValues(
+      const android::CameraMetadata& metadata) override;
+
+ private:
+  int32_t tag_;
+  std::unique_ptr<StateDelegateInterface<T>> delegate_;
+};
+
+// -----------------------------------------------------------------------------
+
+template <typename T>
+int State<T>::PopulateStaticFields(android::CameraMetadata* /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return 0;
+}
+
+template <typename T>
+int State<T>::PopulateDynamicFields(android::CameraMetadata* metadata) const {
+  HAL_LOG_ENTER();
+
+  T value;
+  int res = delegate_->GetValue(&value);
+  if (res) {
+    return res;
+  }
+  return UpdateMetadata(metadata, tag_, value);
+};
+
+template <typename T>
+int State<T>::PopulateTemplateRequest(int /*template_type*/,
+                                      android::CameraMetadata* /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return 0;
+};
+
+template <typename T>
+bool State<T>::SupportsRequestValues(
+    const android::CameraMetadata& /*metadata*/) const {
+  HAL_LOG_ENTER();
+  return true;
+};
+
+template <typename T>
+int State<T>::SetRequestValues(const android::CameraMetadata& /*metadata*/) {
+  HAL_LOG_ENTER();
+  return 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_STATE_H_
diff --git a/hardware/ntimespace/camera/metadata/state_delegate_interface.h b/hardware/ntimespace/camera/metadata/state_delegate_interface.h
new file mode 100644
index 0000000000..c18ee3ce47
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_delegate_interface.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
+
+namespace v4l2_camera_hal {
+
+// A StateDelegate is simply a dynamic value that can be queried.
+// The value may change between queries.
+template <typename T>
+class StateDelegateInterface {
+ public:
+  virtual ~StateDelegateInterface(){};
+  // Returns 0 on success, error code on failure.
+  virtual int GetValue(T* value) = 0;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h b/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
new file mode 100644
index 0000000000..e9698f1601
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_delegate_interface_mock.h
@@ -0,0 +1,37 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for state delegate interfaces.
+
+#ifndef V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_MOCK_H_
+#define V4L2_CAMERA_HAL_METADATA_STATE_DELEGATE_INTERFACE_MOCK_H_
+
+#include "state_delegate_interface.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+template <typename T>
+class StateDelegateInterfaceMock : public StateDelegateInterface<T> {
+ public:
+  StateDelegateInterfaceMock(){};
+  MOCK_METHOD1_T(GetValue, int(T*));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_MOCK_H_
diff --git a/hardware/ntimespace/camera/metadata/state_test.cpp b/hardware/ntimespace/camera/metadata/state_test.cpp
new file mode 100644
index 0000000000..7360bc9bb8
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/state_test.cpp
@@ -0,0 +1,117 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "state.h"
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "metadata_common.h"
+#include "state_delegate_interface_mock.h"
+#include "test_common.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class StateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new StateDelegateInterfaceMock<uint8_t>());
+    // Nullify state so an error will be thrown if a test doesn't call
+    // PrepareState.
+    state_.reset();
+  }
+
+  virtual void PrepareState() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the mocks
+    // to the device.
+    state_.reset(new State<uint8_t>(tag_, std::move(mock_delegate_)));
+  }
+
+  std::unique_ptr<State<uint8_t>> state_;
+  std::unique_ptr<StateDelegateInterfaceMock<uint8_t>> mock_delegate_;
+
+  // Need tag that matches the data type (uint8_t) being passed.
+  const int32_t tag_ = ANDROID_CONTROL_AF_STATE;
+};
+
+TEST_F(StateTest, Tags) {
+  PrepareState();
+  EXPECT_TRUE(state_->StaticTags().empty());
+  EXPECT_TRUE(state_->ControlTags().empty());
+  ASSERT_EQ(state_->DynamicTags().size(), 1u);
+  EXPECT_EQ(state_->DynamicTags()[0], tag_);
+}
+
+TEST_F(StateTest, PopulateStatic) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateStaticFields(&metadata), 0);
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(StateTest, PopulateDynamic) {
+  uint8_t expected = 99;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(expected), Return(0)));
+
+  PrepareState();
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateDynamicFields(&metadata), 0);
+  EXPECT_EQ(metadata.entryCount(), 1u);
+  ExpectMetadataEq(metadata, tag_, expected);
+}
+
+TEST_F(StateTest, PopulateDynamicFail) {
+  int err = 123;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+
+  PrepareState();
+
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateDynamicFields(&metadata), err);
+}
+
+TEST_F(StateTest, PopulateTemplate) {
+  int template_type = 3;
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->PopulateTemplateRequest(template_type, &metadata), 0);
+  EXPECT_TRUE(metadata.isEmpty());
+}
+
+TEST_F(StateTest, SupportsRequest) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  EXPECT_TRUE(state_->SupportsRequestValues(metadata));
+}
+
+TEST_F(StateTest, SetRequest) {
+  PrepareState();
+  android::CameraMetadata metadata;
+  ASSERT_EQ(state_->SetRequestValues(metadata), 0);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_delegate.h b/hardware/ntimespace/camera/metadata/tagged_control_delegate.h
new file mode 100644
index 0000000000..40677f938c
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_delegate.h
@@ -0,0 +1,50 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_DELEGATE_H_
+
+#include <memory>
+
+#include "control_delegate_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A TaggedControlDelegate wraps a ControlDelegate and adds a tag.
+template <typename T>
+class TaggedControlDelegate : public ControlDelegateInterface<T> {
+ public:
+  TaggedControlDelegate(int32_t tag,
+                        std::unique_ptr<ControlDelegateInterface<T>> delegate)
+      : tag_(tag), delegate_(std::move(delegate)){};
+
+  int32_t tag() { return tag_; };
+
+  virtual int GetValue(T* value) override {
+    return delegate_->GetValue(value);
+  };
+  virtual int SetValue(const T& value) override {
+    return delegate_->SetValue(value);
+  };
+
+ private:
+  const int32_t tag_;
+  std::unique_ptr<ControlDelegateInterface<T>> delegate_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_DELEGATE_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
new file mode 100644
index 0000000000..ba29ab7b44
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_delegate_test.cpp
@@ -0,0 +1,90 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "tagged_control_delegate.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_delegate_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class TaggedControlDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_delegate_.reset(new ControlDelegateInterfaceMock<uint8_t>());
+    // Nullify dut so an error will be thrown if a test doesn't call PrepareDUT.
+    dut_.reset();
+  }
+
+  virtual void PrepareDUT() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the
+    // delegate
+    // to the device.
+    dut_.reset(
+        new TaggedControlDelegate<uint8_t>(tag_, std::move(mock_delegate_)));
+  }
+
+  std::unique_ptr<TaggedControlDelegate<uint8_t>> dut_;
+  std::unique_ptr<ControlDelegateInterfaceMock<uint8_t>> mock_delegate_;
+  const int32_t tag_ = 123;
+};
+
+TEST_F(TaggedControlDelegateTest, GetTag) {
+  PrepareDUT();
+  EXPECT_EQ(dut_->tag(), tag_);
+}
+
+TEST_F(TaggedControlDelegateTest, GetSuccess) {
+  uint8_t expected = 3;
+  EXPECT_CALL(*mock_delegate_, GetValue(_))
+      .WillOnce(DoAll(SetArgPointee<0>(expected), Return(0)));
+  PrepareDUT();
+  uint8_t actual = expected + 1;  // Initialize to an incorrect value.
+  ASSERT_EQ(dut_->GetValue(&actual), 0);
+  EXPECT_EQ(actual, expected);
+}
+
+TEST_F(TaggedControlDelegateTest, GetFailure) {
+  int err = 3;
+  EXPECT_CALL(*mock_delegate_, GetValue(_)).WillOnce(Return(err));
+  PrepareDUT();
+  uint8_t unused = 0;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(TaggedControlDelegateTest, SetSuccess) {
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_delegate_, SetValue(value)).WillOnce(Return(0));
+  PrepareDUT();
+  ASSERT_EQ(dut_->SetValue(value), 0);
+}
+
+TEST_F(TaggedControlDelegateTest, SetFailure) {
+  int err = 3;
+  uint8_t value = 12;
+  EXPECT_CALL(*mock_delegate_, SetValue(value)).WillOnce(Return(err));
+  PrepareDUT();
+  ASSERT_EQ(dut_->SetValue(value), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_options.h b/hardware/ntimespace/camera/metadata/tagged_control_options.h
new file mode 100644
index 0000000000..3d900ae9e1
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_options.h
@@ -0,0 +1,61 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_OPTIONS_H_
+#define V4L2_CAMERA_HAL_METADATA_TAGGED_CONTROL_OPTIONS_H_
+
+#include <memory>
+
+#include "control_options_interface.h"
+
+namespace v4l2_camera_hal {
+
+// A constant tag with a value not used as a real tag
+// (since all real tags are unsigned),  to indicate options
+// that should not be reported.
+// Any class working with TaggedControlOptions should check
+// the tag against this value before using it.
+static int32_t DO_NOT_REPORT_OPTIONS = -1;
+
+// A TaggedControlOptions wraps a ControlOptions and adds a tag.
+template <typename T>
+class TaggedControlOptions : public ControlOptionsInterface<T> {
+ public:
+  TaggedControlOptions(int32_t tag,
+                       std::unique_ptr<ControlOptionsInterface<T>> options)
+      : tag_(tag), options_(std::move(options)){};
+
+  int32_t tag() { return tag_; };
+
+  virtual std::vector<T> MetadataRepresentation() override {
+    return options_->MetadataRepresentation();
+  };
+  virtual bool IsSupported(const T& value) override {
+    return options_->IsSupported(value);
+  };
+  virtual int DefaultValueForTemplate(int template_type,
+                                      T* default_value) override {
+    return options_->DefaultValueForTemplate(template_type, default_value);
+  }
+
+ private:
+  const int32_t tag_;
+  std::unique_ptr<ControlOptionsInterface<T>> options_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_CONTROL_OPTIONS_INTERFACE_H_
diff --git a/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp b/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
new file mode 100644
index 0000000000..845426a914
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/tagged_control_options_test.cpp
@@ -0,0 +1,102 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "tagged_control_options.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+
+#include "control_options_interface_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class TaggedControlOptionsTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_options_.reset(new ControlOptionsInterfaceMock<uint8_t>());
+    // Nullify dut so an error will be thrown if a test doesn't call PrepareDUT.
+    dut_.reset();
+  }
+
+  virtual void PrepareDUT() {
+    // Use this method after all the EXPECT_CALLs to pass ownership of the
+    // options
+    // to the device.
+    dut_.reset(
+        new TaggedControlOptions<uint8_t>(tag_, std::move(mock_options_)));
+  }
+
+  std::unique_ptr<TaggedControlOptions<uint8_t>> dut_;
+  std::unique_ptr<ControlOptionsInterfaceMock<uint8_t>> mock_options_;
+  const int32_t tag_ = 123;
+};
+
+TEST_F(TaggedControlOptionsTest, GetTag) {
+  PrepareDUT();
+  EXPECT_EQ(dut_->tag(), tag_);
+}
+
+TEST_F(TaggedControlOptionsTest, MetadataRepresentation) {
+  std::vector<uint8_t> expected{3, 4, 5};
+  EXPECT_CALL(*mock_options_, MetadataRepresentation())
+      .WillOnce(Return(expected));
+  PrepareDUT();
+  ASSERT_EQ(dut_->MetadataRepresentation(), expected);
+}
+
+TEST_F(TaggedControlOptionsTest, IsSupportedTrue) {
+  bool supported = true;
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_options_, IsSupported(value)).WillOnce(Return(supported));
+  PrepareDUT();
+  ASSERT_EQ(dut_->IsSupported(value), supported);
+}
+
+TEST_F(TaggedControlOptionsTest, IsSupportedFalse) {
+  bool supported = false;
+  uint8_t value = 3;
+  EXPECT_CALL(*mock_options_, IsSupported(value)).WillOnce(Return(supported));
+  PrepareDUT();
+  ASSERT_EQ(dut_->IsSupported(value), supported);
+}
+
+TEST_F(TaggedControlOptionsTest, DefaultValue) {
+  uint8_t value = 99;
+  int template_id = 3;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_id, _))
+      .WillOnce(DoAll(SetArgPointee<1>(value), Return(0)));
+  PrepareDUT();
+  uint8_t actual = value + 1;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_id, &actual), 0);
+  EXPECT_EQ(actual, value);
+}
+
+TEST_F(TaggedControlOptionsTest, DefaultValueFail) {
+  int err = 12;
+  int template_id = 3;
+  EXPECT_CALL(*mock_options_, DefaultValueForTemplate(template_id, _))
+      .WillOnce(Return(err));
+  PrepareDUT();
+  uint8_t unused;
+  EXPECT_EQ(dut_->DefaultValueForTemplate(template_id, &unused), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/metadata/test_common.h b/hardware/ntimespace/camera/metadata/test_common.h
new file mode 100644
index 0000000000..35a7681390
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/test_common.h
@@ -0,0 +1,96 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
+#define V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
+
+#include <array>
+#include <vector>
+
+//#include <camera/CameraMetadata.h>
+#include "metadata/camera_metadata.h"
+#include <gtest/gtest.h>
+#include "array_vector.h"
+#include "metadata_common.h"
+
+namespace v4l2_camera_hal {
+
+// Check that metadata of a given tag matches expectations.
+// Generic.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const T* expected,
+                             size_t size) {
+  camera_metadata_ro_entry_t entry = metadata.find(tag);
+  ASSERT_EQ(entry.count, size);
+  const T* data = nullptr;
+  GetDataPointer(entry, &data);
+  ASSERT_NE(data, nullptr);
+  for (size_t i = 0; i < size; ++i) {
+    EXPECT_EQ(data[i], expected[i]);
+  }
+}
+
+// Single item.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             T expected) {
+  ExpectMetadataEq(metadata, tag, &expected, 1);
+}
+
+// Vector of items.
+template <typename T>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::vector<T>& expected) {
+  ExpectMetadataEq(metadata, tag, expected.data(), expected.size());
+}
+
+// Array of items.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::array<T, N>& expected) {
+  ExpectMetadataEq(metadata, tag, expected.data(), N);
+}
+
+// ArrayVector.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const ArrayVector<T, N>& expected) {
+  ExpectMetadataEq(
+      metadata, tag, expected.data(), expected.total_num_elements());
+}
+
+// Vector of arrays.
+template <typename T, size_t N>
+static void ExpectMetadataEq(const android::CameraMetadata& metadata,
+                             int32_t tag,
+                             const std::vector<std::array<T, N>>& expected) {
+  // Convert to array vector so we know all the elements are contiguous.
+  ArrayVector<T, N> array_vector;
+  for (const auto& array : expected) {
+    array_vector.push_back(array);
+  }
+  ExpectMetadataEq(metadata, tag, array_vector);
+}
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_TEST_COMMON_H_
diff --git a/hardware/ntimespace/camera/metadata/types.h b/hardware/ntimespace/camera/metadata/types.h
new file mode 100644
index 0000000000..093fe011dd
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/types.h
@@ -0,0 +1,82 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
+#define DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
+
+#include <array>
+#include <map>
+#include <set>
+
+#include <hardware/camera3.h>
+
+namespace default_camera_hal {
+
+// A variety of Structs describing more complex metadata entries.
+
+// StreamSpec describe the attributes of a single stream.
+struct StreamSpec {
+  int32_t format;
+  int32_t width;
+  int32_t height;
+
+  StreamSpec(int32_t f, int32_t w, int32_t h)
+      : format(f), width(w), height(h) {}
+  StreamSpec(const camera3_stream_t* stream)
+      : format(stream->format), width(stream->width), height(stream->height) {}
+
+  struct Compare {
+    bool operator()(const StreamSpec& left, const StreamSpec& right) const {
+      // Base equality/comparison first on format, then on width, then height.
+      return left.format < right.format ||
+             (left.format == right.format &&
+              (left.width < right.width ||
+               (left.width == right.width && left.height < right.height)));
+    }
+  };
+};
+
+// StreamConfigurations indicate a possible direction configuration for
+// a given set of stream specifications.
+typedef std::array<int32_t, 4> RawStreamConfiguration;
+struct StreamConfiguration {
+  StreamSpec spec;
+  int32_t direction;
+
+  StreamConfiguration(const RawStreamConfiguration& raw)
+      : spec({raw[0], raw[1], raw[2]}), direction(raw[3]) {}
+};
+
+// StreamStallDurations indicate the stall duration (in ns) for
+// when a stream with a given set of specifications is used as output.
+typedef std::array<int64_t, 4> RawStreamStallDuration;
+struct StreamStallDuration {
+  StreamSpec spec;
+  int64_t duration;
+
+  StreamStallDuration(const RawStreamStallDuration& raw)
+      : spec({static_cast<int32_t>(raw[0]),
+              static_cast<int32_t>(raw[1]),
+              static_cast<int32_t>(raw[2])}),
+        duration(raw[3]) {}
+};
+
+// Map input formats to their supported reprocess output formats.
+typedef std::map<int32_t, std::set<int32_t>> ReprocessFormatMap;
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_METADATA_TYPES_H_
diff --git a/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h b/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
new file mode 100644
index 0000000000..b52c252e24
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/v4l2_control_delegate.h
@@ -0,0 +1,66 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
+#define V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
+
+#include "control_delegate_interface.h"
+#include "converter_interface.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A V4L2ControlDelegate routes getting and setting through V4L2
+template <typename TMetadata, typename TV4L2 = int32_t>
+class V4L2ControlDelegate : public ControlDelegateInterface<TMetadata> {
+ public:
+  V4L2ControlDelegate(
+      std::shared_ptr<V4L2Wrapper> device,
+      int control_id,
+      std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> converter)
+      : device_(std::move(device)),
+        control_id_(control_id),
+        converter_(std::move(converter)){};
+
+  int GetValue(TMetadata* value) override {
+    TV4L2 v4l2_value;
+    int res = device_->GetControl(control_id_, &v4l2_value);
+    if (res) {
+      HAL_LOGE("Failed to get device value for control %d.", control_id_);
+      return res;
+    }
+    return converter_->V4L2ToMetadata(v4l2_value, value);
+  };
+
+  int SetValue(const TMetadata& value) override {
+    TV4L2 v4l2_value;
+    int res = converter_->MetadataToV4L2(value, &v4l2_value);
+    if (res) {
+      HAL_LOGE("Failed to convert metadata value to V4L2.");
+      return res;
+    }
+    return device_->SetControl(control_id_, v4l2_value);
+  };
+
+ private:
+  std::shared_ptr<V4L2Wrapper> device_;
+  int control_id_;
+  std::shared_ptr<ConverterInterface<TMetadata, TV4L2>> converter_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_METADATA_V4L2_CONTROL_DELEGATE_H_
diff --git a/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp b/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
new file mode 100644
index 0000000000..63ad0f60f4
--- /dev/null
+++ b/hardware/ntimespace/camera/metadata/v4l2_control_delegate_test.cpp
@@ -0,0 +1,109 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "v4l2_control_delegate.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include "converter_interface_mock.h"
+#include "v4l2_wrapper_mock.h"
+
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace v4l2_camera_hal {
+
+class V4L2ControlDelegateTest : public Test {
+ protected:
+  virtual void SetUp() {
+    mock_device_.reset(new V4L2WrapperMock());
+    mock_converter_.reset(new ConverterInterfaceMock<uint8_t, int32_t>());
+    dut_.reset(new V4L2ControlDelegate<uint8_t>(
+        mock_device_, control_id_, mock_converter_));
+  }
+
+  std::unique_ptr<V4L2ControlDelegate<uint8_t>> dut_;
+  std::shared_ptr<V4L2WrapperMock> mock_device_;
+  std::shared_ptr<ConverterInterfaceMock<uint8_t, int32_t>> mock_converter_;
+  const int control_id_ = 123;
+};
+
+TEST_F(V4L2ControlDelegateTest, GetSuccess) {
+  int32_t device_result = 99;
+  uint8_t conversion_result = 10;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _))
+      .WillOnce(DoAll(SetArgPointee<1>(device_result), Return(0)));
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(device_result, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+
+  uint8_t actual = conversion_result + 1;  // Something incorrect.
+  ASSERT_EQ(dut_->GetValue(&actual), 0);
+  EXPECT_EQ(actual, conversion_result);
+}
+
+TEST_F(V4L2ControlDelegateTest, GetConverterFailure) {
+  int32_t device_result = 99;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _))
+      .WillOnce(DoAll(SetArgPointee<1>(device_result), Return(0)));
+  int err = -99;
+  EXPECT_CALL(*mock_converter_, V4L2ToMetadata(device_result, _))
+      .WillOnce(Return(err));
+
+  uint8_t unused = 1;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, GetDeviceFailure) {
+  int err = -99;
+  EXPECT_CALL(*mock_device_, GetControl(control_id_, _)).WillOnce(Return(err));
+
+  uint8_t unused = 1;
+  ASSERT_EQ(dut_->GetValue(&unused), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetSuccess) {
+  uint8_t input = 10;
+  int32_t conversion_result = 99;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+  EXPECT_CALL(*mock_device_, SetControl(control_id_, conversion_result, _))
+      .WillOnce(Return(0));
+
+  ASSERT_EQ(dut_->SetValue(input), 0);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetConverterFailure) {
+  uint8_t input = 10;
+  int err = 12;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _)).WillOnce(Return(err));
+  ASSERT_EQ(dut_->SetValue(input), err);
+}
+
+TEST_F(V4L2ControlDelegateTest, SetDeviceFailure) {
+  uint8_t input = 10;
+  int32_t conversion_result = 99;
+  EXPECT_CALL(*mock_converter_, MetadataToV4L2(input, _))
+      .WillOnce(DoAll(SetArgPointee<1>(conversion_result), Return(0)));
+  int err = 66;
+  EXPECT_CALL(*mock_device_, SetControl(control_id_, conversion_result, _))
+      .WillOnce(Return(err));
+
+  ASSERT_EQ(dut_->SetValue(input), err);
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/request_tracker.cpp b/hardware/ntimespace/camera/request_tracker.cpp
new file mode 100644
index 0000000000..3cd5208d08
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker.cpp
@@ -0,0 +1,159 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "RequestTracker"
+
+#include "request_tracker.h"
+
+#include <log/log.h>
+
+namespace default_camera_hal {
+
+RequestTracker::RequestTracker() {}
+
+RequestTracker::~RequestTracker() {}
+
+void RequestTracker::SetStreamConfiguration(
+    const camera3_stream_configuration_t& config) {
+  // Clear the old configuration.
+  ClearStreamConfiguration();
+  // Add an entry to the buffer tracking map for each configured stream.
+  for (size_t i = 0; i < config.num_streams; ++i) {
+    buffers_in_flight_.emplace(config.streams[i], 0);
+  }
+}
+
+void RequestTracker::ClearStreamConfiguration() {
+  // The keys of the in flight buffer map are the configured streams.
+  buffers_in_flight_.clear();
+}
+
+// Helper: get the streams used by a request.
+std::set<camera3_stream_t*> RequestStreams(const CaptureRequest& request) {
+  std::set<camera3_stream_t*> result;
+  if (request.input_buffer) {
+    result.insert(request.input_buffer->stream);
+  }
+  for (const auto& output_buffer : request.output_buffers) {
+    result.insert(output_buffer.stream);
+  }
+  return result;
+}
+
+bool RequestTracker::Add(std::shared_ptr<CaptureRequest> request) {
+  if (!CanAddRequest(*request)) {
+    return false;
+  }
+
+  // Add to the count for each stream used.
+  for (const auto stream : RequestStreams(*request)) {
+    ++buffers_in_flight_[stream];
+  }
+
+  // Store the request.
+  frames_in_flight_[request->frame_number] = request;
+
+  return true;
+}
+
+bool RequestTracker::Remove(std::shared_ptr<CaptureRequest> request) {
+  if (!request) {
+    return false;
+  }
+
+  // Get the request.
+  const auto frame_number_request =
+      frames_in_flight_.find(request->frame_number);
+  if (frame_number_request == frames_in_flight_.end()) {
+    HAL_LOGE("%s: Frame %u is not in flight.", __func__, request->frame_number);
+    return false;
+  } else if (request != frame_number_request->second) {
+    HAL_LOGE(
+        "%s: Request for frame %u cannot be removed: "
+        "does not matched the stored request.",
+        __func__,
+        request->frame_number);
+    return false;
+  }
+
+  frames_in_flight_.erase(frame_number_request);
+
+  // Decrement the counts of used streams.
+  for (const auto stream : RequestStreams(*request)) {
+    --buffers_in_flight_[stream];
+  }
+
+  return true;
+}
+
+void RequestTracker::Clear(
+    std::set<std::shared_ptr<CaptureRequest>>* requests) {
+  // If desired, extract all the currently in-flight requests.
+  if (requests) {
+    for (auto& frame_number_request : frames_in_flight_) {
+      requests->insert(frame_number_request.second);
+    }
+  }
+
+  // Clear out all tracking.
+  frames_in_flight_.clear();
+  // Maintain the configuration, but reset counts.
+  for (auto& stream_count : buffers_in_flight_) {
+    stream_count.second = 0;
+  }
+}
+
+bool RequestTracker::CanAddRequest(const CaptureRequest& request) const {
+  // Check that it's not a duplicate.
+  if (frames_in_flight_.count(request.frame_number) > 0) {
+    HAL_LOGE("%s: Already tracking a request with frame number %d.",
+          __func__,
+          request.frame_number);
+    return false;
+  }
+
+  // Check that each stream has space
+  // (which implicitly checks if it is configured).
+  for (const auto stream : RequestStreams(request)) {
+    if (StreamFull(stream)) {
+      HAL_LOGE("%s: Stream %p is full.", __func__, stream);
+      return false;
+    }
+  }
+  return true;
+}
+
+bool RequestTracker::StreamFull(const camera3_stream_t* handle) const {
+  const auto it = buffers_in_flight_.find(handle);
+  if (it == buffers_in_flight_.end()) {
+    // Unconfigured streams are implicitly full.
+    HAL_LOGE("%s: Stream %p is not a configured stream.", __func__, handle);
+    return true;
+  } else {
+    return it->second >= it->first->max_buffers;
+  }
+}
+
+bool RequestTracker::InFlight(uint32_t frame_number) const {
+  return frames_in_flight_.count(frame_number) > 0;
+}
+
+bool RequestTracker::Empty() const {
+  return frames_in_flight_.empty();
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/request_tracker.h b/hardware/ntimespace/camera/request_tracker.h
new file mode 100644
index 0000000000..19004b719d
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker.h
@@ -0,0 +1,80 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
+#define DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
+
+#include <map>
+#include <memory>
+#include <set>
+
+#include <android-base/macros.h>
+#include <hardware/camera3.h>
+#include "capture_request.h"
+#include "common.h"
+
+
+
+namespace default_camera_hal {
+
+// Keep track of what requests and streams are in flight.
+class RequestTracker {
+ public:
+  RequestTracker();
+  virtual ~RequestTracker();
+
+  // Configuration methods. Both have undefined effects on in-flight requests,
+  // and should only be called when empty.
+  // Add configured streams. Replaces the previous configuration if any.
+  virtual void SetStreamConfiguration(
+      const camera3_stream_configuration_t& config);
+  // Reset to no configured streams.
+  virtual void ClearStreamConfiguration();
+
+  // Tracking methods.
+  // Track a request.
+  // False if a request of the same frame number is already being tracked
+  virtual bool Add(std::shared_ptr<CaptureRequest> request);
+  // Stop tracking a request.
+  // False if the given request is not being tracked.
+  virtual bool Remove(std::shared_ptr<CaptureRequest> request = nullptr);
+  // Empty out all requests being tracked.
+  virtual void Clear(
+      std::set<std::shared_ptr<CaptureRequest>>* requests = nullptr);
+
+  // Accessors to check availability.
+  // Check that a request isn't already in flight, and won't overflow any
+  // streams.
+  virtual bool CanAddRequest(const CaptureRequest& request) const;
+  // True if the given stream is already at max capacity.
+  virtual bool StreamFull(const camera3_stream_t* handle) const;
+  // True if a request is being tracked for the given frame number.
+  virtual bool InFlight(uint32_t frame_number) const;
+  // True if no requests being tracked.
+  virtual bool Empty() const;
+
+ private:
+  // Track for each stream, how many buffers are in flight.
+  std::map<const camera3_stream_t*, size_t> buffers_in_flight_;
+  // Track the frames in flight.
+  std::map<uint32_t, std::shared_ptr<CaptureRequest>> frames_in_flight_;
+
+  DISALLOW_COPY_AND_ASSIGN(RequestTracker);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_REQUEST_TRACKER_H_
diff --git a/hardware/ntimespace/camera/request_tracker_test.cpp b/hardware/ntimespace/camera/request_tracker_test.cpp
new file mode 100644
index 0000000000..a7e377c072
--- /dev/null
+++ b/hardware/ntimespace/camera/request_tracker_test.cpp
@@ -0,0 +1,259 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "request_tracker.h"
+
+#include <gtest/gtest.h>
+
+using testing::Test;
+
+namespace default_camera_hal {
+
+class RequestTrackerTest : public Test {
+ protected:
+  void SetUp() {
+    stream1_.max_buffers = 3;
+    stream2_.max_buffers = 3;
+    dut_.reset(new RequestTracker());
+    streams_ = {&stream1_, &stream2_};
+    camera3_stream_configuration_t config{
+        static_cast<uint32_t>(streams_.size()),
+        streams_.data(),
+        0,
+        nullptr};
+    dut_->SetStreamConfiguration(config);
+  }
+
+  std::shared_ptr<CaptureRequest> GenerateCaptureRequest(
+      uint32_t frame, std::vector<camera3_stream_t*> streams) {
+    std::shared_ptr<CaptureRequest> request =
+        std::make_shared<CaptureRequest>();
+
+    // Set the frame number and buffers.
+    request->frame_number = frame;
+    for (const auto stream : streams) {
+      // All we really care about for the buffers is which stream they're for.
+      camera3_stream_buffer_t buffer{stream, nullptr, 0, -1, -1};
+      request->output_buffers.push_back(buffer);
+    }
+
+    return request;
+  }
+
+  void AddRequest(uint32_t frame,
+                  std::vector<camera3_stream_t*> streams,
+                  bool expected = true) {
+    std::shared_ptr<CaptureRequest> request =
+        GenerateCaptureRequest(frame, streams);
+    EXPECT_EQ(dut_->CanAddRequest(*request), expected);
+    if (expected) {
+      EXPECT_FALSE(dut_->InFlight(frame));
+    }
+    EXPECT_EQ(dut_->Add(request), expected);
+    if (expected) {
+      EXPECT_TRUE(dut_->InFlight(frame));
+    }
+  }
+
+  camera3_stream_t stream1_;
+  camera3_stream_t stream2_;
+  std::vector<camera3_stream_t*> streams_;
+  std::shared_ptr<RequestTracker> dut_;
+};
+
+TEST_F(RequestTrackerTest, AddValid) {
+  uint32_t frame = 34;
+  EXPECT_FALSE(dut_->InFlight(frame));
+  AddRequest(frame, {&stream1_});
+}
+
+TEST_F(RequestTrackerTest, AddInput) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  std::shared_ptr<CaptureRequest> expected = GenerateCaptureRequest(frame, {});
+  // Set the input buffer instead of any outputs.
+  expected->input_buffer.reset(
+      new camera3_stream_buffer_t{&stream1_, nullptr, 0, -1, -1});
+  stream1_.max_buffers = 1;
+
+  EXPECT_TRUE(dut_->Add(expected));
+  EXPECT_TRUE(dut_->InFlight(frame));
+  // Should have added to the count of buffers for stream 1.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+}
+
+TEST_F(RequestTrackerTest, AddMultipleStreams) {
+  stream1_.max_buffers = 1;
+  stream2_.max_buffers = 1;
+
+  EXPECT_FALSE(dut_->StreamFull(&stream1_));
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Add a request using both streams.
+  AddRequest(99, {&stream1_, &stream2_});
+
+  // Should both have been counted.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  EXPECT_TRUE(dut_->StreamFull(&stream2_));
+}
+
+TEST_F(RequestTrackerTest, AddUnconfigured) {
+  camera3_stream_t stream;
+  // Unconfigured should be considered full.
+  EXPECT_TRUE(dut_->StreamFull(&stream));
+  AddRequest(1, {&stream}, false);
+}
+
+TEST_F(RequestTrackerTest, AddPastCapacity) {
+  // Set the limit of stream 2 to 1.
+  stream2_.max_buffers = 1;
+
+  for (size_t i = 0; i < stream1_.max_buffers; ++i) {
+    EXPECT_FALSE(dut_->StreamFull(&stream1_));
+    EXPECT_FALSE(dut_->StreamFull(&stream2_));
+    AddRequest(i, {&stream1_});
+  }
+  // Filled up stream 1.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  // Stream 2 should still not be full since nothing was added.
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Limit has been hit, can't add more.
+  AddRequest(stream1_.max_buffers, {&stream1_, &stream2_}, false);
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  // Should not have added to the count of stream 2.
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+}
+
+TEST_F(RequestTrackerTest, AddDuplicate) {
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  // Can't add a duplicate.
+  AddRequest(frame, {&stream2_}, false);
+}
+
+TEST_F(RequestTrackerTest, RemoveValid) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  std::shared_ptr<CaptureRequest> request =
+      GenerateCaptureRequest(frame, {&stream1_});
+  EXPECT_TRUE(dut_->Add(request));
+  EXPECT_TRUE(dut_->InFlight(frame));
+  AddRequest(frame + 1, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Remove it.
+  EXPECT_TRUE(dut_->Remove(request));
+  // Should have removed only the desired request.
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveInvalidFrame) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Try to remove a different one.
+  uint32_t bad_frame = frame + 1;
+  std::shared_ptr<CaptureRequest> bad_request =
+      GenerateCaptureRequest(bad_frame, {&stream1_});
+  EXPECT_FALSE(dut_->InFlight(bad_frame));
+  EXPECT_FALSE(dut_->Remove(bad_request));
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveInvalidData) {
+  EXPECT_TRUE(dut_->Empty());
+
+  // Add a request
+  uint32_t frame = 42;
+  AddRequest(frame, {&stream1_});
+  EXPECT_FALSE(dut_->Empty());
+
+  // Try to remove a different one.
+  // Even though this request looks the same, that fact that it is
+  // a pointer to a different object means it should fail.
+  std::shared_ptr<CaptureRequest> bad_request =
+      GenerateCaptureRequest(frame, {&stream1_});
+  EXPECT_TRUE(dut_->InFlight(frame));
+  EXPECT_FALSE(dut_->Remove(bad_request));
+  EXPECT_FALSE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, RemoveNull) {
+  EXPECT_FALSE(dut_->Remove(nullptr));
+}
+
+TEST_F(RequestTrackerTest, ClearRequests) {
+  // Create some requests.
+  uint32_t frame1 = 42;
+  uint32_t frame2 = frame1 + 1;
+  std::shared_ptr<CaptureRequest> request1 =
+      GenerateCaptureRequest(frame1, {&stream1_});
+  std::shared_ptr<CaptureRequest> request2 =
+      GenerateCaptureRequest(frame2, {&stream2_});
+  std::set<std::shared_ptr<CaptureRequest>> expected;
+  expected.insert(request1);
+  expected.insert(request2);
+
+  // Insert them.
+  EXPECT_TRUE(dut_->Add(request1));
+  EXPECT_TRUE(dut_->Add(request2));
+  EXPECT_TRUE(dut_->InFlight(frame1));
+  EXPECT_TRUE(dut_->InFlight(frame2));
+  EXPECT_FALSE(dut_->Empty());
+  std::set<std::shared_ptr<CaptureRequest>> actual;
+
+  // Clear them out.
+  dut_->Clear(&actual);
+  EXPECT_TRUE(dut_->Empty());
+  EXPECT_EQ(actual, expected);
+
+  // Configuration (max values) should not have been cleared.
+  EXPECT_TRUE(dut_->Add(request1));
+}
+
+TEST_F(RequestTrackerTest, ClearRequestsNoResult) {
+  // Add some requests.
+  EXPECT_TRUE(dut_->Empty());
+  AddRequest(1, {&stream1_});
+  AddRequest(2, {&stream2_});
+  EXPECT_FALSE(dut_->Empty());
+  // Don't bother getting the cleared requests.
+  dut_->Clear();
+  EXPECT_TRUE(dut_->Empty());
+}
+
+TEST_F(RequestTrackerTest, ClearConfiguration) {
+  EXPECT_FALSE(dut_->StreamFull(&stream1_));
+  EXPECT_FALSE(dut_->StreamFull(&stream2_));
+
+  // Clear the configuration.
+  dut_->ClearStreamConfiguration();
+
+  // Both streams should be considered full now, since neither is configured.
+  EXPECT_TRUE(dut_->StreamFull(&stream1_));
+  EXPECT_TRUE(dut_->StreamFull(&stream2_));
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/static_properties.cpp b/hardware/ntimespace/camera/static_properties.cpp
new file mode 100644
index 0000000000..72038bcea2
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties.cpp
@@ -0,0 +1,503 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "StaticProperties"
+
+#include "static_properties.h"
+
+#include <log/log.h>
+#include <hardware/camera3.h>
+#include <system/camera.h>
+
+#include "metadata/metadata_reader.h"
+
+namespace default_camera_hal {
+
+// Build stream capabilities from configs + stall durations.
+static bool ConstructStreamCapabilities(
+    const std::vector<StreamConfiguration>& configs,
+    const std::vector<StreamStallDuration>& stalls,
+    StaticProperties::CapabilitiesMap* capabilities) {
+  HAL_LOG_ENTER();
+  // Extract directional capabilities from the configs.
+  for (const auto& config : configs) {
+    switch (config.direction) {
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT:
+        (*capabilities)[config.spec].output_supported = true;
+        break;
+      case ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT:
+        (*capabilities)[config.spec].input_supported = true;
+        break;
+      default:
+        // Should never happen when using the MetadataReader;
+        // it should validate directions.
+        HAL_LOGE("%s: Unrecognized stream config direction %d.",
+              __func__,
+              config.direction);
+        return false;
+    }
+  }
+
+  // Extract stall durations from the stalls.
+  for (const auto& stall : stalls) {
+    (*capabilities)[stall.spec].stall_duration = stall.duration;
+  }
+
+  return true;
+}
+
+// Check that each output config has a valid corresponding stall duration
+// (extra durations not matching any output config are ignored).
+static bool ValidateStreamCapabilities(
+    StaticProperties::CapabilitiesMap capabilities) {
+  HAL_LOG_ENTER();
+  for (const auto& spec_capabilities : capabilities) {
+    // Only non-negative stall durations are valid. This should only happen
+    // due to output streams without an associated stall duration, as
+    // MetadataReader validates the metadata stall durations.
+    if (spec_capabilities.second.output_supported &&
+        spec_capabilities.second.stall_duration < 0) {
+      HAL_LOGE(
+          "%s: Static metadata does not have a stall duration for "
+          "each output configuration. ",
+          __func__);
+      return false;
+    }
+  }
+  return true;
+}
+
+// Validate that the input/output formats map matches up with
+// the capabilities listed for all formats.
+bool ValidateReprocessFormats(
+    const StaticProperties::CapabilitiesMap& capabilities,
+    const ReprocessFormatMap& reprocess_map) {
+  HAL_LOG_ENTER();
+  // Get input formats.
+  std::set<int32_t> all_input_formats;
+  std::set<int32_t> all_output_formats;
+  for (const auto& spec_capabilities : capabilities) {
+    if (spec_capabilities.second.input_supported) {
+      all_input_formats.insert(spec_capabilities.first.format);
+    }
+    if (spec_capabilities.second.output_supported) {
+      all_output_formats.insert(spec_capabilities.first.format);
+    }
+  }
+
+  // Must be at least one input format.
+  if (all_input_formats.size() < 1) {
+    HAL_LOGE("%s: No input formats, reprocessing can't be supported.", __func__);
+    return false;
+  }
+
+  // Check that the reprocess map input formats are exactly all available
+  // input formats (check size here, then checking for actual value
+  // matches will happen as part of the loop below).
+  if (all_input_formats.size() != reprocess_map.size()) {
+    HAL_LOGE(
+        "%s: Stream configuration input formats do not match "
+        "input/output format map input formats.",
+        __func__);
+    return false;
+  }
+
+  // Check that each input format has at least one matching output format.
+  for (const auto& input_format : all_input_formats) {
+    const auto input_outputs_iterator = reprocess_map.find(input_format);
+    if (input_outputs_iterator == reprocess_map.end()) {
+      HAL_LOGE(
+          "%s: No output formats for input format %d.", __func__, input_format);
+      return false;
+    }
+    // No need to check that the output formats vector is non-empty;
+    // MetadataReader validates this. Instead just check that
+    // all outputs are actually output formats.
+    for (const auto& output_format : input_outputs_iterator->second) {
+      if (all_output_formats.count(output_format) < 1) {
+        HAL_LOGE(
+            "%s: Output format %d for input format %d "
+            "is not a supported output format.",
+            __func__,
+            input_format,
+            output_format);
+        return false;
+      }
+    }
+  }
+
+  return true;
+}
+
+StaticProperties* StaticProperties::NewStaticProperties(
+    std::unique_ptr<const MetadataReader> metadata_reader) {
+  HAL_LOG_ENTER();
+  int facing = 0;
+  int orientation = 0;
+  int32_t max_input_streams = 0;
+  int32_t max_raw_output_streams = 0;
+  int32_t max_non_stalling_output_streams = 0;
+  int32_t max_stalling_output_streams = 0;
+  std::set<uint8_t> request_capabilities;
+  std::vector<StreamConfiguration> configs;
+  std::vector<StreamStallDuration> stalls;
+  CapabilitiesMap stream_capabilities;
+  ReprocessFormatMap reprocess_map;
+
+  // If reading any data returns an error, something is wrong.
+  if (metadata_reader->Facing(&facing) ||
+      metadata_reader->Orientation(&orientation) ||
+      metadata_reader->MaxInputStreams(&max_input_streams) ||
+      metadata_reader->MaxOutputStreams(&max_raw_output_streams,
+                                        &max_non_stalling_output_streams,
+                                        &max_stalling_output_streams) ||
+      metadata_reader->RequestCapabilities(&request_capabilities) ||
+      metadata_reader->StreamConfigurations(&configs) ||
+      metadata_reader->StreamStallDurations(&stalls) ||
+      !ConstructStreamCapabilities(configs, stalls, &stream_capabilities) ||
+      // MetadataReader validates configs and stall seperately,
+      // but not that they match.
+      !ValidateStreamCapabilities(stream_capabilities) ||
+      // Reprocessing metadata only necessary if input streams are allowed.
+      (max_input_streams > 0 &&
+       (metadata_reader->ReprocessFormats(&reprocess_map) ||
+        // MetadataReader validates configs and the reprocess map seperately,
+        // but not that they match.
+        !ValidateReprocessFormats(stream_capabilities, reprocess_map)))) {
+    HAL_LOGE("%s: failed", __func__);
+    return nullptr;
+  }
+
+  return new StaticProperties(std::move(metadata_reader),
+                              facing,
+                              orientation,
+                              max_input_streams,
+                              max_raw_output_streams,
+                              max_non_stalling_output_streams,
+                              max_stalling_output_streams,
+                              std::move(request_capabilities),
+                              std::move(stream_capabilities),
+                              std::move(reprocess_map));
+}
+
+StaticProperties::StaticProperties(
+    std::unique_ptr<const MetadataReader> metadata_reader,
+    int facing,
+    int orientation,
+    int32_t max_input_streams,
+    int32_t max_raw_output_streams,
+    int32_t max_non_stalling_output_streams,
+    int32_t max_stalling_output_streams,
+    std::set<uint8_t> request_capabilities,
+    CapabilitiesMap stream_capabilities,
+    ReprocessFormatMap supported_reprocess_outputs)
+    : metadata_reader_(std::move(metadata_reader)),
+      facing_(facing),
+      orientation_(orientation),
+      max_input_streams_(max_input_streams),
+      max_raw_output_streams_(max_raw_output_streams),
+      max_non_stalling_output_streams_(max_non_stalling_output_streams),
+      max_stalling_output_streams_(max_stalling_output_streams),
+      request_capabilities_(std::move(request_capabilities)),
+      stream_capabilities_(std::move(stream_capabilities)),
+      supported_reprocess_outputs_(std::move(supported_reprocess_outputs)) {}
+
+bool StaticProperties::TemplateSupported(int type) {
+  HAL_LOGE("%s: type: %d", __func__, type);
+  uint8_t required_capability = 0;
+  switch (type) {
+    case CAMERA3_TEMPLATE_PREVIEW:
+      // Preview is always supported.
+      return true;
+    case CAMERA3_TEMPLATE_MANUAL:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR;
+      break;
+    /*
+    case CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING;
+      break;
+    */
+    default:
+      required_capability =
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE;
+      return true;
+  }
+
+  return request_capabilities_.count(required_capability) > 0;
+}
+
+// Helper functions for checking stream properties when verifying support.
+static bool IsInputType(int stream_type) {
+  return stream_type == CAMERA3_STREAM_INPUT ||
+         stream_type == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+static bool IsOutputType(int stream_type) {
+  return stream_type == CAMERA3_STREAM_OUTPUT ||
+         stream_type == CAMERA3_STREAM_BIDIRECTIONAL;
+}
+
+static bool IsRawFormat(int format) {
+  return format == HAL_PIXEL_FORMAT_RAW10 || format == HAL_PIXEL_FORMAT_RAW12 ||
+         format == HAL_PIXEL_FORMAT_RAW16 ||
+         format == HAL_PIXEL_FORMAT_RAW_OPAQUE;
+}
+
+bool StaticProperties::StreamConfigurationSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  return SanityCheckStreamConfiguration(stream_config) &&
+         InputStreamsSupported(stream_config) &&
+         OutputStreamsSupported(stream_config) &&
+         OperationModeSupported(stream_config);
+}
+
+bool StaticProperties::SanityCheckStreamConfiguration(
+    const camera3_stream_configuration_t* stream_config) {
+  // Check for null/empty values.
+  if (stream_config == nullptr) {
+    HAL_LOGE("%s: NULL stream configuration array", __func__);
+    return false;
+  } else if (stream_config->num_streams == 0) {
+    HAL_LOGE("%s: Empty stream configuration array", __func__);
+    return false;
+  } else if (stream_config->streams == nullptr) {
+    HAL_LOGE("%s: NULL stream configuration streams", __func__);
+    return false;
+  }
+
+  // Check that all streams are either inputs or outputs (or both).
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (stream == nullptr) {
+      HAL_LOGE("%s: Stream %zu is null", __func__, i);
+      return false;
+    } else if (!IsInputType(stream->stream_type) &&
+               !IsOutputType(stream->stream_type)) {
+      HAL_LOGE("%s: Stream %zu type %d is neither an input nor an output type",
+            __func__,
+            i,
+            stream->stream_type);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+bool StaticProperties::InputStreamsSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  // Find the input stream(s).
+  int32_t num_input_streams = 0;
+  int input_format = -1;
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (IsInputType(stream->stream_type)) {
+      // Check that this stream is valid as an input.
+      const auto capabilities_iterator = stream_capabilities_.find(stream);
+      if (capabilities_iterator == stream_capabilities_.end() ||
+          !capabilities_iterator->second.input_supported) {
+        HAL_LOGE("%s: %d x %d stream of format %d is not a supported input setup.",
+              __func__,
+              stream->width,
+              stream->height,
+              stream->format);
+        return false;
+      }
+
+      // Valid input stream; count it.
+      ++num_input_streams;
+      input_format = stream->format;
+    }
+  }
+
+  // Check the count.
+  if (num_input_streams > max_input_streams_) {
+    HAL_LOGE(
+        "%s: Requested number of input streams %d is greater than "
+        "the maximum number supported by the device (%d).",
+        __func__,
+        num_input_streams,
+        max_input_streams_);
+    return false;
+  }
+  if (num_input_streams > 1) {
+    HAL_LOGE("%s: Camera HAL 3.4 only supports 1 input stream max.", __func__);
+    return false;
+  }
+
+  // If there's an input stream, the configuration must have at least one
+  // supported output format for reprocessing that input.
+  if (num_input_streams > 0) {
+    const auto input_output_formats_iterator =
+        supported_reprocess_outputs_.find(input_format);
+    if (input_output_formats_iterator == supported_reprocess_outputs_.end()) {
+      // Should never happen; factory should verify that all valid inputs
+      // have one or more valid outputs.
+      HAL_LOGE("%s: No valid output formats for input format %d.",
+            __func__,
+            input_format);
+      return false;
+    }
+    bool match_found = false;
+    // Go through outputs looking for a supported one.
+    for (size_t i = 0; i < stream_config->num_streams; ++i) {
+      const camera3_stream_t* stream = stream_config->streams[i];
+      if (IsOutputType(stream->stream_type)) {
+        if (input_output_formats_iterator->second.count(stream->format) > 0) {
+          match_found = true;
+          break;
+        }
+      }
+    }
+    if (!match_found) {
+      HAL_LOGE("%s: No supported output format provided for input format %d.",
+            __func__,
+            input_format);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+bool StaticProperties::OutputStreamsSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  // Find and count output streams.
+  int32_t num_raw = 0;
+  int32_t num_stalling = 0;
+  int32_t num_non_stalling = 0;
+  for (size_t i = 0; i < stream_config->num_streams; ++i) {
+    const camera3_stream_t* stream = stream_config->streams[i];
+    if (IsOutputType(stream->stream_type)) {
+      // Check that this stream is valid as an output.
+      const auto capabilities_iterator = stream_capabilities_.find(stream);
+      if (capabilities_iterator == stream_capabilities_.end() ||
+          !capabilities_iterator->second.output_supported) {
+        HAL_LOGE(
+            "%s: %d x %d stream of format %d "
+            "is not a supported output setup.",
+            __func__,
+            stream->width,
+            stream->height,
+            stream->format);
+        return false;
+      }
+
+      // Valid output; count it.
+      if (IsRawFormat(stream->format)) {
+        ++num_raw;
+      } else if (capabilities_iterator->second.stall_duration > 0) {
+        ++num_stalling;
+      } else {
+        ++num_non_stalling;
+      }
+    }
+  }
+
+  // Check that the counts are within bounds.
+  if (num_raw > max_raw_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "raw output streams %d (requested %d).",
+        __func__,
+        max_raw_output_streams_,
+        num_raw);
+    return false;
+  } else if (num_stalling > max_stalling_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "stalling output streams %d (requested %u).",
+        __func__,
+        max_stalling_output_streams_,
+        num_stalling);
+    return false;
+  } else if (num_non_stalling > max_non_stalling_output_streams_) {
+    HAL_LOGE(
+        "%s: Requested stream configuration exceeds maximum supported "
+        "non-stalling output streams %d (requested %d).",
+        __func__,
+        max_non_stalling_output_streams_,
+        num_non_stalling);
+    return false;
+  }
+
+  return true;
+}
+
+bool StaticProperties::OperationModeSupported(
+    const camera3_stream_configuration_t* stream_config) {
+  switch (stream_config->operation_mode) {
+    case CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE:
+      return true;
+    case CAMERA3_STREAM_CONFIGURATION_CONSTRAINED_HIGH_SPEED_MODE:
+      // TODO(b/31370792): Check metadata for high speed support,
+      // check that requested streams have support for high speed.
+      HAL_LOGE("%s: Support for CONSTRAINED_HIGH_SPEED not implemented", __func__);
+      return false;
+    default:
+      HAL_LOGE("%s: Unrecognized stream configuration mode: %d",
+            __func__,
+            stream_config->operation_mode);
+      return false;
+  }
+}
+
+bool StaticProperties::ReprocessingSupported(
+    const camera3_stream_t* input_stream,
+    const std::set<const camera3_stream_t*>& output_streams) {
+  // There must be an input.
+  if (!input_stream) {
+    HAL_LOGE("%s: No input stream.", __func__);
+    return false;
+  }
+  // There must be an output.
+  if (output_streams.size() < 1) {
+    HAL_LOGE("%s: No output stream.", __func__);
+    return false;
+  }
+
+  const auto input_output_formats =
+      supported_reprocess_outputs_.find(input_stream->format);
+  if (input_output_formats == supported_reprocess_outputs_.end()) {
+    // Should never happen for a valid input stream.
+    HAL_LOGE("%s: Input format %d does not support any output formats.",
+          __func__,
+          input_stream->format);
+    return false;
+  }
+
+  // Check that all output streams can be outputs for the input stream.
+  const std::set<int32_t>& supported_output_formats =
+      input_output_formats->second;
+  for (const auto output_stream : output_streams) {
+    if (supported_output_formats.count(output_stream->format) < 1) {
+      HAL_LOGE(
+          "%s: Output format %d is not a supported output "
+          "for request input format %d.",
+          __func__,
+          output_stream->format,
+          input_stream->format);
+      return false;
+    }
+  }
+
+  return true;
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/static_properties.h b/hardware/ntimespace/camera/static_properties.h
new file mode 100644
index 0000000000..565118d682
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties.h
@@ -0,0 +1,120 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
+#define DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
+
+#include <memory>
+#include <set>
+
+#include <hardware/camera3.h>
+#include "common.h"
+#include "metadata/metadata_reader.h"
+#include "metadata/types.h"
+
+namespace default_camera_hal {
+
+// StaticProperties provides a wrapper around useful static metadata entries.
+class StaticProperties {
+ public:
+  // Helpful types for interpreting some static properties.
+  struct StreamCapabilities {
+    int64_t stall_duration;
+    int32_t input_supported;
+    int32_t output_supported;
+    // Default constructor ensures no support
+    // and an invalid stall duration.
+    StreamCapabilities()
+        : stall_duration(-1), input_supported(0), output_supported(0) {}
+  };
+  // Map stream spec (format, size) to their
+  // capabilities (input, output, stall).
+  typedef std::map<StreamSpec, StreamCapabilities, StreamSpec::Compare>
+      CapabilitiesMap;
+
+  // Use this method to create StaticProperties objects.
+  // Functionally equivalent to "new StaticProperties",
+  // except that it may return nullptr in case of failure (missing entries).
+  static StaticProperties* NewStaticProperties(
+      std::unique_ptr<const MetadataReader> metadata_reader);
+  static StaticProperties* NewStaticProperties(
+      std::unique_ptr<android::CameraMetadata> metadata) {
+    return NewStaticProperties(
+        std::make_unique<MetadataReader>(std::move(metadata)));
+  }
+  virtual ~StaticProperties(){};
+
+  // Simple accessors.
+  int facing() const { return facing_; };
+  int orientation() const { return orientation_; };
+  // Carrying on the promise of the underlying reader,
+  // the returned pointer is valid only as long as this object is alive.
+  const camera_metadata_t* raw_metadata() const {
+    return metadata_reader_->raw_metadata();
+  };
+
+  // Check if a given template type is supported.
+  bool TemplateSupported(int type);
+  // Validators (check that values are consistent with the capabilities
+  // this object represents/base requirements of the camera HAL).
+  bool StreamConfigurationSupported(
+      const camera3_stream_configuration_t* stream_config);
+  // Check that the inputs and outputs for a request don't conflict.
+  bool ReprocessingSupported(
+      const camera3_stream_t* input_stream,
+      const std::set<const camera3_stream_t*>& output_streams);
+
+ private:
+  // Constructor private to allow failing on bad input.
+  // Use NewStaticProperties instead.
+  StaticProperties(std::unique_ptr<const MetadataReader> metadata_reader,
+                   int facing,
+                   int orientation,
+                   int32_t max_input_streams,
+                   int32_t max_raw_output_streams,
+                   int32_t max_non_stalling_output_streams,
+                   int32_t max_stalling_output_streams,
+                   std::set<uint8_t> request_capabilities,
+                   CapabilitiesMap stream_capabilities,
+                   ReprocessFormatMap supported_reprocess_outputs);
+
+  // Helper functions for StreamConfigurationSupported.
+  bool SanityCheckStreamConfiguration(
+      const camera3_stream_configuration_t* stream_config);
+  bool InputStreamsSupported(
+      const camera3_stream_configuration_t* stream_config);
+  bool OutputStreamsSupported(
+      const camera3_stream_configuration_t* stream_config);
+  bool OperationModeSupported(
+      const camera3_stream_configuration_t* stream_config);
+
+  const std::unique_ptr<const MetadataReader> metadata_reader_;
+  const int facing_;
+  const int orientation_;
+  const int32_t max_input_streams_;
+  const int32_t max_raw_output_streams_;
+  const int32_t max_non_stalling_output_streams_;
+  const int32_t max_stalling_output_streams_;
+  const std::set<uint8_t> request_capabilities_;
+  const CapabilitiesMap stream_capabilities_;
+  const ReprocessFormatMap supported_reprocess_outputs_;
+
+  DISALLOW_COPY_AND_ASSIGN(StaticProperties);
+};
+
+}  // namespace default_camera_hal
+
+#endif  // DEFAULT_CAMERA_HAL_STATIC_PROPERTIES_H_
diff --git a/hardware/ntimespace/camera/static_properties_test.cpp b/hardware/ntimespace/camera/static_properties_test.cpp
new file mode 100644
index 0000000000..13b9e964b1
--- /dev/null
+++ b/hardware/ntimespace/camera/static_properties_test.cpp
@@ -0,0 +1,674 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#include "static_properties.h"
+
+#include <gmock/gmock.h>
+#include <gtest/gtest.h>
+#include <hardware/camera3.h>
+#include <system/camera.h>
+
+#include "metadata/metadata_reader_mock.h"
+
+using testing::AtMost;
+using testing::Expectation;
+using testing::Return;
+using testing::SetArgPointee;
+using testing::Test;
+using testing::_;
+
+namespace default_camera_hal {
+
+class StaticPropertiesTest : public Test {
+ protected:
+  virtual void SetUp() {
+    // Ensure tests will probably fail if PrepareDUT isn't called.
+    dut_.reset();
+    mock_reader_ = std::make_unique<MetadataReaderMock>();
+  }
+
+  void PrepareDUT() {
+    dut_.reset(StaticProperties::NewStaticProperties(std::move(mock_reader_)));
+  }
+
+  void PrepareDefaultDUT() {
+    SetDefaultExpectations();
+    PrepareDUT();
+    ASSERT_NE(dut_, nullptr);
+  }
+
+  void SetDefaultExpectations() {
+    EXPECT_CALL(*mock_reader_, Facing(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_facing_), Return(0)));
+    EXPECT_CALL(*mock_reader_, Orientation(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_orientation_), Return(0)));
+    EXPECT_CALL(*mock_reader_, MaxInputStreams(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_max_inputs_), Return(0)));
+    EXPECT_CALL(*mock_reader_, MaxOutputStreams(_, _, _))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_max_raw_outputs_),
+                        SetArgPointee<1>(test_max_non_stalling_outputs_),
+                        SetArgPointee<2>(test_max_stalling_outputs_),
+                        Return(0)));
+    EXPECT_CALL(*mock_reader_, RequestCapabilities(_))
+        .Times(AtMost(1))
+        .WillOnce(
+            DoAll(SetArgPointee<0>(test_request_capabilities_), Return(0)));
+    EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_configs_), Return(0)));
+    EXPECT_CALL(*mock_reader_, StreamStallDurations(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_stalls_), Return(0)));
+    EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+        .Times(AtMost(1))
+        .WillOnce(DoAll(SetArgPointee<0>(test_reprocess_map_), Return(0)));
+  }
+
+  camera3_stream_t MakeStream(int32_t format,
+                              bool output = true,
+                              bool input = false,
+                              int32_t width = kWidth,
+                              int32_t height = kHeight) {
+    int type = -1;
+    if (output && input) {
+      type = CAMERA3_STREAM_BIDIRECTIONAL;
+    } else if (output) {
+      type = CAMERA3_STREAM_OUTPUT;
+    } else if (input) {
+      type = CAMERA3_STREAM_INPUT;
+    }
+    camera3_stream_t stream;
+    stream.stream_type = type;
+    stream.width = width;
+    stream.height = height;
+    stream.format = format;
+    return stream;
+  }
+
+  void ExpectConfigurationSupported(std::vector<camera3_stream_t>& streams,
+                                    bool expected) {
+    std::vector<camera3_stream_t*> stream_addresses;
+    for (size_t i = 0; i < streams.size(); ++i) {
+      stream_addresses.push_back(&streams[i]);
+    }
+    camera3_stream_configuration_t config = {
+        static_cast<uint32_t>(stream_addresses.size()),
+        stream_addresses.data(),
+        CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE,
+        nullptr};
+    PrepareDefaultDUT();
+    EXPECT_EQ(dut_->StreamConfigurationSupported(&config), expected);
+  }
+
+  std::unique_ptr<StaticProperties> dut_;
+  std::unique_ptr<MetadataReaderMock> mock_reader_;
+
+  // Some helper values used for stream testing.
+  static constexpr int32_t kWidth = 320;
+  static constexpr int32_t kHeight = 240;
+  static constexpr int32_t kAlternateWidth = 640;
+  static constexpr int32_t kAlternateHeight = 480;
+
+  const int test_facing_ = CAMERA_FACING_FRONT;
+  const int test_orientation_ = 90;
+  const int32_t test_max_inputs_ = 3;
+  const int32_t test_max_raw_outputs_ = 1;
+  const int32_t test_max_non_stalling_outputs_ = 2;
+  const int32_t test_max_stalling_outputs_ = 3;
+  const std::set<uint8_t> test_request_capabilities_ = {
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE,
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR,
+      ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING};
+
+  // Some formats for various purposes (in various combinations,
+  // these types should be capable of testing all failure conditions).
+  const int32_t output_multisize_non_stalling_ = 1;
+  const int32_t bidirectional_self_supporting_stalling_ = 2;
+  const int32_t bidirectional_raw_ = HAL_PIXEL_FORMAT_RAW10;
+  const int32_t input_ = 3;
+  const int32_t other = input_;
+
+  const std::vector<StreamConfiguration> test_configs_ = {
+      {{{output_multisize_non_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{output_multisize_non_stalling_,
+         kAlternateWidth,
+         kAlternateHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{bidirectional_self_supporting_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}},
+      {{{bidirectional_self_supporting_stalling_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{bidirectional_raw_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}},
+      {{{bidirectional_raw_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}},
+      {{{input_,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}}};
+  // Raw having a stall duration shouldn't matter,
+  // it should still be counted as the raw type.
+  const std::vector<StreamStallDuration> test_stalls_ = {
+      {{{output_multisize_non_stalling_, kWidth, kHeight, 0}}},
+      {{{output_multisize_non_stalling_,
+         kAlternateWidth,
+         kAlternateHeight,
+         0}}},
+      {{{bidirectional_self_supporting_stalling_, kWidth, kHeight, 10}}},
+      {{{bidirectional_raw_, kWidth, kHeight, 15}}}};
+  // Format 2 can go to itself or 1. 3 and RAW can only go to 1.
+  const ReprocessFormatMap test_reprocess_map_ = {
+      {bidirectional_self_supporting_stalling_,
+       {output_multisize_non_stalling_,
+        bidirectional_self_supporting_stalling_}},
+      {bidirectional_raw_, {output_multisize_non_stalling_}},
+      {input_, {output_multisize_non_stalling_}}};
+  // Codify the above information about format capabilities in some helpful
+  // vectors.
+  int32_t multi_size_format_ = 1;
+  const std::vector<int32_t> input_formats_ = {2, 3, HAL_PIXEL_FORMAT_RAW10};
+  const std::vector<int32_t> output_formats_ = {1, 2, HAL_PIXEL_FORMAT_RAW10};
+};
+
+TEST_F(StaticPropertiesTest, FactorySuccess) {
+  PrepareDefaultDUT();
+  EXPECT_EQ(dut_->facing(), test_facing_);
+  EXPECT_EQ(dut_->orientation(), test_orientation_);
+
+  // Stream configurations tested seperately.
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedFacing) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, Facing(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedOrientation) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, Orientation(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedMaxInputs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, MaxInputStreams(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedMaxOutputs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, MaxOutputStreams(_, _, _)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedRequestCapabilities) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, RequestCapabilities(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedStreamConfigs) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedStallDurations) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, StreamStallDurations(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryFailedReprocessFormats) {
+  SetDefaultExpectations();
+  // Override with a failure expectation.
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_)).WillOnce(Return(99));
+  PrepareDUT();
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryNoReprocessFormats) {
+  // If there are no inputs allowed, the reprocess formats shouldn't matter.
+  SetDefaultExpectations();
+  // Override max inputs.
+  EXPECT_CALL(*mock_reader_, MaxInputStreams(_))
+      .WillOnce(DoAll(SetArgPointee<0>(0), Return(0)));
+  // Override reprocess formats with a failure expectation.
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .Times(AtMost(1))
+      .WillOnce(Return(99));
+  PrepareDUT();
+  // Should be ok.
+  EXPECT_NE(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, FactoryInvalidCapabilities) {
+  SetDefaultExpectations();
+  // Override configs with an extra output format.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  configs.push_back(
+      {{{5,
+         kWidth,
+         kHeight,
+         ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT}}});
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because not every output has a stall.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessNoInputs) {
+  SetDefaultExpectations();
+  // Override configs by removing all inputs.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  for (auto it = configs.begin(); it != configs.end();) {
+    if ((*it).direction ==
+        ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT) {
+      it = configs.erase(it);
+    } else {
+      ++it;
+    }
+  }
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because inputs are supported but there are no input formats.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessExtraInput) {
+  SetDefaultExpectations();
+  // Override configs with an extra input format.
+  std::vector<StreamConfiguration> configs = test_configs_;
+  configs.push_back({{{5,
+                       kWidth,
+                       kHeight,
+                       ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT}}});
+  EXPECT_CALL(*mock_reader_, StreamConfigurations(_))
+      .WillOnce(DoAll(SetArgPointee<0>(configs), Return(0)));
+  PrepareDUT();
+  // Should fail because no reprocess outputs are listed for the extra input.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessExtraMapEntry) {
+  SetDefaultExpectations();
+  // Override the reprocess map with an extra entry.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map[5] = {1};
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because the extra map entry doesn't correspond to an input.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessWrongMapEntries) {
+  SetDefaultExpectations();
+  // Override the reprocess map replacing the entry for the
+  // input-only format with the output-only format.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map.erase(input_);
+  reprocess_map[output_multisize_non_stalling_] = {1};
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because not all input formats are present/
+  // one of the map "input" formats is output only.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, InvalidReprocessNotAnOutput) {
+  SetDefaultExpectations();
+  // Override the reprocess map with a non-output output entry.
+  ReprocessFormatMap reprocess_map = test_reprocess_map_;
+  reprocess_map[input_].insert(input_);
+  EXPECT_CALL(*mock_reader_, ReprocessFormats(_))
+      .WillOnce(DoAll(SetArgPointee<0>(reprocess_map), Return(0)));
+  PrepareDUT();
+  // Should fail because a specified output format doesn't support output.
+  EXPECT_EQ(dut_, nullptr);
+}
+
+TEST_F(StaticPropertiesTest, TemplatesValid) {
+  PrepareDefaultDUT();
+  for (int i = 1; i < CAMERA3_TEMPLATE_COUNT; ++i) {
+    EXPECT_TRUE(dut_->TemplateSupported(i));
+  }
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSingleOutput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureMultipleOutputs) {
+  std::vector<camera3_stream_t> streams;
+  // 2 outputs, of different sizes.
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // Use the alternate size.
+  streams.push_back(MakeStream(output_multisize_non_stalling_,
+                               true,
+                               false,
+                               kAlternateWidth,
+                               kAlternateHeight));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureInput) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> different output.
+  streams.push_back(MakeStream(input_, false, true));
+  // Use the alternate size, it should be ok.
+  streams.push_back(MakeStream(output_multisize_non_stalling_,
+                               true,
+                               false,
+                               kAlternateWidth,
+                               kAlternateHeight));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureBidirectional) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> same output.
+  streams.push_back(
+      MakeStream(bidirectional_self_supporting_stalling_, true, true));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureMultipleReprocess) {
+  std::vector<camera3_stream_t> streams;
+  // Single input -> multiple outputs.
+  streams.push_back(
+      MakeStream(bidirectional_self_supporting_stalling_, true, true));
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNull) {
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(nullptr));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureEmptyStreams) {
+  std::vector<camera3_stream_t*> streams(1);
+  camera3_stream_configuration_t config = {
+      0, streams.data(), CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE, nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNullStreams) {
+  std::vector<camera3_stream_t*> streams(2, nullptr);
+  camera3_stream_configuration_t config = {
+      static_cast<uint32_t>(streams.size()),
+      streams.data(),
+      CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE,
+      nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNullStreamVector) {
+  // Even if the camera claims to have multiple streams, check for null.
+  camera3_stream_configuration_t config = {
+      3, nullptr, CAMERA3_STREAM_CONFIGURATION_NORMAL_MODE, nullptr};
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNoOutput) {
+  std::vector<camera3_stream_t> streams;
+  // Only an input stream, no output.
+  streams.push_back(MakeStream(input_, false, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureInvalidType) {
+  std::vector<camera3_stream_t> streams;
+  // Not input, output, or bidirectional.
+  streams.push_back(MakeStream(output_multisize_non_stalling_, false, false));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSpecFormatDoesNotExist) {
+  std::vector<camera3_stream_t> streams;
+  // Format 99 is not supported in any form.
+  streams.push_back(MakeStream(99));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureSpecSizeDoesNotExist) {
+  std::vector<camera3_stream_t> streams;
+  // Size 99 x 99 not supported for the output format.
+  streams.push_back(
+      MakeStream(output_multisize_non_stalling_, true, false, 99, 99));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNotAnInput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  // Can't use output-only format as an input.
+  streams.push_back(MakeStream(output_multisize_non_stalling_, false, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureNotAnOutput) {
+  std::vector<camera3_stream_t> streams;
+  // Can't use input-only format as an output.
+  streams.push_back(MakeStream(input_));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyInputs) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_inputs_; ++i) {
+    streams.push_back(MakeStream(input_, false, true));
+  }
+  // Have a valid output still.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, false);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_inputs_; ++i) {
+    streams.push_back(MakeStream(input_, false, true));
+  }
+  // Have a valid output still.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyRaw) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_raw_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_raw_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_raw_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_raw_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyStalling) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_self_supporting_stalling_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(bidirectional_self_supporting_stalling_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureTooManyNonStalling) {
+  std::vector<camera3_stream_t> streams;
+  // At the threshold is ok.
+  for (int32_t i = 0; i < test_max_non_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(output_multisize_non_stalling_));
+  }
+  ExpectConfigurationSupported(streams, true);
+
+  // Reset.
+  mock_reader_ = std::make_unique<MetadataReaderMock>();
+  streams.clear();
+
+  // Try again with too many.
+  for (int32_t i = 0; i <= test_max_non_stalling_outputs_; ++i) {
+    streams.push_back(MakeStream(output_multisize_non_stalling_));
+  }
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnuspportedInput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(input_, false, true));
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // No matching output format for input.
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnsupportedOutput) {
+  std::vector<camera3_stream_t> streams;
+  streams.push_back(MakeStream(input_, false, true));
+  // The universal output does match input.
+  streams.push_back(MakeStream(output_multisize_non_stalling_));
+  // Raw does not match input.
+  streams.push_back(MakeStream(bidirectional_raw_));
+  // Input is matched; it's ok that raw doesn't match (only the actual
+  // requests care).
+  ExpectConfigurationSupported(streams, true);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureUnsupportedBidirectional) {
+  std::vector<camera3_stream_t> streams;
+  // The test raw format, while supporting both input and output,
+  // does not actually support itself.
+  streams.push_back(MakeStream(bidirectional_raw_, true, true));
+  ExpectConfigurationSupported(streams, false);
+}
+
+TEST_F(StaticPropertiesTest, ConfigureBadOperationMode) {
+  // A valid stream set.
+  camera3_stream_t stream = MakeStream(output_multisize_non_stalling_);
+  camera3_stream_t* stream_address = &stream;
+  // But not a valid config.
+  camera3_stream_configuration_t config = {
+      1,
+      &stream_address,
+      99, // Not a valid operation mode.
+      nullptr
+  };
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->StreamConfigurationSupported(&config));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingSingleOutput) {
+  camera3_stream_t input_stream = MakeStream(input_);
+  camera3_stream_t output_stream = MakeStream(output_multisize_non_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_TRUE(dut_->ReprocessingSupported(&input_stream, {&output_stream}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingMultipleOutputs) {
+  camera3_stream_t input_stream =
+      MakeStream(bidirectional_self_supporting_stalling_, false, true);
+  // Bi-directional self-supporting supports the universal output and itself.
+  camera3_stream_t output_stream1 = MakeStream(output_multisize_non_stalling_);
+  camera3_stream_t output_stream2 =
+      MakeStream(bidirectional_self_supporting_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_TRUE(dut_->ReprocessingSupported(&input_stream,
+                                          {&output_stream1, &output_stream2}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingNoInput) {
+  camera3_stream_t output_stream = MakeStream(output_multisize_non_stalling_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(nullptr, {&output_stream}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingNoOutput) {
+  camera3_stream_t input_stream = MakeStream(input_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(&input_stream, {}));
+}
+
+TEST_F(StaticPropertiesTest, ReprocessingInvalidOutput) {
+  camera3_stream_t input_stream = MakeStream(input_, false, true);
+  // The universal output does match input.
+  camera3_stream_t output_stream1 = MakeStream(output_multisize_non_stalling_);
+  // Raw does not match input.
+  camera3_stream_t output_stream2 = MakeStream(bidirectional_raw_);
+  PrepareDefaultDUT();
+  EXPECT_FALSE(dut_->ReprocessingSupported(&input_stream,
+                                           {&output_stream1, &output_stream2}));
+}
+
+}  // namespace default_camera_hal
diff --git a/hardware/ntimespace/camera/stream_format.cpp b/hardware/ntimespace/camera/stream_format.cpp
new file mode 100644
index 0000000000..a2be8b9a80
--- /dev/null
+++ b/hardware/ntimespace/camera/stream_format.cpp
@@ -0,0 +1,242 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "StreamFormat"
+
+#include "stream_format.h"
+
+#include <system/graphics.h>
+#include "arc/image_processor.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+
+static const std::vector<uint32_t> GetSupportedFourCCs() {
+  // The preference of supported fourccs in the list is from high to low.
+  static const std::vector<uint32_t> kSupportedFourCCs = {V4L2_PIX_FMT_RGB32,
+                                                          V4L2_PIX_FMT_NV12,
+                                                          V4L2_PIX_FMT_YUYV,
+                                                          V4L2_PIX_FMT_MJPEG};
+  return kSupportedFourCCs;
+}
+
+StreamFormat::StreamFormat(int format, uint32_t width, uint32_t height) 
+    // TODO(b/30000211): multiplanar support.
+    : type_(V4L2_BUF_TYPE_VIDEO_CAPTURE),
+      v4l2_pixel_format_(StreamFormat::HalToV4L2PixelFormat(format)),
+      width_(width),
+      height_(height),
+      bytes_per_line_(0) {}
+
+StreamFormat::StreamFormat(const v4l2_format& format)
+    : type_(format.type),
+      // TODO(b/30000211): multiplanar support.
+      v4l2_pixel_format_(format.fmt.pix.pixelformat),
+      width_(format.fmt.pix.width),
+      height_(format.fmt.pix.height),
+      bytes_per_line_(format.fmt.pix.bytesperline) {}
+
+StreamFormat::StreamFormat(const arc::SupportedFormat& format)
+    : type_(V4L2_BUF_TYPE_VIDEO_CAPTURE),
+      v4l2_pixel_format_(format.fourcc),
+      width_(format.width),
+      height_(format.height),
+      bytes_per_line_(0) {}
+
+void StreamFormat::FillFormatRequest(v4l2_format* format) const {
+  memset(format, 0, sizeof(*format));
+  format->type = type_;
+  format->fmt.pix.pixelformat = v4l2_pixel_format_;
+  format->fmt.pix.width = width_;
+  format->fmt.pix.height = height_;
+  // Bytes per line and min buffer size are outputs set by the driver,
+  // not part of the request.
+}
+
+FormatCategory StreamFormat::Category() const {
+  switch (v4l2_pixel_format_) {
+    case V4L2_PIX_FMT_JPEG:
+      return kFormatCategoryStalling;
+    case V4L2_PIX_FMT_YUV420:  // Fall through.
+    case V4L2_PIX_FMT_BGR32:
+    case V4L2_PIX_FMT_RGB32:
+      return kFormatCategoryNonStalling;
+    default:
+      // Note: currently no supported RAW formats.
+      return kFormatCategoryUnknown;
+  }
+}
+
+bool StreamFormat::operator==(const StreamFormat& other) const {
+  // Used to check that a requested format was actually set, so
+  // don't compare bytes per line or min buffer size.
+  return (type_ == other.type_ &&
+          v4l2_pixel_format_ == other.v4l2_pixel_format_ &&
+          width_ == other.width_ && height_ == other.height_);
+}
+
+bool StreamFormat::operator!=(const StreamFormat& other) const {
+  return !(*this == other);
+}
+
+int StreamFormat::V4L2ToHalPixelFormat(uint32_t v4l2_pixel_format) {
+  HAL_LOGV("[format_mapping]v4l2_pixel_format: 0x%x", v4l2_pixel_format);
+  // Translate V4L2 format to HAL format.
+  switch (v4l2_pixel_format) {
+    case V4L2_PIX_FMT_BGR32:
+      return HAL_PIXEL_FORMAT_RGBA_8888;
+    case V4L2_PIX_FMT_JPEG:
+      return HAL_PIXEL_FORMAT_BLOB;
+    case V4L2_PIX_FMT_NV21:
+      return HAL_PIXEL_FORMAT_YCbCr_420_888;
+      //return HAL_PIXEL_FORMAT_YCrCb_420_SP;
+    case V4L2_PIX_FMT_NV12:
+      #if HAS_RGA
+        return HAL_PIXEL_FORMAT_YCbCr_420_888;
+      #else
+        return HAL_PIXEL_FORMAT_YCRCB_420_SP;
+      #endif
+    case V4L2_PIX_FMT_YUV420:
+      return HAL_PIXEL_FORMAT_YCbCr_420_888;
+    case V4L2_PIX_FMT_YUYV:
+      return HAL_PIXEL_FORMAT_YCbCr_422_I;
+    case V4L2_PIX_FMT_YVU420:
+      return HAL_PIXEL_FORMAT_YV12;
+    case V4L2_PIX_FMT_RGB32:
+      return HAL_PIXEL_FORMAT_RGBA_8888;
+    default:
+      // Unrecognized format.
+      HAL_LOGE("Unrecognized v4l2 pixel format 0x%x", v4l2_pixel_format);
+      break;
+  }
+  return -1;
+}
+
+uint32_t StreamFormat::HalToV4L2PixelFormat(int hal_pixel_format) {
+  HAL_LOGV("[format_mapping]hal_pixel_format: 0x%x", hal_pixel_format);
+  switch (hal_pixel_format) {
+    case HAL_PIXEL_FORMAT_BLOB:
+      return V4L2_PIX_FMT_JPEG;
+    case HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED:  // Fall-through
+    case HAL_PIXEL_FORMAT_RGBA_8888:
+      return V4L2_PIX_FMT_RGB32;
+      //return V4L2_PIX_FMT_BGR32;
+    case HAL_PIXEL_FORMAT_YCbCr_420_888:
+      // This is a flexible YUV format that depends on platform. Different
+      // platform may have different format. It can be YVU420 or NV12. Now we
+      // return YVU420 first.
+      // TODO(): call drm_drv.get_fourcc() to get correct format.
+      #if HAS_RGA
+        return V4L2_PIX_FMT_NV12;
+      #else
+        return V4L2_PIX_FMT_NV21;
+      #endif
+      //return V4L2_PIX_FMT_YUV420;
+      //return V4L2_PIX_FMT_NV12;      
+    case HAL_PIXEL_FORMAT_YCbCr_422_I:
+      return V4L2_PIX_FMT_YUYV;
+    case HAL_PIXEL_FORMAT_YCrCb_420_SP:
+      return V4L2_PIX_FMT_NV21;
+    case HAL_PIXEL_FORMAT_YV12:
+      return V4L2_PIX_FMT_YVU420;
+    default:
+      HAL_LOGE("Pixel format 0x%x is unsupported.", hal_pixel_format);
+      break;
+  }
+  return -1;
+}
+
+// Copy the qualified format into out_format and return true if there is a
+// proper and fitting format in the given format lists.
+bool StreamFormat::FindBestFitFormat(const SupportedFormats& supported_formats,
+                                     const SupportedFormats& qualified_formats,
+                                     uint32_t fourcc, uint32_t width,
+                                     uint32_t height,
+                                     SupportedFormat* out_format) {
+  // Match exact format and resolution if possible.
+  for (const auto& format : supported_formats) {
+    if (format.fourcc == fourcc && format.width == width &&
+        format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  // All conversions will be done through CachedFrame for now, which will
+  // immediately convert the qualified format into YU12 (YUV420). We check
+  // here that the conversion between YU12 and |fourcc| is supported.
+  if (!arc::ImageProcessor::SupportsConversion(V4L2_PIX_FMT_YUV420, fourcc)) {
+    HAL_LOGE("Conversion between YU12 and 0x%x not supported.", fourcc);
+    return false;
+  }
+
+  // Choose the qualified format with a matching resolution.
+  for (const auto& format : qualified_formats) {
+    if (format.width == width && format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  return false;
+}
+
+// Copy corresponding format into out_format and return true by matching
+// resolution |width|x|height| in |formats|.
+bool StreamFormat::FindFormatByResolution(const SupportedFormats& formats,
+                                          uint32_t width, uint32_t height,
+                                          SupportedFormat* out_format) {
+  for (const auto& format : formats) {
+    if (format.width == width && format.height == height) {
+      if (out_format != NULL) {
+        *out_format = format;
+      }
+      return true;
+    }
+  }
+  return false;
+}
+
+SupportedFormats StreamFormat::GetQualifiedFormats(
+    const SupportedFormats& supported_formats) {
+  // The preference of supported fourccs in the list is from high to low.
+  const std::vector<uint32_t> supported_fourccs = GetSupportedFourCCs();
+  SupportedFormats qualified_formats;
+  for (const auto& supported_fourcc : supported_fourccs) {
+    for (const auto& supported_format : supported_formats) {
+      if (supported_format.fourcc != supported_fourcc) {
+        continue;
+      }
+
+      // Skip if |qualified_formats| already has the same resolution with a more
+      // preferred fourcc.
+      if (FindFormatByResolution(qualified_formats, supported_format.width,
+                                 supported_format.height, NULL)) {
+        continue;
+      }
+      qualified_formats.push_back(supported_format);
+    }
+  }
+  return qualified_formats;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/stream_format.h b/hardware/ntimespace/camera/stream_format.h
new file mode 100644
index 0000000000..3f0c514614
--- /dev/null
+++ b/hardware/ntimespace/camera/stream_format.h
@@ -0,0 +1,83 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_STREAM_FORMAT_H_
+#define V4L2_CAMERA_HAL_STREAM_FORMAT_H_
+
+#include <cstring>
+
+#include <linux/videodev2.h>
+#include "arc/common_types.h"
+
+namespace v4l2_camera_hal {
+
+enum FormatCategory {
+  kFormatCategoryRaw,
+  kFormatCategoryStalling,
+  kFormatCategoryNonStalling,
+  kFormatCategoryUnknown,
+};
+
+class StreamFormat {
+ public:
+  StreamFormat(int format, uint32_t width, uint32_t height);
+  StreamFormat(const v4l2_format& format);
+  StreamFormat(const arc::SupportedFormat& format);
+  virtual ~StreamFormat() = default;
+  // Only uint32_t members, use default generated copy and assign.
+
+  void FillFormatRequest(v4l2_format* format) const;
+  FormatCategory Category() const;
+
+  // Accessors.
+  inline uint32_t type() const { return type_; };
+  inline uint32_t width() const { return width_; };
+  inline uint32_t height() const { return height_; };
+  inline uint32_t v4l2_pixel_format() const { return v4l2_pixel_format_; }
+  inline uint32_t bytes_per_line() const { return bytes_per_line_; };
+
+  bool operator==(const StreamFormat& other) const;
+  bool operator!=(const StreamFormat& other) const;
+
+  // HAL <-> V4L2 conversions
+  // Returns 0 for unrecognized.
+  static uint32_t HalToV4L2PixelFormat(int hal_pixel_format);
+  // Returns -1 for unrecognized.
+  static int V4L2ToHalPixelFormat(uint32_t v4l2_pixel_format);
+
+  // ARC++ SupportedFormat Helpers
+  static bool FindBestFitFormat(const arc::SupportedFormats& supported_formats,
+                                const arc::SupportedFormats& qualified_formats,
+                                uint32_t fourcc, uint32_t width,
+                                uint32_t height,
+                                arc::SupportedFormat* out_format);
+  static bool FindFormatByResolution(const arc::SupportedFormats& formats,
+                                     uint32_t width, uint32_t height,
+                                     arc::SupportedFormat* out_format);
+  static arc::SupportedFormats GetQualifiedFormats(
+      const arc::SupportedFormats& supported_formats);
+
+ private:
+  uint32_t type_;
+  uint32_t v4l2_pixel_format_;
+  uint32_t width_;
+  uint32_t height_;
+  uint32_t bytes_per_line_;
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_STREAM_FORMAT_H_
diff --git a/hardware/ntimespace/camera/v4l2_camera.cpp b/hardware/ntimespace/camera/v4l2_camera.cpp
new file mode 100644
index 0000000000..670a256235
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera.cpp
@@ -0,0 +1,912 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Camera"
+
+#include "v4l2_camera.h"
+#include <cstdlib>
+#include <fcntl.h>
+#include "metadata/camera_metadata.h"
+#include <hardware/camera3.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "common.h"
+#include "function_thread.h"
+#include "metadata/metadata_common.h"
+#include "stream_format.h"
+#include "v4l2_metadata_factory.h"
+#include "arc/format_convert_test.h"
+//#include <utils/CallStack.h>
+#include "debug.h"
+
+#define ARRAY_SIZE(a) (sizeof(a) / sizeof(*(a)))
+
+namespace v4l2_camera_hal {
+
+V4L2Camera* V4L2Camera::NewV4L2Camera(int id, const std::string path) {
+  HAL_LOG_ENTER();
+  HAL_LOGE("path: %s.", path.c_str());
+
+  std::shared_ptr<V4L2Wrapper> v4l2_wrapper(V4L2Wrapper::NewV4L2Wrapper(path, id));
+  if (!v4l2_wrapper) {
+    HAL_LOGE("Failed to initialize V4L2 wrapper.");
+    return nullptr;
+  }
+
+  std::unique_ptr<Metadata> metadata;
+  int res = GetV4L2Metadata(v4l2_wrapper, &metadata);
+  if (res) {
+    HAL_LOGE("Failed to initialize V4L2 metadata: %d", res);
+    return nullptr;
+  }
+  //metadata->Dump("/data/local/metadata_GetV4L2Metadata.log");
+
+  return new V4L2Camera(id, std::move(v4l2_wrapper), std::move(metadata));
+}
+
+V4L2Camera::V4L2Camera(int id,
+                       std::shared_ptr<V4L2Wrapper> v4l2_wrapper,
+                       std::unique_ptr<Metadata> metadata)
+    : default_camera_hal::Camera(id),
+      device_(std::move(v4l2_wrapper)),
+      metadata_(std::move(metadata)),
+      buffer_enqueuer_(new FunctionThread(
+          std::bind(&V4L2Camera::enqueueRequestBuffers, this))),
+      buffer_dequeuer_(new FunctionThread(
+          std::bind(&V4L2Camera::dequeueRequestBuffers, this))),
+      unit_tester_(new FunctionThread(
+          std::bind(&V4L2Camera::unitTest, this))),          
+      max_input_streams_(0),
+      max_output_streams_({{0, 0, 0}}) {
+  HAL_LOG_ENTER();
+}
+
+V4L2Camera::~V4L2Camera() {
+  HAL_LOG_ENTER();
+}
+
+int V4L2Camera::connect() {
+  HAL_LOG_ENTER();
+
+  if (connection_) {
+    HAL_LOGE("Already connected. Please disconnect and try again.");
+    return -EIO;
+  }
+
+  connection_.reset(new V4L2Wrapper::Connection(device_));
+  if (connection_->status()) {
+    HAL_LOGE("Failed to connect to device.");
+    return connection_->status();
+  }
+
+//  initDevice();
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at |device_|'s path may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so connect() is never called on an unsupported camera)
+
+  // TODO(b/29158098): Inform service of any flashes that are no longer
+  // available because this camera is in use.
+  return 0;
+}
+
+void V4L2Camera::disconnect() {
+  HAL_LOG_ENTER();
+
+  StopQueue();
+  connection_.reset();
+  // TODO(b/29158098): Inform service of any flashes that are available again
+  // because this camera is no longer in use.
+}
+
+int V4L2Camera::flushBuffers() {
+  HAL_LOG_ENTER();
+
+  device_->StreamOff();
+  requests_available_.notify_one();
+  return 0;
+}
+
+int V4L2Camera::UpdateVendorStaticInfo(android::CameraMetadata* metadata)
+{
+    int32_t max_input_streams = 1;
+    metadata->update(ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS,
+                      &max_input_streams,
+                      1);
+
+    int32_t MAX_STALLING_STREAMS = 1;
+    int32_t MAX_PROCESSED_STREAMS = 2;
+    int32_t MAX_RAW_STREAMS = 0;
+    int32_t max_output_streams[] = {
+            MAX_STALLING_STREAMS,
+            MAX_PROCESSED_STREAMS,
+            MAX_RAW_STREAMS};
+    metadata->update(ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+            max_output_streams,
+            sizeof(max_output_streams)/sizeof(max_output_streams[0]));
+
+    /* format of the map is : input format, num_output_formats, outputFormat1,..,outputFormatN */
+    int32_t io_format_map[] = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 1, HAL_PIXEL_FORMAT_YCbCr_420_888,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1, HAL_PIXEL_FORMAT_YCbCr_420_888
+    };
+    metadata->update(ANDROID_SCALER_AVAILABLE_INPUT_OUTPUT_FORMATS_MAP,
+                      io_format_map, sizeof(io_format_map)/sizeof(io_format_map[0]));
+
+    //for reprocess check
+    int32_t max_stall_duration = 0;
+    metadata->update(ANDROID_REPROCESS_MAX_CAPTURE_STALL, &max_stall_duration, 1);
+
+    std::vector<uint8_t> available_capabilities;
+    available_capabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_SENSOR);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_MANUAL_POST_PROCESSING);
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_READ_SENSOR_SETTINGS);
+    if (/*supportBurst*/0) {
+        available_capabilities.push_back(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BURST_CAPTURE);
+    }
+    //available_capabilities.add(ANDROID_REQUEST_AVAILABLE_CAPABILITIES_PRIVATE_REPROCESSING);
+    metadata->update(ANDROID_REQUEST_AVAILABLE_CAPABILITIES,
+            &available_capabilities[0],
+            available_capabilities.size());   
+
+#if 0
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,  
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,   
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,            
+
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,  
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,      
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 768, 1024, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 960, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,                               
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 1024, 768, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,        
+    };
+#elif 0
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,  
+          
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,  
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,      
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 720, 1280, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 480, 640, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,                               
+    };
+#else
+    const std::vector<int32_t> availableStreamConfigurations = {
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_INPUT,   
+
+        HAL_PIXEL_FORMAT_RGBA_8888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_RGBA_8888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_YCbCr_420_888, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+
+        HAL_PIXEL_FORMAT_BLOB, 640, 480, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+        HAL_PIXEL_FORMAT_BLOB, 1280, 720, ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS_OUTPUT,
+    };    
+#endif
+
+    metadata->update(ANDROID_SCALER_AVAILABLE_STREAM_CONFIGURATIONS,
+            &availableStreamConfigurations[0],
+            availableStreamConfigurations.size());
+
+    uint8_t lensFacing = (getCameraId() == 1 ? ANDROID_LENS_FACING_FRONT : ANDROID_LENS_FACING_BACK);
+    metadata->update(ANDROID_LENS_FACING, &lensFacing, 1);
+
+    int32_t lensOrientation = (getCameraId() == 1 ? 270 : 90); 
+    metadata->update(ANDROID_SENSOR_ORIENTATION, &lensOrientation, 1);
+
+    int32_t jpegOrientation = (getCameraId() == 1 ? 270 : 90); 
+    metadata->update(ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+    /* android.control */
+    int32_t aeTargetFpsRange[2] = {
+        15, 30
+    };
+    metadata->update(ANDROID_CONTROL_AE_TARGET_FPS_RANGE, aeTargetFpsRange, 2);          
+
+    static const int32_t availableTargetFpsRanges[] = {
+        15, 30
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_TARGET_FPS_RANGES,
+            availableTargetFpsRanges,
+            sizeof(availableTargetFpsRanges)/sizeof(int32_t));
+
+    const uint8_t controlMode = ANDROID_CONTROL_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_MODE, &controlMode, 1);
+
+    static const uint8_t effectMode = ANDROID_CONTROL_EFFECT_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_EFFECT_MODE, &effectMode, 1);
+
+    //const uint8_t sceneMode = ANDROID_CONTROL_SCENE_MODE_FACE_PRIORITY;
+    //metadata->update(ANDROID_CONTROL_SCENE_MODE, &sceneMode, 1);
+
+    const uint8_t aeMode = ANDROID_CONTROL_AE_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_AE_MODE, &aeMode, 1);
+#if 0
+    static const uint8_t aeLock = ANDROID_CONTROL_AE_LOCK_OFF;
+    metadata->update(ANDROID_CONTROL_AE_LOCK, &aeLock, 1);
+#endif    
+    static const int32_t controlRegions[5] = {
+        0, 0, 0, 0, 0
+    };
+    metadata->update(ANDROID_CONTROL_AE_REGIONS, controlRegions, 5);
+
+    static const int32_t aeExpCompensation = 0;
+    metadata->update(ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION, &aeExpCompensation, 1);
+
+    static const uint8_t aeAntibandingMode =
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO;
+    metadata->update(ANDROID_CONTROL_AE_ANTIBANDING_MODE, &aeAntibandingMode, 1);
+
+    static const uint8_t aePrecaptureTrigger = ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_IDLE;
+    metadata->update(ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER, &aePrecaptureTrigger, 1);
+
+    const uint8_t awbMode = ANDROID_CONTROL_AWB_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_AWB_MODE, &awbMode, 1);
+
+    static const uint8_t awbLock = ANDROID_CONTROL_AWB_LOCK_OFF;
+    metadata->update(ANDROID_CONTROL_AWB_LOCK, &awbLock, 1);
+
+    uint8_t afMode[] = {ANDROID_CONTROL_AF_MODE_OFF, ANDROID_CONTROL_AF_MODE_AUTO};
+    metadata->update(ANDROID_CONTROL_AF_MODE, afMode, 2);
+
+    metadata->update(ANDROID_CONTROL_AF_REGIONS, controlRegions, 5);
+#if 0
+    static const uint8_t afTrigger = ANDROID_CONTROL_AF_TRIGGER_IDLE;
+    metadata->update(ANDROID_CONTROL_AF_TRIGGER, &afTrigger, 1);
+
+    static const uint8_t vstabMode =
+            ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF;
+    metadata->update(ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+                    &vstabMode, 1);
+#endif
+    static const uint8_t availableSceneModes[] = {
+            ANDROID_CONTROL_SCENE_MODE_DISABLED
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+            availableSceneModes, sizeof(availableSceneModes));
+
+    static const uint8_t availableEffects[] = {
+            ANDROID_CONTROL_EFFECT_MODE_OFF
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_EFFECTS,
+            availableEffects, sizeof(availableEffects));
+
+    static const int32_t max3aRegions[] = {/*AE*/ 0,/*AWB*/ 0,/*AF*/ 0};
+    metadata->update(ANDROID_CONTROL_MAX_REGIONS,
+            max3aRegions, sizeof(max3aRegions)/sizeof(max3aRegions[0]));
+
+    static const uint8_t availableAeModes[] = {
+            ANDROID_CONTROL_AE_MODE_OFF,
+            ANDROID_CONTROL_AE_MODE_ON
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_MODES,
+            availableAeModes, sizeof(availableAeModes));
+
+    static const camera_metadata_rational exposureCompensationStep = {
+            1, 3
+    };
+    metadata->update(ANDROID_CONTROL_AE_COMPENSATION_STEP,
+            &exposureCompensationStep, 1);
+
+    int32_t exposureCompensationRange[] = {-9, 9};
+    metadata->update(ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+            exposureCompensationRange,
+            sizeof(exposureCompensationRange)/sizeof(int32_t));
+
+    static const uint8_t availableAntibandingModes[] = {
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF,
+            ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO
+    };
+    metadata->update(ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+            availableAntibandingModes, sizeof(availableAntibandingModes));
+
+    static const uint8_t availableAwbModes[] = {
+            ANDROID_CONTROL_AWB_MODE_OFF,
+            ANDROID_CONTROL_AWB_MODE_AUTO,
+            ANDROID_CONTROL_AWB_MODE_INCANDESCENT,
+            ANDROID_CONTROL_AWB_MODE_FLUORESCENT,
+            ANDROID_CONTROL_AWB_MODE_DAYLIGHT,
+            ANDROID_CONTROL_AWB_MODE_SHADE
+    };
+    metadata->update(ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+            availableAwbModes, sizeof(availableAwbModes));
+
+    static const uint8_t availableAfModesBack[] = {
+            ANDROID_CONTROL_AF_MODE_OFF,
+            ANDROID_CONTROL_AF_MODE_AUTO,
+            ANDROID_CONTROL_AF_MODE_MACRO,
+            ANDROID_CONTROL_AF_MODE_CONTINUOUS_VIDEO,
+            ANDROID_CONTROL_AF_MODE_CONTINUOUS_PICTURE
+    };
+
+    metadata->update(ANDROID_CONTROL_AF_AVAILABLE_MODES,
+                availableAfModesBack, sizeof(availableAfModesBack));
+
+    static const uint8_t availableVstabModes[] = {
+            ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF
+    };
+    metadata->update(ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+            availableVstabModes, sizeof(availableVstabModes));
+
+    static const uint8_t blackLevelLock = ANDROID_BLACK_LEVEL_LOCK_OFF;
+    metadata->update(ANDROID_BLACK_LEVEL_LOCK, &blackLevelLock, 1);
+
+    /*
+    static const uint8_t lensShadingMapMode =
+            ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF;
+    metadata->update(ANDROID_STATISTICS_LENS_SHADING_MAP_MODE,
+                    &lensShadingMapMode, 1);
+    */
+    static const uint8_t aberrationMode =
+            ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST;
+    metadata->update(ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+                    &aberrationMode, 1);
+
+  /* android.jpeg */
+  int32_t android_jpeg_available_thumbnail_sizes[] = {0, 0, 128, 96};
+  metadata->update(ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+          android_jpeg_available_thumbnail_sizes,
+          ARRAY_SIZE(android_jpeg_available_thumbnail_sizes));
+
+  int32_t android_jpeg_max_size[] = {13 * 1024 * 1024}; // 13MB
+  metadata->update(ANDROID_JPEG_MAX_SIZE,
+          android_jpeg_max_size,
+          ARRAY_SIZE(android_jpeg_max_size));
+#if 0
+  /* android.lens */
+  float android_lens_info_available_focal_lengths[] = {1.0};
+  metadata->addFloat(ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
+          ARRAY_SIZE(android_lens_info_available_focal_lengths),
+          android_lens_info_available_focal_lengths);
+#endif
+
+  /** android.sensor */
+  const int64_t USEC = 1000LL;
+  const int64_t MSEC = USEC * 1000LL;
+  static const int64_t exposureTime = 10 * MSEC;
+  metadata->update(ANDROID_SENSOR_EXPOSURE_TIME, &exposureTime, 1);
+
+  static const int64_t frameDuration = 33333333L; // 1/30 s
+  metadata->update(ANDROID_SENSOR_FRAME_DURATION, &frameDuration, 1);
+
+  static const int32_t sensitivity = 100;
+  metadata->update(ANDROID_SENSOR_SENSITIVITY, &sensitivity, 1);
+
+  //if (hasCapability(MANUAL_SENSOR)) 
+  {
+    const nsecs_t kExposureTimeRange[2] =
+      {1000L, 300000000L} ; // 1 us - 0.3 sec
+    const nsecs_t kFrameDurationRange[2] =
+      {33331760L, 300000000L}; // ~1/30 s - 0.3 sec
+    const int32_t kSensitivityRange[2] = {100, 1600};
+
+      metadata->update(ANDROID_SENSOR_INFO_EXPOSURE_TIME_RANGE,
+              kExposureTimeRange, 2);
+
+      metadata->update(ANDROID_SENSOR_INFO_MAX_FRAME_DURATION,
+              &kFrameDurationRange[1], 1);
+
+      metadata->update(ANDROID_SENSOR_INFO_SENSITIVITY_RANGE,
+              kSensitivityRange,
+              sizeof(kSensitivityRange)
+              /sizeof(int32_t));
+
+      metadata->update(ANDROID_SENSOR_MAX_ANALOG_SENSITIVITY,
+              &kSensitivityRange[1], 1);
+  }
+
+  /** android.lens */
+  static const float focalLength = 5.0f;
+  metadata->update(ANDROID_LENS_FOCAL_LENGTH, &focalLength, 1);
+
+  //if (hasCapability(BACKWARD_COMPATIBLE)) 
+  {
+      static const float focusDistance = 0;
+      metadata->update(ANDROID_LENS_FOCUS_DISTANCE, &focusDistance, 1);
+
+      static const float aperture = 2.8f;
+      metadata->update(ANDROID_LENS_APERTURE, &aperture, 1);
+
+      static const float filterDensity = 0;
+      metadata->update(ANDROID_LENS_FILTER_DENSITY, &filterDensity, 1);
+
+      static const uint8_t opticalStabilizationMode =
+              ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF;
+      metadata->update(ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+              &opticalStabilizationMode, 1);
+  }
+
+  return 0;
+}
+
+int V4L2Camera::initStaticInfo(android::CameraMetadata* out) {
+  HAL_LOG_ENTER();
+
+  int res = metadata_->FillStaticMetadata(out);
+  if (res) {
+    HAL_LOGE("Failed to get static metadata.");
+    return res;
+  }
+
+  UpdateVendorStaticInfo(out);
+
+  // Extract max streams for use in verifying stream configs.
+  res = SingleTagValue(
+      *out, ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, &max_input_streams_);
+  if (res) {
+    HAL_LOGE("Failed to get max num input streams from static metadata.");
+    return res;
+  }
+  res = SingleTagValue(
+      *out, ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS, &max_output_streams_);
+  if (res) {
+    HAL_LOGE("Failed to get max num output streams from static metadata.");
+    return res;
+  }
+
+  HAL_LOGE("Get max num input/output streams [%d/%d/%d/%d] from static metadata.", max_input_streams_, 
+  max_output_streams_[0], max_output_streams_[1], max_output_streams_[2]);
+
+  return 0;
+}
+
+int V4L2Camera::initTemplate(int type, android::CameraMetadata* out) {
+  HAL_LOG_ENTER();
+
+  return metadata_->GetRequestTemplate(type, out);
+}
+
+void V4L2Camera::initDeviceInfo(camera_info_t* info) {
+  HAL_LOG_ENTER();
+
+  // TODO(b/31044975): move this into device interface.
+  // For now, just constants.
+  info->resource_cost = 100;
+  info->conflicting_devices = nullptr;
+  info->conflicting_devices_length = 0;
+}
+
+int V4L2Camera::initDevice() {
+  HAL_LOG_ENTER();
+
+  // Start the buffer enqueue/dequeue threads if they're not already running.
+  if (!buffer_enqueuer_->isRunning()) {
+    android::status_t res = buffer_enqueuer_->run("Enqueue buffers");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start buffer enqueue thread: %d", res);
+      return -ENODEV;
+    }
+  }
+  if (!buffer_dequeuer_->isRunning()) {
+    android::status_t res = buffer_dequeuer_->run("Dequeue buffers");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start buffer dequeue thread: %d", res);
+      return -ENODEV;
+    }
+  }
+
+  if (!unit_tester_->isRunning()) {
+    android::status_t res = unit_tester_->run("Unit Tester");
+    if (res != android::OK) {
+      HAL_LOGE("Failed to start unit test thread: %d", res);
+      return -ENODEV;
+    }
+  }
+
+  HAL_LOGD("Queue thread Running");
+
+  return 0;
+}
+
+int V4L2Camera::StopQueue()
+{
+    HAL_LOG_ENTER();
+
+    if (buffer_enqueuer_->isRunning()) {
+        buffer_enqueuer_->requestExitAndWait();
+    }
+    HAL_LOGD("enqueue buffers thread stoped!");
+
+    if (buffer_dequeuer_->isRunning()){
+        buffer_dequeuer_->requestExitAndWait();
+    }
+
+    HAL_LOGD("deuqueue buffers thread stoped!");
+
+    if (unit_tester_->isRunning())
+        unit_tester_->requestExit();
+    HAL_LOGD("Stop Queue done");
+
+    {
+    std::lock_guard<std::mutex> guard(request_queue_lock_);
+    //clear request_queue_ 
+    while(!request_queue_.empty())
+        request_queue_.pop();
+    }
+
+    return 0;
+}
+
+int V4L2Camera::enqueueRequest(
+    std::shared_ptr<default_camera_hal::CaptureRequest> request) {
+  HAL_LOG_ENTER();
+
+    if (device_->get_stream_status() == 0)
+    {
+        flush_lite();
+        return 0;
+    }
+  // Assume request validated before calling this function.
+  // (For now, always exactly 1 output buffer, no inputs).
+  {
+    std::lock_guard<std::mutex> guard(request_queue_lock_);
+    request_queue_.push(request);
+    requests_available_.notify_one();
+  }
+
+  return 0;
+}
+
+void dump_metadata(const android::CameraMetadata& metadata, std::string file) {
+    HAL_LOGE("Dump metadata start: %s", file.c_str());
+    
+    int fp = open(file.c_str(), O_CREAT |O_RDWR | O_CLOEXEC, 0);
+    if (fp != -1) {
+      metadata.dump(fp);
+    }
+    else {
+      HAL_LOGE("Dump metadata failed: %s", file.c_str());
+    }
+    ::close(fp);
+}
+
+std::shared_ptr<default_camera_hal::CaptureRequest>
+V4L2Camera::dequeueRequest() {
+  std::unique_lock<std::mutex> lock(request_queue_lock_);
+  while (request_queue_.empty() && device_->get_stream_status() == 1) {
+    HAL_LOGV("request_queue_ empty, wait");
+    requests_available_.wait_for(lock, std::chrono::seconds(10));
+//    requests_available_.wait(lock);
+  }
+
+  if (device_->get_stream_status() == 0)
+    return NULL;
+
+  std::shared_ptr<default_camera_hal::CaptureRequest> request =
+      request_queue_.front();
+  request_queue_.pop();
+
+  return request;
+}
+
+bool V4L2Camera::enqueueRequestBuffers() {
+  HAL_LOG_ENTER();
+
+    if (device_->get_stream_status() == 0)
+        return false;
+    // Actually enqueue the buffer for capture.
+    int res = device_->EnqueueRequest();
+    if (res) {
+      HAL_LOGD("Device failed to enqueue buffer.");
+//      completeRequest(request, res);
+      return true;
+    }
+
+  return true;
+}
+
+bool V4L2Camera::dequeueRequestBuffers() {
+  HAL_LOG_ENTER();
+  // Dequeue a buffer.
+  //std::shared_ptr<default_camera_hal::CaptureRequest> request;
+  int res;
+
+  if (device_->get_stream_status() == 0)
+    return false;
+
+  // Get a request from the queue (blocks this thread until one is available).
+  std::shared_ptr<default_camera_hal::CaptureRequest> request =
+      dequeueRequest();
+  if (!request)
+    return false;
+
+  // Assume request validated before being added to the queue
+  // (For now, always exactly 1 output buffer, no inputs).
+
+  // Setting and getting settings are best effort here,
+  // since there's no way to know through V4L2 exactly what
+  // settings are used for a buffer unless we were to enqueue them
+  // one at a time, which would be too slow.
+
+  //metadata_->Dump("/data/local/metadata_enqueueRequestBuffers_meata_0.log");
+  //dump_metadata(request->settings, "/data/local/metadata_enqueueRequestBuffers_request_0.log");
+
+  // Set the requested settings
+  res = metadata_->SetRequestSettings(request->settings);
+  if (res) {
+    HAL_LOGE("Failed to set metadata");
+    completeRequest(request, res);
+    return true;
+  }
+
+  // Replace the requested settings with a snapshot of
+  // the used settings/state immediately before enqueue.
+  res = metadata_->FillResultMetadata(&request->settings);
+  if (res) {
+    // Note: since request is a shared pointer, this may happen if another
+    // thread has already decided to complete the request (e.g. via flushing),
+    // since that locks the metadata (in that case, this failing is fine,
+    // and completeRequest will simply do nothing).
+    HAL_LOGE("Failed to fill result metadata.");
+    completeRequest(request, res);
+    return true;
+  }
+
+  int32_t jpegOrientation = (getCameraId() == 1 ? 270 : 90); 
+  request->settings.update(ANDROID_JPEG_ORIENTATION, &jpegOrientation, 1);
+
+
+  {
+    int retry = 5;
+    while (retry > 0) {
+        res = device_->DequeueRequest(request);
+        if (device_->get_stream_status() == 0)
+        {
+            HAL_LOGE("get request when stream is offf, we will flush_lite");
+            flush_lite();
+            {
+                std::lock_guard<std::mutex> guard(request_queue_lock_);
+                //clear request_queue_ 
+                while(!request_queue_.empty())
+                    request_queue_.pop();
+            }
+            return false;
+        }
+        if ( res == -EAGAIN)
+            continue;
+        if (!res)
+        {
+            completeRequest(request, res);
+            return true;
+        }
+    }
+    completeRequest(request, res);
+    msleep(100);
+  }
+  return true;
+}
+
+bool V4L2Camera:: unitTest() {
+  HAL_LOG_ENTER();
+  arc::FormatConvert_UnitTest();
+  return false;
+}
+
+bool V4L2Camera::validateDataspacesAndRotations(
+    const camera3_stream_configuration_t* stream_config) {
+  HAL_LOG_ENTER();
+
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    if (stream_config->streams[i]->rotation != CAMERA3_STREAM_ROTATION_0) {
+      HAL_LOGE("Rotation %d for stream %d not supported",
+               stream_config->streams[i]->rotation,
+               i);
+      return false;
+    }
+    // Accept all dataspaces, as it will just be overwritten below anyways.
+  }
+  return true;
+}
+
+int V4L2Camera::setupStreams(camera3_stream_configuration_t* stream_config) {
+  HAL_LOG_ENTER();
+
+  // The framework should be enforcing this, but doesn't hurt to be safe.
+  int res = 0; 
+  if (device_->GetInFlightBufferCount() != 0) {
+    res = device_->StreamOff();
+    if (res) {
+        HAL_LOGE("Device failed to turn off stream for reconfiguration: %d.", res);
+        return -ENODEV;
+    }
+  } 
+
+  // TODO(b/29939583):  V4L2 doesn't actually support more than 1
+  // stream at a time. If not all streams are the same format
+  // and size, error. Note that this means the HAL is not spec-compliant.
+  // Technically, this error should be thrown during validation, but
+  // since it isn't a spec-valid error validation isn't set up to check it.
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    HAL_LOGE(
+        "(stream %d: stream_type %d format %d, width %u, height %u rotation %d max_buffers %d).",
+        i,
+        stream_config->streams[i]->stream_type,
+        stream_config->streams[i]->format,
+        stream_config->streams[i]->width,
+        stream_config->streams[i]->height,
+        stream_config->streams[i]->rotation,
+        stream_config->streams[i]->max_buffers);
+  }
+
+  // stream_config should have been validated; assume at least 1 streametadata->
+  camera3_stream_t* stream = nullptr;
+  int format = 0;
+  uint32_t width = 0;
+  uint32_t height = 0;
+  uint32_t idx = 0;
+
+  //we always use the max size output stream to config hardware
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    if (stream_config->streams[i]->stream_type == CAMERA3_STREAM_OUTPUT) {
+      if ((stream_config->streams[i]->width > width && stream_config->streams[i]->height > height)) {
+          stream = stream_config->streams[i];
+          width = stream->width;
+          height = stream->height;
+          format = stream->format;
+          idx = i;
+      }
+    }
+  }
+  if (stream == nullptr) {
+    HAL_LOGE("no output stream found. return");
+    return -EINVAL;
+  } else {
+    HAL_LOGE("Will configure hw with stream %d", idx);
+  }  
+
+  // Ensure the stream is off.
+  res = device_->StreamOff();
+  if (res) {
+    HAL_LOGE("Device failed to turn off stream for reconfiguration: %d.", res);
+    return -ENODEV;
+  }
+
+  StreamFormat stream_format(format, width, height);
+  uint32_t max_buffers = 0;
+  res = device_->SetFormat(stream_format, &max_buffers);
+  if (res) {
+    HAL_LOGE("Failed to set device to correct format for stream: %d.", res);
+    return -ENODEV;
+  }
+
+  // Sanity check.
+  if (max_buffers < 1) {
+    HAL_LOGE("Setting format resulted in an invalid maximum of %u buffers.",
+             max_buffers);
+    return -ENODEV;
+  }
+
+  // Set all the streams dataspaces, usages, and max buffers.
+  for (uint32_t i = 0; i < stream_config->num_streams; ++i) {
+    stream = stream_config->streams[i];
+
+    // Override HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED format.
+    if (stream->format == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
+      stream->format = HAL_PIXEL_FORMAT_RGBA_8888;
+    }
+
+    // Max buffers as reported by the device.
+    stream->max_buffers = max_buffers;
+
+    // Usage: currently using sw graphics.
+    switch (stream->stream_type) {
+      case CAMERA3_STREAM_INPUT:
+        stream->usage = GRALLOC_USAGE_SW_READ_OFTEN;
+        break;
+      case CAMERA3_STREAM_OUTPUT:
+        stream->usage = GRALLOC_USAGE_SW_WRITE_OFTEN;
+        break;
+      case CAMERA3_STREAM_BIDIRECTIONAL:
+        stream->usage =
+            GRALLOC_USAGE_SW_READ_OFTEN | GRALLOC_USAGE_SW_WRITE_OFTEN;
+        break;
+      default:
+        // nothing to do.
+        break;
+    }
+
+    // Doesn't matter what was requested, we always use dataspace V0_JFIF.
+    // Note: according to camera3.h, this isn't allowed, but the camera
+    // framework team claims it's underdocumented; the implementation lets the
+    // HAL overwrite it. If this is changed, change the validation above.
+    stream->data_space = HAL_DATASPACE_V0_JFIF;
+  }
+    // Make sure the stream is on (no effect if already on).
+    res = device_->StreamOn();
+    if (res) {
+      HAL_LOGE("Device failed to turn on stream, res=%d", res);
+      // Don't really want to send an error for only the request here,
+      // since this is a full device error.
+      // TODO: Should trigger full flush.
+      return -ENODEV;
+    }
+    res = initDevice();
+    if (res != 0) {
+        HAL_LOGE("Failed to init device res=%d!", res);
+        return res;
+    }
+
+  return 0;
+}
+
+bool V4L2Camera::isValidRequestSettings(
+    const android::CameraMetadata& settings) {
+  if (!metadata_->IsValidRequest(settings)) {
+    HAL_LOGE("Invalid request metadata->");
+    return false;
+  }
+  return true;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_camera.h b/hardware/ntimespace/camera/v4l2_camera.h
new file mode 100644
index 0000000000..f27841281f
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera.h
@@ -0,0 +1,120 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Loosely based on hardware/libhardware/modules/camera/ExampleCamera.h
+
+#ifndef V4L2_CAMERA_HAL_V4L2_CAMERA_H_
+#define V4L2_CAMERA_HAL_V4L2_CAMERA_H_
+
+#include <array>
+#include <condition_variable>
+#include <queue>
+#include <string>
+
+//#include <camera/CameraMetadata.h>
+#include <utils/StrongPointer.h>
+#include <utils/Thread.h>
+#include "camera.h"
+#include "common.h"
+#include "metadata/metadata.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+// V4L2Camera is a specific V4L2-supported camera device. The Camera object
+// contains all logic common between all cameras (e.g. front and back cameras),
+// while a specific camera device (e.g. V4L2Camera) holds all specific
+// metadata and logic about that device.
+class V4L2Camera : public default_camera_hal::Camera {
+ public:
+  // Use this method to create V4L2Camera objects. Functionally equivalent
+  // to "new V4L2Camera", except that it may return nullptr in case of failure.
+  static V4L2Camera* NewV4L2Camera(int id, const std::string path);
+  ~V4L2Camera();
+
+ private:
+  // Constructor private to allow failing on bad input.
+  // Use NewV4L2Camera instead.
+  V4L2Camera(int id,
+             std::shared_ptr<V4L2Wrapper> v4l2_wrapper,
+             std::unique_ptr<Metadata> metadata);
+
+  // default_camera_hal::Camera virtual methods.
+  // Connect to the device: open dev nodes, etc.
+  int connect() override;
+  // Disconnect from the device: close dev nodes, etc.
+  void disconnect() override;
+  // Initialize static camera characteristics for individual device.
+  int initStaticInfo(android::CameraMetadata* out) override;
+  // Initialize a template of the given type.
+  int initTemplate(int type, android::CameraMetadata* out) override;
+  // Initialize device info: resource cost and conflicting devices
+  // (/conflicting devices length).
+  void initDeviceInfo(camera_info_t* info) override;
+  // Extra initialization of device when opened.
+  int initDevice() override;
+  int StopQueue();
+  // Verify stream configuration dataspaces and rotation values
+  bool validateDataspacesAndRotations(
+      const camera3_stream_configuration_t* stream_config) override;
+  // Set up the streams, including seting usage & max_buffers
+  int setupStreams(camera3_stream_configuration_t* stream_config) override;
+  // Verify settings are valid for a capture or reprocessing.
+  bool isValidRequestSettings(const android::CameraMetadata& settings) override;
+  // Enqueue a request to receive data from the camera.
+  int enqueueRequest(
+      std::shared_ptr<default_camera_hal::CaptureRequest> request) override;
+  // Flush in flight buffers.
+  int flushBuffers() override;
+  int GetStreamStatus() override {return device_->get_stream_status();}
+
+  int UpdateVendorStaticInfo(android::CameraMetadata* metadata);
+  
+  // Async request processing helpers.
+  // Dequeue a request from the waiting queue.
+  // Blocks until a request is available.
+  std::shared_ptr<default_camera_hal::CaptureRequest> dequeueRequest();
+
+  // Thread functions. Return true to loop, false to exit.
+  // Pass buffers for enqueued requests to the device.
+  bool enqueueRequestBuffers();
+  // Retreive buffers from the device.
+  bool dequeueRequestBuffers();
+
+  bool unitTest();
+
+  // V4L2 helper.
+  std::shared_ptr<V4L2Wrapper> device_;
+  std::unique_ptr<V4L2Wrapper::Connection> connection_;
+  std::unique_ptr<Metadata> metadata_;
+  std::mutex request_queue_lock_;
+  std::queue<std::shared_ptr<default_camera_hal::CaptureRequest>>
+      request_queue_;
+  // Threads require holding an Android strong pointer.
+  android::sp<android::Thread> buffer_enqueuer_;
+  android::sp<android::Thread> buffer_dequeuer_;
+  std::condition_variable requests_available_;
+
+  android::sp<android::Thread> unit_tester_;
+
+  int32_t max_input_streams_;
+  std::array<int, 3> max_output_streams_;  // {raw, non-stalling, stalling}.
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2Camera);
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_CAMERA_H_
diff --git a/hardware/ntimespace/camera/v4l2_camera_hal.cpp b/hardware/ntimespace/camera/v4l2_camera_hal.cpp
new file mode 100644
index 0000000000..f73282d2db
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera_hal.cpp
@@ -0,0 +1,345 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/CameraHAL.cpp
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2CameraHAL"
+
+#include "hardware/camera3.h"
+#include "v4l2_camera_hal.h"
+
+#include <dirent.h>
+#include <fcntl.h>
+#include <linux/videodev2.h>
+#include <sys/ioctl.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include <unistd.h>
+#include <algorithm>
+#include <cstdlib>
+#include <unordered_set>
+#include <android-base/parseint.h>
+#include "common.h"
+#include "v4l2_camera.h"
+#include "flash.h"
+#include "arc/cached_frame.h"
+#include <cutils/properties.h>
+
+/*
+ * This file serves as the entry point to the HAL. It is modified from the
+ * example default HAL available in hardware/libhardware/modules/camera.
+ * It contains the module structure and functions used by the framework
+ * to load and interface to this HAL, as well as the handles to the individual
+ * camera devices.
+ */
+
+namespace v4l2_camera_hal {
+
+// Default global camera hal.
+static V4L2CameraHAL gCameraHAL;
+int ion_fd = -1;
+bool using_hw;
+
+void open_ion() {
+  if (ion_fd < 0) {
+    ion_fd = open("/dev/ion", O_RDONLY | O_CLOEXEC);
+    if (ion_fd < 0) {
+      LOGF(ERROR) << "open /dev/ion failed!"; 
+      return;
+    }   
+  }
+}
+
+void close_ion() {
+  if (ion_fd > 0) {
+    close(ion_fd);
+    ion_fd = -1;
+  }
+}
+
+void check_convert_mode() {
+  using_hw = false;
+  char value[PROPERTY_VALUE_MAX];
+  if (property_get("camera.debug.convert_mode", value, "hw") && !strcmp("hw", value)) {
+    using_hw = true;
+  }
+}
+
+V4L2CameraHAL::V4L2CameraHAL() : mCameras(), mCallbacks(NULL) {
+  HAL_LOG_ENTER();
+
+  const char kDateTime[] = __DATE__ " " __TIME__ " PST";
+  HAL_LOGE("v4l2 camera hal built time %s", kDateTime);
+
+  // Adds all available V4L2 devices.
+  // List /dev nodes.
+  DIR* dir = opendir("/dev");
+  if (dir == NULL) {
+    HAL_LOGE("Failed to open /dev");
+    return;
+  }
+  // Find /dev/camera* nodes.
+  std::vector<std::string> nodes;
+  std::string desired = "/dev/camera";
+  std::string path = "";
+  for (int i = 0; i < MAX_NODE; i++)
+  {
+    path = desired + std::to_string(i);
+    if (access(path.c_str(), F_OK|R_OK|W_OK) == 0)
+    {
+        nodes.push_back(path);
+        HAL_LOGD("Found video node %s.", nodes.back().c_str());    
+    }
+  }
+
+  // Test each for V4L2 support and uniqueness.
+  std::unordered_set<std::string> buses;
+  std::string bus;
+  v4l2_capability cap;
+  int fd;
+  int id = 0;
+  for (const auto& node : nodes) {
+    HAL_LOGE("Try to open %s ", node.c_str());
+    // Open the node.
+    fd = TEMP_FAILURE_RETRY(open(node.c_str(), O_RDONLY));
+    if (fd < 0) {
+      HAL_LOGE("failed to open %s (%s).", node.c_str(), strerror(errno));
+      continue;
+    }
+    // Read V4L2 capabilities.
+    if (TEMP_FAILURE_RETRY(ioctl(fd, VIDIOC_QUERYCAP, &cap)) != 0) {
+      HAL_LOGE(
+          "VIDIOC_QUERYCAP on %s fail: %s.", node.c_str(), strerror(errno));
+    } else if (!(cap.capabilities & V4L2_CAP_VIDEO_CAPTURE)) {
+      HAL_LOGE("%s is not a V4L2 video capture device.", node.c_str());
+    } else {
+      // If the node is unique, add a camera for it.
+      bus = reinterpret_cast<char*>(cap.bus_info);
+      /*if (buses.insert(bus).second) */{
+        HAL_LOGD("Found unique bus at %s.", node.c_str());
+        std::unique_ptr<V4L2Camera> cam(V4L2Camera::NewV4L2Camera(id++, node));
+        if (cam) {
+          HAL_LOGD("Add camera %s with id %d.", node.c_str(), id - 1);
+          mCameras.push_back(std::move(cam));
+        } else {
+          HAL_LOGE("Failed to initialize camera at %s.", node.c_str());
+        }
+      }
+    }
+    close(fd);
+  }
+
+  open_ion();
+  check_convert_mode();
+  HAL_LOG_EXIT();
+}
+
+V4L2CameraHAL::~V4L2CameraHAL() {
+  HAL_LOG_ENTER();
+  close_ion();
+}
+
+int V4L2CameraHAL::getNumberOfCameras() {
+  HAL_LOGD("returns %zu", mCameras.size());
+  return mCameras.size();
+}
+
+int V4L2CameraHAL::getCameraInfo(int id, camera_info_t* info) {
+  HAL_LOG_ENTER();
+  if (id < 0 || static_cast<size_t>(id) >= mCameras.size()) {
+    return -EINVAL;
+  }
+  // TODO(b/29185945): Hotplugging: return -EINVAL if unplugged.
+  return mCameras[id]->getInfo(info);
+}
+
+int V4L2CameraHAL::setCallbacks(const camera_module_callbacks_t* callbacks) {
+  HAL_LOG_ENTER();
+  mCallbacks = callbacks;
+  return 0;
+}
+
+void V4L2CameraHAL::getVendorTagOps(vendor_tag_ops_t* /*ops*/) {
+  HAL_LOG_ENTER();
+  // No vendor ops for this HAL. From <hardware/camera_common.h>:
+  // "leave ops unchanged if no vendor tags are defined."
+}
+
+int V4L2CameraHAL::openLegacy(const hw_module_t* /*module*/,
+                              const char* id,
+                              uint32_t halVersion,
+                              hw_device_t** /*device*/) {
+  HAL_LOG_ENTER();
+
+  HAL_LOGI("openLegacy halVersion: %d cameraId = %s", halVersion, id);
+
+  // Not supported.
+  return -EINVAL;
+}
+
+int V4L2CameraHAL::setTorchMode(const char* camera_id, bool on) {
+  HAL_LOG_ENTER();
+
+#if SUPPORT_FLASH
+  int retVal(0);
+  long cameraIdLong(-1);
+  int cameraIdInt(-1);
+  char* endPointer = NULL;
+  errno = 0;
+  qcamera::CameraFlash& flash = qcamera::CameraFlash::getInstance();
+
+  cameraIdLong = strtol(camera_id, &endPointer, 10);
+
+  if ((errno == ERANGE) ||
+          (cameraIdLong < 0) ||
+          (cameraIdLong >= static_cast<long>(getNumberOfCameras())) ||
+          (endPointer == camera_id) ||
+          (*endPointer != '\0')) {
+      retVal = -EINVAL;
+  } else if (on) {
+      cameraIdInt = static_cast<int>(cameraIdLong);
+      retVal = flash.initFlash(cameraIdInt);
+
+      if (retVal == 0) {
+          retVal = flash.setFlashMode(cameraIdInt, on);
+          if ((retVal == 0) && (mCallbacks != NULL)) {
+              mCallbacks->torch_mode_status_change(mCallbacks,
+                      camera_id,
+                      TORCH_MODE_STATUS_AVAILABLE_ON);
+          } else if (retVal == -EALREADY) {
+              // Flash is already on, so treat this as a success.
+              retVal = 0;
+          }
+      }
+  } else {
+      cameraIdInt = static_cast<int>(cameraIdLong);
+      retVal = flash.setFlashMode(cameraIdInt, on);
+
+      if (retVal == 0) {
+          retVal = flash.deinitFlash(cameraIdInt);
+          if ((retVal == 0) && (mCallbacks != NULL)) {
+              mCallbacks->torch_mode_status_change(mCallbacks,
+                      camera_id,
+                      TORCH_MODE_STATUS_AVAILABLE_OFF);
+          }
+      } else if (retVal == -EALREADY) {
+          // Flash is already off, so treat this as a success.
+          retVal = 0;
+      }
+  }
+
+  return retVal;
+#else 
+  (void)camera_id;
+  (void)on;
+  return -ENOSYS;
+#endif  
+}
+
+int V4L2CameraHAL::openDevice(const hw_module_t* module,
+                              const char* name,
+                              hw_device_t** device) {
+  HAL_LOG_ENTER();
+
+  if (module != &HAL_MODULE_INFO_SYM.common) {
+    HAL_LOGE(
+        "Invalid module %p expected %p", module, &HAL_MODULE_INFO_SYM.common);
+    return -EINVAL;
+  }
+
+  int id;
+  if (!android::base::ParseInt(name, &id, 0, getNumberOfCameras() - 1)) {
+    return -EINVAL;
+  }
+
+#if SUPPORT_FLASH
+  int rc = qcamera::CameraFlash::getInstance().reserveFlashForCamera(id);
+  if (rc < 0) {
+      HAL_LOGE("Failed to reserve flash for camera id: %d", id);
+      //return -EINVAL;
+  }
+#endif
+
+  // TODO(b/29185945): Hotplugging: return -EINVAL if unplugged.
+  return mCameras[id]->openDevice(module, device);
+}
+
+/*
+ * The framework calls the following wrappers, which in turn
+ * call the corresponding methods of the global HAL object.
+ */
+
+static int get_number_of_cameras() {
+  return gCameraHAL.getNumberOfCameras();
+}
+
+static int get_camera_info(int id, struct camera_info* info) {
+  return gCameraHAL.getCameraInfo(id, info);
+}
+
+static int set_callbacks(const camera_module_callbacks_t* callbacks) {
+  return gCameraHAL.setCallbacks(callbacks);
+}
+
+static void get_vendor_tag_ops(vendor_tag_ops_t* ops) {
+  return gCameraHAL.getVendorTagOps(ops);
+}
+
+static int open_legacy(const hw_module_t* module,
+                       const char* id,
+                       uint32_t halVersion,
+                       hw_device_t** device) {
+  return gCameraHAL.openLegacy(module, id, halVersion, device);
+}
+
+static int set_torch_mode(const char* camera_id, bool enabled) {
+  return gCameraHAL.setTorchMode(camera_id, enabled);
+}
+
+static int open_dev(const hw_module_t* module,
+                    const char* name,
+                    hw_device_t** device) {
+  return gCameraHAL.openDevice(module, name, device);
+}
+
+}  // namespace v4l2_camera_hal
+
+static hw_module_methods_t v4l2_module_methods = {
+    .open = v4l2_camera_hal::open_dev};
+
+camera_module_t HAL_MODULE_INFO_SYM __attribute__((visibility("default"))) = {
+    .common =
+        {
+            .tag = HARDWARE_MODULE_TAG,
+            .module_api_version = CAMERA_MODULE_API_VERSION_2_4,
+            .hal_api_version = HARDWARE_HAL_API_VERSION,
+            .id = CAMERA_HARDWARE_MODULE_ID,
+            .name = "V4L2 Camera HAL v3",
+            .author = "The Android Open Source Project",
+            .methods = &v4l2_module_methods,
+            .dso = nullptr,
+            .reserved = {0},
+        },
+    .get_number_of_cameras = v4l2_camera_hal::get_number_of_cameras,
+    .get_camera_info = v4l2_camera_hal::get_camera_info,
+    .set_callbacks = v4l2_camera_hal::set_callbacks,
+    .get_vendor_tag_ops = v4l2_camera_hal::get_vendor_tag_ops,
+    .open_legacy = v4l2_camera_hal::open_legacy,
+    .set_torch_mode = v4l2_camera_hal::set_torch_mode,
+    .init = nullptr,
+//    .get_physical_camera_info = nullptr,
+    .reserved = {nullptr, nullptr}};
diff --git a/hardware/ntimespace/camera/v4l2_camera_hal.h b/hardware/ntimespace/camera/v4l2_camera_hal.h
new file mode 100644
index 0000000000..b99b627b7b
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_camera_hal.h
@@ -0,0 +1,74 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Modified from hardware/libhardware/modules/camera/CameraHAL.h
+
+#ifndef V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
+#define V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
+
+#include <vector>
+
+#include <hardware/camera_common.h>
+#include <hardware/hardware.h>
+
+#include "camera.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+/*
+ * V4L2CameraHAL contains all module state that isn't specific to an
+ * individual camera device. This class is based off of the sample
+ * default CameraHAL from /hardware/libhardware/modules/camera.
+ */
+class V4L2CameraHAL {
+ public:
+  V4L2CameraHAL();
+  ~V4L2CameraHAL();
+
+  // Camera Module Interface (see <hardware/camera_common.h>).
+  int getNumberOfCameras();
+  int getCameraInfo(int camera_id, camera_info_t* info);
+  int setCallbacks(const camera_module_callbacks_t* callbacks);
+  void getVendorTagOps(vendor_tag_ops_t* ops);
+  int openLegacy(const hw_module_t* module,
+                 const char* id,
+                 uint32_t halVersion,
+                 hw_device_t** device);
+  int setTorchMode(const char* camera_id, bool on);
+
+  // Hardware Module Interface (see <hardware/hardware.h>).
+  int openDevice(const hw_module_t* mod, const char* name, hw_device_t** dev);
+
+ private:
+  // Vector of cameras.
+  std::vector<std::unique_ptr<default_camera_hal::Camera>> mCameras;
+  // Callback handle.
+  const camera_module_callbacks_t* mCallbacks;
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2CameraHAL);
+};
+
+extern int ion_fd;
+extern bool using_hw;
+}  // namespace v4l2_camera_hal
+
+extern camera_module_t HAL_MODULE_INFO_SYM;
+
+
+#define MAX_NODE 2
+#define MM_CAMERA_MAX_NUM_SENSORS MAX_NODE
+
+#endif  // V4L2_CAMERA_HAL_V4L2_CAMERA_HAL_H_
diff --git a/hardware/ntimespace/camera/v4l2_metadata_factory.cpp b/hardware/ntimespace/camera/v4l2_metadata_factory.cpp
new file mode 100644
index 0000000000..6f3f49245e
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_metadata_factory.cpp
@@ -0,0 +1,601 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2MetadataFactory"
+
+#include "v4l2_metadata_factory.h"
+
+#include "metadata/camera_metadata.h"
+#include "common.h"
+#include "format_metadata_factory.h"
+#include "metadata/boottime_state_delegate.h"
+#include "metadata/control.h"
+#include "metadata/enum_converter.h"
+#include "metadata/partial_metadata_factory.h"
+#include "metadata/property.h"
+#include "metadata/scaling_converter.h"
+#include "flash.h"
+
+namespace v4l2_camera_hal {
+
+// According to spec, each unit of V4L2_CID_AUTO_EXPOSURE_BIAS is 0.001 EV.
+//const camera_metadata_rational_t kAeCompensationUnit = {1, 1000};
+// According to spec, each unit of V4L2_CID_EXPOSURE_ABSOLUTE is 100 us.
+const int64_t kV4L2ExposureTimeStepNs = 100000;
+// According to spec, each unit of V4L2_CID_ISO_SENSITIVITY is ISO/1000.
+const int32_t kV4L2SensitivityDenominator = 1000;
+// Generously allow up to 6MB (the largest size on the RPi Camera is about 5MB).
+const size_t kV4L2MaxJpegSize = 6000000;
+
+int GetV4L2Metadata(std::shared_ptr<V4L2Wrapper> device,
+                    std::unique_ptr<Metadata>* result) {
+  HAL_LOG_ENTER();
+
+  // Open a temporary connection to the device for all the V4L2 querying
+  // that will be happening (this could be done for each component individually,
+  // but doing it here prevents connecting and disconnecting for each one).
+  V4L2Wrapper::Connection temp_connection = V4L2Wrapper::Connection(device);
+  if (temp_connection.status()) {
+    HAL_LOGE("Failed to connect to device: %d.", temp_connection.status());
+    return temp_connection.status();
+  }
+
+  //return 0;
+  // TODO(b/30035628): Add states.
+
+  PartialMetadataSet components;
+
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_COLOR_CORRECTION_ABERRATION_MODE,
+      ANDROID_COLOR_CORRECTION_AVAILABLE_ABERRATION_MODES,
+      {ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST,
+       ANDROID_COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_COLOR_CORRECTION_ABERRATION_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_COLOR_CORRECTION_ABERRATION_MODE_FAST}}));
+
+#if 0
+  // TODO(b/30510395): subcomponents of 3A.
+  // In general, default to ON/AUTO since they imply pretty much nothing,
+  // while OFF implies guarantees about not hindering performance.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 3>>(ANDROID_CONTROL_MAX_REGIONS,
+                                           {{/*AE*/ 0, /*AWB*/ 0, /*AF*/ 0}})));
+#endif
+#if 0
+  // TODO(b/30921166): V4L2_CID_AUTO_EXPOSURE_BIAS is an int menu, so
+  // this will be falling back to NoEffect until int menu support is added.
+  components.insert(V4L2ControlOrDefault<int32_t>(
+      ControlType::kSlider,
+      ANDROID_CONTROL_AE_EXPOSURE_COMPENSATION,
+      ANDROID_CONTROL_AE_COMPENSATION_RANGE,
+      device,
+      V4L2_CID_AUTO_EXPOSURE_BIAS,
+      // No scaling necessary, AE_COMPENSATION_STEP handles this.
+      std::make_shared<ScalingConverter<int32_t, int32_t>>(1, 1),
+      0,
+      {{OTHER_TEMPLATES, 0}}));
+#endif
+#if 0
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<camera_metadata_rational_t>(
+          ANDROID_CONTROL_AE_COMPENSATION_STEP, kAeCompensationUnit)));
+#endif
+#if 0
+  // TODO(b/31021522): Autofocus subcomponent.
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AF_MODE,
+                                   ANDROID_CONTROL_AF_AVAILABLE_MODES,
+                                   {ANDROID_CONTROL_AF_MODE_OFF}));
+#endif
+  // TODO(b/31021522): Should read autofocus state from
+  // V4L2_CID_AUTO_FOCUS_STATUS bitmask. The framework gets a little more
+  // complex than that does; there's a whole state-machine table in
+  // the docs (system/media/camera/docs/docs.html).
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AF_STATE,
+                                        ANDROID_CONTROL_AF_STATE_INACTIVE));
+  // TODO(b/31022735): Correctly implement AE & AF triggers that
+  // actually do something. These no effect triggers are even worse than most
+  // of the useless controls in this class, since technically they should
+  // revert back to IDLE eventually after START/CANCEL, but for now they won't
+  // unless IDLE is requested.
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AF_TRIGGER,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AF_TRIGGER_IDLE,
+                                    ANDROID_CONTROL_AF_TRIGGER_START,
+                                    ANDROID_CONTROL_AF_TRIGGER_CANCEL}));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER,
+      DO_NOT_REPORT_OPTIONS,
+      {ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_IDLE,
+       ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_START,
+       ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER_CANCEL}));
+#if 0
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AE_ANTIBANDING_MODE,
+      ANDROID_CONTROL_AE_AVAILABLE_ANTIBANDING_MODES,
+      device,
+      V4L2_CID_POWER_LINE_FREQUENCY,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+          new EnumConverter({{V4L2_CID_POWER_LINE_FREQUENCY_DISABLED,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_50HZ,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_50HZ},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_60HZ,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_60HZ},
+                             {V4L2_CID_POWER_LINE_FREQUENCY_AUTO,
+                              ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO}})),
+      ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO,
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AE_ANTIBANDING_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AE_ANTIBANDING_MODE_AUTO}}));
+#endif
+  std::unique_ptr<PartialMetadataInterface> exposure_time =
+      V4L2Control<int64_t>(ControlType::kSlider,
+                           ANDROID_SENSOR_EXPOSURE_TIME,
+                           ANDROID_SENSOR_INFO_EXPOSURE_TIME_RANGE,
+                           device,
+                           V4L2_CID_EXPOSURE_ABSOLUTE,
+                           std::make_shared<ScalingConverter<int64_t, int32_t>>(
+                               kV4L2ExposureTimeStepNs, 1));
+  // TODO(b/31037072): Sensitivity has additional V4L2 controls
+  // (V4L2_CID_ISO_SENSITIVITY_AUTO), so this control currently has
+  // undefined behavior.
+  // TODO(b/30921166): V4L2_CID_ISO_SENSITIVITY is an int menu, so
+  // this will return nullptr until that is added.
+  std::unique_ptr<PartialMetadataInterface> sensitivity =
+      V4L2Control<int32_t>(ControlType::kSlider,
+                           ANDROID_SENSOR_SENSITIVITY,
+                           ANDROID_SENSOR_INFO_SENSITIVITY_RANGE,
+                           device,
+                           V4L2_CID_ISO_SENSITIVITY,
+                           std::make_shared<ScalingConverter<int32_t, int32_t>>(
+                               1, kV4L2SensitivityDenominator));
+  std::multimap<int32_t, uint8_t> ae_mode_mapping = {
+      {V4L2_EXPOSURE_AUTO, ANDROID_CONTROL_AE_MODE_ON}};
+  if (exposure_time && sensitivity) {
+    // TODO(b/30510395): as part of coordinated 3A component,
+    // if these aren't available don't advertise AE mode OFF, only AUTO.
+    components.insert(std::move(exposure_time));
+    components.insert(std::move(sensitivity));
+    ae_mode_mapping.emplace(V4L2_EXPOSURE_MANUAL, ANDROID_CONTROL_AE_MODE_OFF);
+  }
+#if 0
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AE_MODE,
+      ANDROID_CONTROL_AE_AVAILABLE_MODES,
+      device,
+      V4L2_CID_EXPOSURE_AUTO,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+          new EnumConverter(ae_mode_mapping)),
+      ANDROID_CONTROL_AE_MODE_ON,
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AE_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AE_MODE_ON}}));
+#endif
+  // Can't get AE status from V4L2.
+  // TODO(b/30510395): If AE mode is OFF, this should switch to INACTIVE.
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AE_STATE,
+                                        ANDROID_CONTROL_AE_STATE_CONVERGED));
+  // V4L2 offers multiple white balance interfaces. Try the advanced one before
+  // falling
+  // back to the simpler version.
+  // Modes from each API that don't match up:
+  // Android: WARM_FLUORESCENT, TWILIGHT.
+  // V4L2: FLUORESCENT_H, HORIZON, FLASH.
+  std::unique_ptr<PartialMetadataInterface> awb(V4L2Control<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_AWB_MODE,
+      ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+      device,
+      V4L2_CID_AUTO_N_PRESET_WHITE_BALANCE,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_WHITE_BALANCE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+           {V4L2_WHITE_BALANCE_AUTO, ANDROID_CONTROL_AWB_MODE_AUTO},
+           {V4L2_WHITE_BALANCE_INCANDESCENT,
+            ANDROID_CONTROL_AWB_MODE_INCANDESCENT},
+           {V4L2_WHITE_BALANCE_FLUORESCENT,
+            ANDROID_CONTROL_AWB_MODE_FLUORESCENT},
+           {V4L2_WHITE_BALANCE_DAYLIGHT, ANDROID_CONTROL_AWB_MODE_DAYLIGHT},
+           {V4L2_WHITE_BALANCE_CLOUDY,
+            ANDROID_CONTROL_AWB_MODE_CLOUDY_DAYLIGHT},
+           {V4L2_WHITE_BALANCE_SHADE, ANDROID_CONTROL_AWB_MODE_SHADE}})),
+      {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_AWB_MODE_AUTO}}));
+  if (awb) {
+    components.insert(std::move(awb));
+  } else {
+    // Fall back to simpler AWB or even just an ignored control.
+    components.insert(V4L2ControlOrDefault<uint8_t>(
+        ControlType::kMenu,
+        ANDROID_CONTROL_AWB_MODE,
+        ANDROID_CONTROL_AWB_AVAILABLE_MODES,
+        device,
+        V4L2_CID_AUTO_WHITE_BALANCE,
+        std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(
+            new EnumConverter({{0, ANDROID_CONTROL_AWB_MODE_OFF},
+                               {1, ANDROID_CONTROL_AWB_MODE_AUTO}})),
+        ANDROID_CONTROL_AWB_MODE_AUTO,
+        {{CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_AWB_MODE_OFF},
+         {OTHER_TEMPLATES, ANDROID_CONTROL_AWB_MODE_AUTO}}));
+  }
+  // TODO(b/31041577): Handle AWB state machine correctly.
+  components.insert(FixedState<uint8_t>(ANDROID_CONTROL_AWB_STATE,
+                                        ANDROID_CONTROL_AWB_STATE_CONVERGED));
+  // TODO(b/31022153): 3A locks.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_CONTROL_AE_LOCK_AVAILABLE,
+                            ANDROID_CONTROL_AE_LOCK_AVAILABLE_FALSE)));
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AE_LOCK,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AE_LOCK_OFF, ANDROID_CONTROL_AE_LOCK_ON}));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_CONTROL_AWB_LOCK_AVAILABLE,
+                            ANDROID_CONTROL_AWB_LOCK_AVAILABLE_TRUE)));
+  components.insert(
+      NoEffectMenuControl<uint8_t>(ANDROID_CONTROL_AWB_LOCK,
+                                   DO_NOT_REPORT_OPTIONS,
+                                   {ANDROID_CONTROL_AWB_LOCK_OFF}));
+  // TODO(b/30510395): subcomponents of scene modes
+  // (may itself be a subcomponent of 3A).
+  // Modes from each API that don't match up:
+  // Android: FACE_PRIORITY, ACTION, NIGHT_PORTRAIT, THEATRE, STEADYPHOTO,
+  // BARCODE, HIGH_SPEED_VIDEO.
+  // V4L2: BACKLIGHT, DAWN_DUSK, FALL_COLORS, TEXT.
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_SCENE_MODE,
+      ANDROID_CONTROL_AVAILABLE_SCENE_MODES,
+      device,
+      V4L2_CID_SCENE_MODE,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_SCENE_MODE_NONE, ANDROID_CONTROL_SCENE_MODE_DISABLED},
+           {V4L2_SCENE_MODE_BEACH_SNOW, ANDROID_CONTROL_SCENE_MODE_BEACH},
+           {V4L2_SCENE_MODE_BEACH_SNOW, ANDROID_CONTROL_SCENE_MODE_SNOW},
+           {V4L2_SCENE_MODE_CANDLE_LIGHT,
+            ANDROID_CONTROL_SCENE_MODE_CANDLELIGHT},
+           {V4L2_SCENE_MODE_FIREWORKS, ANDROID_CONTROL_SCENE_MODE_FIREWORKS},
+           {V4L2_SCENE_MODE_LANDSCAPE, ANDROID_CONTROL_SCENE_MODE_LANDSCAPE},
+           {V4L2_SCENE_MODE_NIGHT, ANDROID_CONTROL_SCENE_MODE_NIGHT},
+           {V4L2_SCENE_MODE_PARTY_INDOOR, ANDROID_CONTROL_SCENE_MODE_PARTY},
+           {V4L2_SCENE_MODE_SPORTS, ANDROID_CONTROL_SCENE_MODE_SPORTS},
+           {V4L2_SCENE_MODE_SUNSET, ANDROID_CONTROL_SCENE_MODE_SUNSET}})),
+      ANDROID_CONTROL_SCENE_MODE_DISABLED));
+#if 0
+  // TODO(b/31022612): Scene mode overrides.
+  // Modes from each API that don't match up:
+  // Android: POSTERIZE, WHITEBOARD, BLACKBOARD.
+  // V4L2: ANTIQUE, ART_FREEZE, EMBOSS, GRASS_GREEN, SKETCH, SKIN_WHITEN,
+  // SKY_BLUE, SILHOUETTE, VIVID, SET_CBCR.
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_EFFECT_MODE,
+      ANDROID_CONTROL_AVAILABLE_EFFECTS,
+      device,
+      V4L2_CID_COLORFX,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{V4L2_COLORFX_NONE, ANDROID_CONTROL_EFFECT_MODE_OFF},
+           {V4L2_COLORFX_BW, ANDROID_CONTROL_EFFECT_MODE_MONO},
+           {V4L2_COLORFX_NEGATIVE, ANDROID_CONTROL_EFFECT_MODE_NEGATIVE},
+           {V4L2_COLORFX_SOLARIZATION, ANDROID_CONTROL_EFFECT_MODE_SOLARIZE},
+           {V4L2_COLORFX_SEPIA, ANDROID_CONTROL_EFFECT_MODE_SEPIA},
+           {V4L2_COLORFX_AQUA, ANDROID_CONTROL_EFFECT_MODE_AQUA}})),
+      ANDROID_CONTROL_EFFECT_MODE_OFF));
+#endif
+  // TODO(b/31021654): This should behave as a top level switch, not no effect.
+  // Should enforce being set to USE_SCENE_MODE when a scene mode is requested.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_MODE,
+      ANDROID_CONTROL_AVAILABLE_MODES,
+      {ANDROID_CONTROL_MODE_AUTO, ANDROID_CONTROL_MODE_USE_SCENE_MODE}));
+
+  // Not sure if V4L2 does or doesn't do this, but HAL documentation says
+  // all devices must support FAST, and FAST can be equivalent to OFF, so
+  // either way it's fine to list. And if FAST is included, HIGH_QUALITY
+  // is supposed to be included as well.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_EDGE_MODE,
+      ANDROID_EDGE_AVAILABLE_EDGE_MODES,
+      {ANDROID_EDGE_MODE_FAST, ANDROID_EDGE_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE, ANDROID_EDGE_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_EDGE_MODE_FAST}}));
+
+#if SUPPORT_FLASH
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_FLASH_INFO_AVAILABLE, ANDROID_FLASH_INFO_AVAILABLE_TRUE)));
+  components.insert(FixedState<uint8_t>(ANDROID_FLASH_STATE,
+                                        ANDROID_FLASH_STATE_UNAVAILABLE));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_FLASH_MODE, DO_NOT_REPORT_OPTIONS, {ANDROID_FLASH_MODE_OFF}));
+#else
+  // TODO(b/31023454): subcomponents of flash.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_FLASH_INFO_AVAILABLE, ANDROID_FLASH_INFO_AVAILABLE_FALSE)));
+  components.insert(FixedState<uint8_t>(ANDROID_FLASH_STATE,
+                                        ANDROID_FLASH_STATE_UNAVAILABLE));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_FLASH_MODE, DO_NOT_REPORT_OPTIONS, {ANDROID_FLASH_MODE_OFF}));
+#endif
+
+  // TODO(30510395): subcomponents of hotpixel.
+  // No known V4L2 hot pixel correction. But it might be happening,
+  // so we report FAST/HIGH_QUALITY.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_HOT_PIXEL_MODE,
+      ANDROID_HOT_PIXEL_AVAILABLE_HOT_PIXEL_MODES,
+      {ANDROID_HOT_PIXEL_MODE_FAST, ANDROID_HOT_PIXEL_MODE_HIGH_QUALITY}));
+  // ON only needs to be supported for RAW capable devices.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_HOT_PIXEL_MAP_MODES,
+      {ANDROID_STATISTICS_HOT_PIXEL_MAP_MODE_OFF}));
+
+  // TODO(30510395): subcomponents focus/lens.
+  // No way to actually get the aperture and focal length
+  // in V4L2, but they're required keys, so fake them.
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_APERTURE,
+                                 ANDROID_LENS_INFO_AVAILABLE_APERTURES,
+                                 {2.0}));  // RPi camera v2 is f/2.0.
+  // Always assume external-facing.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_LENS_FACING, ANDROID_LENS_FACING_EXTERNAL)));
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FOCAL_LENGTH,
+                                 ANDROID_LENS_INFO_AVAILABLE_FOCAL_LENGTHS,
+                                 {3.04}));  // RPi camera v2 is 3.04mm.
+  // No known way to get filter densities from V4L2,
+  // report 0 to indicate this control is not supported.
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FILTER_DENSITY,
+                                 ANDROID_LENS_INFO_AVAILABLE_FILTER_DENSITIES,
+                                 {0.0}));
+  // V4L2 focal units do not correspond to a particular physical unit.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<uint8_t>(
+          ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION,
+          ANDROID_LENS_INFO_FOCUS_DISTANCE_CALIBRATION_UNCALIBRATED)));
+  // TODO(b/31022711): Focus distance component.
+  // Using a NoEffectMenuControl for now because for
+  // fixed-focus it meets expectations. Framework may allow
+  // setting any value and expect it to be clamped to 0, in which
+  // case this will have unexpected behavior (failing on non-0 settings).
+  components.insert(
+      NoEffectMenuControl<float>(ANDROID_LENS_FOCUS_DISTANCE,
+                                 ANDROID_LENS_INFO_MINIMUM_FOCUS_DISTANCE,
+                                 {0}));
+  // Hypefocal distance doesn't mean much for a fixed-focus uncalibrated device.
+  components.insert(std::make_unique<Property<float>>(
+      ANDROID_LENS_INFO_HYPERFOCAL_DISTANCE, 0));
+
+  // No way to know when the lens is moving or not in V4L2.
+  components.insert(
+      FixedState<uint8_t>(ANDROID_LENS_STATE, ANDROID_LENS_STATE_STATIONARY));
+  // No known V4L2 lens shading. But it might be happening,
+  // so report FAST/HIGH_QUALITY.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_SHADING_MODE,
+      ANDROID_SHADING_AVAILABLE_MODES,
+      {ANDROID_SHADING_MODE_FAST, ANDROID_SHADING_MODE_HIGH_QUALITY}));
+  // ON only needs to be supported for RAW capable devices.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_LENS_SHADING_MAP_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_LENS_SHADING_MAP_MODES,
+      {ANDROID_STATISTICS_LENS_SHADING_MAP_MODE_OFF}));
+  // V4L2 doesn't differentiate between OPTICAL and VIDEO stabilization,
+  // so only report one (and report the other as OFF).
+  components.insert(V4L2ControlOrDefault<uint8_t>(
+      ControlType::kMenu,
+      ANDROID_CONTROL_VIDEO_STABILIZATION_MODE,
+      ANDROID_CONTROL_AVAILABLE_VIDEO_STABILIZATION_MODES,
+      device,
+      V4L2_CID_IMAGE_STABILIZATION,
+      std::shared_ptr<ConverterInterface<uint8_t, int32_t>>(new EnumConverter(
+          {{0, ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF},
+           {1, ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_ON}})),
+      ANDROID_CONTROL_VIDEO_STABILIZATION_MODE_OFF));
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_LENS_OPTICAL_STABILIZATION_MODE,
+      ANDROID_LENS_INFO_AVAILABLE_OPTICAL_STABILIZATION,
+      {ANDROID_LENS_OPTICAL_STABILIZATION_MODE_OFF}));
+  // TODO(b/31017806): This should definitely have a different default depending
+  // on template.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_CONTROL_CAPTURE_INTENT,
+      DO_NOT_REPORT_OPTIONS,
+      {ANDROID_CONTROL_CAPTURE_INTENT_CUSTOM,
+       ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW,
+       ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE,
+       ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD,
+       ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT,
+       ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG,
+       ANDROID_CONTROL_CAPTURE_INTENT_MANUAL},
+      {{CAMERA3_TEMPLATE_PREVIEW, ANDROID_CONTROL_CAPTURE_INTENT_PREVIEW},
+       {CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_CONTROL_CAPTURE_INTENT_STILL_CAPTURE},
+      // {CAMERA3_TEMPLATE_VIDEO_RECORD,
+      //  ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_RECORD},
+     //  {CAMERA3_TEMPLATE_VIDEO_SNAPSHOT,
+     //   ANDROID_CONTROL_CAPTURE_INTENT_VIDEO_SNAPSHOT},
+     //  {CAMERA3_TEMPLATE_ZERO_SHUTTER_LAG,
+     //   ANDROID_CONTROL_CAPTURE_INTENT_ZERO_SHUTTER_LAG},
+     //  {CAMERA3_TEMPLATE_MANUAL, ANDROID_CONTROL_CAPTURE_INTENT_MANUAL},
+       {OTHER_TEMPLATES, ANDROID_CONTROL_CAPTURE_INTENT_CUSTOM}}));
+
+  // Unable to control noise reduction in V4L2 devices,
+  // but FAST is allowed to be the same as OFF,
+  // and HIGH_QUALITY can be the same as FAST.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_NOISE_REDUCTION_MODE,
+      ANDROID_NOISE_REDUCTION_AVAILABLE_NOISE_REDUCTION_MODES,
+      {ANDROID_NOISE_REDUCTION_MODE_FAST,
+       ANDROID_NOISE_REDUCTION_MODE_HIGH_QUALITY},
+      {{CAMERA3_TEMPLATE_STILL_CAPTURE,
+        ANDROID_NOISE_REDUCTION_MODE_HIGH_QUALITY},
+       {OTHER_TEMPLATES, ANDROID_NOISE_REDUCTION_MODE_FAST}}));
+
+  // TODO(30510395): subcomponents of formats/streams.
+  // For now, no thumbnails available (only [0,0], the "no thumbnail" size).
+  // TODO(b/29580107): Could end up with a mismatch between request & result,
+  // since V4L2 doesn't actually allow for thumbnail size control.
+  components.insert(NoEffectMenuControl<std::array<int32_t, 2>>(
+      ANDROID_JPEG_THUMBNAIL_SIZE,
+      ANDROID_JPEG_AVAILABLE_THUMBNAIL_SIZES,
+      {{{0, 0}}}));
+  // TODO(b/31022752): Get this from the device, not constant.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_JPEG_MAX_SIZE, kV4L2MaxJpegSize)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_JPEG_ORIENTATION, 0)));
+
+  // TODO(b/31021672): Other JPEG controls (GPS, quality, orientation).
+  // TODO(b/29939583): V4L2 can only support 1 stream at a time.
+  // For now, just reporting minimum allowable for LIMITED devices.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 3>>(
+          ANDROID_REQUEST_MAX_NUM_OUTPUT_STREAMS,
+          {{/* Raw */ 0, /* Non-stalling */ 2, /* Stalling */ 1}})));
+  // Reprocessing not supported.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_REQUEST_MAX_NUM_INPUT_STREAMS, 0)));
+  // No way to know pipeline depth for V4L2, so fake with max allowable latency.
+  // Doesn't mean much without per-frame controls anyways.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_REQUEST_PIPELINE_MAX_DEPTH, 4)));
+  components.insert(FixedState<uint8_t>(ANDROID_REQUEST_PIPELINE_DEPTH, 4));
+  // "LIMITED devices are strongly encouraged to use a non-negative value.
+  // If UNKNOWN is used here then app developers do not have a way to know
+  // when sensor settings have been applied." - Unfortunately, V4L2 doesn't
+  // really help here either. Could even be that adjusting settings mid-stream
+  // blocks in V4L2, and should be avoided.
+  components.insert(
+      std::unique_ptr<PartialMetadataInterface>(new Property<int32_t>(
+          ANDROID_SYNC_MAX_LATENCY, ANDROID_SYNC_MAX_LATENCY_UNKNOWN)));
+  // Never know when controls are synced.
+  components.insert(FixedState<int64_t>(ANDROID_SYNC_FRAME_NUMBER,
+                                        ANDROID_SYNC_FRAME_NUMBER_UNKNOWN));
+
+  // TODO(b/31022480): subcomponents of cropping/sensors.
+  // Need ANDROID_SCALER_CROP_REGION control support.
+  // V4L2 VIDIOC_CROPCAP doesn't give a way to query this;
+  // it's driver dependent. For now, assume freeform, and
+  // some cameras may just behave badly.
+  // TODO(b/29579652): Figure out a way to determine this.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<float>(ANDROID_SCALER_AVAILABLE_MAX_DIGITAL_ZOOM, 1)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_SCALER_CROPPING_TYPE,
+                            ANDROID_SCALER_CROPPING_TYPE_FREEFORM)));
+  // Spoof pixel array size for now, eventually get from CROPCAP.
+  std::array<int32_t, 2> pixel_array_size = {{3280, 2464}};
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 2>>(ANDROID_SENSOR_INFO_PIXEL_ARRAY_SIZE,
+                                           pixel_array_size)));
+  // Active array size is {x-offset, y-offset, width, height}, relative to
+  // the pixel array size, with {0, 0} being the top left. Since there's no way
+  // to get this in V4L2, assume the full pixel array is the active array.
+  std::array<int32_t, 4> active_array_size = {
+      {0, 0, pixel_array_size[0], pixel_array_size[1]}};
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<int32_t, 4>>(
+          ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE, active_array_size)));
+  // This is really more freeform than a menu control, but since we're
+  // restricting it to not being used anyways this works for now.
+  components.insert(NoEffectMenuControl<std::array<int32_t, 4>>(
+      ANDROID_SCALER_CROP_REGION, DO_NOT_REPORT_OPTIONS, {active_array_size}));
+  // No way to get in V4L2, so faked. RPi camera v2 is 3.674 x 2.760 mm.
+  // Physical size is used in framework calculations (field of view,
+  // pixel pitch, etc.), so faking it may have unexpected results.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::array<float, 2>>(ANDROID_SENSOR_INFO_PHYSICAL_SIZE,
+                                         {{3.674, 2.760}})));
+  // HAL uses BOOTTIME timestamps.
+  // TODO(b/29457051): make sure timestamps are consistent throughout the HAL.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE,
+                            ANDROID_SENSOR_INFO_TIMESTAMP_SOURCE_UNKNOWN)));
+  components.insert(std::make_unique<State<int64_t>>(
+      ANDROID_SENSOR_TIMESTAMP, std::make_unique<BoottimeStateDelegate>()));
+  // No way to actually get shutter skew from V4L2.
+  components.insert(
+      FixedState<int64_t>(ANDROID_SENSOR_ROLLING_SHUTTER_SKEW, 0));
+  // No way to actually get orientation from V4L2.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_SENSOR_ORIENTATION, 90)));
+  // TODO(b/31023611): Sensor frame duration. Range should
+  // be dependent on the stream configuration being used.
+  // No test patterns supported.
+  components.insert(
+      NoEffectMenuControl<int32_t>(ANDROID_SENSOR_TEST_PATTERN_MODE,
+                                   ANDROID_SENSOR_AVAILABLE_TEST_PATTERN_MODES,
+                                   {ANDROID_SENSOR_TEST_PATTERN_MODE_OFF}));
+
+  // TODO(b/30510395): subcomponents of face detection.
+  // Face detection not supported.
+  components.insert(NoEffectMenuControl<uint8_t>(
+      ANDROID_STATISTICS_FACE_DETECT_MODE,
+      ANDROID_STATISTICS_INFO_AVAILABLE_FACE_DETECT_MODES,
+      {ANDROID_STATISTICS_FACE_DETECT_MODE_OFF}));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<int32_t>(ANDROID_STATISTICS_INFO_MAX_FACE_COUNT, 0)));
+
+  // No way to get detected scene flicker from V4L2.
+  components.insert(FixedState<uint8_t>(ANDROID_STATISTICS_SCENE_FLICKER,
+                                        ANDROID_STATISTICS_SCENE_FLICKER_NONE));
+
+  // TOOD(b/31023265): V4L2_CID_FLASH_INDICATOR_INTENSITY could be queried
+  // to see if there's a transmit LED. Would need to translate HAL off/on
+  // enum to slider min/max value. For now, no LEDs available.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_LED_AVAILABLE_LEDS, {})));
+
+  /* Capabilities. */
+  // The V4L2Metadata pretends to at least meet the
+  // "LIMITED" and "BACKWARD_COMPATIBLE" functionality requirements.
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<uint8_t>(ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL,
+                            ANDROID_INFO_SUPPORTED_HARDWARE_LEVEL_LIMITED)));
+  components.insert(std::unique_ptr<PartialMetadataInterface>(
+      new Property<std::vector<uint8_t>>(
+          ANDROID_REQUEST_AVAILABLE_CAPABILITIES,
+          {ANDROID_REQUEST_AVAILABLE_CAPABILITIES_BACKWARD_COMPATIBLE})));
+
+  // Request is unused, and can be any value,
+  // but that value needs to be propagated.
+  components.insert(NoEffectOptionlessControl<int32_t>(ANDROID_REQUEST_ID, 0));
+
+  // Metadata is returned in a single result; not multiple pieces.
+  components.insert(std::make_unique<Property<int32_t>>(
+      ANDROID_REQUEST_PARTIAL_RESULT_COUNT, 1));
+
+  int res =
+      AddFormatComponents(device, std::inserter(components, components.end()));
+  if (res) {
+    HAL_LOGE("Failed to initialize format components.");
+    return res;
+  }
+
+  *result = std::make_unique<Metadata>(std::move(components));
+  return 0;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_metadata_factory.h b/hardware/ntimespace/camera/v4l2_metadata_factory.h
new file mode 100644
index 0000000000..f25a370ff3
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_metadata_factory.h
@@ -0,0 +1,34 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
+#define V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
+
+#include <memory>
+
+#include "metadata/metadata.h"
+#include "v4l2_wrapper.h"
+
+namespace v4l2_camera_hal {
+
+// A static function to get a Metadata object populated with V4L2 or other
+// controls as appropriate.
+int GetV4L2Metadata(std::shared_ptr<V4L2Wrapper> device,
+                    std::unique_ptr<Metadata>* result);
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_METADATA_FACTORY_H_
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp b/hardware/ntimespace/camera/v4l2_wrapper.cpp
new file mode 100644
index 0000000000..f794a6b708
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp
@@ -0,0 +1,1136 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Wrapper"
+
+#include "v4l2_wrapper.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "arc/cached_frame.h"
+#include "android-base/properties.h"
+#include "debug.h"
+
+namespace v4l2_camera_hal {
+
+using arc::V4L2FrameBuffer;
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+using default_camera_hal::CaptureRequest;
+
+const int32_t kStandardSizes[][2] = {
+  {4096, 2160}, // 4KDCI (for USB camera)
+  {3840, 2160}, // 4KUHD (for USB camera)
+  {3280, 2464}, // 8MP
+  {2560, 1440}, // QHD
+  {1920, 1080}, // HD1080
+  {1640, 1232}, // 2MP
+  {1280,  720}, // HD
+  {1024,  768}, // XGA
+  { 960,  540}, // VGA
+  { 640,  480}, // VGA
+  { 640,  360}, // VGA
+  { 320,  240}, // QVGA
+  { 176,  144}  // QCIF
+};
+
+V4L2Wrapper* V4L2Wrapper::NewV4L2Wrapper(const std::string device_path, int camera_id) {
+  return new V4L2Wrapper(device_path, camera_id);
+}
+
+V4L2Wrapper::V4L2Wrapper(const std::string device_path, int camera_id)
+    : device_path_(std::move(device_path)), connection_count_(0) {
+      HAL_LOG_ENTER();
+      camera_id_ = camera_id;
+      camera_share_fd_ = -1;
+      last_index_ = -1;
+      last_dq_index = -1;
+      stream_status = 0;
+      dump_data_init();
+      get_gpu_pixel_alignment();
+    }
+
+V4L2Wrapper::~V4L2Wrapper() {}
+
+inline std::string V4L2Wrapper::FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+int V4L2Wrapper::Connect() {
+  HAL_LOG_ENTER();
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connected()) {
+    HAL_LOGV("Camera device %s is already connected.", device_path_.c_str());
+    ++connection_count_;
+    return 0;
+  }
+
+  if (camera_share_fd_ > 0)
+    close(camera_share_fd_);
+  camera_share_fd_ = -1;
+  last_index_ = -1;  
+  last_dq_index = 0;
+  // Open in nonblocking mode (DQBUF may return EAGAIN).
+  int fd = TEMP_FAILURE_RETRY(open(device_path_.c_str(), O_RDONLY | O_NONBLOCK));
+  if (fd < 0) {
+    HAL_LOGE("failed to open %s (%s)", device_path_.c_str(), strerror(errno));
+    return -ENODEV;
+  }
+  device_fd_.reset(fd);
+  ++connection_count_;
+
+  // Check if this connection has the extended control query capability.
+  v4l2_query_ext_ctrl query;
+  query.id = V4L2_CTRL_FLAG_NEXT_CTRL | V4L2_CTRL_FLAG_NEXT_COMPOUND;
+  extended_query_supported_ = (IoctlLocked(VIDIOC_QUERY_EXT_CTRL, &query) == 0);
+
+  //camera id 0: back, facing 0
+  //camera id 1: front, facing 1
+  //other id: facing 0
+  int facing = (camera_id_ == 1 ? 1 : 0);
+  struct v4l2_control ctrl;
+  memset(&ctrl, 0, sizeof(ctrl));
+  ctrl.id = CID_SET_FACING;
+  ctrl.value = facing;
+  ctrl.value = 1;
+  if (IoctlLocked(VIDIOC_S_CTRL, &ctrl) != 0)
+  {
+      HAL_LOGE("%s(%d) set facing info failed", __FUNCTION__, __LINE__);
+  }
+  HAL_LOGE("VIDIOC_S_CTRL CID_SET_FACING val = %d", ctrl.value);
+
+  if (IoctlLocked(VIDIOC_G_CTRL, &ctrl) != 0)
+  {
+      HAL_LOGE("%s(%d) get facing info failed", __FUNCTION__, __LINE__);
+  }
+  else
+  {
+      HAL_LOGE("VIDIOC_G_CTRL CID_SET_FACING val = %d", ctrl.value);
+  }
+
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at device_path_ may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so Connect() is never called on an unsupported camera)
+
+  supported_formats_ = GetSupportedFormats();
+  qualified_formats_ = StreamFormat::GetQualifiedFormats(supported_formats_);
+
+  HAL_LOG_EXIT();
+
+  return 0;
+}
+
+void V4L2Wrapper::Disconnect() {
+  HAL_LOG_ENTER();
+  HAL_LOGD("Disconnect...");
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connection_count_ == 0) {
+    // Not connected.
+    HAL_LOGE("Camera device %s is not connected, cannot disconnect.",
+             device_path_.c_str());
+    return;
+  }
+
+  --connection_count_;
+  if (connection_count_ > 0) {
+    HAL_LOGV("Disconnected from camera device %s. %d connections remain.",
+             device_path_.c_str(), connection_count_);
+    return;
+  }
+
+  device_fd_.reset(-1);  // Includes close().
+  format_.reset();
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+    buffers_.clear();
+  }
+
+  if (camera_share_fd_ > 0){
+    close(camera_share_fd_);
+    camera_share_fd_ = -1;
+  }
+}
+
+// Helper function. Should be used instead of ioctl throughout this class.
+template <typename T>
+int V4L2Wrapper::IoctlLocked(unsigned long request, T data) {
+  // Potentially called so many times logging entry is a bad idea.
+  std::lock_guard<std::mutex> lock(device_lock_);
+
+  HAL_LOG_ENTER();
+
+  if (!connected()) {
+    HAL_LOGE("Device %s not connected.", device_path_.c_str());
+    return -ENODEV;
+  }
+  return TEMP_FAILURE_RETRY(ioctl(device_fd_.get(), request, data));
+}
+
+int V4L2Wrapper::StreamOn() {
+  HAL_LOG_ENTER();
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before turning on stream.");
+    return -EINVAL;
+  }
+
+  int32_t buffer_numbers = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  if (IoctlLocked(VIDIOC_STREAMON, &buffer_numbers) < 0) {
+    HAL_LOGE("STREAMON fails (%d): %s", errno, strerror(errno));
+    return -ENODEV;
+  }
+
+  stream_status = 1;
+  HAL_LOGD("Stream turned on.");
+  return 0;
+}
+
+int V4L2Wrapper::StreamOff() {
+  HAL_LOG_ENTER();
+  stream_status = 0;
+  buffer_queue_notify_.notify_one();
+  if (!format_) {
+    // Can't have turned on the stream without format being set,
+    // so nothing to turn off here.
+    return 0;
+  }
+
+  int32_t type = format_->type();
+  int res = IoctlLocked(VIDIOC_STREAMOFF, &type);
+  // Calling STREAMOFF releases all queued buffers back to the user.
+  // No buffers in flight.
+  if (res < 0) {
+    HAL_LOGE("STREAMOFF fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    buffer.active = false;
+  }
+
+  last_index_ = -1;
+  last_dq_index = 0;
+  HAL_LOGI("Stream turned off.");
+  return 0;
+}
+
+int V4L2Wrapper::QueryControl(uint32_t control_id,
+                              v4l2_query_ext_ctrl* result) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("control_id: %d", control_id);
+
+  int res;
+  memset(result, 0, sizeof(*result));
+
+  if (extended_query_supported_) {
+    result->id = control_id;
+    res = IoctlLocked(VIDIOC_QUERY_EXT_CTRL, result);
+    // Assuming the operation was supported (not ENOTTY), no more to do.
+    if (errno != ENOTTY) {
+      if (res) {
+        HAL_LOGE("QUERY_EXT_CTRL fails: %s", strerror(errno));
+        return -ENODEV;
+      }
+      return 0;
+    }
+  }
+
+  // Extended control querying not supported, fall back to basic control query.
+  v4l2_queryctrl query;
+  query.id = control_id;
+  if (IoctlLocked(VIDIOC_QUERYCTRL, &query)) {
+    HAL_LOGE("QUERYCTRL fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Convert the basic result to the extended result.
+  result->id = query.id;
+  result->type = query.type;
+  memcpy(result->name, query.name, sizeof(query.name));
+  result->minimum = query.minimum;
+  if (query.type == V4L2_CTRL_TYPE_BITMASK) {
+    // According to the V4L2 documentation, when type is BITMASK,
+    // max and default should be interpreted as __u32. Practically,
+    // this means the conversion from 32 bit to 64 will pad with 0s not 1s.
+    result->maximum = static_cast<uint32_t>(query.maximum);
+    result->default_value = static_cast<uint32_t>(query.default_value);
+  } else {
+    result->maximum = query.maximum;
+    result->default_value = query.default_value;
+  }
+  result->step = static_cast<uint32_t>(query.step);
+  result->flags = query.flags;
+  result->elems = 1;
+  switch (result->type) {
+    case V4L2_CTRL_TYPE_INTEGER64:
+      result->elem_size = sizeof(int64_t);
+      break;
+    case V4L2_CTRL_TYPE_STRING:
+      result->elem_size = result->maximum + 1;
+      break;
+    default:
+      result->elem_size = sizeof(int32_t);
+      break;
+  }
+
+  return 0;
+}
+
+int V4L2Wrapper::GetControl(uint32_t control_id, int32_t* value) {
+  HAL_LOG_ENTER();
+  // For extended controls (any control class other than "user"),
+  // G_EXT_CTRL must be used instead of G_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_G_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("G_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  } else {
+    v4l2_control control{control_id, 0};
+    if (IoctlLocked(VIDIOC_G_CTRL, &control) < 0) {
+      HAL_LOGE("G_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::SetControl(uint32_t control_id,
+                            int32_t desired,
+                            int32_t* result) {
+  int32_t result_value = 0;
+
+  HAL_LOG_ENTER();
+  // TODO(b/29334616): When async, this may need to check if the stream
+  // is on, and if so, lock it off while setting format. Need to look
+  // into if V4L2 supports adjusting controls while the stream is on.
+
+  // For extended controls (any control class other than "user"),
+  // S_EXT_CTRL must be used instead of S_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    control.value = desired;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_S_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("S_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  } else {
+    v4l2_control control{control_id, desired};
+    if (IoctlLocked(VIDIOC_S_CTRL, &control) < 0) {
+      HAL_LOGE("S_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  }
+
+  // If the caller wants to know the result, pass it back.
+  if (result != nullptr) {
+    *result = result_value;
+  }
+  return 0;
+}
+
+const SupportedFormats V4L2Wrapper::GetSupportedFormats() {
+  HAL_LOG_ENTER();
+
+  SupportedFormats formats;
+  std::set<uint32_t> pixel_formats;
+
+  int res = GetFormats(&pixel_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return formats;
+  }
+
+  arc::SupportedFormat supported_format;
+  std::set<std::array<int32_t, 2>> frame_sizes;
+
+  for (auto pixel_format : pixel_formats) {
+    supported_format.fourcc = pixel_format;
+
+    frame_sizes.clear();
+    res = GetFormatFrameSizes(pixel_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get frame sizes for format: 0x%x", pixel_format);
+      continue;
+    }
+    for (auto frame_size : frame_sizes) {
+      supported_format.width = frame_size[0];
+      supported_format.height = frame_size[1];
+      formats.push_back(supported_format);
+    }
+  }
+  return formats;
+}
+
+int V4L2Wrapper::GetFormats(std::set<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+
+  v4l2_fmtdesc format_query;
+  memset(&format_query, 0, sizeof(format_query));
+  // TODO(b/30000211): multiplanar support.
+  format_query.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  while (IoctlLocked(VIDIOC_ENUM_FMT, &format_query) >= 0) {
+    HAL_LOGE("ENUM_FMT got at index %d with %s 0x%x [%d]", format_query.index, 
+              FormatToString(format_query.pixelformat).c_str(), 
+              format_query.pixelformat, format_query.pixelformat);
+    v4l2_formats->insert(format_query.pixelformat);
+    ++format_query.index;
+  }
+
+  if (errno != EINVAL) {
+    HAL_LOGE(
+        "ENUM_FMT fails at index %d: %s", format_query.index, strerror(errno));
+    return -ENODEV;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+  if (!connected()) {
+    HAL_LOGE(
+        "Device is not connected, qualified formats may not have been set.");
+    return -EINVAL;
+  }
+  v4l2_formats->clear();
+  std::set<uint32_t> unique_fourccs;
+  for (auto& format : qualified_formats_) {
+    unique_fourccs.insert(format.fourcc);
+  }
+  v4l2_formats->assign(unique_fourccs.begin(), unique_fourccs.end());
+  return 0;
+}
+
+int V4L2Wrapper::GetFormatFrameSizes(uint32_t v4l2_format,
+                                     std::set<std::array<int32_t, 2>>* sizes) {
+  v4l2_frmsizeenum size_query;
+
+  HAL_LOG_ENTER();
+  memset(&size_query, 0, sizeof(size_query));
+  size_query.pixel_format = v4l2_format;
+  if (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) < 0) {
+    HAL_LOGE("ENUM_FRAMESIZES failed at pixel_format 0x%x index 0: %s", v4l2_format, strerror(errno));
+    return -ENODEV;
+  }
+  if (size_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all sizes using VIDIOC_ENUM_FRAMESIZES.
+    // Assuming that a driver with discrete frame sizes has a reasonable number
+    // of them.
+    do {
+      sizes->insert({{{static_cast<int32_t>(size_query.discrete.width),
+                       static_cast<int32_t>(size_query.discrete.height)}}});
+      ++size_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMESIZES fails at index %d: %s",
+               size_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: based on the stepwise struct returned by the query.
+    // Fully listing all possible sizes, with large enough range/small enough
+    // step size, may produce far too many potential sizes. Instead, find the
+    // closest to a set of standard sizes.
+    for (const auto size : kStandardSizes) {
+      // Find the closest size, rounding up.
+      uint32_t desired_width = size[0];
+      uint32_t desired_height = size[1];
+      if (desired_width < size_query.stepwise.min_width ||
+          desired_height < size_query.stepwise.min_height) {
+        HAL_LOGE("Standard size %u x %u is too small for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      } else if (desired_width > size_query.stepwise.max_width ||
+                 desired_height > size_query.stepwise.max_height) {
+        HAL_LOGE("Standard size %u x %u is too big for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      }
+
+      // Round up.
+      uint32_t width_steps = (desired_width - size_query.stepwise.min_width +
+                              size_query.stepwise.step_width - 1) /
+                             size_query.stepwise.step_width;
+      uint32_t height_steps = (desired_height - size_query.stepwise.min_height +
+                               size_query.stepwise.step_height - 1) /
+                              size_query.stepwise.step_height;
+      sizes->insert(
+          {{{static_cast<int32_t>(size_query.stepwise.min_width +
+                                  width_steps * size_query.stepwise.step_width),
+             static_cast<int32_t>(size_query.stepwise.min_height +
+                                  height_steps *
+                                      size_query.stepwise.step_height)}}});
+    }
+  }
+  return 0;
+}
+
+// Converts a v4l2_fract with units of seconds to an int64_t with units of ns.
+inline int64_t FractToNs(const v4l2_fract& fract) {
+  return (1000000000LL * fract.numerator) / fract.denominator;
+}
+
+int V4L2Wrapper::GetFormatFrameDurationRange(
+    uint32_t v4l2_format,
+    const std::array<int32_t, 2>& size,
+    std::array<int64_t, 2>* duration_range) {
+  // Potentially called so many times logging entry is a bad idea.
+
+  v4l2_frmivalenum duration_query;
+  memset(&duration_query, 0, sizeof(duration_query));
+  duration_query.pixel_format = v4l2_format;
+  duration_query.width = size[0];
+  duration_query.height = size[1];
+  if (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) < 0) {
+    HAL_LOGE("ENUM_FRAMEINTERVALS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  int64_t min = std::numeric_limits<int64_t>::max();
+  int64_t max = std::numeric_limits<int64_t>::min();
+  if (duration_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all durations using VIDIOC_ENUM_FRAMEINTERVALS.
+    do {
+      min = std::min(min, FractToNs(duration_query.discrete));
+      max = std::max(max, FractToNs(duration_query.discrete));
+      ++duration_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMEINTERVALS fails at index %d: %s",
+               duration_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: simply convert the given min and max.
+    min = FractToNs(duration_query.stepwise.min);
+    max = FractToNs(duration_query.stepwise.max);
+  }
+  (*duration_range)[0] = min;
+  (*duration_range)[1] = max;
+  return 0;
+}
+
+int V4L2Wrapper::SetFormat(const StreamFormat& desired_format,
+                           uint32_t* result_max_buffers) {
+  HAL_LOG_ENTER();
+
+  if (format_ && desired_format == *format_) {
+    HAL_LOGV("Already in correct format, skipping format setting.");
+    *result_max_buffers = buffers_.size();
+    return 0;
+  }
+
+  if (format_) {
+    // If we had an old format, first request 0 buffers to inform the device
+    // we're no longer using any previously "allocated" buffers from the old
+    // format. This seems like it shouldn't be necessary for USERPTR memory,
+    // and/or should happen from turning the stream off, but the driver
+    // complained. May be a driver issue, or may be intended behavior.
+    int res = RequestBuffers(0);
+    if (res) {
+      return res;
+    }
+  }
+
+  // Select the matching format, or if not available, select a qualified format
+  // we can convert from.
+  SupportedFormat format;
+  if (!StreamFormat::FindBestFitFormat(supported_formats_, qualified_formats_,
+                                       desired_format.v4l2_pixel_format(),
+                                       desired_format.width(),
+                                       desired_format.height(), &format)) {
+    HAL_LOGE(
+        "Unable to find supported resolution in list, "
+        "width: %d, height: %d",
+        desired_format.width(), desired_format.height());
+    return -EINVAL;
+  }
+
+  HAL_LOGD("supported format size:%d,%d forcc:%x", format.width, format.height, format.fourcc);
+
+  // Set the camera to the new format.
+  v4l2_format new_format;
+  const StreamFormat resolved_format(format);
+  resolved_format.FillFormatRequest(&new_format);
+
+  // TODO(b/29334616): When async, this will need to check if the stream
+  // is on, and if so, lock it off while setting format.
+  if (IoctlLocked(VIDIOC_S_FMT, &new_format) < 0) {
+    HAL_LOGE("S_FMT failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  HAL_LOGD("S_FMT format size:%d,%d forcc:%x", 
+		  new_format.fmt.pix.width, 
+		  new_format.fmt.pix.height, 
+		  new_format.fmt.pix.pixelformat);
+  // Check that the driver actually set to the requested values.
+  if (resolved_format != new_format) {
+    HAL_LOGE("Device doesn't support desired stream configuration.");
+    return -EINVAL;
+  }
+
+  // Keep track of our new format.
+  format_.reset(new StreamFormat(new_format));
+
+  // Format changed, request new buffers.
+  buffer_numbers_ = android::base::GetIntProperty("camera.debug.buffers", DEFAULT_BUFFER_NUMBERS);
+  HAL_LOGI("Requesting buffers with number %d.", buffer_numbers_);
+  int res = RequestBuffers(buffer_numbers_);
+  if (res) {
+    HAL_LOGE("Requesting buffers for new format failed.");
+    return res;
+  }
+  *result_max_buffers = buffers_.size();
+  return 0;
+}
+
+int V4L2Wrapper::RequestBuffers(uint32_t num_requested) {
+  v4l2_requestbuffers req_buffers;
+
+  memset(&req_buffers, 0, sizeof(req_buffers));
+  req_buffers.type = format_->type();
+  req_buffers.memory = V4L2_MEMORY_MMAP;
+  req_buffers.count = num_requested;
+
+  int res = IoctlLocked(VIDIOC_REQBUFS, &req_buffers);
+  // Calling REQBUFS releases all queued buffers back to the user.
+  if (res < 0) {
+    HAL_LOGE("REQBUFS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // V4L2 will set req_buffers.count to a number of buffers it can handle.
+  if (num_requested > 0 && req_buffers.count < 1) {
+    HAL_LOGE("REQBUFS claims it can't handle any buffers.");
+    return -ENODEV;
+  }
+
+  HAL_LOGE("FW REQBUFS: %d kernel support: %d ", num_requested, req_buffers.count);
+
+  buffers_.resize(req_buffers.count);
+  last_index_ = -1; 
+  last_dq_index = 0;
+
+  return 0;
+}
+
+int V4L2Wrapper::get_camera_sharefd()
+{
+    if (camera_share_fd_ > 0) {
+      return camera_share_fd_;
+    }
+
+    int camera_share_fd = -1;
+    struct v4l2_control ctrl;
+    memset(&ctrl, 0, sizeof(ctrl));
+    ctrl.id = CID_GET_DMABUF_FD;
+    ctrl.value = 0;
+    if (IoctlLocked(VIDIOC_S_CTRL, &ctrl) != 0)
+    {
+        HAL_LOGE("CID_GET_DMABUF_FD: ioctl error\n");
+        camera_share_fd = -1;
+    }
+    else
+    {
+        if (IoctlLocked(VIDIOC_G_CTRL, &ctrl) != 0)
+        {
+            HAL_LOGE("VIDIOC_G_CTRL CID_GET_DMABUF_FD: ioctl error\n");
+            camera_share_fd = -1;
+        }
+        else
+        {
+            HAL_LOGI("CID_GET_DMABUF_FD fd=%d", ctrl.value);
+            camera_share_fd = ctrl.value;
+        }
+    }
+    camera_share_fd_ = camera_share_fd;
+
+    HAL_LOGD("dma buffer fd: %d", camera_share_fd_);
+    return camera_share_fd_;
+}
+
+uint64_t dq_time_end = 0;
+uint64_t q_time_start = 0;
+bool dq_success = false;
+
+void calulateTimespan() {
+  if (dq_success) {
+    uint64_t testDurationNs = q_time_start - dq_time_end;
+    HAL_LOGD("+++++++++++++++++++++++++++++Dequeue->Queue [+ %d ms]+++++++++++++++++++++++++++++", 
+      toMilliSeconds(testDurationNs));  
+
+    dq_success = false;
+  } 
+}
+
+int V4L2Wrapper::EnqueueRequest() {
+  HAL_LOG_ENTER();
+  HAL_LOGV("++++++++++++++++++++++++++++++++++++Try to QBUF++++++++++++++++++++++++++++++++++++"); 
+  int ret = 0;
+
+  uint64_t startTimeNs = timeNanos();
+  q_time_start = startTimeNs;
+  if (isDebug()) {
+    calulateTimespan();
+  }
+
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before enqueuing buffers.");
+    ret = -ENODEV;
+    goto Exit;
+  }
+
+  {
+    int index = -1;
+    size_t i = 1;
+    for(i = 1; i <= buffers_.size(); i++)
+    {
+      std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+      index = (last_index_ + i) % buffers_.size();
+      if (!buffers_[index].active) {
+        last_index_ = index;
+        ret = 0;
+        HAL_LOGV("enqueue buffer at index: %d.", last_index_);
+        break;
+      }
+      else {
+        ret = -EAGAIN;
+      }
+    }
+
+    if (stream_status == 0)
+    {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+    }
+
+    if (ret == -EAGAIN) {
+        HAL_LOGD("Cannot enqueue buffer: stream is already full. wait");
+        goto Exit;
+        //// wait!
+        /*
+        std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+        buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+        */
+        goto Exit;
+    }
+
+
+    {
+      // Set up a v4l2 buffer struct.
+      v4l2_buffer device_buffer;
+      memset(&device_buffer, 0, sizeof(device_buffer));
+      device_buffer.type = format_->type();
+      device_buffer.index = index;
+      device_buffer.memory = V4L2_MEMORY_MMAP;
+
+      // Use QUERYBUF to ensure our buffer/device is in good shape,
+      // and fill out remaining fields.
+      if (IoctlLocked(VIDIOC_QUERYBUF, &device_buffer) < 0) {
+        HAL_LOGE("QUERYBUF fails: %s", strerror(errno));
+        // Return buffer index.
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        buffers_[index].active = false;
+        ret = -ENODEV;
+        goto Exit;
+      }
+
+      //HAL_LOGE("device_buffer.length: %d device_buffer.m.offset: %d", device_buffer.length, device_buffer.m.offset);
+      if (stream_status == 0)
+      {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+      }
+
+        HAL_LOGI("VIDIOC_QUERYBUF[%d] length=%d offset=%d",device_buffer.index, device_buffer.length, device_buffer.m.offset);
+      {
+        // Setup our request context and fill in the user pointer field.
+        RequestContext* request_context;
+        {
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context = &buffers_[index];
+          request_context->camera_buffer->SetFd(get_camera_sharefd());
+          request_context->camera_buffer->SetDataSize(device_buffer.length);
+          request_context->camera_buffer->SetOffset(device_buffer.m.offset);
+          request_context->camera_buffer->Map();
+
+          request_context->camera_buffer->SetFourcc(format_->v4l2_pixel_format());
+          request_context->camera_buffer->SetWidth(format_->width());
+          request_context->camera_buffer->SetHeight(format_->height());
+          //request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart() + device_buffer.m.offset);
+          request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart());
+          request_context->request = NULL;
+        }
+
+        // Pass the buffer to the camera.
+        if (IoctlLocked(VIDIOC_QBUF, &device_buffer) < 0) {
+          HAL_LOGE("QBUF fails: %s", strerror(errno));
+          ret = -ENODEV;
+          goto Exit;
+        }
+
+        {
+          // Mark the buffer as in flight.
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context->active = true;
+        }
+      }
+    }
+  }
+
+Exit:
+  uint64_t testDurationNs = timeNanos() - startTimeNs;
+  if (!ret) {
+    if (isDebug()) {
+        HAL_LOGD("+++++++++++++++++++++++++++++QBUF index[%d] Done[+ %d ms]++++++++++++++++++++++++++++++++++",
+            last_index_,
+            toMilliSeconds(testDurationNs));
+    }
+  } else if (ret == -EAGAIN) {
+    std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+    buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF AGAIN[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+  else {
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF Fail[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+
+  if (stream_status == 0)
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+  }
+
+  return ret;
+}
+
+void V4L2Wrapper::CopyBlt(void * dest, const void * src, size_t width, size_t height) {
+    size_t stride = Align64(width);
+    for(size_t r = 0; r < height; r++) {
+      for(size_t c = 0; c < width; c++) {
+          for(size_t i = 0; i < 4; i++) {
+            *((unsigned char *)dest + 4 * (r * stride + c) + i) =  *((unsigned char *)src + 4 * (r * width + c) + i);
+          }
+      }
+    }
+    HAL_LOGV("width %zu stride %zu", width, stride);
+}
+
+int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("------------------------------------Try to DQBUF------------------------------------");
+  uint64_t startTimeNs = timeNanos();
+  uint64_t ioctlTimeNs = timeNanos();
+  uint64_t convertTimeNs = 0;
+  uint64_t memcpyTimeNs = 0;
+
+  int ret = 0;
+  int res = 0;
+
+  if (!format_) {
+    HAL_LOGV(
+        "Format not set, so stream can't be on, "
+        "so no buffers available for dequeueing");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  if (!request)
+  {
+    HAL_LOGE("DequeueRequest failed, request is null");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  {
+    v4l2_buffer buffer;
+    memset(&buffer, 0, sizeof(buffer));
+    buffer.type = format_->type();
+    buffer.memory = V4L2_MEMORY_MMAP;
+    static int frame_count = 0;
+
+    int retry = 5;
+    while (retry > 0)
+    {
+        res = IoctlLocked(VIDIOC_DQBUF, &buffer);
+        if (res) {
+            if (errno == EAGAIN) {
+                // Expected failure.
+                retry--;
+                if (retry > 0)
+                {
+                    usleep(5*1000);
+                    continue;
+                }
+                else
+                {
+                    frame_count++;
+                    HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    ret = -EAGAIN;
+                    //goto Exit;
+                }
+            } else {
+                // Unexpected failure.
+                HAL_LOGE("DQBUF fails: %s", strerror(errno));
+                usleep(10*1000);
+                ret = -EIO;
+                goto Exit;
+            }
+        }
+        else
+        {
+            break;
+        }
+    }
+    ioctlTimeNs = timeNanos();
+    if (ret == -EAGAIN)
+        buffer.index = last_dq_index;
+    if (stream_status == 0)
+    {
+        ret = -EIO;
+        goto Exit;
+    }
+    HAL_LOGD("VIDIOC_DQBUF got buffer index %d", buffer.index);
+
+    {
+      RequestContext* request_context = &buffers_[buffer.index];
+
+      request_context->request = request;
+      retry = 5;
+      while (!request_context->active && retry > 0)
+      {
+        buffer_queue_notify_.notify_one();
+        usleep(5*1000);
+        retry--;
+        if (retry == 0) {
+            ret = -EAGAIN;
+            goto Exit;
+        }
+      }
+      if (ret == -EAGAIN)
+      {
+        buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
+      }
+
+      last_dq_index = buffer.index;
+      dump_data_index = request_context->request->frame_number;
+      HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
+        (uint32_t)request_context->request->output_buffers.size());
+
+      // Perform the format conversion.
+      arc::CachedFrame cached_frame;
+      uint32_t output_buffer_size = request_context->request->output_buffers.size();      
+      for(uint32_t i = 0; i < output_buffer_size; i++) {
+          HAL_LOGV("-----------------------------------------------------------");
+          HAL_LOGD("Process buffer[%d]", i);
+          if (stream_status == 0)
+          {
+            ret = -EIO;
+            goto Exit;
+          }
+          // Lock the camera stream buffer for painting.
+          const camera3_stream_buffer_t* stream_buffer = &request_context->request->output_buffers[i];
+          uint32_t fourcc = StreamFormat::HalToV4L2PixelFormat(stream_buffer->stream->format);
+          HAL_LOGD("Driver format: %s 0x%x width: %d height: %d", 
+            FormatToString(request_context->camera_buffer->GetFourcc()).c_str(),
+            request_context->camera_buffer->GetFourcc(),
+            request_context->camera_buffer->GetWidth(),
+            request_context->camera_buffer->GetHeight());
+
+          HAL_LOGD("App format: %s 0x%x width: %d height: %d", 
+            FormatToString(fourcc).c_str(), 
+            fourcc,
+            stream_buffer->stream->width,
+            stream_buffer->stream->height);
+
+          dump_data(dump_data_index, (unsigned char *)request_context->camera_buffer->GetData(), 
+                    request_context->camera_buffer->GetWidth(), request_context->camera_buffer->GetHeight(), 
+                    request_context->camera_buffer->GetFourcc(), i, "pre-used");
+
+          // Note that the device buffer length is passed to the output frame. If the
+          // GrallocFrameBuffer does not have support for the transformation to
+          // |fourcc|, it will assume that the amount of data to lock is based on
+          // |buffer.length|, otherwise it will use the ImageProcessor::ConvertedSize.   
+          arc::GrallocFrameBuffer output_frame( *stream_buffer->buffer, stream_buffer->stream->width,
+                                                stream_buffer->stream->height, fourcc, buffer.length, 
+                                                stream_buffer->stream->usage);
+
+          HAL_LOGV("out buffer  fd: %d", 
+            ((buffer_handle_t)*stream_buffer->buffer)->data[0]);
+
+          res = output_frame.Map();
+          if (res) {
+            HAL_LOGE("Failed to map output frame.");
+            request_context->request.reset();
+            ret = -EINVAL;
+            goto Exit;
+          }
+
+          uint64_t time = timeNanos();
+          if (request_context->camera_buffer->GetFourcc() == fourcc &&
+            request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+            request_context->camera_buffer->GetHeight() == stream_buffer->stream->height) {
+            HAL_LOGV("No need to do conversion. Copy directly");
+            #if 1            
+            // If no format conversion needs to be applied, directly copy the data over.
+            memcpy(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetDataSize());
+            #else
+            CopyBlt(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetWidth(),
+                  request_context->camera_buffer->GetHeight());
+            #endif
+            memcpyTimeNs = timeNanos() - time;
+          } else {
+            HAL_LOGV("Need to perform the format conversion.");
+            bool can_convert_directly = (fourcc != V4L2_PIX_FMT_JPEG);
+            bool size_match = ( request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+                                request_context->camera_buffer->GetHeight() == stream_buffer->stream->height);
+            if (output_buffer_size == 1 && size_match && can_convert_directly){
+              arc::SimpleFrameBuffer in_frame(request_context->camera_buffer->GetData(), 
+                                              request_context->camera_buffer->GetFourcc(),
+                                              request_context->camera_buffer->GetWidth(), 
+                                              request_context->camera_buffer->GetHeight(),  
+                                              request_context->camera_buffer->GetFd(),
+                                              buffer.length);
+ 
+              cached_frame.ConvertDirectly(request_context->request->settings, in_frame, &output_frame);
+            } else {
+              if (!cached_frame.already_cached) {
+                cached_frame.SetSource(request_context->request->settings, request_context->camera_buffer.get(), 0);
+                dump_data(dump_data_index, (unsigned char *)cached_frame.yu12_frame_->GetData(), 
+                              cached_frame.yu12_frame_->GetWidth(), cached_frame.yu12_frame_->GetHeight(), 
+                              cached_frame.yu12_frame_->GetFourcc(), i, "mid");                
+              }
+              
+              cached_frame.Convert(request_context->request->settings, &output_frame, i);                                  
+            }
+
+          HAL_LOGV("copy data buffer  fd: %d", ((buffer_handle_t)output_frame.buffer_)->data[0]);
+
+          dump_data(dump_data_index, (unsigned char *)output_frame.GetData(), 
+                      output_frame.GetWidth(), output_frame.GetHeight(), fourcc, i, "post");
+          convertTimeNs = timeNanos() - time;
+          }  
+ 
+      }
+
+      //EAGAIN we will not QBUF
+      if (ret == -EAGAIN) {
+        ret = 0;
+        goto Exit;
+      }
+
+      {
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        request_context->request.reset();
+        // Mark the buffer as not in flight.
+        request_context->active = false;
+      }
+
+      buffer_queue_notify_.notify_one();
+    }
+  }
+
+Exit:
+  if (isDebug())
+  {
+    uint64_t testDurationNs = timeNanos() - startTimeNs;
+    if (!ret) {
+        dq_time_end = timeNanos();
+        dq_success = true;
+        //dump_data_index++;
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] index[%d] Done[+ %d ms] [ioctl:%d ms] [convert:%d ms] [memcpy:%d ms]------------------------------------",
+            dump_data_index, last_dq_index,
+            toMilliSeconds(testDurationNs), toMilliSeconds(ioctlTimeNs-startTimeNs), toMilliSeconds(convertTimeNs), toMilliSeconds(memcpyTimeNs));
+    } else {
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] Fail[+ %d ms]------------------------------------",
+            dump_data_index,
+            toMilliSeconds(testDurationNs));
+    }
+}
+  if (!ret) {
+    ShowPreviewFPS();
+  }
+
+  return ret;
+}
+
+int V4L2Wrapper::GetInFlightBufferCount() {
+  int count = 0;
+  std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    if (buffer.active) {
+      count++;
+    }
+  }
+  return count;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.cpp_10 b/hardware/ntimespace/camera/v4l2_wrapper.cpp_10
new file mode 100644
index 0000000000..ec3a9a8f73
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.cpp_10
@@ -0,0 +1,1089 @@
+/*
+ * Copyright 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+//#define LOG_NDEBUG 0
+#define LOG_TAG "V4L2Wrapper"
+
+#include "v4l2_wrapper.h"
+#include <algorithm>
+#include <fcntl.h>
+#include <limits>
+#include <android-base/unique_fd.h>
+#include <linux/videodev2.h>
+#include <sys/stat.h>
+#include <sys/types.h>
+#include "arc/cached_frame.h"
+#include "android-base/properties.h"
+#include "debug.h"
+#include "common.h"
+
+namespace v4l2_camera_hal {
+
+using arc::V4L2FrameBuffer;
+using arc::SupportedFormat;
+using arc::SupportedFormats;
+using default_camera_hal::CaptureRequest;
+
+const int32_t kStandardSizes[][2] = {
+  {4096, 2160}, // 4KDCI (for USB camera)
+  {3840, 2160}, // 4KUHD (for USB camera)
+  {3280, 2464}, // 8MP
+  {2560, 1440}, // QHD
+  {1920, 1080}, // HD1080
+  {1640, 1232}, // 2MP
+  {1280,  720}, // HD
+  {1024,  768}, // XGA
+  { 960,  540}, // VGA
+  { 640,  480}, // VGA
+  { 640,  360}, // VGA
+  { 320,  240}, // QVGA
+  { 176,  144}  // QCIF
+};
+
+V4L2Wrapper* V4L2Wrapper::NewV4L2Wrapper(const std::string device_path, int camera_id) {
+  return new V4L2Wrapper(device_path, camera_id);
+}
+
+V4L2Wrapper::V4L2Wrapper(const std::string device_path, int camera_id)
+    : device_path_(std::move(device_path)), connection_count_(0) {
+      HAL_LOG_ENTER();
+      camera_id_ = camera_id;
+      camera_share_fd_ = -1;
+      last_index_ = -1;
+      last_dq_index = -1;
+      stream_status = 0;
+      dump_data_init();
+      get_gpu_pixel_alignment();
+    }
+
+V4L2Wrapper::~V4L2Wrapper() {}
+
+inline std::string V4L2Wrapper::FormatToString(int32_t format) {
+  return std::string(reinterpret_cast<char*>(&format), 4);
+}
+
+int V4L2Wrapper::Connect() {
+  HAL_LOG_ENTER();
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connected()) {
+    HAL_LOGV("Camera device %s is already connected.", device_path_.c_str());
+    ++connection_count_;
+    return 0;
+  }
+
+  if (camera_share_fd_ > 0)
+    close(camera_share_fd_);
+  camera_share_fd_ = -1;
+  last_index_ = -1;  
+  last_dq_index = 0;
+  // Open in nonblocking mode (DQBUF may return EAGAIN).
+  int fd = TEMP_FAILURE_RETRY(open(device_path_.c_str(), O_RDONLY | O_NONBLOCK));
+  if (fd < 0) {
+    HAL_LOGE("failed to open %s (%s)", device_path_.c_str(), strerror(errno));
+    return -ENODEV;
+  }
+  device_fd_.reset(fd);
+  ++connection_count_;
+
+  // Check if this connection has the extended control query capability.
+  v4l2_query_ext_ctrl query;
+  query.id = V4L2_CTRL_FLAG_NEXT_CTRL | V4L2_CTRL_FLAG_NEXT_COMPOUND;
+  extended_query_supported_ = (IoctlLocked(VIDIOC_QUERY_EXT_CTRL, &query) == 0);
+
+  //camera id 0: back, facing 0
+  //camera id 1: front, facing 1
+  //other id: facing 0
+  long facing = (camera_id_ == 1 ? 1 : 0);
+  if (IoctlLocked(RFVIDEO_SET_FACING, &facing) != 0)
+  {
+      HAL_LOGE("%s(%d) set facing info failed", __FUNCTION__, __LINE__);
+  }
+
+  // TODO(b/29185945): confirm this is a supported device.
+  // This is checked by the HAL, but the device at device_path_ may
+  // not be the same one that was there when the HAL was loaded.
+  // (Alternatively, better hotplugging support may make this unecessary
+  // by disabling cameras that get disconnected and checking newly connected
+  // cameras, so Connect() is never called on an unsupported camera)
+
+  supported_formats_ = GetSupportedFormats();
+  qualified_formats_ = StreamFormat::GetQualifiedFormats(supported_formats_);
+
+  HAL_LOG_EXIT();
+
+  return 0;
+}
+
+void V4L2Wrapper::Disconnect() {
+  HAL_LOG_ENTER();
+  HAL_LOGD("DisConnect...");
+  std::lock_guard<std::mutex> lock(connection_lock_);
+
+  if (connection_count_ == 0) {
+    // Not connected.
+    HAL_LOGE("Camera device %s is not connected, cannot disconnect.",
+             device_path_.c_str());
+    return;
+  }
+
+  --connection_count_;
+  if (connection_count_ > 0) {
+    HAL_LOGV("Disconnected from camera device %s. %d connections remain.",
+             device_path_.c_str(), connection_count_);
+    return;
+  }
+
+  device_fd_.reset(-1);  // Includes close().
+  format_.reset();
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+    buffers_.clear();
+  }
+
+  if (camera_share_fd_ > 0){
+    close(camera_share_fd_);
+    camera_share_fd_ = -1;
+  }
+}
+
+// Helper function. Should be used instead of ioctl throughout this class.
+template <typename T>
+int V4L2Wrapper::IoctlLocked(unsigned long request, T data) {
+  // Potentially called so many times logging entry is a bad idea.
+  std::lock_guard<std::mutex> lock(device_lock_);
+
+  HAL_LOG_ENTER();
+
+  if (!connected()) {
+    HAL_LOGE("Device %s not connected.", device_path_.c_str());
+    return -ENODEV;
+  }
+  return TEMP_FAILURE_RETRY(ioctl(device_fd_.get(), request, data));
+}
+
+int V4L2Wrapper::StreamOn() {
+  HAL_LOG_ENTER();
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before turning on stream.");
+    return -EINVAL;
+  }
+
+  int32_t buffer_numbers = buffer_numbers_;
+  if (IoctlLocked(VIDIOC_STREAMON, &buffer_numbers) < 0) {
+    HAL_LOGE("STREAMON fails (%d): %s", errno, strerror(errno));
+    return -ENODEV;
+  }
+
+  stream_status = 1;
+  HAL_LOGD("Stream turned on.");
+  return 0;
+}
+
+int V4L2Wrapper::StreamOff() {
+  HAL_LOG_ENTER();
+  stream_status = 0;
+  buffer_queue_notify_.notify_one();
+  if (!format_) {
+    // Can't have turned on the stream without format being set,
+    // so nothing to turn off here.
+    return 0;
+  }
+
+  int32_t type = format_->type();
+  int res = IoctlLocked(VIDIOC_STREAMOFF, &type);
+  // Calling STREAMOFF releases all queued buffers back to the user.
+  // No buffers in flight.
+  if (res < 0) {
+    HAL_LOGE("STREAMOFF fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    buffer.active = false;
+  }
+
+  last_index_ = -1;
+  last_dq_index = 0;
+  HAL_LOGI("Stream turned off.");
+  return 0;
+}
+
+int V4L2Wrapper::QueryControl(uint32_t control_id,
+                              v4l2_query_ext_ctrl* result) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("control_id: %d", control_id);
+
+  int res;
+  memset(result, 0, sizeof(*result));
+
+  if (extended_query_supported_) {
+    result->id = control_id;
+    res = IoctlLocked(VIDIOC_QUERY_EXT_CTRL, result);
+    // Assuming the operation was supported (not ENOTTY), no more to do.
+    if (errno != ENOTTY) {
+      if (res) {
+        HAL_LOGE("QUERY_EXT_CTRL fails: %s", strerror(errno));
+        return -ENODEV;
+      }
+      return 0;
+    }
+  }
+
+  // Extended control querying not supported, fall back to basic control query.
+  v4l2_queryctrl query;
+  query.id = control_id;
+  if (IoctlLocked(VIDIOC_QUERYCTRL, &query)) {
+    HAL_LOGE("QUERYCTRL fails: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Convert the basic result to the extended result.
+  result->id = query.id;
+  result->type = query.type;
+  memcpy(result->name, query.name, sizeof(query.name));
+  result->minimum = query.minimum;
+  if (query.type == V4L2_CTRL_TYPE_BITMASK) {
+    // According to the V4L2 documentation, when type is BITMASK,
+    // max and default should be interpreted as __u32. Practically,
+    // this means the conversion from 32 bit to 64 will pad with 0s not 1s.
+    result->maximum = static_cast<uint32_t>(query.maximum);
+    result->default_value = static_cast<uint32_t>(query.default_value);
+  } else {
+    result->maximum = query.maximum;
+    result->default_value = query.default_value;
+  }
+  result->step = static_cast<uint32_t>(query.step);
+  result->flags = query.flags;
+  result->elems = 1;
+  switch (result->type) {
+    case V4L2_CTRL_TYPE_INTEGER64:
+      result->elem_size = sizeof(int64_t);
+      break;
+    case V4L2_CTRL_TYPE_STRING:
+      result->elem_size = result->maximum + 1;
+      break;
+    default:
+      result->elem_size = sizeof(int32_t);
+      break;
+  }
+
+  return 0;
+}
+
+int V4L2Wrapper::GetControl(uint32_t control_id, int32_t* value) {
+  HAL_LOG_ENTER();
+  // For extended controls (any control class other than "user"),
+  // G_EXT_CTRL must be used instead of G_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_G_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("G_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  } else {
+    v4l2_control control{control_id, 0};
+    if (IoctlLocked(VIDIOC_G_CTRL, &control) < 0) {
+      HAL_LOGE("G_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    *value = control.value;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::SetControl(uint32_t control_id,
+                            int32_t desired,
+                            int32_t* result) {
+  int32_t result_value = 0;
+
+  HAL_LOG_ENTER();
+  // TODO(b/29334616): When async, this may need to check if the stream
+  // is on, and if so, lock it off while setting format. Need to look
+  // into if V4L2 supports adjusting controls while the stream is on.
+
+  // For extended controls (any control class other than "user"),
+  // S_EXT_CTRL must be used instead of S_CTRL.
+  if (V4L2_CTRL_ID2CLASS(control_id) != V4L2_CTRL_CLASS_USER) {
+    v4l2_ext_control control;
+    v4l2_ext_controls controls;
+    memset(&control, 0, sizeof(control));
+    memset(&controls, 0, sizeof(controls));
+
+    control.id = control_id;
+    control.value = desired;
+    controls.ctrl_class = V4L2_CTRL_ID2CLASS(control_id);
+    controls.count = 1;
+    controls.controls = &control;
+
+    if (IoctlLocked(VIDIOC_S_EXT_CTRLS, &controls) < 0) {
+      HAL_LOGE("S_EXT_CTRLS fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  } else {
+    v4l2_control control{control_id, desired};
+    if (IoctlLocked(VIDIOC_S_CTRL, &control) < 0) {
+      HAL_LOGE("S_CTRL fails: %s", strerror(errno));
+      return -ENODEV;
+    }
+    result_value = control.value;
+  }
+
+  // If the caller wants to know the result, pass it back.
+  if (result != nullptr) {
+    *result = result_value;
+  }
+  return 0;
+}
+
+const SupportedFormats V4L2Wrapper::GetSupportedFormats() {
+  HAL_LOG_ENTER();
+
+  SupportedFormats formats;
+  std::set<uint32_t> pixel_formats;
+
+  int res = GetFormats(&pixel_formats);
+  if (res) {
+    HAL_LOGE("Failed to get device formats.");
+    return formats;
+  }
+
+  arc::SupportedFormat supported_format;
+  std::set<std::array<int32_t, 2>> frame_sizes;
+
+  for (auto pixel_format : pixel_formats) {
+    supported_format.fourcc = pixel_format;
+
+    frame_sizes.clear();
+    res = GetFormatFrameSizes(pixel_format, &frame_sizes);
+    if (res) {
+      HAL_LOGE("Failed to get frame sizes for format: 0x%x", pixel_format);
+      continue;
+    }
+    for (auto frame_size : frame_sizes) {
+      supported_format.width = frame_size[0];
+      supported_format.height = frame_size[1];
+      formats.push_back(supported_format);
+    }
+  }
+  return formats;
+}
+
+int V4L2Wrapper::GetFormats(std::set<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+
+  v4l2_fmtdesc format_query;
+  memset(&format_query, 0, sizeof(format_query));
+  // TODO(b/30000211): multiplanar support.
+  format_query.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
+  while (IoctlLocked(VIDIOC_ENUM_FMT, &format_query) >= 0) {
+    HAL_LOGE("ENUM_FMT got at index %d with %s 0x%x [%d]", format_query.index, 
+              FormatToString(format_query.pixelformat).c_str(), 
+              format_query.pixelformat, format_query.pixelformat);
+    v4l2_formats->insert(format_query.pixelformat);
+    ++format_query.index;
+  }
+
+  if (errno != EINVAL) {
+    HAL_LOGE(
+        "ENUM_FMT fails at index %d: %s", format_query.index, strerror(errno));
+    return -ENODEV;
+  }
+  return 0;
+}
+
+int V4L2Wrapper::GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats) {
+  HAL_LOG_ENTER();
+  if (!connected()) {
+    HAL_LOGE(
+        "Device is not connected, qualified formats may not have been set.");
+    return -EINVAL;
+  }
+  v4l2_formats->clear();
+  std::set<uint32_t> unique_fourccs;
+  for (auto& format : qualified_formats_) {
+    unique_fourccs.insert(format.fourcc);
+  }
+  v4l2_formats->assign(unique_fourccs.begin(), unique_fourccs.end());
+  return 0;
+}
+
+int V4L2Wrapper::GetFormatFrameSizes(uint32_t v4l2_format,
+                                     std::set<std::array<int32_t, 2>>* sizes) {
+  v4l2_frmsizeenum size_query;
+
+  HAL_LOG_ENTER();
+  memset(&size_query, 0, sizeof(size_query));
+  size_query.pixel_format = v4l2_format;
+  if (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) < 0) {
+    HAL_LOGE("ENUM_FRAMESIZES failed at pixel_format 0x%x index 0: %s", v4l2_format, strerror(errno));
+    return -ENODEV;
+  }
+  if (size_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all sizes using VIDIOC_ENUM_FRAMESIZES.
+    // Assuming that a driver with discrete frame sizes has a reasonable number
+    // of them.
+    do {
+      sizes->insert({{{static_cast<int32_t>(size_query.discrete.width),
+                       static_cast<int32_t>(size_query.discrete.height)}}});
+      ++size_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMESIZES, &size_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMESIZES fails at index %d: %s",
+               size_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: based on the stepwise struct returned by the query.
+    // Fully listing all possible sizes, with large enough range/small enough
+    // step size, may produce far too many potential sizes. Instead, find the
+    // closest to a set of standard sizes.
+    for (const auto size : kStandardSizes) {
+      // Find the closest size, rounding up.
+      uint32_t desired_width = size[0];
+      uint32_t desired_height = size[1];
+      if (desired_width < size_query.stepwise.min_width ||
+          desired_height < size_query.stepwise.min_height) {
+        HAL_LOGE("Standard size %u x %u is too small for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      } else if (desired_width > size_query.stepwise.max_width ||
+                 desired_height > size_query.stepwise.max_height) {
+        HAL_LOGE("Standard size %u x %u is too big for format %d",
+                 desired_width,
+                 desired_height,
+                 v4l2_format);
+        continue;
+      }
+
+      // Round up.
+      uint32_t width_steps = (desired_width - size_query.stepwise.min_width +
+                              size_query.stepwise.step_width - 1) /
+                             size_query.stepwise.step_width;
+      uint32_t height_steps = (desired_height - size_query.stepwise.min_height +
+                               size_query.stepwise.step_height - 1) /
+                              size_query.stepwise.step_height;
+      sizes->insert(
+          {{{static_cast<int32_t>(size_query.stepwise.min_width +
+                                  width_steps * size_query.stepwise.step_width),
+             static_cast<int32_t>(size_query.stepwise.min_height +
+                                  height_steps *
+                                      size_query.stepwise.step_height)}}});
+    }
+  }
+  return 0;
+}
+
+// Converts a v4l2_fract with units of seconds to an int64_t with units of ns.
+inline int64_t FractToNs(const v4l2_fract& fract) {
+  return (1000000000LL * fract.numerator) / fract.denominator;
+}
+
+int V4L2Wrapper::GetFormatFrameDurationRange(
+    uint32_t v4l2_format,
+    const std::array<int32_t, 2>& size,
+    std::array<int64_t, 2>* duration_range) {
+  // Potentially called so many times logging entry is a bad idea.
+
+  v4l2_frmivalenum duration_query;
+  memset(&duration_query, 0, sizeof(duration_query));
+  duration_query.pixel_format = v4l2_format;
+  duration_query.width = size[0];
+  duration_query.height = size[1];
+  if (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) < 0) {
+    HAL_LOGE("ENUM_FRAMEINTERVALS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  int64_t min = std::numeric_limits<int64_t>::max();
+  int64_t max = std::numeric_limits<int64_t>::min();
+  if (duration_query.type == V4L2_FRMSIZE_TYPE_DISCRETE) {
+    // Discrete: enumerate all durations using VIDIOC_ENUM_FRAMEINTERVALS.
+    do {
+      min = std::min(min, FractToNs(duration_query.discrete));
+      max = std::max(max, FractToNs(duration_query.discrete));
+      ++duration_query.index;
+    } while (IoctlLocked(VIDIOC_ENUM_FRAMEINTERVALS, &duration_query) >= 0);
+    if (errno != EINVAL) {
+      HAL_LOGE("ENUM_FRAMEINTERVALS fails at index %d: %s",
+               duration_query.index,
+               strerror(errno));
+      return -ENODEV;
+    }
+  } else {
+    // Continuous/Step-wise: simply convert the given min and max.
+    min = FractToNs(duration_query.stepwise.min);
+    max = FractToNs(duration_query.stepwise.max);
+  }
+  (*duration_range)[0] = min;
+  (*duration_range)[1] = max;
+  return 0;
+}
+
+int V4L2Wrapper::SetFormat(const StreamFormat& desired_format,
+                           uint32_t* result_max_buffers) {
+  HAL_LOG_ENTER();
+
+  if (format_ && desired_format == *format_) {
+    HAL_LOGV("Already in correct format, skipping format setting.");
+    *result_max_buffers = buffers_.size();
+    return 0;
+  }
+
+  if (format_) {
+    // If we had an old format, first request 0 buffers to inform the device
+    // we're no longer using any previously "allocated" buffers from the old
+    // format. This seems like it shouldn't be necessary for USERPTR memory,
+    // and/or should happen from turning the stream off, but the driver
+    // complained. May be a driver issue, or may be intended behavior.
+    int res = RequestBuffers(0);
+    if (res) {
+      return res;
+    }
+  }
+
+  // Select the matching format, or if not available, select a qualified format
+  // we can convert from.
+  SupportedFormat format;
+  if (!StreamFormat::FindBestFitFormat(supported_formats_, qualified_formats_,
+                                       desired_format.v4l2_pixel_format(),
+                                       desired_format.width(),
+                                       desired_format.height(), &format)) {
+    HAL_LOGE(
+        "Unable to find supported resolution in list, "
+        "width: %d, height: %d",
+        desired_format.width(), desired_format.height());
+    return -EINVAL;
+  }
+
+  // Set the camera to the new format.
+  v4l2_format new_format;
+  const StreamFormat resolved_format(format);
+  resolved_format.FillFormatRequest(&new_format);
+
+  // TODO(b/29334616): When async, this will need to check if the stream
+  // is on, and if so, lock it off while setting format.
+  if (IoctlLocked(VIDIOC_S_FMT, &new_format) < 0) {
+    HAL_LOGE("S_FMT failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // Check that the driver actually set to the requested values.
+  if (resolved_format != new_format) {
+    HAL_LOGE("Device doesn't support desired stream configuration.");
+    return -EINVAL;
+  }
+
+  // Keep track of our new format.
+  format_.reset(new StreamFormat(new_format));
+
+  // Format changed, request new buffers.
+  buffer_numbers_ = android::base::GetIntProperty("camera.debug.buffers", DEFAULT_BUFFER_NUMBERS);
+  HAL_LOGI("Requesting buffers with number %d.", buffer_numbers_);
+  int res = RequestBuffers(buffer_numbers_);
+  if (res) {
+    HAL_LOGE("Requesting buffers for new format failed.");
+    return res;
+  }
+  *result_max_buffers = buffers_.size();
+  return 0;
+}
+
+int V4L2Wrapper::RequestBuffers(uint32_t num_requested) {
+  v4l2_requestbuffers req_buffers;
+
+  memset(&req_buffers, 0, sizeof(req_buffers));
+  req_buffers.type = format_->type();
+  req_buffers.memory = V4L2_MEMORY_MMAP;
+  req_buffers.count = num_requested;
+
+  int res = IoctlLocked(VIDIOC_REQBUFS, &req_buffers);
+  // Calling REQBUFS releases all queued buffers back to the user.
+  if (res < 0) {
+    HAL_LOGE("REQBUFS failed: %s", strerror(errno));
+    return -ENODEV;
+  }
+
+  // V4L2 will set req_buffers.count to a number of buffers it can handle.
+  if (num_requested > 0 && req_buffers.count < 1) {
+    HAL_LOGE("REQBUFS claims it can't handle any buffers.");
+    return -ENODEV;
+  }
+
+  HAL_LOGE("FW REQBUFS: %d kernel support: %d ", num_requested, req_buffers.count);
+
+  buffers_.resize(req_buffers.count);
+  last_index_ = -1; 
+  last_dq_index = 0;
+
+  return 0;
+}
+
+int V4L2Wrapper::get_camera_sharefd(int nCameraFd)
+{
+    if (camera_share_fd_ > 0) {
+      return camera_share_fd_;
+    }
+
+    int camera_share_fd = -1;
+    if (ioctl(nCameraFd, RFVIDEO_GET_DMABUF_FD, &camera_share_fd) != 0) {
+        HAL_LOGE("RFVIDEO_GET_DMABUF_FD: ioctl error\n");
+        camera_share_fd = -1;
+    }
+    camera_share_fd_ = camera_share_fd;
+
+    HAL_LOGD("dma buffer fd: %d", camera_share_fd_);
+    return camera_share_fd_;
+}
+
+uint64_t dq_time_end = 0;
+uint64_t q_time_start = 0;
+bool dq_success = false;
+
+void calulateTimespan() {
+  if (dq_success) {
+    uint64_t testDurationNs = q_time_start - dq_time_end;
+    HAL_LOGD("+++++++++++++++++++++++++++++Dequeue->Queue [+ %d ms]+++++++++++++++++++++++++++++", 
+      toMilliSeconds(testDurationNs));  
+
+    dq_success = false;
+  } 
+}
+
+int V4L2Wrapper::EnqueueRequest() {
+  HAL_LOG_ENTER();
+  HAL_LOGV("++++++++++++++++++++++++++++++++++++Try to QBUF++++++++++++++++++++++++++++++++++++"); 
+  int ret = 0;
+
+  uint64_t startTimeNs = timeNanos();
+  q_time_start = startTimeNs;
+  if (isDebug()) {
+    calulateTimespan();
+  }
+
+  if (!format_) {
+    HAL_LOGE("Stream format must be set before enqueuing buffers.");
+    ret = -ENODEV;
+    goto Exit;
+  }
+
+  {
+    int index = -1;
+    size_t i = 1;
+    for(i = 1; i <= buffers_.size(); i++)
+    {
+      std::lock_guard<std::mutex> guard(buffer_queue_lock_);  
+        index = (last_index_ + i) % buffers_.size();
+        if (!buffers_[index].active) {
+          last_index_ = index;
+          ret = 0;
+          HAL_LOGV("enqueue buffer at index: %d.", last_index_);
+          break;
+        }
+        else {
+          ret = -EAGAIN;
+        }
+    }
+
+    if (stream_status == 0)
+    {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+    }
+
+    if (ret == -EAGAIN) {
+        HAL_LOGD("Cannot enqueue buffer: stream is already full. wait");
+        goto Exit;
+        //// wait!
+        /*
+        std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+        buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+        */
+        goto Exit;
+    }
+
+    {
+      // Set up a v4l2 buffer struct.
+      v4l2_buffer device_buffer;
+      memset(&device_buffer, 0, sizeof(device_buffer));
+      device_buffer.type = format_->type();
+      device_buffer.index = index;
+      device_buffer.memory = V4L2_MEMORY_MMAP;
+
+      // Use QUERYBUF to ensure our buffer/device is in good shape,
+      // and fill out remaining fields.
+      if (IoctlLocked(VIDIOC_QUERYBUF, &device_buffer) < 0) {
+        HAL_LOGE("QUERYBUF fails: %s", strerror(errno));
+        // Return buffer index.
+        std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+        buffers_[index].active = false;
+        ret = -ENODEV;
+        goto Exit;
+      }
+
+      //HAL_LOGE("device_buffer.length: %d device_buffer.m.offset: %d", device_buffer.length, device_buffer.m.offset);
+      if (stream_status == 0)
+      {
+        ret = -1;
+        HAL_LOGE("Cannot enqueue buffer : stream is off");
+        goto Exit;
+      }
+
+      {
+        // Setup our request context and fill in the user pointer field.
+        RequestContext* request_context;
+        {
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context = &buffers_[index];
+          request_context->camera_buffer->SetFd(get_camera_sharefd(device_fd_));
+          request_context->camera_buffer->Map();
+
+          request_context->camera_buffer->SetDataSize(device_buffer.length);
+          request_context->camera_buffer->SetFourcc(format_->v4l2_pixel_format());
+          request_context->camera_buffer->SetWidth(format_->width());
+          request_context->camera_buffer->SetHeight(format_->height());
+          request_context->camera_buffer->SetData(request_context->camera_buffer->GetMapStart() + device_buffer.m.offset);
+          request_context->request = NULL;
+        }
+
+        // Pass the buffer to the camera.
+        if (IoctlLocked(VIDIOC_QBUF, &device_buffer) < 0) {
+          HAL_LOGE("QBUF fails: %s", strerror(errno));
+          ret = -ENODEV;
+          goto Exit;
+        }
+
+        {
+          // Mark the buffer as in flight.
+          std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+          request_context->active = true;
+        }
+      }
+    }
+  }
+
+Exit:
+  uint64_t testDurationNs = timeNanos() - startTimeNs;
+  if (!ret) {
+    if (isDebug()) {
+        HAL_LOGD("+++++++++++++++++++++++++++++QBUF index[%d] Done[+ %d ms]++++++++++++++++++++++++++++++++++",
+            last_index_,
+            toMilliSeconds(testDurationNs));
+    }
+  } else if (ret == -EAGAIN) {
+    std::unique_lock<std::mutex> guard(buffer_queue_lock_);  
+    buffer_queue_notify_.wait_for(guard, std::chrono::seconds(10));
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF AGAIN[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+  else {
+    if (isDebug()) {
+        HAL_LOGD("++++++++++++++++++++++++++++++++++++QBUF Fail[+ %d ms]++++++++++++++++++++++++++++++++++++",
+            toMilliSeconds(testDurationNs));
+    }
+  }
+
+  if (stream_status == 0)
+  {
+    std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+    for (auto& buffer : buffers_) {
+        buffer.active = false;
+    }
+  }
+
+  return ret;
+}
+
+void V4L2Wrapper::CopyBlt(void * dest, const void * src, size_t width, size_t height) {
+    size_t stride = Align64(width);
+    for(size_t r = 0; r < height; r++) {
+      for(size_t c = 0; c < width; c++) {
+          for(size_t i = 0; i < 4; i++) {
+            *((unsigned char *)dest + 4 * (r * stride + c) + i) =  *((unsigned char *)src + 4 * (r * width + c) + i);
+          }
+      }
+    }
+    HAL_LOGV("width %zu stride %zu", width, stride);
+}
+
+int V4L2Wrapper::DequeueRequest(std::shared_ptr<CaptureRequest> request) {
+  HAL_LOG_ENTER();
+  HAL_LOGV("------------------------------------Try to DQBUF------------------------------------");
+  uint64_t startTimeNs = timeNanos();
+  uint64_t ioctlTimeNs = timeNanos();
+  uint64_t convertTimeNs = 0;
+  uint64_t memcpyTimeNs = 0;
+
+  int ret = 0;
+  int res = 0;
+
+  if (!format_) {
+    HAL_LOGV(
+        "Format not set, so stream can't be on, "
+        "so no buffers available for dequeueing");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  if (!request)
+  {
+    HAL_LOGE("DequeueRequest failed, request is null");
+    ret = -EAGAIN;
+    goto Exit;
+  }
+
+  {
+    v4l2_buffer buffer;
+    memset(&buffer, 0, sizeof(buffer));
+    buffer.type = format_->type();
+    buffer.memory = V4L2_MEMORY_MMAP;
+    static int frame_count = 0;
+
+    int retry = 5;
+    while (retry > 0)
+    {
+        res = IoctlLocked(VIDIOC_DQBUF, &buffer);
+        if (res) {
+            if (errno == EAGAIN) {
+                // Expected failure.
+                retry--;
+                if (retry > 0)
+                {
+                    usleep(5*1000);
+                    continue;
+                }
+                else
+                {
+                    frame_count++;
+                    HAL_LOGE("[fps]DQBUF: %s. No aviable data. frame_count=%d", strerror(errno), frame_count);
+                    ret = -EAGAIN;
+                    //goto Exit;
+                }
+            } else {
+                // Unexpected failure.
+                HAL_LOGE("DQBUF fails: %s", strerror(errno));
+                usleep(10*1000);
+                ret = -EIO;
+                goto Exit;
+            }
+        }
+        else
+        {
+            break;
+        }
+    }
+    ioctlTimeNs = timeNanos();
+    if (ret == -EAGAIN)
+        buffer.index = last_dq_index;
+    if (stream_status == 0)
+    {
+        ret = -EIO;
+        goto Exit;
+    }
+    HAL_LOGD("VIDIOC_DQBUF got buffer index %d", buffer.index);
+
+    {
+      RequestContext* request_context = &buffers_[buffer.index];
+
+      request_context->request = request;
+      retry = 5;
+      while (!request_context->active && retry > 0)
+      {
+        buffer_queue_notify_.notify_one();
+        usleep(5*1000);
+        retry--;
+        if (retry == 0){
+            ret = -EAGAIN;
+            goto Exit;
+        }
+      }
+      if (ret == -EAGAIN)
+      {
+        buffer.length = request_context->camera_buffer->GetWidth() * request_context->camera_buffer->GetHeight() * 4;
+      }
+
+      last_dq_index = buffer.index;
+      dump_data_index = request_context->request->frame_number;
+      HAL_LOGD("Process frame %u, buffer numbers %d", dump_data_index, 
+        (uint32_t)request_context->request->output_buffers.size());
+
+      // Perform the format conversion.
+      arc::CachedFrame cached_frame;
+      uint32_t output_buffer_size = request_context->request->output_buffers.size();      
+      for(uint32_t i = 0; i < output_buffer_size; i++) {
+          HAL_LOGV("-----------------------------------------------------------");
+          HAL_LOGD("Process buffer[%d]", i);
+          if (stream_status == 0)
+          {
+            ret = -EIO;
+            goto Exit;
+          }
+          // Lock the camera stream buffer for painting.
+          const camera3_stream_buffer_t* stream_buffer = &request_context->request->output_buffers[i];
+          uint32_t fourcc = StreamFormat::HalToV4L2PixelFormat(stream_buffer->stream->format);
+          HAL_LOGD("Driver format: %s 0x%x width: %d height: %d", 
+            FormatToString(request_context->camera_buffer->GetFourcc()).c_str(),
+            request_context->camera_buffer->GetFourcc(),
+            request_context->camera_buffer->GetWidth(),
+            request_context->camera_buffer->GetHeight());
+
+          HAL_LOGD("App format: %s 0x%x width: %d height: %d", 
+            FormatToString(fourcc).c_str(), 
+            fourcc,
+            stream_buffer->stream->width,
+            stream_buffer->stream->height);
+
+          dump_data(dump_data_index, (unsigned char *)request_context->camera_buffer->GetData(), 
+                    request_context->camera_buffer->GetWidth(), request_context->camera_buffer->GetHeight(), 
+                    request_context->camera_buffer->GetFourcc(), i, "pre-used");
+
+          // Note that the device buffer length is passed to the output frame. If the
+          // GrallocFrameBuffer does not have support for the transformation to
+          // |fourcc|, it will assume that the amount of data to lock is based on
+          // |buffer.length|, otherwise it will use the ImageProcessor::ConvertedSize.   
+          arc::GrallocFrameBuffer output_frame( *stream_buffer->buffer, stream_buffer->stream->width,
+                                                stream_buffer->stream->height, fourcc, buffer.length, 
+                                                stream_buffer->stream->usage);
+
+          res = output_frame.Map();
+          if (res) {
+            HAL_LOGE("Failed to map output frame.");
+            request_context->request.reset();
+            ret = -EINVAL;
+            goto Exit;
+          }
+
+          uint64_t time = timeNanos();
+          if (request_context->camera_buffer->GetFourcc() == fourcc &&
+            request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+            request_context->camera_buffer->GetHeight() == stream_buffer->stream->height) {
+            HAL_LOGV("No need to do conversion. Copy directly");
+            #if 1            
+            // If no format conversion needs to be applied, directly copy the data over.
+            memcpy(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetDataSize());
+            #else
+            CopyBlt(output_frame.GetData(), request_context->camera_buffer->GetData(),
+                  request_context->camera_buffer->GetWidth(),
+                  request_context->camera_buffer->GetHeight());
+            #endif
+            memcpyTimeNs = timeNanos() - time;
+          } else {
+            HAL_LOGV("Need to perform the format conversion.");
+            bool can_convert_directly = (fourcc != V4L2_PIX_FMT_JPEG);
+            bool size_match = ( request_context->camera_buffer->GetWidth() == stream_buffer->stream->width &&
+                                request_context->camera_buffer->GetHeight() == stream_buffer->stream->height);
+            if (output_buffer_size == 1 && size_match && can_convert_directly){
+              arc::SimpleFrameBuffer in_frame(request_context->camera_buffer->GetData(), 
+                                              request_context->camera_buffer->GetFourcc(),
+                                              request_context->camera_buffer->GetWidth(), 
+                                              request_context->camera_buffer->GetHeight(),  
+                                              request_context->camera_buffer->GetFd(),
+                                              buffer.length);
+ 
+              cached_frame.ConvertDirectly(request_context->request->settings, in_frame, &output_frame);
+            } else {
+              if (!cached_frame.already_cached) {
+                cached_frame.SetSource(request_context->request->settings, request_context->camera_buffer.get(), 0);
+                dump_data(dump_data_index, (unsigned char *)cached_frame.yu12_frame_->GetData(), 
+                              cached_frame.yu12_frame_->GetWidth(), cached_frame.yu12_frame_->GetHeight(), 
+                              cached_frame.yu12_frame_->GetFourcc(), i, "mid");                
+              }
+              
+              cached_frame.Convert(request_context->request->settings, &output_frame, i);                                  
+            }
+
+            dump_data(dump_data_index, (unsigned char *)output_frame.GetData(), 
+                      output_frame.GetWidth(), output_frame.GetHeight(), fourcc, i, "post");                
+            convertTimeNs = timeNanos() - time;
+          }  
+ 
+      }
+
+      //EAGAIN we will not QBUF
+      if (ret == -EAGAIN) {
+        ret = 0;
+        goto Exit;
+      }
+
+      {
+        std::lock_guard<std::mutex> lock(buffer_queue_lock_);
+        request_context->request.reset();
+        // Mark the buffer as not in flight.
+        request_context->active = false;
+      }
+
+      buffer_queue_notify_.notify_one();
+    }
+  }
+
+Exit:
+  if (isDebug())
+  {
+    uint64_t testDurationNs = timeNanos() - startTimeNs;
+    if (!ret) {
+        dq_time_end = timeNanos();
+        dq_success = true;
+        //dump_data_index++;
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] index[%d] Done[+ %d ms] [ioctl:%d ms] [convert:%d ms] [memcpy:%d ms]------------------------------------",
+            dump_data_index, last_dq_index,
+            toMilliSeconds(testDurationNs), toMilliSeconds(ioctlTimeNs-startTimeNs), toMilliSeconds(convertTimeNs), toMilliSeconds(memcpyTimeNs));
+    } else {
+        HAL_LOGI("------------------------------------DQBUF FRAME[%d] Fail[+ %d ms]------------------------------------",
+            dump_data_index,
+            toMilliSeconds(testDurationNs));
+    }
+}
+  if (!ret) {
+    ShowPreviewFPS();
+  }
+
+  return ret;
+}
+
+int V4L2Wrapper::GetInFlightBufferCount() {
+  int count = 0;
+  std::lock_guard<std::mutex> guard(buffer_queue_lock_);
+  for (auto& buffer : buffers_) {
+    if (buffer.active) {
+      count++;
+    }
+  }
+  return count;
+}
+
+}  // namespace v4l2_camera_hal
diff --git a/hardware/ntimespace/camera/v4l2_wrapper.h b/hardware/ntimespace/camera/v4l2_wrapper.h
new file mode 100644
index 0000000000..a500ef81fc
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper.h
@@ -0,0 +1,187 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+#ifndef V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
+#define V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
+
+#include <array>
+#include <memory>
+#include <mutex>
+#include <set>
+#include <string>
+#include <vector>
+
+#include <android-base/unique_fd.h>
+#include "arc/common_types.h"
+#include "arc/frame_buffer.h"
+#include "capture_request.h"
+#include "common.h"
+#include "stream_format.h"
+
+namespace v4l2_camera_hal {
+
+#define DEFAULT_BUFFER_NUMBERS 2
+
+class V4L2Wrapper {
+ public:
+  // Use this method to create V4L2Wrapper objects. Functionally equivalent
+  // to "new V4L2Wrapper", except that it may return nullptr in case of failure.
+  static V4L2Wrapper* NewV4L2Wrapper(const std::string device_path, int camera_id);
+  virtual ~V4L2Wrapper();
+
+  // Helper class to ensure all opened connections are closed.
+  class Connection {
+   public:
+    Connection(std::shared_ptr<V4L2Wrapper> device)
+        : device_(std::move(device)), connect_result_(device_->Connect()) {}
+    ~Connection() {
+      if (connect_result_ == 0) {
+        device_->Disconnect();
+      }
+    }
+    // Check whether the connection succeeded or not.
+    inline int status() const { return connect_result_; }
+
+   private:
+    std::shared_ptr<V4L2Wrapper> device_;
+    const int connect_result_;
+  };
+
+  // Turn the stream on or off.
+  virtual int StreamOn();
+  virtual int StreamOff();
+  // Manage controls.
+  virtual int QueryControl(uint32_t control_id, v4l2_query_ext_ctrl* result);
+  virtual int GetControl(uint32_t control_id, int32_t* value);
+  virtual int SetControl(uint32_t control_id,
+                         int32_t desired,
+                         int32_t* result = nullptr);
+  // Manage format.
+  virtual int GetFormats(std::set<uint32_t>* v4l2_formats);
+  virtual int GetQualifiedFormats(std::vector<uint32_t>* v4l2_formats);
+  virtual int GetFormatFrameSizes(uint32_t v4l2_format,
+                                  std::set<std::array<int32_t, 2>>* sizes);
+
+  // Durations are returned in ns.
+  virtual int GetFormatFrameDurationRange(
+      uint32_t v4l2_format,
+      const std::array<int32_t, 2>& size,
+      std::array<int64_t, 2>* duration_range);
+  virtual int SetFormat(const StreamFormat& desired_format,
+                        uint32_t* result_max_buffers);
+  // Manage buffers.
+  virtual int EnqueueRequest();
+  virtual int DequeueRequest(
+      std::shared_ptr<default_camera_hal::CaptureRequest> request);
+  virtual int GetInFlightBufferCount();
+
+  int get_fd() {return device_fd_;}
+  int get_camera_sharefd();
+  int get_stream_status() {return stream_status;}
+
+  inline std::string FormatToString(int32_t format);
+  void CopyBlt(void * dest, const void * src, size_t width, size_t height);
+  
+ private:
+  // Constructor is private to allow failing on bad input.
+  // Use NewV4L2Wrapper instead.
+  V4L2Wrapper(const std::string device_path, int camera_id);
+
+  // Connect or disconnect to the device. Access by creating/destroying
+  // a V4L2Wrapper::Connection object.
+  int Connect();
+  void Disconnect();
+  // Perform an ioctl call in a thread-safe fashion.
+  template <typename T>
+  int IoctlLocked(unsigned long request, T data);
+  // Request/release userspace buffer mode via VIDIOC_REQBUFS.
+  int RequestBuffers(uint32_t num_buffers);
+
+  inline bool connected() { return device_fd_.get() >= 0; }
+
+  // Format management.
+  const arc::SupportedFormats GetSupportedFormats();
+
+  // The camera device path. For example, /dev/video0.
+  const std::string device_path_;
+  int camera_id_;
+  // The opened device fd.
+  android::base::unique_fd device_fd_;
+
+  //dma buffer fd
+  int camera_share_fd_;
+  int ion_fd_;
+  
+  // The underlying gralloc module.
+  // std::unique_ptr<V4L2Gralloc> gralloc_;
+  // Whether or not the device supports the extended control query.
+  bool extended_query_supported_;
+  // The format this device is set up for.
+  std::unique_ptr<StreamFormat> format_;
+  // Lock protecting use of the buffer tracker.
+  std::mutex buffer_queue_lock_;
+  std::condition_variable buffer_queue_notify_;
+
+  // Lock protecting use of the device.
+  std::mutex device_lock_;
+  // Lock protecting connecting/disconnecting the device.
+  std::mutex connection_lock_;
+  // Reference count connections.
+  int connection_count_;
+  // Supported formats.
+  arc::SupportedFormats supported_formats_;
+  // Qualified formats.
+  arc::SupportedFormats qualified_formats_;
+
+  class RequestContext {
+   public:
+    RequestContext()
+        : active(false),
+          camera_buffer(std::make_shared<arc::V4L2FrameBuffer>()){};
+    ~RequestContext(){};
+    // Indicates whether this request context is in use.
+    bool active;
+    // Buffer handles of the context.
+    std::shared_ptr<arc::V4L2FrameBuffer> camera_buffer;
+    std::shared_ptr<default_camera_hal::CaptureRequest> request;
+  };
+
+  // Map of in flight requests.
+  // |buffers_.size()| will always be the maximum number of buffers this device
+  // can handle in its current format.
+  std::vector<RequestContext> buffers_;
+  int last_index_;
+  int last_dq_index;
+  int stream_status;
+  int buffer_numbers_ = DEFAULT_BUFFER_NUMBERS;
+
+  friend class Connection;
+  friend class V4L2WrapperMock;
+
+  DISALLOW_COPY_AND_ASSIGN(V4L2Wrapper);
+};
+
+#define V4L2LOOPBACK_CID_BASE (V4L2_CID_USER_BASE | 0xf000)
+#define CID_KEEP_FORMAT (V4L2LOOPBACK_CID_BASE + 0)
+#define CID_SUSTAIN_FRAMERATE (V4L2LOOPBACK_CID_BASE + 1)
+#define CID_TIMEOUT (V4L2LOOPBACK_CID_BASE + 2)
+#define CID_TIMEOUT_IMAGE_IO (V4L2LOOPBACK_CID_BASE + 3)
+#define CID_SET_FACING  (V4L2LOOPBACK_CID_BASE + 4)
+#define CID_GET_DMABUF_FD (V4L2LOOPBACK_CID_BASE + 5)
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_WRAPPER_H_
diff --git a/hardware/ntimespace/camera/v4l2_wrapper_mock.h b/hardware/ntimespace/camera/v4l2_wrapper_mock.h
new file mode 100644
index 0000000000..1e4d3ad5fa
--- /dev/null
+++ b/hardware/ntimespace/camera/v4l2_wrapper_mock.h
@@ -0,0 +1,56 @@
+/*
+ * Copyright (C) 2016 The Android Open Source Project
+ *
+ * Licensed under the Apache License, Version 2.0 (the "License");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// Mock for wrapper class used to communicate with V4L2 devices.
+
+#ifndef V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
+#define V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
+
+#include "v4l2_wrapper.h"
+
+#include <gmock/gmock.h>
+
+namespace v4l2_camera_hal {
+
+class V4L2WrapperMock : public V4L2Wrapper {
+ public:
+  V4L2WrapperMock() : V4L2Wrapper(""){};
+  MOCK_METHOD0(StreamOn, int());
+  MOCK_METHOD0(StreamOff, int());
+  MOCK_METHOD2(QueryControl,
+               int(uint32_t control_id, v4l2_query_ext_ctrl* result));
+  MOCK_METHOD2(GetControl, int(uint32_t control_id, int32_t* value));
+  MOCK_METHOD3(SetControl,
+               int(uint32_t control_id, int32_t desired, int32_t* result));
+  MOCK_METHOD1(GetFormats, int(std::set<uint32_t>*));
+  MOCK_METHOD1(GetQualifiedFormats, int(std::vector<uint32_t>*));
+  MOCK_METHOD2(GetFormatFrameSizes,
+               int(uint32_t, std::set<std::array<int32_t, 2>>*));
+  MOCK_METHOD3(GetFormatFrameDurationRange,
+               int(uint32_t,
+                   const std::array<int32_t, 2>&,
+                   std::array<int64_t, 2>*));
+  MOCK_METHOD2(SetFormat, int(const StreamFormat& desired_format,
+                              uint32_t* result_max_buffers));
+  MOCK_METHOD2(EnqueueBuffer,
+               int(const camera3_stream_buffer_t* camera_buffer,
+                   uint32_t* enqueued_index));
+  MOCK_METHOD1(DequeueBuffer, int(uint32_t* dequeued_index));
+};
+
+}  // namespace v4l2_camera_hal
+
+#endif  // V4L2_CAMERA_HAL_V4L2_WRAPPER_MOCK_H_
-- 
2.25.1

